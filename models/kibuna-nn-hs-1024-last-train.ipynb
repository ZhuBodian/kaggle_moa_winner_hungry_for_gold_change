{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.067626,
     "end_time": "2020-11-26T05:19:44.582813",
     "exception": false,
     "start_time": "2020-11-26T05:19:44.515187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- a notebook to save preprocessing model and train/save NN models\n",
    "- all necessary ouputs are stored in MODEL_DIR = output/kaggle/working/model\n",
    "    - put those into dataset, and load it from inference notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:19:44.738720Z",
     "iopub.status.busy": "2020-11-26T05:19:44.737831Z",
     "iopub.status.idle": "2020-11-26T05:19:51.950919Z",
     "shell.execute_reply": "2020-11-26T05:19:51.950264Z"
    },
    "papermill": {
     "duration": 7.302337,
     "end_time": "2020-11-26T05:19:51.951067",
     "exception": false,
     "start_time": "2020-11-26T05:19:44.648730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "sys.path.append('../input/umaplearn/umap')\n",
    "\n",
    "%mkdir model\n",
    "%mkdir interim\n",
    "\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from umap import UMAP\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA,FactorAnalysis\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "print(torch.cuda.is_available())\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:19:52.101444Z",
     "iopub.status.busy": "2020-11-26T05:19:52.100472Z",
     "iopub.status.idle": "2020-11-26T05:19:52.104231Z",
     "shell.execute_reply": "2020-11-26T05:19:52.104811Z"
    },
    "papermill": {
     "duration": 0.086709,
     "end_time": "2020-11-26T05:19:52.104956",
     "exception": false,
     "start_time": "2020-11-26T05:19:52.018247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:19:52.251927Z",
     "iopub.status.busy": "2020-11-26T05:19:52.250122Z",
     "iopub.status.idle": "2020-11-26T05:19:52.252715Z",
     "shell.execute_reply": "2020-11-26T05:19:52.253450Z"
    },
    "papermill": {
     "duration": 0.080754,
     "end_time": "2020-11-26T05:19:52.253626",
     "exception": false,
     "start_time": "2020-11-26T05:19:52.172872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NB = '25'\n",
    "\n",
    "IS_TRAIN = True\n",
    "MODEL_DIR = \"model\" # \"../model\"\n",
    "INT_DIR = \"interim\" # \"../interim\"\n",
    "\n",
    "NSEEDS = 5  # 5\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 5e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "NFOLDS = 5  # 5\n",
    "\n",
    "PMIN = 0.0005\n",
    "PMAX = 0.9995\n",
    "SMIN = 0.0\n",
    "SMAX = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:19:52.407694Z",
     "iopub.status.busy": "2020-11-26T05:19:52.406698Z",
     "iopub.status.idle": "2020-11-26T05:19:59.744804Z",
     "shell.execute_reply": "2020-11-26T05:19:59.745992Z"
    },
    "papermill": {
     "duration": 7.421184,
     "end_time": "2020-11-26T05:19:59.746193",
     "exception": false,
     "start_time": "2020-11-26T05:19:52.325009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "sample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:19:59.938437Z",
     "iopub.status.busy": "2020-11-26T05:19:59.937312Z",
     "iopub.status.idle": "2020-11-26T05:20:00.170944Z",
     "shell.execute_reply": "2020-11-26T05:20:00.170023Z"
    },
    "papermill": {
     "duration": 0.323437,
     "end_time": "2020-11-26T05:20:00.171132",
     "exception": false,
     "start_time": "2020-11-26T05:19:59.847695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 332)\n"
     ]
    }
   ],
   "source": [
    "train_targets_nonscored = train_targets_nonscored.loc[:, train_targets_nonscored.sum() != 0]\n",
    "print(train_targets_nonscored.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:20:00.324626Z",
     "iopub.status.busy": "2020-11-26T05:20:00.323031Z",
     "iopub.status.idle": "2020-11-26T05:20:03.381176Z",
     "shell.execute_reply": "2020-11-26T05:20:03.380576Z"
    },
    "papermill": {
     "duration": 3.138803,
     "end_time": "2020-11-26T05:20:03.381302",
     "exception": false,
     "start_time": "2020-11-26T05:20:00.242499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for c in train_targets_scored.columns:\n",
    "#     if c != \"sig_id\":\n",
    "#         train_targets_scored[c] = np.maximum(PMIN, np.minimum(PMAX, train_targets_scored[c]))\n",
    "for c in train_targets_nonscored.columns:\n",
    "    if c != \"sig_id\":\n",
    "        train_targets_nonscored[c] = np.maximum(PMIN, np.minimum(PMAX, train_targets_nonscored[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:20:03.525039Z",
     "iopub.status.busy": "2020-11-26T05:20:03.524000Z",
     "iopub.status.idle": "2020-11-26T05:20:03.529649Z",
     "shell.execute_reply": "2020-11-26T05:20:03.530565Z"
    },
    "papermill": {
     "duration": 0.08113,
     "end_time": "2020-11-26T05:20:03.530748",
     "exception": false,
     "start_time": "2020-11-26T05:20:03.449618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(nsamples, nfeatures)\n",
      "(23814, 876)\n",
      "(23814, 207)\n",
      "(23814, 332)\n",
      "(3982, 876)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(\"(nsamples, nfeatures)\")\n",
    "print(train_features.shape)\n",
    "print(train_targets_scored.shape)\n",
    "print(train_targets_nonscored.shape)\n",
    "print(test_features.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:20:03.693208Z",
     "iopub.status.busy": "2020-11-26T05:20:03.691544Z",
     "iopub.status.idle": "2020-11-26T05:20:03.693990Z",
     "shell.execute_reply": "2020-11-26T05:20:03.694557Z"
    },
    "papermill": {
     "duration": 0.095073,
     "end_time": "2020-11-26T05:20:03.694695",
     "exception": false,
     "start_time": "2020-11-26T05:20:03.599622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:20:03.842346Z",
     "iopub.status.busy": "2020-11-26T05:20:03.841456Z",
     "iopub.status.idle": "2020-11-26T05:20:03.848296Z",
     "shell.execute_reply": "2020-11-26T05:20:03.847675Z"
    },
    "papermill": {
     "duration": 0.084307,
     "end_time": "2020-11-26T05:20:03.848444",
     "exception": false,
     "start_time": "2020-11-26T05:20:03.764137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=1903):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=1903)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.068841,
     "end_time": "2020-11-26T05:20:03.986247",
     "exception": false,
     "start_time": "2020-11-26T05:20:03.917406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:20:04.156515Z",
     "iopub.status.busy": "2020-11-26T05:20:04.149606Z",
     "iopub.status.idle": "2020-11-26T05:25:57.500817Z",
     "shell.execute_reply": "2020-11-26T05:25:57.500054Z"
    },
    "papermill": {
     "duration": 353.445244,
     "end_time": "2020-11-26T05:25:57.500960",
     "exception": false,
     "start_time": "2020-11-26T05:20:04.055716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GENES\n",
    "n_comp = 90\n",
    "n_dim = 45\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "\n",
    "if IS_TRAIN:\n",
    "    fa = FactorAnalysis(n_components=n_comp, random_state=1903).fit(data[GENES])\n",
    "    pd.to_pickle(fa, f'{MODEL_DIR}/{NB}_factor_analysis_g.pkl')\n",
    "    umap = UMAP(n_components=n_dim, random_state=1903).fit(data[GENES])\n",
    "    pd.to_pickle(umap, f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "else:\n",
    "    fa = pd.read_pickle(f'{MODEL_DIR}/{NB}_factor_analysis_g.pkl')\n",
    "    umap = pd.read_pickle(f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "\n",
    "data2 = (fa.transform(data[GENES]))\n",
    "data3 = (umap.transform(data[GENES]))\n",
    "\n",
    "train2 = data2[:train_features.shape[0]]\n",
    "test2 = data2[-test_features.shape[0]:]\n",
    "train3 = data3[:train_features.shape[0]]\n",
    "test3 = data3[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'fa_G-{i}' for i in range(n_comp)])\n",
    "train3 = pd.DataFrame(train3, columns=[f'umap_G-{i}' for i in range(n_dim)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'fa_G-{i}' for i in range(n_comp)])\n",
    "test3 = pd.DataFrame(test3, columns=[f'umap_G-{i}' for i in range(n_dim)])\n",
    "\n",
    "train_features = pd.concat((train_features, train2, train3), axis=1)\n",
    "test_features = pd.concat((test_features, test2, test3), axis=1)\n",
    "\n",
    "#CELLS\n",
    "n_comp = 50\n",
    "n_dim = 25\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "\n",
    "if IS_TRAIN:\n",
    "    fa = FactorAnalysis(n_components=n_comp, random_state=1903).fit(data[CELLS])\n",
    "    pd.to_pickle(fa, f'{MODEL_DIR}/{NB}_factor_analysis_c.pkl')\n",
    "    umap = UMAP(n_components=n_dim, random_state=1903).fit(data[CELLS])\n",
    "    pd.to_pickle(umap, f'{MODEL_DIR}/{NB}_umap_c.pkl')\n",
    "else:\n",
    "    fa = pd.read_pickle(f'{MODEL_DIR}/{NB}_factor_analysis_c.pkl')\n",
    "    umap = pd.read_pickle(f'{MODEL_DIR}/{NB}_umap_c.pkl')\n",
    "    \n",
    "data2 = (fa.transform(data[CELLS]))\n",
    "data3 = (umap.fit_transform(data[CELLS]))\n",
    "\n",
    "train2 = data2[:train_features.shape[0]]\n",
    "test2 = data2[-test_features.shape[0]:]\n",
    "train3 = data3[:train_features.shape[0]]\n",
    "test3 = data3[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'fa_C-{i}' for i in range(n_comp)])\n",
    "train3 = pd.DataFrame(train3, columns=[f'umap_C-{i}' for i in range(n_dim)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'fa_C-{i}' for i in range(n_comp)])\n",
    "test3 = pd.DataFrame(test3, columns=[f'umap_C-{i}' for i in range(n_dim)])\n",
    "\n",
    "train_features = pd.concat((train_features, train2, train3), axis=1)\n",
    "test_features = pd.concat((test_features, test2, test3), axis=1)\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.069099,
     "end_time": "2020-11-26T05:25:57.639838",
     "exception": false,
     "start_time": "2020-11-26T05:25:57.570739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:25:57.794066Z",
     "iopub.status.busy": "2020-11-26T05:25:57.792303Z",
     "iopub.status.idle": "2020-11-26T05:28:04.035606Z",
     "shell.execute_reply": "2020-11-26T05:28:04.034723Z"
    },
    "papermill": {
     "duration": 126.326427,
     "end_time": "2020-11-26T05:28:04.035817",
     "exception": false,
     "start_time": "2020-11-26T05:25:57.709390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "for col in (GENES + CELLS):\n",
    "    vec_len = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    raw_vec = pd.concat([train_features, test_features])[col].values.reshape(vec_len+vec_len_test, 1)\n",
    "    if IS_TRAIN:\n",
    "        transformer = QuantileTransformer(n_quantiles=100, random_state=123, output_distribution=\"normal\")\n",
    "        transformer.fit(raw_vec)\n",
    "        pd.to_pickle(transformer, f'{MODEL_DIR}/{NB}_{col}_quantile_transformer.pkl')\n",
    "    else:\n",
    "        transformer = pd.read_pickle(f'{MODEL_DIR}/{NB}_{col}_quantile_transformer.pkl')        \n",
    "\n",
    "    train_features[col] = transformer.transform(train_features[col].values.reshape(vec_len, 1)).reshape(1, vec_len)[0]\n",
    "    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:04.258054Z",
     "iopub.status.busy": "2020-11-26T05:28:04.255783Z",
     "iopub.status.idle": "2020-11-26T05:28:04.258942Z",
     "shell.execute_reply": "2020-11-26T05:28:04.259587Z"
    },
    "papermill": {
     "duration": 0.097692,
     "end_time": "2020-11-26T05:28:04.259739",
     "exception": false,
     "start_time": "2020-11-26T05:28:04.162047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PCAS = [col for col in train_features.columns if col.startswith('pca_')]\n",
    "# UMAPS = [col for col in train_features.columns if col.startswith('umap_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:04.414926Z",
     "iopub.status.busy": "2020-11-26T05:28:04.413073Z",
     "iopub.status.idle": "2020-11-26T05:28:04.416399Z",
     "shell.execute_reply": "2020-11-26T05:28:04.415725Z"
    },
    "papermill": {
     "duration": 0.083039,
     "end_time": "2020-11-26T05:28:04.416541",
     "exception": false,
     "start_time": "2020-11-26T05:28:04.333502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# n_deg = 2\n",
    "\n",
    "# data = pd.concat([pd.DataFrame(train_features[PCAS]), pd.DataFrame(test_features[PCAS])])\n",
    "# data2 = (PolynomialFeatures(degree=n_deg, include_bias=False).fit_transform(data[PCAS]))\n",
    "\n",
    "# # print(data2)\n",
    "# # data4 = (UMAP(n_components=n_dim, n_neighbors=5, random_state=1903).fit_transform(data[GENES]))\n",
    "# # data5 = (UMAP(n_components=n_dim, min_dist=0.01, random_state=1903).fit_transform(data[GENES]))\n",
    "\n",
    "# train2 = data2[:train_features.shape[0]]\n",
    "# test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "# # print(train2.shape)\n",
    "# train2 = pd.DataFrame(train2, columns=[f'poly_C-{i}' for i in range(train2.shape[1])])\n",
    "# test2 = pd.DataFrame(test2, columns=[f'poly_C-{i}' for i in range(train2.shape[1])])\n",
    "\n",
    "# # drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "# # train_features = pd.concat((train_features, train2, train3, train4, train5), axis=1)\n",
    "# # test_features = pd.concat((test_features, test2, test3, test4, test5), axis=1)\n",
    "# train_features = pd.concat((train_features, train2), axis=1)\n",
    "# test_features = pd.concat((test_features, test2), axis=1)\n",
    "\n",
    "\n",
    "# data = pd.concat([pd.DataFrame(train_features[UMAPS]), pd.DataFrame(test_features[UMAPS])])\n",
    "# data2 = (PolynomialFeatures(degree=n_deg, include_bias=False).fit_transform(data[UMAPS]))\n",
    "\n",
    "# # print(data2)\n",
    "# # data4 = (UMAP(n_components=n_dim, n_neighbors=5, random_state=1903).fit_transform(data[GENES]))\n",
    "# # data5 = (UMAP(n_components=n_dim, min_dist=0.01, random_state=1903).fit_transform(data[GENES]))\n",
    "\n",
    "# train2 = data2[:train_features.shape[0]]\n",
    "# test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "# # print(train2.shape)\n",
    "# train2 = pd.DataFrame(train2, columns=[f'poly_C-{i}' for i in range(train2.shape[1])])\n",
    "# test2 = pd.DataFrame(test2, columns=[f'poly_C-{i}' for i in range(train2.shape[1])])\n",
    "\n",
    "# # drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "# # train_features = pd.concat((train_features, train2, train3, train4, train5), axis=1)\n",
    "# # test_features = pd.concat((test_features, test2, test3, test4, test5), axis=1)\n",
    "# train_features = pd.concat((train_features, train2), axis=1)\n",
    "# test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:04.567693Z",
     "iopub.status.busy": "2020-11-26T05:28:04.566780Z",
     "iopub.status.idle": "2020-11-26T05:28:04.572411Z",
     "shell.execute_reply": "2020-11-26T05:28:04.573173Z"
    },
    "papermill": {
     "duration": 0.08439,
     "end_time": "2020-11-26T05:28:04.573375",
     "exception": false,
     "start_time": "2020-11-26T05:28:04.488985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 1086)\n",
      "(3982, 1086)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.074064,
     "end_time": "2020-11-26T05:28:04.721137",
     "exception": false,
     "start_time": "2020-11-26T05:28:04.647073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:04.877100Z",
     "iopub.status.busy": "2020-11-26T05:28:04.876180Z",
     "iopub.status.idle": "2020-11-26T05:28:05.570681Z",
     "shell.execute_reply": "2020-11-26T05:28:05.569763Z"
    },
    "papermill": {
     "duration": 0.775547,
     "end_time": "2020-11-26T05:28:05.570816",
     "exception": false,
     "start_time": "2020-11-26T05:28:04.795269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train_features.merge(train_targets_nonscored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "# target = train[train_targets_scored.columns]\n",
    "target = train[train_targets_nonscored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:05.803722Z",
     "iopub.status.busy": "2020-11-26T05:28:05.801418Z",
     "iopub.status.idle": "2020-11-26T05:28:05.812425Z",
     "shell.execute_reply": "2020-11-26T05:28:05.811744Z"
    },
    "papermill": {
     "duration": 0.168252,
     "end_time": "2020-11-26T05:28:05.812611",
     "exception": false,
     "start_time": "2020-11-26T05:28:05.644359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:05.970687Z",
     "iopub.status.busy": "2020-11-26T05:28:05.969358Z",
     "iopub.status.idle": "2020-11-26T05:28:05.973575Z",
     "shell.execute_reply": "2020-11-26T05:28:05.971394Z"
    },
    "papermill": {
     "duration": 0.087631,
     "end_time": "2020-11-26T05:28:05.973759",
     "exception": false,
     "start_time": "2020-11-26T05:28:05.886128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 332)\n",
      "(23814, 1086)\n",
      "(3982, 1086)\n",
      "(21948, 1416)\n",
      "(3624, 1085)\n"
     ]
    }
   ],
   "source": [
    "print(target.shape)\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:06.147024Z",
     "iopub.status.busy": "2020-11-26T05:28:06.145261Z",
     "iopub.status.idle": "2020-11-26T05:28:06.155218Z",
     "shell.execute_reply": "2020-11-26T05:28:06.156257Z"
    },
    "papermill": {
     "duration": 0.107011,
     "end_time": "2020-11-26T05:28:06.156496",
     "exception": false,
     "start_time": "2020-11-26T05:28:06.049485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:06.333485Z",
     "iopub.status.busy": "2020-11-26T05:28:06.331832Z",
     "iopub.status.idle": "2020-11-26T05:28:09.268803Z",
     "shell.execute_reply": "2020-11-26T05:28:09.269468Z"
    },
    "papermill": {
     "duration": 3.030392,
     "end_time": "2020-11-26T05:28:09.269668",
     "exception": false,
     "start_time": "2020-11-26T05:28:06.239276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=False, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>...</th>\n",
       "      <th>vasopressin_receptor_antagonist</th>\n",
       "      <th>ve-cadherin_antagonist</th>\n",
       "      <th>vesicular_monoamine_transporter_inhibitor</th>\n",
       "      <th>vitamin_k_antagonist</th>\n",
       "      <th>voltage-gated_potassium_channel_activator</th>\n",
       "      <th>voltage-gated_sodium_channel_blocker</th>\n",
       "      <th>wdr5_mll_interaction_inhibitor</th>\n",
       "      <th>xanthine_oxidase_inhibitor</th>\n",
       "      <th>xiap_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.146806</td>\n",
       "      <td>0.902075</td>\n",
       "      <td>-0.418339</td>\n",
       "      <td>-0.961202</td>\n",
       "      <td>-0.254770</td>\n",
       "      <td>-1.021300</td>\n",
       "      <td>-1.369236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.128824</td>\n",
       "      <td>0.676862</td>\n",
       "      <td>0.274345</td>\n",
       "      <td>0.090495</td>\n",
       "      <td>1.208863</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>0.316734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.790372</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>1.428097</td>\n",
       "      <td>-0.121817</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>1.495091</td>\n",
       "      <td>0.238763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.729866</td>\n",
       "      <td>-0.277163</td>\n",
       "      <td>-0.441200</td>\n",
       "      <td>0.766612</td>\n",
       "      <td>2.347817</td>\n",
       "      <td>-0.862761</td>\n",
       "      <td>-2.308829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.444558</td>\n",
       "      <td>-0.481202</td>\n",
       "      <td>0.974729</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>1.468304</td>\n",
       "      <td>-0.874772</td>\n",
       "      <td>-0.372682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.247623</td>\n",
       "      <td>-1.231184</td>\n",
       "      <td>0.221572</td>\n",
       "      <td>-0.354096</td>\n",
       "      <td>-0.332073</td>\n",
       "      <td>0.570635</td>\n",
       "      <td>-0.150125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.217613</td>\n",
       "      <td>-0.027031</td>\n",
       "      <td>-0.237430</td>\n",
       "      <td>-0.787215</td>\n",
       "      <td>-0.677817</td>\n",
       "      <td>0.919474</td>\n",
       "      <td>0.742866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.914666</td>\n",
       "      <td>0.581880</td>\n",
       "      <td>-0.588706</td>\n",
       "      <td>1.303439</td>\n",
       "      <td>-1.009079</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>-0.302814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.826302</td>\n",
       "      <td>0.411235</td>\n",
       "      <td>0.433297</td>\n",
       "      <td>0.307575</td>\n",
       "      <td>1.075324</td>\n",
       "      <td>-0.024425</td>\n",
       "      <td>0.051483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.245739</td>\n",
       "      <td>1.567230</td>\n",
       "      <td>-0.269829</td>\n",
       "      <td>1.092958</td>\n",
       "      <td>-0.515819</td>\n",
       "      <td>-2.091765</td>\n",
       "      <td>-1.627645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1417 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  cp_time cp_dose       g-0       g-1       g-2       g-3  \\\n",
       "0      id_000644bb2       24      D1  1.146806  0.902075 -0.418339 -0.961202   \n",
       "1      id_000779bfc       72      D1  0.128824  0.676862  0.274345  0.090495   \n",
       "2      id_000a6266a       48      D1  0.790372  0.939951  1.428097 -0.121817   \n",
       "3      id_0015fd391       48      D1 -0.729866 -0.277163 -0.441200  0.766612   \n",
       "4      id_001626bd3       72      D2 -0.444558 -0.481202  0.974729  0.977467   \n",
       "...             ...      ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444       72      D1  0.247623 -1.231184  0.221572 -0.354096   \n",
       "21944  id_fffb1ceed       24      D2  0.217613 -0.027031 -0.237430 -0.787215   \n",
       "21945  id_fffb70c0c       24      D2 -1.914666  0.581880 -0.588706  1.303439   \n",
       "21946  id_fffcb9e7c       24      D1  0.826302  0.411235  0.433297  0.307575   \n",
       "21947  id_ffffdd77b       72      D1 -1.245739  1.567230 -0.269829  1.092958   \n",
       "\n",
       "            g-4       g-5       g-6  ...  vasopressin_receptor_antagonist  \\\n",
       "0     -0.254770 -1.021300 -1.369236  ...                           0.0005   \n",
       "1      1.208863  0.688965  0.316734  ...                           0.0005   \n",
       "2     -0.002067  1.495091  0.238763  ...                           0.0005   \n",
       "3      2.347817 -0.862761 -2.308829  ...                           0.0005   \n",
       "4      1.468304 -0.874772 -0.372682  ...                           0.0005   \n",
       "...         ...       ...       ...  ...                              ...   \n",
       "21943 -0.332073  0.570635 -0.150125  ...                           0.0005   \n",
       "21944 -0.677817  0.919474  0.742866  ...                           0.0005   \n",
       "21945 -1.009079  0.852202 -0.302814  ...                           0.0005   \n",
       "21946  1.075324 -0.024425  0.051483  ...                           0.0005   \n",
       "21947 -0.515819 -2.091765 -1.627645  ...                           0.0005   \n",
       "\n",
       "       ve-cadherin_antagonist  vesicular_monoamine_transporter_inhibitor  \\\n",
       "0                      0.0005                                     0.0005   \n",
       "1                      0.0005                                     0.0005   \n",
       "2                      0.0005                                     0.0005   \n",
       "3                      0.0005                                     0.0005   \n",
       "4                      0.0005                                     0.0005   \n",
       "...                       ...                                        ...   \n",
       "21943                  0.0005                                     0.0005   \n",
       "21944                  0.0005                                     0.0005   \n",
       "21945                  0.0005                                     0.0005   \n",
       "21946                  0.0005                                     0.0005   \n",
       "21947                  0.0005                                     0.0005   \n",
       "\n",
       "       vitamin_k_antagonist  voltage-gated_potassium_channel_activator  \\\n",
       "0                    0.0005                                     0.0005   \n",
       "1                    0.0005                                     0.0005   \n",
       "2                    0.0005                                     0.0005   \n",
       "3                    0.0005                                     0.0005   \n",
       "4                    0.0005                                     0.0005   \n",
       "...                     ...                                        ...   \n",
       "21943                0.0005                                     0.0005   \n",
       "21944                0.0005                                     0.0005   \n",
       "21945                0.0005                                     0.0005   \n",
       "21946                0.0005                                     0.0005   \n",
       "21947                0.0005                                     0.0005   \n",
       "\n",
       "       voltage-gated_sodium_channel_blocker  wdr5_mll_interaction_inhibitor  \\\n",
       "0                                    0.0005                          0.0005   \n",
       "1                                    0.0005                          0.0005   \n",
       "2                                    0.0005                          0.0005   \n",
       "3                                    0.0005                          0.0005   \n",
       "4                                    0.0005                          0.0005   \n",
       "...                                     ...                             ...   \n",
       "21943                                0.0005                          0.0005   \n",
       "21944                                0.0005                          0.0005   \n",
       "21945                                0.0005                          0.0005   \n",
       "21946                                0.0005                          0.0005   \n",
       "21947                                0.0005                          0.0005   \n",
       "\n",
       "       xanthine_oxidase_inhibitor  xiap_inhibitor  kfold  \n",
       "0                          0.0005          0.0005      0  \n",
       "1                          0.0005          0.0005      3  \n",
       "2                          0.0005          0.0005      4  \n",
       "3                          0.0005          0.0005      2  \n",
       "4                          0.0005          0.0005      1  \n",
       "...                           ...             ...    ...  \n",
       "21943                      0.0005          0.0005      0  \n",
       "21944                      0.0005          0.0005      2  \n",
       "21945                      0.0005          0.0005      0  \n",
       "21946                      0.0005          0.0005      3  \n",
       "21947                      0.0005          0.0005      1  \n",
       "\n",
       "[21948 rows x 1417 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=NFOLDS)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:09.433877Z",
     "iopub.status.busy": "2020-11-26T05:28:09.432883Z",
     "iopub.status.idle": "2020-11-26T05:28:09.442544Z",
     "shell.execute_reply": "2020-11-26T05:28:09.443132Z"
    },
    "papermill": {
     "duration": 0.091037,
     "end_time": "2020-11-26T05:28:09.443294",
     "exception": false,
     "start_time": "2020-11-26T05:28:09.352257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1416)\n",
      "(21948, 1417)\n",
      "(3624, 1085)\n",
      "(21948, 332)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:09.606553Z",
     "iopub.status.busy": "2020-11-26T05:28:09.604376Z",
     "iopub.status.idle": "2020-11-26T05:28:09.607372Z",
     "shell.execute_reply": "2020-11-26T05:28:09.608114Z"
    },
    "papermill": {
     "duration": 0.091446,
     "end_time": "2020-11-26T05:28:09.608267",
     "exception": false,
     "start_time": "2020-11-26T05:28:09.516821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:09.775708Z",
     "iopub.status.busy": "2020-11-26T05:28:09.774627Z",
     "iopub.status.idle": "2020-11-26T05:28:09.777291Z",
     "shell.execute_reply": "2020-11-26T05:28:09.777884Z"
    },
    "papermill": {
     "duration": 0.095633,
     "end_time": "2020-11-26T05:28:09.778024",
     "exception": false,
     "start_time": "2020-11-26T05:28:09.682391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:09.942018Z",
     "iopub.status.busy": "2020-11-26T05:28:09.940914Z",
     "iopub.status.idle": "2020-11-26T05:28:09.943651Z",
     "shell.execute_reply": "2020-11-26T05:28:09.944337Z"
    },
    "papermill": {
     "duration": 0.092238,
     "end_time": "2020-11-26T05:28:09.944483",
     "exception": false,
     "start_time": "2020-11-26T05:28:09.852245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(0.15)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.dense2 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.leaky_relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.leaky_relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:10.323279Z",
     "iopub.status.busy": "2020-11-26T05:28:10.319718Z",
     "iopub.status.idle": "2020-11-26T05:28:10.324499Z",
     "shell.execute_reply": "2020-11-26T05:28:10.325376Z"
    },
    "papermill": {
     "duration": 0.125648,
     "end_time": "2020-11-26T05:28:10.325587",
     "exception": false,
     "start_time": "2020-11-26T05:28:10.199939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    \n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "#     data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "#     data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "\n",
    "# --------------------- Normalize ---------------------\n",
    "#     for col in GENES:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#     for col in CELLS:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#--------------------- Removing Skewness ---------------------\n",
    "#     for col in GENES + CELLS:\n",
    "#         if(abs(data[col].skew()) > 0.75):\n",
    "            \n",
    "#             if(data[col].skew() < 0): # neg-skewness\n",
    "#                 data[col] = data[col].max() - data[col] + 1\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "            \n",
    "#             else:\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:10.553740Z",
     "iopub.status.busy": "2020-11-26T05:28:10.552692Z",
     "iopub.status.idle": "2020-11-26T05:28:10.738373Z",
     "shell.execute_reply": "2020-11-26T05:28:10.739650Z"
    },
    "papermill": {
     "duration": 0.307386,
     "end_time": "2020-11-26T05:28:10.739875",
     "exception": false,
     "start_time": "2020-11-26T05:28:10.432489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1087"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:10.934351Z",
     "iopub.status.busy": "2020-11-26T05:28:10.933270Z",
     "iopub.status.idle": "2020-11-26T05:28:10.935958Z",
     "shell.execute_reply": "2020-11-26T05:28:10.936601Z"
    },
    "papermill": {
     "duration": 0.083777,
     "end_time": "2020-11-26T05:28:10.936745",
     "exception": false,
     "start_time": "2020-11-26T05:28:10.852968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=2048\n",
    "# hidden_size=4096\n",
    "# hidden_size=9192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:11.122808Z",
     "iopub.status.busy": "2020-11-26T05:28:11.121666Z",
     "iopub.status.idle": "2020-11-26T05:28:11.151735Z",
     "shell.execute_reply": "2020-11-26T05:28:11.151016Z"
    },
    "papermill": {
     "duration": 0.139806,
     "end_time": "2020-11-26T05:28:11.151872",
     "exception": false,
     "start_time": "2020-11-26T05:28:11.012066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.2, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler,loss_fn,trainloader, DEVICE)\n",
    "        print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"SEED: {seed} ,FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"model/{NB}-nonscored1-SEED{seed}-FOLD{fold}_.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"model/{NB}-nonscored1-SEED{seed}-FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:11.321952Z",
     "iopub.status.busy": "2020-11-26T05:28:11.321040Z",
     "iopub.status.idle": "2020-11-26T05:28:11.325097Z",
     "shell.execute_reply": "2020-11-26T05:28:11.325648Z"
    },
    "papermill": {
     "duration": 0.087906,
     "end_time": "2020-11-26T05:28:11.325803",
     "exception": false,
     "start_time": "2020-11-26T05:28:11.237897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:11.489483Z",
     "iopub.status.busy": "2020-11-26T05:28:11.487773Z",
     "iopub.status.idle": "2020-11-26T05:39:54.203525Z",
     "shell.execute_reply": "2020-11-26T05:39:54.204298Z"
    },
    "papermill": {
     "duration": 702.8027,
     "end_time": "2020-11-26T05:39:54.204518",
     "exception": false,
     "start_time": "2020-11-26T05:28:11.401818",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 940, FOLD: 0, EPOCH: 0, train_loss: 0.6479452919700871\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 0, valid_loss: 0.24815115415387684\n",
      "SEED: 940, FOLD: 0, EPOCH: 1, train_loss: 0.03601686417570581\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 1, valid_loss: 0.009409155800110765\n",
      "SEED: 940, FOLD: 0, EPOCH: 2, train_loss: 0.00938437124579281\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 2, valid_loss: 0.009297710274242692\n",
      "SEED: 940, FOLD: 0, EPOCH: 3, train_loss: 0.00926585112819853\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 3, valid_loss: 0.009222983330902126\n",
      "SEED: 940, FOLD: 0, EPOCH: 4, train_loss: 0.009361455783895824\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 4, valid_loss: 0.009119504545297887\n",
      "SEED: 940, FOLD: 0, EPOCH: 5, train_loss: 0.008960283104924189\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 5, valid_loss: 0.009035923569980595\n",
      "SEED: 940, FOLD: 0, EPOCH: 6, train_loss: 0.008879928458212078\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 6, valid_loss: 0.00893180077481601\n",
      "SEED: 940, FOLD: 0, EPOCH: 7, train_loss: 0.008805801126889992\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 7, valid_loss: 0.008888928892297877\n",
      "SEED: 940, FOLD: 0, EPOCH: 8, train_loss: 0.00872872815048997\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 8, valid_loss: 0.008849300185425414\n",
      "SEED: 940, FOLD: 0, EPOCH: 9, train_loss: 0.008650014851836191\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 9, valid_loss: 0.008837969663242498\n",
      "SEED: 940, FOLD: 0, EPOCH: 10, train_loss: 0.00855469350716558\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 10, valid_loss: 0.008769922475847933\n",
      "SEED: 940, FOLD: 0, EPOCH: 11, train_loss: 0.008444556379285843\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 11, valid_loss: 0.008736687531280849\n",
      "SEED: 940, FOLD: 0, EPOCH: 12, train_loss: 0.008288515009579884\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 12, valid_loss: 0.008676534906650582\n",
      "SEED: 940, FOLD: 0, EPOCH: 13, train_loss: 0.008133495152266561\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 13, valid_loss: 0.008654582029622462\n",
      "SEED: 940, FOLD: 0, EPOCH: 14, train_loss: 0.00802860893579065\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 14, valid_loss: 0.008650324074551463\n",
      "SEED: 940, FOLD: 1, EPOCH: 0, train_loss: 0.6481047968069712\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 0, valid_loss: 0.22750751343038347\n",
      "SEED: 940, FOLD: 1, EPOCH: 1, train_loss: 0.03621251578780188\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 1, valid_loss: 0.009526962983525462\n",
      "SEED: 940, FOLD: 1, EPOCH: 2, train_loss: 0.009484993185901987\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 2, valid_loss: 0.009144279174506664\n",
      "SEED: 940, FOLD: 1, EPOCH: 3, train_loss: 0.00930332904006692\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 3, valid_loss: 0.009277336040718688\n",
      "SEED: 940, FOLD: 1, EPOCH: 4, train_loss: 0.00992369472278633\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 4, valid_loss: 0.009641483322613768\n",
      "SEED: 940, FOLD: 1, EPOCH: 5, train_loss: 0.009228087462268877\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 5, valid_loss: 0.009080360436605083\n",
      "SEED: 940, FOLD: 1, EPOCH: 6, train_loss: 0.008920111079308866\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 6, valid_loss: 0.008992866871671544\n",
      "SEED: 940, FOLD: 1, EPOCH: 7, train_loss: 0.00883085920434931\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 7, valid_loss: 0.00894027922509445\n",
      "SEED: 940, FOLD: 1, EPOCH: 8, train_loss: 0.008732899355337671\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 8, valid_loss: 0.008934536327918371\n",
      "SEED: 940, FOLD: 1, EPOCH: 9, train_loss: 0.008684237764311441\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 9, valid_loss: 0.008944058118181096\n",
      "SEED: 940, FOLD: 1, EPOCH: 10, train_loss: 0.008595652878284454\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 10, valid_loss: 0.008823490028993951\n",
      "SEED: 940, FOLD: 1, EPOCH: 11, train_loss: 0.008471249110078898\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 11, valid_loss: 0.008785120108061366\n",
      "SEED: 940, FOLD: 1, EPOCH: 12, train_loss: 0.008322693002612694\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 12, valid_loss: 0.008724242138365904\n",
      "SEED: 940, FOLD: 1, EPOCH: 13, train_loss: 0.008178993863849968\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 13, valid_loss: 0.00871231308620837\n",
      "SEED: 940, FOLD: 1, EPOCH: 14, train_loss: 0.008074986552684635\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 14, valid_loss: 0.008713971875194047\n",
      "SEED: 940, FOLD: 2, EPOCH: 0, train_loss: 0.6476552767166193\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 0, valid_loss: 0.2391093514031834\n",
      "SEED: 940, FOLD: 2, EPOCH: 1, train_loss: 0.03567143706469864\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 1, valid_loss: 0.009501696667737432\n",
      "SEED: 940, FOLD: 2, EPOCH: 2, train_loss: 0.009374644026916096\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 2, valid_loss: 0.009278588669581546\n",
      "SEED: 940, FOLD: 2, EPOCH: 3, train_loss: 0.009194319595353327\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 3, valid_loss: 0.009202176549782356\n",
      "SEED: 940, FOLD: 2, EPOCH: 4, train_loss: 0.0091544722031424\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 4, valid_loss: 0.009139060508459806\n",
      "SEED: 940, FOLD: 2, EPOCH: 5, train_loss: 0.009089890692005123\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 5, valid_loss: 0.009232863111214505\n",
      "SEED: 940, FOLD: 2, EPOCH: 6, train_loss: 0.008877110944224009\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 6, valid_loss: 0.008977774737609757\n",
      "SEED: 940, FOLD: 2, EPOCH: 7, train_loss: 0.008788896744827862\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 7, valid_loss: 0.008957378902576037\n",
      "SEED: 940, FOLD: 2, EPOCH: 8, train_loss: 0.008726262514465961\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 8, valid_loss: 0.008985651501764854\n",
      "SEED: 940, FOLD: 2, EPOCH: 9, train_loss: 0.008672773460115211\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 9, valid_loss: 0.008860636761205064\n",
      "SEED: 940, FOLD: 2, EPOCH: 10, train_loss: 0.00854982973575808\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 10, valid_loss: 0.008830411256187491\n",
      "SEED: 940, FOLD: 2, EPOCH: 11, train_loss: 0.008442559603439726\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 11, valid_loss: 0.00885070643077294\n",
      "SEED: 940, FOLD: 2, EPOCH: 12, train_loss: 0.008282772839015377\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 12, valid_loss: 0.008757195021543238\n",
      "SEED: 940, FOLD: 2, EPOCH: 13, train_loss: 0.008150506110025057\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 13, valid_loss: 0.008736526283125082\n",
      "SEED: 940, FOLD: 2, EPOCH: 14, train_loss: 0.00806427133553054\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 14, valid_loss: 0.00872081538869275\n",
      "SEED: 940, FOLD: 3, EPOCH: 0, train_loss: 0.6470525815435078\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 0, valid_loss: 0.21908627450466156\n",
      "SEED: 940, FOLD: 3, EPOCH: 1, train_loss: 0.03547701223388962\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 1, valid_loss: 0.00956433778628707\n",
      "SEED: 940, FOLD: 3, EPOCH: 2, train_loss: 0.009300034965617933\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 2, valid_loss: 0.009573929891404178\n",
      "SEED: 940, FOLD: 3, EPOCH: 3, train_loss: 0.00929043882701924\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 3, valid_loss: 0.009350199304107163\n",
      "SEED: 940, FOLD: 3, EPOCH: 4, train_loss: 0.009052487198209417\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 4, valid_loss: 0.009207550694959031\n",
      "SEED: 940, FOLD: 3, EPOCH: 5, train_loss: 0.00889577180741058\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 5, valid_loss: 0.009529094263497326\n",
      "SEED: 940, FOLD: 3, EPOCH: 6, train_loss: 0.008836803127728079\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 6, valid_loss: 0.009176967562072806\n",
      "SEED: 940, FOLD: 3, EPOCH: 7, train_loss: 0.008741770209609598\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 7, valid_loss: 0.009053937625139952\n",
      "SEED: 940, FOLD: 3, EPOCH: 8, train_loss: 0.008664722513893375\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 8, valid_loss: 0.009063190521879328\n",
      "SEED: 940, FOLD: 3, EPOCH: 9, train_loss: 0.008602280169725418\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 9, valid_loss: 0.009003502316772938\n",
      "SEED: 940, FOLD: 3, EPOCH: 10, train_loss: 0.008511024594738863\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 10, valid_loss: 0.008964003322439061\n",
      "SEED: 940, FOLD: 3, EPOCH: 11, train_loss: 0.00838385185604726\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 11, valid_loss: 0.008901761223872503\n",
      "SEED: 940, FOLD: 3, EPOCH: 12, train_loss: 0.008242213646408873\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 12, valid_loss: 0.008873731467045017\n",
      "SEED: 940, FOLD: 3, EPOCH: 13, train_loss: 0.008083580635434044\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 13, valid_loss: 0.008848790648496814\n",
      "SEED: 940, FOLD: 3, EPOCH: 14, train_loss: 0.007975364556077166\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 14, valid_loss: 0.008846815675497055\n",
      "SEED: 940, FOLD: 4, EPOCH: 0, train_loss: 0.6485805355984232\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 0, valid_loss: 0.2561669995387395\n",
      "SEED: 940, FOLD: 4, EPOCH: 1, train_loss: 0.03616090726269328\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 1, valid_loss: 0.00910649024364021\n",
      "SEED: 940, FOLD: 4, EPOCH: 2, train_loss: 0.00947043755888075\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 2, valid_loss: 0.008798883684600392\n",
      "SEED: 940, FOLD: 4, EPOCH: 3, train_loss: 0.009332120567020298\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 3, valid_loss: 0.008799060377188854\n",
      "SEED: 940, FOLD: 4, EPOCH: 4, train_loss: 0.00920977431308964\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 4, valid_loss: 0.008729589326928059\n",
      "SEED: 940, FOLD: 4, EPOCH: 5, train_loss: 0.009189862832157076\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 5, valid_loss: 0.008706050355815224\n",
      "SEED: 940, FOLD: 4, EPOCH: 6, train_loss: 0.008950526907068232\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 6, valid_loss: 0.00873595398540298\n",
      "SEED: 940, FOLD: 4, EPOCH: 7, train_loss: 0.008879613171777\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 7, valid_loss: 0.0085600387925903\n",
      "SEED: 940, FOLD: 4, EPOCH: 8, train_loss: 0.008803143800384756\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 8, valid_loss: 0.008473385746280352\n",
      "SEED: 940, FOLD: 4, EPOCH: 9, train_loss: 0.008721719725408417\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 9, valid_loss: 0.008563570704104172\n",
      "SEED: 940, FOLD: 4, EPOCH: 10, train_loss: 0.008616556062538555\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 10, valid_loss: 0.008406926438005434\n",
      "SEED: 940, FOLD: 4, EPOCH: 11, train_loss: 0.008501153864452372\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 11, valid_loss: 0.008374120160523389\n",
      "SEED: 940, FOLD: 4, EPOCH: 12, train_loss: 0.008372347370006037\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 12, valid_loss: 0.00834378933844467\n",
      "SEED: 940, FOLD: 4, EPOCH: 13, train_loss: 0.00821859558261391\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 13, valid_loss: 0.008323356612688966\n",
      "SEED: 940, FOLD: 4, EPOCH: 14, train_loss: 0.008120562361580307\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 14, valid_loss: 0.008316016264466776\n",
      "elapsed time: 120.98117852210999\n",
      "SEED: 1513, FOLD: 0, EPOCH: 0, train_loss: 0.6471398429594178\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 0, valid_loss: 0.21855431463983324\n",
      "SEED: 1513, FOLD: 0, EPOCH: 1, train_loss: 0.03592875580964745\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 1, valid_loss: 0.009389103131575717\n",
      "SEED: 1513, FOLD: 0, EPOCH: 2, train_loss: 0.009380360248674086\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 2, valid_loss: 0.00912922067153785\n",
      "SEED: 1513, FOLD: 0, EPOCH: 3, train_loss: 0.009287848933667376\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 3, valid_loss: 0.011522684246301651\n",
      "SEED: 1513, FOLD: 0, EPOCH: 4, train_loss: 0.009196833106756641\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 4, valid_loss: 0.00908099440857768\n",
      "SEED: 1513, FOLD: 0, EPOCH: 5, train_loss: 0.009104790031046106\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 5, valid_loss: 0.008999679341084428\n",
      "SEED: 1513, FOLD: 0, EPOCH: 6, train_loss: 0.00888931602779506\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 6, valid_loss: 0.008966385024703212\n",
      "SEED: 1513, FOLD: 0, EPOCH: 7, train_loss: 0.008781142100907755\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 7, valid_loss: 0.008889529491878219\n",
      "SEED: 1513, FOLD: 0, EPOCH: 8, train_loss: 0.008730766815605803\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 8, valid_loss: 0.00887580014144381\n",
      "SEED: 1513, FOLD: 0, EPOCH: 9, train_loss: 0.008642787228513887\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 9, valid_loss: 0.008830584352836013\n",
      "SEED: 1513, FOLD: 0, EPOCH: 10, train_loss: 0.008575098427093548\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 10, valid_loss: 0.008802348618499108\n",
      "SEED: 1513, FOLD: 0, EPOCH: 11, train_loss: 0.008442016534399296\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 11, valid_loss: 0.00873800809495151\n",
      "SEED: 1513, FOLD: 0, EPOCH: 12, train_loss: 0.00830806456371278\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 12, valid_loss: 0.008685814966965053\n",
      "SEED: 1513, FOLD: 0, EPOCH: 13, train_loss: 0.008146629020895647\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 13, valid_loss: 0.00867870069729785\n",
      "SEED: 1513, FOLD: 0, EPOCH: 14, train_loss: 0.008065892113507658\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 14, valid_loss: 0.008669727688862218\n",
      "SEED: 1513, FOLD: 1, EPOCH: 0, train_loss: 0.6470911880766136\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 0, valid_loss: 0.23212208102146784\n",
      "SEED: 1513, FOLD: 1, EPOCH: 1, train_loss: 0.03570161232103904\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 1, valid_loss: 0.00939673138782382\n",
      "SEED: 1513, FOLD: 1, EPOCH: 2, train_loss: 0.009389859894155592\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 2, valid_loss: 0.009138675303094916\n",
      "SEED: 1513, FOLD: 1, EPOCH: 3, train_loss: 0.009208564066152641\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 3, valid_loss: 0.009176103346463706\n",
      "SEED: 1513, FOLD: 1, EPOCH: 4, train_loss: 0.009092665668846905\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 4, valid_loss: 0.009111315218938721\n",
      "SEED: 1513, FOLD: 1, EPOCH: 5, train_loss: 0.008977139719586441\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 5, valid_loss: 0.009026889223605394\n",
      "SEED: 1513, FOLD: 1, EPOCH: 6, train_loss: 0.00902508007551449\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 6, valid_loss: 0.008996630190975137\n",
      "SEED: 1513, FOLD: 1, EPOCH: 7, train_loss: 0.00880547455660459\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 7, valid_loss: 0.00895607600816422\n",
      "SEED: 1513, FOLD: 1, EPOCH: 8, train_loss: 0.008742013534504002\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 8, valid_loss: 0.009028113033208583\n",
      "SEED: 1513, FOLD: 1, EPOCH: 9, train_loss: 0.008671231547613506\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 9, valid_loss: 0.008883919411649307\n",
      "SEED: 1513, FOLD: 1, EPOCH: 10, train_loss: 0.008588485095811926\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 10, valid_loss: 0.008798766363826063\n",
      "SEED: 1513, FOLD: 1, EPOCH: 11, train_loss: 0.008454902306792961\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 11, valid_loss: 0.00878548575565219\n",
      "SEED: 1513, FOLD: 1, EPOCH: 12, train_loss: 0.008330594289346018\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 12, valid_loss: 0.008714097552001476\n",
      "SEED: 1513, FOLD: 1, EPOCH: 13, train_loss: 0.008163138920360285\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 13, valid_loss: 0.00870011110479633\n",
      "SEED: 1513, FOLD: 1, EPOCH: 14, train_loss: 0.008080822543875463\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 14, valid_loss: 0.00869488607471188\n",
      "SEED: 1513, FOLD: 2, EPOCH: 0, train_loss: 0.6480281586232393\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 0, valid_loss: 0.24418040282196468\n",
      "SEED: 1513, FOLD: 2, EPOCH: 1, train_loss: 0.03640578746579695\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 1, valid_loss: 0.00939860629538695\n",
      "SEED: 1513, FOLD: 2, EPOCH: 2, train_loss: 0.009365880052032679\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 2, valid_loss: 0.009207448249475824\n",
      "SEED: 1513, FOLD: 2, EPOCH: 3, train_loss: 0.009308561777183111\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 3, valid_loss: 0.012740010033465095\n",
      "SEED: 1513, FOLD: 2, EPOCH: 4, train_loss: 0.00989065109414683\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 4, valid_loss: 0.009399091876629326\n",
      "SEED: 1513, FOLD: 2, EPOCH: 5, train_loss: 0.009089428769505543\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 5, valid_loss: 0.009132926817983389\n",
      "SEED: 1513, FOLD: 2, EPOCH: 6, train_loss: 0.008964037084007177\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 6, valid_loss: 0.009058299189847376\n",
      "SEED: 1513, FOLD: 2, EPOCH: 7, train_loss: 0.008854078371887621\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 7, valid_loss: 0.00899226143438783\n",
      "SEED: 1513, FOLD: 2, EPOCH: 8, train_loss: 0.008785995283582504\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 8, valid_loss: 0.00896749886063238\n",
      "SEED: 1513, FOLD: 2, EPOCH: 9, train_loss: 0.008702718436825966\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 9, valid_loss: 0.008894622274157073\n",
      "SEED: 1513, FOLD: 2, EPOCH: 10, train_loss: 0.008596685620537703\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 10, valid_loss: 0.008889587699539132\n",
      "SEED: 1513, FOLD: 2, EPOCH: 11, train_loss: 0.008455734747205523\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 11, valid_loss: 0.008794582759340605\n",
      "SEED: 1513, FOLD: 2, EPOCH: 12, train_loss: 0.008290037931199524\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 12, valid_loss: 0.008751739877172642\n",
      "SEED: 1513, FOLD: 2, EPOCH: 13, train_loss: 0.008122110719104176\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 13, valid_loss: 0.008722684553100003\n",
      "SEED: 1513, FOLD: 2, EPOCH: 14, train_loss: 0.008016582416451496\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 14, valid_loss: 0.008718691041900052\n",
      "SEED: 1513, FOLD: 3, EPOCH: 0, train_loss: 0.6468942215045294\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 0, valid_loss: 0.22094014204210705\n",
      "SEED: 1513, FOLD: 3, EPOCH: 1, train_loss: 0.03543817130443842\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 1, valid_loss: 0.009528066600776382\n",
      "SEED: 1513, FOLD: 3, EPOCH: 2, train_loss: 0.009391284250802752\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 2, valid_loss: 0.009325914447092347\n",
      "SEED: 1513, FOLD: 3, EPOCH: 3, train_loss: 0.009239137280678404\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 3, valid_loss: 0.010254389451195797\n",
      "SEED: 1513, FOLD: 3, EPOCH: 4, train_loss: 0.009214977808026732\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 4, valid_loss: 0.009245413665970167\n",
      "SEED: 1513, FOLD: 3, EPOCH: 5, train_loss: 0.008977296694681265\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 5, valid_loss: 0.009906898770067427\n",
      "SEED: 1513, FOLD: 3, EPOCH: 6, train_loss: 0.008890510320771431\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 6, valid_loss: 0.009115317681183418\n",
      "SEED: 1513, FOLD: 3, EPOCH: 7, train_loss: 0.008751287570466166\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 7, valid_loss: 0.009065173876782259\n",
      "SEED: 1513, FOLD: 3, EPOCH: 8, train_loss: 0.008706741217199875\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 8, valid_loss: 0.009088528083844317\n",
      "SEED: 1513, FOLD: 3, EPOCH: 9, train_loss: 0.008613831228644087\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 9, valid_loss: 0.008989049432178339\n",
      "SEED: 1513, FOLD: 3, EPOCH: 10, train_loss: 0.008530791909636362\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 10, valid_loss: 0.008930890820920467\n",
      "SEED: 1513, FOLD: 3, EPOCH: 11, train_loss: 0.008394304379496885\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 11, valid_loss: 0.008892467400679985\n",
      "SEED: 1513, FOLD: 3, EPOCH: 12, train_loss: 0.008258751391068749\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 12, valid_loss: 0.008840130279875465\n",
      "SEED: 1513, FOLD: 3, EPOCH: 13, train_loss: 0.008100422740360533\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 13, valid_loss: 0.008835609588358138\n",
      "SEED: 1513, FOLD: 3, EPOCH: 14, train_loss: 0.008020113863428865\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 14, valid_loss: 0.008823316233853499\n",
      "SEED: 1513, FOLD: 4, EPOCH: 0, train_loss: 0.6473575189061787\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 0, valid_loss: 0.22716956751214135\n",
      "SEED: 1513, FOLD: 4, EPOCH: 1, train_loss: 0.03594946253882802\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 1, valid_loss: 0.009032847670217356\n",
      "SEED: 1513, FOLD: 4, EPOCH: 2, train_loss: 0.009417876061322033\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 2, valid_loss: 0.0087780328726189\n",
      "SEED: 1513, FOLD: 4, EPOCH: 3, train_loss: 0.009342989492891491\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 3, valid_loss: 0.008987712104701333\n",
      "SEED: 1513, FOLD: 4, EPOCH: 4, train_loss: 0.009178939950314985\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 4, valid_loss: 0.008716261842184596\n",
      "SEED: 1513, FOLD: 4, EPOCH: 5, train_loss: 0.009075949710888275\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 5, valid_loss: 0.008672225573617551\n",
      "SEED: 1513, FOLD: 4, EPOCH: 6, train_loss: 0.008915418678003809\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 6, valid_loss: 0.008627705198402206\n",
      "SEED: 1513, FOLD: 4, EPOCH: 7, train_loss: 0.008849917337352383\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 7, valid_loss: 0.00855990781241821\n",
      "SEED: 1513, FOLD: 4, EPOCH: 8, train_loss: 0.008784337104230688\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 8, valid_loss: 0.008524011898164948\n",
      "SEED: 1513, FOLD: 4, EPOCH: 9, train_loss: 0.00869331364452407\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 9, valid_loss: 0.00847458603998853\n",
      "SEED: 1513, FOLD: 4, EPOCH: 10, train_loss: 0.008615483118194168\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 10, valid_loss: 0.008391573766453398\n",
      "SEED: 1513, FOLD: 4, EPOCH: 11, train_loss: 0.00848184049507414\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 11, valid_loss: 0.008378786397063069\n",
      "SEED: 1513, FOLD: 4, EPOCH: 12, train_loss: 0.00832775986307989\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 12, valid_loss: 0.008325903624710109\n",
      "SEED: 1513, FOLD: 4, EPOCH: 13, train_loss: 0.00816498244640188\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 13, valid_loss: 0.008314175789968835\n",
      "SEED: 1513, FOLD: 4, EPOCH: 14, train_loss: 0.008073139321598886\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 14, valid_loss: 0.008305041352286935\n",
      "elapsed time: 236.13528180122375\n",
      "SEED: 1269, FOLD: 0, EPOCH: 0, train_loss: 0.6463643040346063\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 0, valid_loss: 0.21208193401495615\n",
      "SEED: 1269, FOLD: 0, EPOCH: 1, train_loss: 0.03627315564485996\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 1, valid_loss: 0.00953590606028835\n",
      "SEED: 1269, FOLD: 0, EPOCH: 2, train_loss: 0.00948861136060694\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 2, valid_loss: 0.009131904950158464\n",
      "SEED: 1269, FOLD: 0, EPOCH: 3, train_loss: 0.009254335898204126\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 3, valid_loss: 0.009226715761340328\n",
      "SEED: 1269, FOLD: 0, EPOCH: 4, train_loss: 0.010129632401293602\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 4, valid_loss: 0.009259688667953014\n",
      "SEED: 1269, FOLD: 0, EPOCH: 5, train_loss: 0.009133960417323355\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 5, valid_loss: 0.009024228900671005\n",
      "SEED: 1269, FOLD: 0, EPOCH: 6, train_loss: 0.00893429227416282\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 6, valid_loss: 0.008968823227203555\n",
      "SEED: 1269, FOLD: 0, EPOCH: 7, train_loss: 0.008870823092866634\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 7, valid_loss: 0.008927519691901075\n",
      "SEED: 1269, FOLD: 0, EPOCH: 8, train_loss: 0.008822376529375711\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 8, valid_loss: 0.008910851501342323\n",
      "SEED: 1269, FOLD: 0, EPOCH: 9, train_loss: 0.008722010891938555\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 9, valid_loss: 0.008822450750610895\n",
      "SEED: 1269, FOLD: 0, EPOCH: 10, train_loss: 0.008612313894959896\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 10, valid_loss: 0.008799096776379479\n",
      "SEED: 1269, FOLD: 0, EPOCH: 11, train_loss: 0.008502049817015295\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 11, valid_loss: 0.008768340520974662\n",
      "SEED: 1269, FOLD: 0, EPOCH: 12, train_loss: 0.00833474972244838\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 12, valid_loss: 0.008716439052174488\n",
      "SEED: 1269, FOLD: 0, EPOCH: 13, train_loss: 0.008189990529385597\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 13, valid_loss: 0.0087050323943711\n",
      "SEED: 1269, FOLD: 0, EPOCH: 14, train_loss: 0.00808591789741447\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 14, valid_loss: 0.008706038093401326\n",
      "SEED: 1269, FOLD: 1, EPOCH: 0, train_loss: 0.6455479512612025\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 0, valid_loss: 0.21480770823028353\n",
      "SEED: 1269, FOLD: 1, EPOCH: 1, train_loss: 0.0360388829899223\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 1, valid_loss: 0.009418973906172646\n",
      "SEED: 1269, FOLD: 1, EPOCH: 2, train_loss: 0.009388917935607225\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 2, valid_loss: 0.009143680075390471\n",
      "SEED: 1269, FOLD: 1, EPOCH: 3, train_loss: 0.009264822144979153\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 3, valid_loss: 0.009154485538601875\n",
      "SEED: 1269, FOLD: 1, EPOCH: 4, train_loss: 0.009142423062112884\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 4, valid_loss: 0.009118194484876262\n",
      "SEED: 1269, FOLD: 1, EPOCH: 5, train_loss: 0.008970950689652691\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 5, valid_loss: 0.009024959264530076\n",
      "SEED: 1269, FOLD: 1, EPOCH: 6, train_loss: 0.008907779848769955\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 6, valid_loss: 0.009043263530151712\n",
      "SEED: 1269, FOLD: 1, EPOCH: 7, train_loss: 0.008806708727733812\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 7, valid_loss: 0.008932809397164319\n",
      "SEED: 1269, FOLD: 1, EPOCH: 8, train_loss: 0.008737762337145598\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 8, valid_loss: 0.008946429627637068\n",
      "SEED: 1269, FOLD: 1, EPOCH: 9, train_loss: 0.008621178250219942\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 9, valid_loss: 0.008880194328311417\n",
      "SEED: 1269, FOLD: 1, EPOCH: 10, train_loss: 0.008531109119455019\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 10, valid_loss: 0.008814009423885081\n",
      "SEED: 1269, FOLD: 1, EPOCH: 11, train_loss: 0.008409847842826359\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 11, valid_loss: 0.008753207926121023\n",
      "SEED: 1269, FOLD: 1, EPOCH: 12, train_loss: 0.008248792340358099\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 12, valid_loss: 0.008720022471000751\n",
      "SEED: 1269, FOLD: 1, EPOCH: 13, train_loss: 0.008081052546807821\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 13, valid_loss: 0.008691566582355235\n",
      "SEED: 1269, FOLD: 1, EPOCH: 14, train_loss: 0.007993317911050457\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 14, valid_loss: 0.00868345114092032\n",
      "SEED: 1269, FOLD: 2, EPOCH: 0, train_loss: 0.6474622876747794\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 0, valid_loss: 0.2428416982293129\n",
      "SEED: 1269, FOLD: 2, EPOCH: 1, train_loss: 0.03679691468351993\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 1, valid_loss: 0.009371718029595084\n",
      "SEED: 1269, FOLD: 2, EPOCH: 2, train_loss: 0.009346648888743442\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 2, valid_loss: 0.009285762440413237\n",
      "SEED: 1269, FOLD: 2, EPOCH: 3, train_loss: 0.009212502453854118\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 3, valid_loss: 0.009280864304552475\n",
      "SEED: 1269, FOLD: 2, EPOCH: 4, train_loss: 0.009127286681230518\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 4, valid_loss: 0.00922701833769679\n",
      "SEED: 1269, FOLD: 2, EPOCH: 5, train_loss: 0.009015823498476242\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 5, valid_loss: 0.009147977146009604\n",
      "SEED: 1269, FOLD: 2, EPOCH: 6, train_loss: 0.008880716539325489\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 6, valid_loss: 0.009019523859024048\n",
      "SEED: 1269, FOLD: 2, EPOCH: 7, train_loss: 0.008805837745413832\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 7, valid_loss: 0.008951132418587804\n",
      "SEED: 1269, FOLD: 2, EPOCH: 8, train_loss: 0.008699216076807268\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 8, valid_loss: 0.009005459905084636\n",
      "SEED: 1269, FOLD: 2, EPOCH: 9, train_loss: 0.00864925064092529\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 9, valid_loss: 0.008848311146721244\n",
      "SEED: 1269, FOLD: 2, EPOCH: 10, train_loss: 0.008544262093694313\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 10, valid_loss: 0.008820299783514606\n",
      "SEED: 1269, FOLD: 2, EPOCH: 11, train_loss: 0.008438508033050575\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 11, valid_loss: 0.00881819592581855\n",
      "SEED: 1269, FOLD: 2, EPOCH: 12, train_loss: 0.008282079219656147\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 12, valid_loss: 0.008731052538173066\n",
      "SEED: 1269, FOLD: 2, EPOCH: 13, train_loss: 0.008122930195236551\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 13, valid_loss: 0.008717622452725967\n",
      "SEED: 1269, FOLD: 2, EPOCH: 14, train_loss: 0.008036809635982998\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 14, valid_loss: 0.008706864098914795\n",
      "SEED: 1269, FOLD: 3, EPOCH: 0, train_loss: 0.6456047711165055\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 0, valid_loss: 0.20226807395617166\n",
      "SEED: 1269, FOLD: 3, EPOCH: 1, train_loss: 0.03578500089276096\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 1, valid_loss: 0.009588178557654222\n",
      "SEED: 1269, FOLD: 3, EPOCH: 2, train_loss: 0.009459169001143047\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 2, valid_loss: 0.009307988039735291\n",
      "SEED: 1269, FOLD: 3, EPOCH: 3, train_loss: 0.009301710333945095\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 3, valid_loss: 0.00971426995885041\n",
      "SEED: 1269, FOLD: 3, EPOCH: 4, train_loss: 0.009281126876780088\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 4, valid_loss: 0.009256122995995812\n",
      "SEED: 1269, FOLD: 3, EPOCH: 5, train_loss: 0.008967084783142891\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 5, valid_loss: 0.009222695190045569\n",
      "SEED: 1269, FOLD: 3, EPOCH: 6, train_loss: 0.008831725185871988\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 6, valid_loss: 0.009198428649041388\n",
      "SEED: 1269, FOLD: 3, EPOCH: 7, train_loss: 0.008767344867405684\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 7, valid_loss: 0.009108175109657977\n",
      "SEED: 1269, FOLD: 3, EPOCH: 8, train_loss: 0.008732661483404429\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 8, valid_loss: 0.009061396225459047\n",
      "SEED: 1269, FOLD: 3, EPOCH: 9, train_loss: 0.008624480929279673\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 9, valid_loss: 0.009071708346406618\n",
      "SEED: 1269, FOLD: 3, EPOCH: 10, train_loss: 0.008503998278815678\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 10, valid_loss: 0.008967875192562738\n",
      "SEED: 1269, FOLD: 3, EPOCH: 11, train_loss: 0.008388235604903404\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 11, valid_loss: 0.008933376003470685\n",
      "SEED: 1269, FOLD: 3, EPOCH: 12, train_loss: 0.00823276390766968\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 12, valid_loss: 0.008862072550174262\n",
      "SEED: 1269, FOLD: 3, EPOCH: 13, train_loss: 0.008073452353963385\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 13, valid_loss: 0.00884295560212599\n",
      "SEED: 1269, FOLD: 3, EPOCH: 14, train_loss: 0.007976542753369911\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 14, valid_loss: 0.008837872184813023\n",
      "SEED: 1269, FOLD: 4, EPOCH: 0, train_loss: 0.6470333506231722\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 0, valid_loss: 0.2137831739253468\n",
      "SEED: 1269, FOLD: 4, EPOCH: 1, train_loss: 0.036569842447837196\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 1, valid_loss: 0.008996213527603282\n",
      "SEED: 1269, FOLD: 4, EPOCH: 2, train_loss: 0.009507561426447786\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 2, valid_loss: 0.008854315693800649\n",
      "SEED: 1269, FOLD: 4, EPOCH: 3, train_loss: 0.010616904367571291\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 3, valid_loss: 0.00940910204210215\n",
      "SEED: 1269, FOLD: 4, EPOCH: 4, train_loss: 0.00949993095887096\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 4, valid_loss: 0.008797120665096574\n",
      "SEED: 1269, FOLD: 4, EPOCH: 5, train_loss: 0.009149351022273733\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 5, valid_loss: 0.008731747253073586\n",
      "SEED: 1269, FOLD: 4, EPOCH: 6, train_loss: 0.009079646197674067\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 6, valid_loss: 0.008686676388606429\n",
      "SEED: 1269, FOLD: 4, EPOCH: 7, train_loss: 0.008963755763851214\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 7, valid_loss: 0.008633896061736677\n",
      "SEED: 1269, FOLD: 4, EPOCH: 8, train_loss: 0.008844602097203766\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 8, valid_loss: 0.008553585761951076\n",
      "SEED: 1269, FOLD: 4, EPOCH: 9, train_loss: 0.008737440457216639\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 9, valid_loss: 0.008556269911221333\n",
      "SEED: 1269, FOLD: 4, EPOCH: 10, train_loss: 0.008634295301052971\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 10, valid_loss: 0.008455659366316266\n",
      "SEED: 1269, FOLD: 4, EPOCH: 11, train_loss: 0.008482115734638512\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 11, valid_loss: 0.0083938325341377\n",
      "SEED: 1269, FOLD: 4, EPOCH: 12, train_loss: 0.00830187807129561\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 12, valid_loss: 0.008372566792079143\n",
      "SEED: 1269, FOLD: 4, EPOCH: 13, train_loss: 0.008130857707473679\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 13, valid_loss: 0.008367896131757233\n",
      "SEED: 1269, FOLD: 4, EPOCH: 14, train_loss: 0.00801648258946944\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 14, valid_loss: 0.008354212260908551\n",
      "elapsed time: 350.8782331943512\n",
      "SEED: 1392, FOLD: 0, EPOCH: 0, train_loss: 0.6457229733899019\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 0, valid_loss: 0.22118832005394828\n",
      "SEED: 1392, FOLD: 0, EPOCH: 1, train_loss: 0.035341878529584064\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 1, valid_loss: 0.009391779493954446\n",
      "SEED: 1392, FOLD: 0, EPOCH: 2, train_loss: 0.009461822717086128\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 2, valid_loss: 0.0093332314863801\n",
      "SEED: 1392, FOLD: 0, EPOCH: 3, train_loss: 0.009633162342335867\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 3, valid_loss: 0.04814355665196975\n",
      "SEED: 1392, FOLD: 0, EPOCH: 4, train_loss: 0.009420738110075827\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 4, valid_loss: 0.009096413592083586\n",
      "SEED: 1392, FOLD: 0, EPOCH: 5, train_loss: 0.009020482129214899\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 5, valid_loss: 0.00900620532532533\n",
      "SEED: 1392, FOLD: 0, EPOCH: 6, train_loss: 0.00890804312961257\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 6, valid_loss: 0.008971128509276442\n",
      "SEED: 1392, FOLD: 0, EPOCH: 7, train_loss: 0.008842825309197971\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 7, valid_loss: 0.008927985197967954\n",
      "SEED: 1392, FOLD: 0, EPOCH: 8, train_loss: 0.00876835616224486\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 8, valid_loss: 0.00900274251277248\n",
      "SEED: 1392, FOLD: 0, EPOCH: 9, train_loss: 0.008695019280834906\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 9, valid_loss: 0.008824779238137934\n",
      "SEED: 1392, FOLD: 0, EPOCH: 10, train_loss: 0.00859491853043437\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 10, valid_loss: 0.00877719952000512\n",
      "SEED: 1392, FOLD: 0, EPOCH: 11, train_loss: 0.00846063787036616\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 11, valid_loss: 0.008739108763014277\n",
      "SEED: 1392, FOLD: 0, EPOCH: 12, train_loss: 0.008311466084442276\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 12, valid_loss: 0.008687979929770032\n",
      "SEED: 1392, FOLD: 0, EPOCH: 13, train_loss: 0.008154736811538105\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 13, valid_loss: 0.00867644089481069\n",
      "SEED: 1392, FOLD: 0, EPOCH: 14, train_loss: 0.00805242868491273\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 14, valid_loss: 0.008674135612737801\n",
      "SEED: 1392, FOLD: 1, EPOCH: 0, train_loss: 0.646138387961664\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 0, valid_loss: 0.19585574169953665\n",
      "SEED: 1392, FOLD: 1, EPOCH: 1, train_loss: 0.03547061879889689\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 1, valid_loss: 0.009431235026568174\n",
      "SEED: 1392, FOLD: 1, EPOCH: 2, train_loss: 0.009392342206252657\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 2, valid_loss: 0.009202827906443013\n",
      "SEED: 1392, FOLD: 1, EPOCH: 3, train_loss: 0.009192801364090132\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 3, valid_loss: 0.009375936093015803\n",
      "SEED: 1392, FOLD: 1, EPOCH: 4, train_loss: 0.009100726009279058\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 4, valid_loss: 0.009212123023139106\n",
      "SEED: 1392, FOLD: 1, EPOCH: 5, train_loss: 0.009057673666140308\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 5, valid_loss: 0.009115678103019794\n",
      "SEED: 1392, FOLD: 1, EPOCH: 6, train_loss: 0.008878668945660625\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 6, valid_loss: 0.00900887589280804\n",
      "SEED: 1392, FOLD: 1, EPOCH: 7, train_loss: 0.008801754881236433\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 7, valid_loss: 0.00894000929676824\n",
      "SEED: 1392, FOLD: 1, EPOCH: 8, train_loss: 0.008705660451095606\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 8, valid_loss: 0.00894051386664311\n",
      "SEED: 1392, FOLD: 1, EPOCH: 9, train_loss: 0.008654614498811787\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 9, valid_loss: 0.008857111860480573\n",
      "SEED: 1392, FOLD: 1, EPOCH: 10, train_loss: 0.00855528910819819\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 10, valid_loss: 0.00878145545721054\n",
      "SEED: 1392, FOLD: 1, EPOCH: 11, train_loss: 0.008425901778906153\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 11, valid_loss: 0.008736815355304215\n",
      "SEED: 1392, FOLD: 1, EPOCH: 12, train_loss: 0.00828265294810568\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 12, valid_loss: 0.008707039523869753\n",
      "SEED: 1392, FOLD: 1, EPOCH: 13, train_loss: 0.008130699834799852\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 13, valid_loss: 0.00868031227340301\n",
      "SEED: 1392, FOLD: 1, EPOCH: 14, train_loss: 0.00804986961968783\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 14, valid_loss: 0.008677055748800436\n",
      "SEED: 1392, FOLD: 2, EPOCH: 0, train_loss: 0.6468201672685319\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 0, valid_loss: 0.22752242700921166\n",
      "SEED: 1392, FOLD: 2, EPOCH: 1, train_loss: 0.03597479902099872\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 1, valid_loss: 0.009483198635280132\n",
      "SEED: 1392, FOLD: 2, EPOCH: 2, train_loss: 0.009340170541427273\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 2, valid_loss: 0.009254641520480314\n",
      "SEED: 1392, FOLD: 2, EPOCH: 3, train_loss: 0.009302269964330439\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 3, valid_loss: 0.018464751075953245\n",
      "SEED: 1392, FOLD: 2, EPOCH: 4, train_loss: 0.010929169956648695\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 4, valid_loss: 0.009428421501070261\n",
      "SEED: 1392, FOLD: 2, EPOCH: 5, train_loss: 0.009149020389262318\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 5, valid_loss: 0.009169897633708186\n",
      "SEED: 1392, FOLD: 2, EPOCH: 6, train_loss: 0.00900742479775479\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 6, valid_loss: 0.009072067060818275\n",
      "SEED: 1392, FOLD: 2, EPOCH: 7, train_loss: 0.008918805614761684\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 7, valid_loss: 0.009035429917275906\n",
      "SEED: 1392, FOLD: 2, EPOCH: 8, train_loss: 0.008847585879266262\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 8, valid_loss: 0.008987658036251863\n",
      "SEED: 1392, FOLD: 2, EPOCH: 9, train_loss: 0.008775322752046412\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 9, valid_loss: 0.008911798940971494\n",
      "SEED: 1392, FOLD: 2, EPOCH: 10, train_loss: 0.008677387340129286\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 10, valid_loss: 0.00890234213632842\n",
      "SEED: 1392, FOLD: 2, EPOCH: 11, train_loss: 0.008552521676419006\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 11, valid_loss: 0.008839285932481289\n",
      "SEED: 1392, FOLD: 2, EPOCH: 12, train_loss: 0.008412517175294352\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 12, valid_loss: 0.00880935788154602\n",
      "SEED: 1392, FOLD: 2, EPOCH: 13, train_loss: 0.00825890169168512\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 13, valid_loss: 0.008793002020360695\n",
      "SEED: 1392, FOLD: 2, EPOCH: 14, train_loss: 0.008150496877783882\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 14, valid_loss: 0.008785521456350883\n",
      "SEED: 1392, FOLD: 3, EPOCH: 0, train_loss: 0.6470042674437814\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 0, valid_loss: 0.21280868185891044\n",
      "SEED: 1392, FOLD: 3, EPOCH: 1, train_loss: 0.03588283349476431\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 1, valid_loss: 0.009601189082281457\n",
      "SEED: 1392, FOLD: 3, EPOCH: 2, train_loss: 0.009343198129394348\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 2, valid_loss: 0.009421704802662134\n",
      "SEED: 1392, FOLD: 3, EPOCH: 3, train_loss: 0.009330379884636057\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 3, valid_loss: 0.010163343149340816\n",
      "SEED: 1392, FOLD: 3, EPOCH: 4, train_loss: 0.009148305093032726\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 4, valid_loss: 0.00921250062270297\n",
      "SEED: 1392, FOLD: 3, EPOCH: 5, train_loss: 0.008892053090359854\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 5, valid_loss: 0.00924340019830399\n",
      "SEED: 1392, FOLD: 3, EPOCH: 6, train_loss: 0.008826732682739046\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 6, valid_loss: 0.009124626457277272\n",
      "SEED: 1392, FOLD: 3, EPOCH: 7, train_loss: 0.008741915664649096\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 7, valid_loss: 0.009062383944789568\n",
      "SEED: 1392, FOLD: 3, EPOCH: 8, train_loss: 0.00869174097813126\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 8, valid_loss: 0.009050056855711672\n",
      "SEED: 1392, FOLD: 3, EPOCH: 9, train_loss: 0.008586404082513805\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 9, valid_loss: 0.00902056766466962\n",
      "SEED: 1392, FOLD: 3, EPOCH: 10, train_loss: 0.00851789497486923\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 10, valid_loss: 0.008958644337124295\n",
      "SEED: 1392, FOLD: 3, EPOCH: 11, train_loss: 0.008348678684105043\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 11, valid_loss: 0.008879819315754704\n",
      "SEED: 1392, FOLD: 3, EPOCH: 12, train_loss: 0.008212858406097992\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 12, valid_loss: 0.008867172679553429\n",
      "SEED: 1392, FOLD: 3, EPOCH: 13, train_loss: 0.008064577544944874\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 13, valid_loss: 0.008853851507107416\n",
      "SEED: 1392, FOLD: 3, EPOCH: 14, train_loss: 0.007974724170576403\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 14, valid_loss: 0.008849519718852308\n",
      "SEED: 1392, FOLD: 4, EPOCH: 0, train_loss: 0.6467495595199474\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 0, valid_loss: 0.24207048614819845\n",
      "SEED: 1392, FOLD: 4, EPOCH: 1, train_loss: 0.03596524439374174\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 1, valid_loss: 0.009093098031977812\n",
      "SEED: 1392, FOLD: 4, EPOCH: 2, train_loss: 0.00942402181175092\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 2, valid_loss: 0.008801843453612592\n",
      "SEED: 1392, FOLD: 4, EPOCH: 3, train_loss: 0.009313901413933954\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 3, valid_loss: 0.008772997547768883\n",
      "SEED: 1392, FOLD: 4, EPOCH: 4, train_loss: 0.009162572576947834\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 4, valid_loss: 0.008783077045033375\n",
      "SEED: 1392, FOLD: 4, EPOCH: 5, train_loss: 0.009069228052175131\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 5, valid_loss: 0.008909656795569591\n",
      "SEED: 1392, FOLD: 4, EPOCH: 6, train_loss: 0.008998348661091017\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 6, valid_loss: 0.008606847711942263\n",
      "SEED: 1392, FOLD: 4, EPOCH: 7, train_loss: 0.008852615797271332\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 7, valid_loss: 0.008563745145996412\n",
      "SEED: 1392, FOLD: 4, EPOCH: 8, train_loss: 0.008853847046207258\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 8, valid_loss: 0.008516609254810546\n",
      "SEED: 1392, FOLD: 4, EPOCH: 9, train_loss: 0.008721831220917511\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 9, valid_loss: 0.008486675590069758\n",
      "SEED: 1392, FOLD: 4, EPOCH: 10, train_loss: 0.008616544603221659\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 10, valid_loss: 0.008435448010762533\n",
      "SEED: 1392, FOLD: 4, EPOCH: 11, train_loss: 0.008505496695853662\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 11, valid_loss: 0.00838753953576088\n",
      "SEED: 1392, FOLD: 4, EPOCH: 12, train_loss: 0.008341780404789724\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 12, valid_loss: 0.0083381581482374\n",
      "SEED: 1392, FOLD: 4, EPOCH: 13, train_loss: 0.008193681981630516\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 13, valid_loss: 0.008339820559033088\n",
      "SEED: 1392, FOLD: 4, EPOCH: 14, train_loss: 0.008105938282349835\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 14, valid_loss: 0.008330333615756698\n",
      "elapsed time: 467.23657488822937\n",
      "SEED: 1119, FOLD: 0, EPOCH: 0, train_loss: 0.6464747687180837\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 0, valid_loss: 0.23735982262425953\n",
      "SEED: 1119, FOLD: 0, EPOCH: 1, train_loss: 0.03594717577747677\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 1, valid_loss: 0.009508137901624044\n",
      "SEED: 1119, FOLD: 0, EPOCH: 2, train_loss: 0.00946251516216907\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 2, valid_loss: 0.009221326611522172\n",
      "SEED: 1119, FOLD: 0, EPOCH: 3, train_loss: 0.009261002129726652\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 3, valid_loss: 0.009156969220687946\n",
      "SEED: 1119, FOLD: 0, EPOCH: 4, train_loss: 0.009096810931636803\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 4, valid_loss: 0.009077900348024236\n",
      "SEED: 1119, FOLD: 0, EPOCH: 5, train_loss: 0.009005558946966261\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 5, valid_loss: 0.009033253054238029\n",
      "SEED: 1119, FOLD: 0, EPOCH: 6, train_loss: 0.008889242453311665\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 6, valid_loss: 0.008954283522648944\n",
      "SEED: 1119, FOLD: 0, EPOCH: 7, train_loss: 0.00880641094746365\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 7, valid_loss: 0.00890942414601644\n",
      "SEED: 1119, FOLD: 0, EPOCH: 8, train_loss: 0.008699672688068687\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 8, valid_loss: 0.008800623110598989\n",
      "SEED: 1119, FOLD: 0, EPOCH: 9, train_loss: 0.008631292440375124\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 9, valid_loss: 0.008780244194592038\n",
      "SEED: 1119, FOLD: 0, EPOCH: 10, train_loss: 0.008509777277114166\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 10, valid_loss: 0.008739087601295777\n",
      "SEED: 1119, FOLD: 0, EPOCH: 11, train_loss: 0.00838554482502134\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 11, valid_loss: 0.008705717692565586\n",
      "SEED: 1119, FOLD: 0, EPOCH: 12, train_loss: 0.008222472273569176\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 12, valid_loss: 0.008692021818003721\n",
      "SEED: 1119, FOLD: 0, EPOCH: 13, train_loss: 0.008066996196419865\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 13, valid_loss: 0.008649823333447179\n",
      "SEED: 1119, FOLD: 0, EPOCH: 14, train_loss: 0.007971648113343163\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 14, valid_loss: 0.008640338718477223\n",
      "SEED: 1119, FOLD: 1, EPOCH: 0, train_loss: 0.6467666755551877\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 0, valid_loss: 0.22535301744937897\n",
      "SEED: 1119, FOLD: 1, EPOCH: 1, train_loss: 0.03584361510972182\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 1, valid_loss: 0.009490211183826128\n",
      "SEED: 1119, FOLD: 1, EPOCH: 2, train_loss: 0.009370565549402998\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 2, valid_loss: 0.00918101431387994\n",
      "SEED: 1119, FOLD: 1, EPOCH: 3, train_loss: 0.009641768059868744\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 3, valid_loss: 0.010139453483538495\n",
      "SEED: 1119, FOLD: 1, EPOCH: 4, train_loss: 0.009247738787013552\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 4, valid_loss: 0.009073104554166397\n",
      "SEED: 1119, FOLD: 1, EPOCH: 5, train_loss: 0.009009909613624863\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 5, valid_loss: 0.009000728010303445\n",
      "SEED: 1119, FOLD: 1, EPOCH: 6, train_loss: 0.008907967152586882\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 6, valid_loss: 0.008983241445902321\n",
      "SEED: 1119, FOLD: 1, EPOCH: 7, train_loss: 0.008787894810455433\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 7, valid_loss: 0.009059961212591993\n",
      "SEED: 1119, FOLD: 1, EPOCH: 8, train_loss: 0.00871436391700653\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 8, valid_loss: 0.008878132380131219\n",
      "SEED: 1119, FOLD: 1, EPOCH: 9, train_loss: 0.008620948476743872\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 9, valid_loss: 0.008869461404780546\n",
      "SEED: 1119, FOLD: 1, EPOCH: 10, train_loss: 0.008534516261863535\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 10, valid_loss: 0.00881955467371477\n",
      "SEED: 1119, FOLD: 1, EPOCH: 11, train_loss: 0.008391623553968426\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 11, valid_loss: 0.00875560628871123\n",
      "SEED: 1119, FOLD: 1, EPOCH: 12, train_loss: 0.008221927058437595\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 12, valid_loss: 0.008727077084283033\n",
      "SEED: 1119, FOLD: 1, EPOCH: 13, train_loss: 0.00805487736141768\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 13, valid_loss: 0.008702506156017384\n",
      "SEED: 1119, FOLD: 1, EPOCH: 14, train_loss: 0.007935231139856403\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 14, valid_loss: 0.008691592400686609\n",
      "SEED: 1119, FOLD: 2, EPOCH: 0, train_loss: 0.6466195054244304\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 0, valid_loss: 0.22059193170732921\n",
      "SEED: 1119, FOLD: 2, EPOCH: 1, train_loss: 0.035639718066954956\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 1, valid_loss: 0.00952271009898848\n",
      "SEED: 1119, FOLD: 2, EPOCH: 2, train_loss: 0.009346804649069689\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 2, valid_loss: 0.00931536504584882\n",
      "SEED: 1119, FOLD: 2, EPOCH: 3, train_loss: 0.009267483783912832\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 3, valid_loss: 0.009403646923601627\n",
      "SEED: 1119, FOLD: 2, EPOCH: 4, train_loss: 0.009203273600534252\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 4, valid_loss: 0.009196935842434565\n",
      "SEED: 1119, FOLD: 2, EPOCH: 5, train_loss: 0.008980601918006289\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 5, valid_loss: 0.009128594124275777\n",
      "SEED: 1119, FOLD: 2, EPOCH: 6, train_loss: 0.00888977492687063\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 6, valid_loss: 0.008981609147869878\n",
      "SEED: 1119, FOLD: 2, EPOCH: 7, train_loss: 0.008789580112890057\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 7, valid_loss: 0.008919006653337015\n",
      "SEED: 1119, FOLD: 2, EPOCH: 8, train_loss: 0.00871341482506714\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 8, valid_loss: 0.00889014408716725\n",
      "SEED: 1119, FOLD: 2, EPOCH: 9, train_loss: 0.008657670903788961\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 9, valid_loss: 0.008866806850872107\n",
      "SEED: 1119, FOLD: 2, EPOCH: 10, train_loss: 0.00854570547496711\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 10, valid_loss: 0.008864732588537864\n",
      "SEED: 1119, FOLD: 2, EPOCH: 11, train_loss: 0.0084399973663191\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 11, valid_loss: 0.00878106851855086\n",
      "SEED: 1119, FOLD: 2, EPOCH: 12, train_loss: 0.008296278521310593\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 12, valid_loss: 0.008724326681759622\n",
      "SEED: 1119, FOLD: 2, EPOCH: 13, train_loss: 0.008141910468322643\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 13, valid_loss: 0.008715678084020814\n",
      "SEED: 1119, FOLD: 2, EPOCH: 14, train_loss: 0.00804886574168568\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 14, valid_loss: 0.008713236518411173\n",
      "SEED: 1119, FOLD: 3, EPOCH: 0, train_loss: 0.6455916587425314\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 0, valid_loss: 0.23266583349969652\n",
      "SEED: 1119, FOLD: 3, EPOCH: 1, train_loss: 0.03562466681435488\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 1, valid_loss: 0.009604690182540152\n",
      "SEED: 1119, FOLD: 3, EPOCH: 2, train_loss: 0.009355354838181233\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 2, valid_loss: 0.009341047507607274\n",
      "SEED: 1119, FOLD: 3, EPOCH: 3, train_loss: 0.009189643465198469\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 3, valid_loss: 0.009331153447015418\n",
      "SEED: 1119, FOLD: 3, EPOCH: 4, train_loss: 0.009128492460518644\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 4, valid_loss: 0.00921403704625037\n",
      "SEED: 1119, FOLD: 3, EPOCH: 5, train_loss: 0.009097047845252615\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 5, valid_loss: 0.009501929136200083\n",
      "SEED: 1119, FOLD: 3, EPOCH: 6, train_loss: 0.008864430319247902\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 6, valid_loss: 0.009127152928461632\n",
      "SEED: 1119, FOLD: 3, EPOCH: 7, train_loss: 0.008749134001740511\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 7, valid_loss: 0.009106808393779729\n",
      "SEED: 1119, FOLD: 3, EPOCH: 8, train_loss: 0.00867281751572222\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 8, valid_loss: 0.009035867121484544\n",
      "SEED: 1119, FOLD: 3, EPOCH: 9, train_loss: 0.00857264122021371\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 9, valid_loss: 0.00900153075862262\n",
      "SEED: 1119, FOLD: 3, EPOCH: 10, train_loss: 0.008506725744708725\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 10, valid_loss: 0.00898859825813108\n",
      "SEED: 1119, FOLD: 3, EPOCH: 11, train_loss: 0.008381029395251602\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 11, valid_loss: 0.008912732410762046\n",
      "SEED: 1119, FOLD: 3, EPOCH: 12, train_loss: 0.008209293849928223\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 12, valid_loss: 0.008870825223210786\n",
      "SEED: 1119, FOLD: 3, EPOCH: 13, train_loss: 0.008067661153989426\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 13, valid_loss: 0.00884528189069695\n",
      "SEED: 1119, FOLD: 3, EPOCH: 14, train_loss: 0.007960396508375803\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 14, valid_loss: 0.00884306337684393\n",
      "SEED: 1119, FOLD: 4, EPOCH: 0, train_loss: 0.6469709845124811\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 0, valid_loss: 0.21554778847429487\n",
      "SEED: 1119, FOLD: 4, EPOCH: 1, train_loss: 0.03614570076266924\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 1, valid_loss: 0.009018039874111613\n",
      "SEED: 1119, FOLD: 4, EPOCH: 2, train_loss: 0.00945835077352282\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 2, valid_loss: 0.008823933157448968\n",
      "SEED: 1119, FOLD: 4, EPOCH: 3, train_loss: 0.009321676229761131\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 3, valid_loss: 0.008824724781637391\n",
      "SEED: 1119, FOLD: 4, EPOCH: 4, train_loss: 0.009253626270894554\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 4, valid_loss: 0.008705481964473924\n",
      "SEED: 1119, FOLD: 4, EPOCH: 5, train_loss: 0.009033832726055298\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 5, valid_loss: 0.008639247467120489\n",
      "SEED: 1119, FOLD: 4, EPOCH: 6, train_loss: 0.00892192149615806\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 6, valid_loss: 0.008566125166705914\n",
      "SEED: 1119, FOLD: 4, EPOCH: 7, train_loss: 0.008838926482459774\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 7, valid_loss: 0.008516871189284656\n",
      "SEED: 1119, FOLD: 4, EPOCH: 8, train_loss: 0.008778504534638014\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 8, valid_loss: 0.008524272953056626\n",
      "SEED: 1119, FOLD: 4, EPOCH: 9, train_loss: 0.008714258441350597\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 9, valid_loss: 0.008457532566454675\n",
      "SEED: 1119, FOLD: 4, EPOCH: 10, train_loss: 0.008594674105499533\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 10, valid_loss: 0.008472540571043888\n",
      "SEED: 1119, FOLD: 4, EPOCH: 11, train_loss: 0.00847649209174341\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 11, valid_loss: 0.0083469124769585\n",
      "SEED: 1119, FOLD: 4, EPOCH: 12, train_loss: 0.008321956454681746\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 12, valid_loss: 0.0083220017194334\n",
      "SEED: 1119, FOLD: 4, EPOCH: 13, train_loss: 0.008179810161337904\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 13, valid_loss: 0.008319628243851993\n",
      "SEED: 1119, FOLD: 4, EPOCH: 14, train_loss: 0.008077546124063108\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 14, valid_loss: 0.008307585182289282\n",
      "elapsed time: 582.9320271015167\n",
      "SEED: 1303, FOLD: 0, EPOCH: 0, train_loss: 0.6477691349775895\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 0, valid_loss: 0.21537495818403032\n",
      "SEED: 1303, FOLD: 0, EPOCH: 1, train_loss: 0.03630925094087919\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 1, valid_loss: 0.00929129071947601\n",
      "SEED: 1303, FOLD: 0, EPOCH: 2, train_loss: 0.009410452016669771\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 2, valid_loss: 0.009133213768816657\n",
      "SEED: 1303, FOLD: 0, EPOCH: 3, train_loss: 0.009241896762472132\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 3, valid_loss: 0.009211905041916503\n",
      "SEED: 1303, FOLD: 0, EPOCH: 4, train_loss: 0.009144761734574602\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 4, valid_loss: 0.009172899493326744\n",
      "SEED: 1303, FOLD: 0, EPOCH: 5, train_loss: 0.009004864720222742\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 5, valid_loss: 0.009015810313738055\n",
      "SEED: 1303, FOLD: 0, EPOCH: 6, train_loss: 0.009431544394380804\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 6, valid_loss: 0.009086911618295643\n",
      "SEED: 1303, FOLD: 0, EPOCH: 7, train_loss: 0.00897505626325374\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 7, valid_loss: 0.009008009038451645\n",
      "SEED: 1303, FOLD: 0, EPOCH: 8, train_loss: 0.008835234348594711\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 8, valid_loss: 0.008933333214372396\n",
      "SEED: 1303, FOLD: 0, EPOCH: 9, train_loss: 0.008725302577342676\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 9, valid_loss: 0.009075629938807752\n",
      "SEED: 1303, FOLD: 0, EPOCH: 10, train_loss: 0.008647678858614054\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 10, valid_loss: 0.008827010117885139\n",
      "SEED: 1303, FOLD: 0, EPOCH: 11, train_loss: 0.008531046113458233\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 11, valid_loss: 0.008767829561192129\n",
      "SEED: 1303, FOLD: 0, EPOCH: 12, train_loss: 0.00840570907904834\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 12, valid_loss: 0.008795738194344772\n",
      "SEED: 1303, FOLD: 0, EPOCH: 13, train_loss: 0.00827674634511704\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 13, valid_loss: 0.008786356697479883\n",
      "SEED: 1303, FOLD: 0, EPOCH: 14, train_loss: 0.008177690747855366\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 14, valid_loss: 0.008745306818228629\n",
      "SEED: 1303, FOLD: 1, EPOCH: 0, train_loss: 0.6481554996276248\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 0, valid_loss: 0.2023764666583803\n",
      "SEED: 1303, FOLD: 1, EPOCH: 1, train_loss: 0.03576671959751326\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 1, valid_loss: 0.009431407942126194\n",
      "SEED: 1303, FOLD: 1, EPOCH: 2, train_loss: 0.009427618019390797\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 2, valid_loss: 0.009220929764625099\n",
      "SEED: 1303, FOLD: 1, EPOCH: 3, train_loss: 0.009223104468074398\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 3, valid_loss: 0.009362240684115224\n",
      "SEED: 1303, FOLD: 1, EPOCH: 4, train_loss: 0.009470069160064062\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 4, valid_loss: 0.009118546783510182\n",
      "SEED: 1303, FOLD: 1, EPOCH: 5, train_loss: 0.009017077699789534\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 5, valid_loss: 0.009219516120437119\n",
      "SEED: 1303, FOLD: 1, EPOCH: 6, train_loss: 0.008901981731363829\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 6, valid_loss: 0.009016454737219546\n",
      "SEED: 1303, FOLD: 1, EPOCH: 7, train_loss: 0.00879674954879759\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 7, valid_loss: 0.008970766328275204\n",
      "SEED: 1303, FOLD: 1, EPOCH: 8, train_loss: 0.008741964133915262\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 8, valid_loss: 0.008935484517779615\n",
      "SEED: 1303, FOLD: 1, EPOCH: 9, train_loss: 0.00867319121227964\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 9, valid_loss: 0.008844942992760075\n",
      "SEED: 1303, FOLD: 1, EPOCH: 10, train_loss: 0.008570928848685993\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 10, valid_loss: 0.008813491505053308\n",
      "SEED: 1303, FOLD: 1, EPOCH: 11, train_loss: 0.008454512035393196\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 11, valid_loss: 0.008756271770430936\n",
      "SEED: 1303, FOLD: 1, EPOCH: 12, train_loss: 0.008287036568736252\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 12, valid_loss: 0.008694112559573518\n",
      "SEED: 1303, FOLD: 1, EPOCH: 13, train_loss: 0.008154601763016071\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 13, valid_loss: 0.00869385799806979\n",
      "SEED: 1303, FOLD: 1, EPOCH: 14, train_loss: 0.008052522640513338\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 14, valid_loss: 0.008682903109325303\n",
      "SEED: 1303, FOLD: 2, EPOCH: 0, train_loss: 0.648623144713001\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 0, valid_loss: 0.2292623089419471\n",
      "SEED: 1303, FOLD: 2, EPOCH: 1, train_loss: 0.03609340763448373\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 1, valid_loss: 0.009349236678746011\n",
      "SEED: 1303, FOLD: 2, EPOCH: 2, train_loss: 0.009404591595133146\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 2, valid_loss: 0.009248261288222339\n",
      "SEED: 1303, FOLD: 2, EPOCH: 3, train_loss: 0.009367664054414068\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 3, valid_loss: 0.022159350156370137\n",
      "SEED: 1303, FOLD: 2, EPOCH: 4, train_loss: 0.010306824538586796\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 4, valid_loss: 0.009205060390134653\n",
      "SEED: 1303, FOLD: 2, EPOCH: 5, train_loss: 0.009098408264580412\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 5, valid_loss: 0.009122435676140917\n",
      "SEED: 1303, FOLD: 2, EPOCH: 6, train_loss: 0.008972729677739351\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 6, valid_loss: 0.009062821511179209\n",
      "SEED: 1303, FOLD: 2, EPOCH: 7, train_loss: 0.008867320753094078\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 7, valid_loss: 0.008994912883887688\n",
      "SEED: 1303, FOLD: 2, EPOCH: 8, train_loss: 0.00878075355043014\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 8, valid_loss: 0.008991962247010734\n",
      "SEED: 1303, FOLD: 2, EPOCH: 9, train_loss: 0.008699245575437511\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 9, valid_loss: 0.00892498103591303\n",
      "SEED: 1303, FOLD: 2, EPOCH: 10, train_loss: 0.00859051508208116\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 10, valid_loss: 0.008876147809334926\n",
      "SEED: 1303, FOLD: 2, EPOCH: 11, train_loss: 0.008447546910062649\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 11, valid_loss: 0.008819076129131846\n",
      "SEED: 1303, FOLD: 2, EPOCH: 12, train_loss: 0.008287259660985159\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 12, valid_loss: 0.008753124262309737\n",
      "SEED: 1303, FOLD: 2, EPOCH: 13, train_loss: 0.008121161748641643\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 13, valid_loss: 0.008751497500472598\n",
      "SEED: 1303, FOLD: 2, EPOCH: 14, train_loss: 0.008009367986865665\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 14, valid_loss: 0.008763046003878117\n",
      "SEED: 1303, FOLD: 3, EPOCH: 0, train_loss: 0.6461830095968385\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 0, valid_loss: 0.19992675963375303\n",
      "SEED: 1303, FOLD: 3, EPOCH: 1, train_loss: 0.035852585379304226\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 1, valid_loss: 0.009545513170046939\n",
      "SEED: 1303, FOLD: 3, EPOCH: 2, train_loss: 0.009371533288040024\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 2, valid_loss: 0.009459105268534686\n",
      "SEED: 1303, FOLD: 3, EPOCH: 3, train_loss: 0.009207288113733133\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 3, valid_loss: 0.009294899128791358\n",
      "SEED: 1303, FOLD: 3, EPOCH: 4, train_loss: 0.009133190726456434\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 4, valid_loss: 0.009351971714446941\n",
      "SEED: 1303, FOLD: 3, EPOCH: 5, train_loss: 0.008936515631343143\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 5, valid_loss: 0.009147942945775058\n",
      "SEED: 1303, FOLD: 3, EPOCH: 6, train_loss: 0.008801629098699144\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 6, valid_loss: 0.009242908615205023\n",
      "SEED: 1303, FOLD: 3, EPOCH: 7, train_loss: 0.008741012045546719\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 7, valid_loss: 0.009074976098620229\n",
      "SEED: 1303, FOLD: 3, EPOCH: 8, train_loss: 0.008653063111115192\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 8, valid_loss: 0.00903277275049024\n",
      "SEED: 1303, FOLD: 3, EPOCH: 9, train_loss: 0.008570526449846617\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 9, valid_loss: 0.009002401079568598\n",
      "SEED: 1303, FOLD: 3, EPOCH: 10, train_loss: 0.008475032689022844\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 10, valid_loss: 0.008937683422118425\n",
      "SEED: 1303, FOLD: 3, EPOCH: 11, train_loss: 0.008352647225062052\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 11, valid_loss: 0.008899187358717123\n",
      "SEED: 1303, FOLD: 3, EPOCH: 12, train_loss: 0.008200191568745218\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 12, valid_loss: 0.0088492000165085\n",
      "SEED: 1303, FOLD: 3, EPOCH: 13, train_loss: 0.008053919192457544\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 13, valid_loss: 0.008837317323519124\n",
      "SEED: 1303, FOLD: 3, EPOCH: 14, train_loss: 0.0079526427620347\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 14, valid_loss: 0.008825022520290481\n",
      "SEED: 1303, FOLD: 4, EPOCH: 0, train_loss: 0.6469865318225778\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 0, valid_loss: 0.2228935890727573\n",
      "SEED: 1303, FOLD: 4, EPOCH: 1, train_loss: 0.035808086030833096\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 1, valid_loss: 0.009045541389948793\n",
      "SEED: 1303, FOLD: 4, EPOCH: 2, train_loss: 0.009447386987723303\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 2, valid_loss: 0.00882910417082409\n",
      "SEED: 1303, FOLD: 4, EPOCH: 3, train_loss: 0.009310918468712032\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 3, valid_loss: 0.008932591027890643\n",
      "SEED: 1303, FOLD: 4, EPOCH: 4, train_loss: 0.009173776097325743\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 4, valid_loss: 0.008813308758868111\n",
      "SEED: 1303, FOLD: 4, EPOCH: 5, train_loss: 0.009049253065840921\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 5, valid_loss: 0.008646519880534874\n",
      "SEED: 1303, FOLD: 4, EPOCH: 6, train_loss: 0.008946200184847998\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 6, valid_loss: 0.008613680153050356\n",
      "SEED: 1303, FOLD: 4, EPOCH: 7, train_loss: 0.008852001785746088\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 7, valid_loss: 0.008551698022832474\n",
      "SEED: 1303, FOLD: 4, EPOCH: 8, train_loss: 0.008764137345217709\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 8, valid_loss: 0.008507830556482077\n",
      "SEED: 1303, FOLD: 4, EPOCH: 9, train_loss: 0.008701549586502539\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 9, valid_loss: 0.008440180785126157\n",
      "SEED: 1303, FOLD: 4, EPOCH: 10, train_loss: 0.008588477544000616\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 10, valid_loss: 0.00841432522671918\n",
      "SEED: 1303, FOLD: 4, EPOCH: 11, train_loss: 0.008462741113929213\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 11, valid_loss: 0.008383270016767912\n",
      "SEED: 1303, FOLD: 4, EPOCH: 12, train_loss: 0.00833521825193927\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 12, valid_loss: 0.008334849055649506\n",
      "SEED: 1303, FOLD: 4, EPOCH: 13, train_loss: 0.008183385056537994\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 13, valid_loss: 0.008325954407660497\n",
      "SEED: 1303, FOLD: 4, EPOCH: 14, train_loss: 0.00807440765471994\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 14, valid_loss: 0.008323788849843873\n",
      "elapsed time: 699.0165469646454\n",
      "(21948, 331)\n",
      "(3624, 331)\n"
     ]
    }
   ],
   "source": [
    "SEED = [940, 1513, 1269,1392,1119,1303]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "    print(f\"elapsed time: {time.time() - time_start}\")\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions\n",
    "\n",
    "print(oof.shape)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:39:54.777818Z",
     "iopub.status.busy": "2020-11-26T05:39:54.776738Z",
     "iopub.status.idle": "2020-11-26T05:39:55.452574Z",
     "shell.execute_reply": "2020-11-26T05:39:55.451908Z"
    },
    "papermill": {
     "duration": 0.957526,
     "end_time": "2020-11-26T05:39:55.452699",
     "exception": false,
     "start_time": "2020-11-26T05:39:54.495173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.to_pickle(f\"{INT_DIR}/{NB}-train_nonscore_pred.pkl\")\n",
    "test.to_pickle(f\"{INT_DIR}/{NB}-test_nonscore_pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:39:56.014342Z",
     "iopub.status.busy": "2020-11-26T05:39:56.013570Z",
     "iopub.status.idle": "2020-11-26T05:39:56.019451Z",
     "shell.execute_reply": "2020-11-26T05:39:56.020058Z"
    },
    "papermill": {
     "duration": 0.289817,
     "end_time": "2020-11-26T05:39:56.020199",
     "exception": false,
     "start_time": "2020-11-26T05:39:55.730382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:39:56.622292Z",
     "iopub.status.busy": "2020-11-26T05:39:56.621021Z",
     "iopub.status.idle": "2020-11-26T05:39:58.962147Z",
     "shell.execute_reply": "2020-11-26T05:39:58.962718Z"
    },
    "papermill": {
     "duration": 2.648271,
     "end_time": "2020-11-26T05:39:58.962876",
     "exception": false,
     "start_time": "2020-11-26T05:39:56.314605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.004823565553260081\n"
     ]
    }
   ],
   "source": [
    "train[target_cols] = np.maximum(PMIN, np.minimum(PMAX, train[target_cols]))\n",
    "valid_results = train_targets_nonscored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "y_true = train_targets_nonscored[target_cols].values\n",
    "y_true = y_true > 0.5\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.279152,
     "end_time": "2020-11-26T05:39:59.520941",
     "exception": false,
     "start_time": "2020-11-26T05:39:59.241789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "CV log_loss:  0.014761779358699672\n",
    "CV log_loss:  0.014519859174255039\n",
    "CV log_loss:  0.014525173864593479\n",
    "CV log_loss:  0.014354930596928602 # 3 umap features\n",
    "CV log_loss:  0.014353604854355429 # more umap features\n",
    "CV log_loss:  0.01436484670778641 # more hidden nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:00.092739Z",
     "iopub.status.busy": "2020-11-26T05:40:00.091533Z",
     "iopub.status.idle": "2020-11-26T05:40:00.093751Z",
     "shell.execute_reply": "2020-11-26T05:40:00.094316Z"
    },
    "papermill": {
     "duration": 0.286236,
     "end_time": "2020-11-26T05:40:00.094485",
     "exception": false,
     "start_time": "2020-11-26T05:39:59.808249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 25\n",
    "# NFOLDS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:00.656315Z",
     "iopub.status.busy": "2020-11-26T05:40:00.655596Z",
     "iopub.status.idle": "2020-11-26T05:40:00.660126Z",
     "shell.execute_reply": "2020-11-26T05:40:00.660675Z"
    },
    "papermill": {
     "duration": 0.287198,
     "end_time": "2020-11-26T05:40:00.660831",
     "exception": false,
     "start_time": "2020-11-26T05:40:00.373633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "# sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:01.267098Z",
     "iopub.status.busy": "2020-11-26T05:40:01.265017Z",
     "iopub.status.idle": "2020-11-26T05:40:01.267881Z",
     "shell.execute_reply": "2020-11-26T05:40:01.268448Z"
    },
    "papermill": {
     "duration": 0.308938,
     "end_time": "2020-11-26T05:40:01.268604",
     "exception": false,
     "start_time": "2020-11-26T05:40:00.959666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nonscored_target = [c for c in train[train_targets_nonscored.columns] if c != \"sig_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:01.843910Z",
     "iopub.status.busy": "2020-11-26T05:40:01.842123Z",
     "iopub.status.idle": "2020-11-26T05:40:01.848048Z",
     "shell.execute_reply": "2020-11-26T05:40:01.848654Z"
    },
    "papermill": {
     "duration": 0.29991,
     "end_time": "2020-11-26T05:40:01.848817",
     "exception": false,
     "start_time": "2020-11-26T05:40:01.548907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc_transporter_expression_enhancer',\n",
       " 'abl_inhibitor',\n",
       " 'ace_inhibitor',\n",
       " 'acetylcholine_release_enhancer',\n",
       " 'adenosine_kinase_inhibitor',\n",
       " 'adenylyl_cyclase_inhibitor',\n",
       " 'age_inhibitor',\n",
       " 'alcohol_dehydrogenase_inhibitor',\n",
       " 'aldehyde_dehydrogenase_activator',\n",
       " 'aldose_reductase_inhibitor',\n",
       " 'ampk_inhibitor',\n",
       " 'androgen_biosynthesis_inhibitor',\n",
       " 'angiotensin_receptor_agonist',\n",
       " 'antacid',\n",
       " 'anthelmintic',\n",
       " 'antipruritic',\n",
       " 'antirheumatic_drug',\n",
       " 'antiseptic',\n",
       " 'antispasmodic',\n",
       " 'antithyroid_agent',\n",
       " 'antitussive',\n",
       " 'anxiolytic',\n",
       " 'ap_inhibitor',\n",
       " 'apoptosis_inhibitor',\n",
       " 'arf_inhibitor',\n",
       " 'aryl_hydrocarbon_receptor_agonist',\n",
       " 'aryl_hydrocarbon_receptor_antagonist',\n",
       " 'aspartic_protease_inhibitor',\n",
       " 'atherogenesis_inhibitor',\n",
       " 'atherosclerosis_formation_inhibitor',\n",
       " 'atp-sensitive_potassium_channel_agonist',\n",
       " 'atp-sensitive_potassium_channel_inhibitor',\n",
       " 'atp_channel_blocker',\n",
       " 'atp_citrase_lyase_inhibitor',\n",
       " 'autophagy_inducer',\n",
       " 'axl_kinase_inhibitor',\n",
       " 'bacterial_atpase_inhibitor',\n",
       " 'bacterial_permeability_inducer',\n",
       " 'bacterial_protein_synthesis_inhibitor',\n",
       " 'benzodiazepine_receptor_antagonist',\n",
       " 'beta_catenin_inhibitor',\n",
       " 'beta_lactamase_inhibitor',\n",
       " 'beta_secretase_inhibitor',\n",
       " 'big1_inhibitor',\n",
       " 'bile_acid',\n",
       " 'bone_resorption_inhibitor',\n",
       " 'botulin_neurotoxin_inhibitor',\n",
       " 'bradykinin_receptor_antagonist',\n",
       " 'breast_cancer_resistance_protein_inhibitor',\n",
       " 'bronchodilator',\n",
       " 'calcitonin_antagonist',\n",
       " 'calcium_channel_activator',\n",
       " 'calmodulin_inhibitor',\n",
       " 'camp_stimulant',\n",
       " 'capillary_stabilizing_agent',\n",
       " 'car_antagonist',\n",
       " 'carcinogen',\n",
       " 'carnitine_palmitoyltransferase_inhibitor',\n",
       " 'caspase_inhibitor',\n",
       " 'cathepsin_inhibitor',\n",
       " 'cc_chemokine_receptor_agonist',\n",
       " 'cdc_inhibitor',\n",
       " 'cdk_expression_enhancer',\n",
       " 'cell_cycle_inhibitor',\n",
       " 'ceramidase_inhibitor',\n",
       " 'cftr_channel_agonist',\n",
       " 'chitin_inhibitor',\n",
       " 'chloride_channel_activator',\n",
       " 'choleretic_agent',\n",
       " 'cholinergic_receptor_agonist',\n",
       " 'cholinesterase_inhibitor',\n",
       " 'clk_inhibitor',\n",
       " 'coenzyme_a_precursor',\n",
       " 'contraceptive_agent',\n",
       " 'contrast_agent',\n",
       " 'corticosteroid_antagonist',\n",
       " 'cyclin_d_inhibitor',\n",
       " 'cytidine_deaminase_inhibitor',\n",
       " 'cytokine_production_inhibitor',\n",
       " 'dehydrogenase_inhibitor',\n",
       " 'diacylglycerol_kinase_inhibitor',\n",
       " 'diacylglycerol_o_acyltransferase_inhibitor',\n",
       " 'differentiation_inducer',\n",
       " 'dihydroorotate_dehydrogenase_inhibitor',\n",
       " 'dihydropteroate_synthase_inhibitor',\n",
       " 'dihydropyrimidine_dehydrogenase_inhibitor',\n",
       " 'dna_dependent_protein_kinase_inhibitor',\n",
       " 'dna_methyltransferase_inhibitor',\n",
       " 'dna_polymerase_inhibitor',\n",
       " 'dna_synthesis_inhibitor',\n",
       " 'dopamine_release_enhancer',\n",
       " 'dot1l_inhibitor',\n",
       " 'dynamin_inhibitor',\n",
       " 'dyrk_inhibitor',\n",
       " 'endothelin_receptor_antagonist',\n",
       " 'enkephalinase_inhibitor',\n",
       " 'ephrin_inhibitor',\n",
       " 'epoxide_hydolase_inhibitor',\n",
       " 'eukaryotic_translation_initiation_factor_inhibitor',\n",
       " 'exportin_antagonist',\n",
       " 'fabi_inhibitor',\n",
       " 'farnesyl_pyrophosphate_synthase_inhibitor',\n",
       " 'fatty_acid_receptor_antagonist',\n",
       " 'fatty_acid_synthase_inhibitor',\n",
       " 'folate_receptor_ligand',\n",
       " 'fungal_ergosterol_inhibitor',\n",
       " 'fungal_lanosterol_demethylase_inhibitor',\n",
       " 'fxr_agonist',\n",
       " 'g_protein-coupled_receptor_agonist',\n",
       " 'g_protein-coupled_receptor_antagonist',\n",
       " 'g_protein_signaling_inhibitor',\n",
       " 'gaba_gated_chloride_channel_blocker',\n",
       " 'gaba_receptor_modulator',\n",
       " 'gaba_uptake_inhibitor',\n",
       " 'gap_junction_modulator',\n",
       " 'gastrin_inhibitor',\n",
       " 'gat_inhibitor',\n",
       " 'gli_antagonist',\n",
       " 'glp_receptor_agonist',\n",
       " 'glucagon_receptor_antagonist',\n",
       " 'glucocorticoid_receptor_antagonist',\n",
       " 'gluconeogenesis_inhibitor',\n",
       " 'glucose_dependent_insulinotropic_receptor_agonist',\n",
       " 'glucosidase_inhibitor',\n",
       " 'glutamate_receptor_modulator',\n",
       " 'glutathione_reductase_(nadph)_activators',\n",
       " 'glycine_receptor_antagonist',\n",
       " 'glycine_transporter_inhibitor',\n",
       " 'glycogen_phosphorylase_inhibitor',\n",
       " 'glycosylation_inhibitor',\n",
       " 'gonadotropin_receptor_antagonist',\n",
       " 'growth_factor_receptor_inhibitor',\n",
       " 'gtpase_inhibitor',\n",
       " 'guanylate_cyclase_activator',\n",
       " 'guanylyl_cyclase_activator',\n",
       " 'haemostatic_agent',\n",
       " 'hcn_channel_antagonist',\n",
       " 'hedgehog_pathway_inhibitor',\n",
       " 'heme_oxygenase_activators',\n",
       " 'hemoglobin_antagonist',\n",
       " 'hexokinase_inhibitor',\n",
       " 'hgf_receptor_inhibitor',\n",
       " 'hif_inhibitor',\n",
       " 'histamine_release_inhibitor',\n",
       " 'histone_acetyltransferase_inhibitor',\n",
       " 'histone_demethylase_inhibitor',\n",
       " 'hiv_integrase_inhibitor',\n",
       " 'hiv_protease_inhibitor',\n",
       " 'hydantoin_antiepileptic',\n",
       " 'hydroxycarboxylic_acid_receptor_agonist',\n",
       " 'icam1_antagonist',\n",
       " 'icam1_inhibitor',\n",
       " 'id1_expression_inhibitor',\n",
       " 'imidazoline_ligand',\n",
       " 'immunostimulant',\n",
       " 'indoleamine_2,3-dioxygenase_inhibitor',\n",
       " 'inosine_monophosphate_dehydrogenase_inhibitor',\n",
       " 'inositol_monophosphatase_inhibitor',\n",
       " 'interferon_inducer',\n",
       " 'interleukin_inhibitor',\n",
       " 'interleukin_receptor_agonist',\n",
       " 'ion_channel_antagonist',\n",
       " 'ip1_prostacyclin_receptor_agonist',\n",
       " 'isocitrate_dehydrogenase_inhibitor',\n",
       " 'jnk_inhibitor',\n",
       " 'kainate_receptor_antagonist',\n",
       " 'katp_activator',\n",
       " 'keap1_ligand',\n",
       " 'kinesin_inhibitor',\n",
       " 'lactamase_inhibitor',\n",
       " 'lactate_dehydrogenase_inhibitor',\n",
       " 'lanosterol_demethylase_inhibitor',\n",
       " 'leucyl-trna_synthetase_inhibitor',\n",
       " 'leukocyte_elastase_inhibitor',\n",
       " 'lim_inhibitor',\n",
       " 'lipase_clearing_factor_inhibitor',\n",
       " 'lipid_peroxidase_inhibitor',\n",
       " 'lipoprotein_lipase_activator',\n",
       " 'lrkk2_inhibitor',\n",
       " 'lymphocyte_inhibitor',\n",
       " 'lysophosphatidic_acid_receptor_antagonist',\n",
       " 'macrophage_inhibitor',\n",
       " 'macrophage_migration_inhibiting_factor_inhibitor',\n",
       " 'map_k',\n",
       " 'map_kinase_inhibitor',\n",
       " 'matrix_metalloprotease_inhibitor',\n",
       " 'mcl1_inhibitor',\n",
       " 'melanin_inhibitor',\n",
       " 'melatonin_receptor_agonist',\n",
       " 'membrane_permeability_inhibitor',\n",
       " 'mer_tyrosine_kinase_inhibitor',\n",
       " 'met_inhibitor',\n",
       " 'metalloproteinase_inhibitor',\n",
       " 'mineralocorticoid_receptor_agonist',\n",
       " 'mitochondrial_inhibitor',\n",
       " 'mitochondrial_na+_ca2+_exchanger_antagonist',\n",
       " 'monocarboxylate_transporter_inhibitor',\n",
       " 'motilin_receptor_agonist',\n",
       " 'mrp_inhibitor',\n",
       " 'mth1_inhibitor',\n",
       " 'mucus_protecting_agent',\n",
       " 'muscle_relaxant',\n",
       " 'na_k-atpase_inhibitor',\n",
       " 'nadph_inhibitor',\n",
       " 'nampt_inhibitor',\n",
       " 'neprilysin_inhibitor',\n",
       " 'neural_stem_cell_inducer',\n",
       " 'neuraminidase_inhibitor',\n",
       " 'neurokinin_receptor_antagonist',\n",
       " 'neurotensin_receptor_agonist',\n",
       " 'neurotensin_receptor_antagonist',\n",
       " 'neurotransmitter',\n",
       " 'neurotrophic_agent',\n",
       " 'nfkb_activator',\n",
       " 'niemann-pick_c1-like_1_protein_antagonist',\n",
       " 'nitric_oxide_scavenger',\n",
       " 'nociceptin_orphanin_fq_(nop)_receptor_antagonist',\n",
       " 'non-nucleoside_reverse_transcriptase_inhibitor',\n",
       " 'nootropic_agent',\n",
       " 'nop_receptor_agonist',\n",
       " 'norepinephrine_inhibitor',\n",
       " 'notch_signaling_inhibitor',\n",
       " 'nucleoside_reverse_transcriptase_inhibitor',\n",
       " 'oct_activator',\n",
       " 'omega_3_fatty_acid_stimulant',\n",
       " 'osteoclast_inhibitor',\n",
       " 'oxidosqualene_cyclase_inhibitor',\n",
       " 'oxytocin_receptor_agonist',\n",
       " 'oxytocin_receptor_antagonist',\n",
       " 'p21_activated_kinase_inhibitor',\n",
       " 'p53_activator',\n",
       " 'p53_inhibitor',\n",
       " 'paba_antagonist',\n",
       " 'pdk1_inhibitor',\n",
       " 'penicillin_binding_protein_inhibitor',\n",
       " 'peptidase_inhibitor',\n",
       " 'perk_inhibitor',\n",
       " 'phosphofructokinase_inhibitor',\n",
       " 'phospholipase_activator',\n",
       " 'pim_inhibitor',\n",
       " 'pka_inhibitor',\n",
       " 'plasminogen_activator_inhibitor',\n",
       " 'platelet_activating_factor_receptor_antagonist',\n",
       " 'platelet_aggregation_inhibitor',\n",
       " 'plk_inhibitor',\n",
       " 'porcupine_inhibitor',\n",
       " 'potassium_channel_agonist',\n",
       " 'potassium_channel_blocker',\n",
       " 'prmt_inhibitor',\n",
       " 'progestogen_hormone',\n",
       " 'prolactin_inhibitor',\n",
       " 'prostacyclin_analog',\n",
       " 'prostanoid_receptor_agonist',\n",
       " 'protease_inhibitor',\n",
       " 'protein_kinase_activator',\n",
       " 'protein_synthesis_stimulant',\n",
       " 'psychoactive_drug',\n",
       " 'purine_antagonist',\n",
       " 'purinergic_receptor_antagonist',\n",
       " 'quorum_sensing_signaling_modulator',\n",
       " 'rad51_inhibitor',\n",
       " 'receptor_tyrosine_protein_kinase_inhibitor',\n",
       " 'reducing_agent',\n",
       " 'ret_inhibitor',\n",
       " 'ret_tyrosine_kinase_inhibitor',\n",
       " 'reverse_transcriptase_inhibitor',\n",
       " 'ribosomal_protein_inhibitor',\n",
       " 'rna_synthesis_inhibitor',\n",
       " 'ror_inverse_agonist',\n",
       " 'rsv_fusion_inhibitor',\n",
       " 'sars_coronavirus_3c-like_protease_inhibitor',\n",
       " 'sedative',\n",
       " 'selective_estrogen_receptor_modulator_(serm)',\n",
       " 'selective_serotonin_reuptake_inhibitor_(ssri)',\n",
       " 'serine_protease_inhibitor',\n",
       " 'serine_threonine_kinase_inhibitor',\n",
       " 'serotonin_release_inhibitor',\n",
       " 'sirt_activator',\n",
       " 'sirt_inhibitor',\n",
       " 'smoothened_receptor_agonist',\n",
       " 'sodium_calcium_exchange_inhibitor',\n",
       " 'sodium_channel_activator',\n",
       " 'sodium_channel_blocker',\n",
       " 'somatostatin_receptor_agonist',\n",
       " 'sphingosine_1_phosphate_receptor_agonist',\n",
       " 'sphingosine_kinase_inhibitor',\n",
       " 'srebp_inhibitor',\n",
       " 'stat_inhibitor',\n",
       " 'steroid_sulfatase_inhibitor',\n",
       " 'steroidal_progestin',\n",
       " 'sterol_demethylase_inhibitor',\n",
       " 'steryl_sulfatase_inhibitor',\n",
       " 'structural_glycoprotein_antagonist',\n",
       " 'succinimide_antiepileptic',\n",
       " 't_cell_inhibitor',\n",
       " 'tankyrase_inhibitor',\n",
       " 'telomerase_inhibitor',\n",
       " 'testosterone_receptor_antagonist',\n",
       " 'thiazide_diuretic',\n",
       " 'thrombopoietin_receptor_agonist',\n",
       " 'thromboxane_receptor_antagonist',\n",
       " 'thromboxane_synthase_inhibitor',\n",
       " 'thyroid_hormone_inhibitor',\n",
       " 'thyroid_hormone_stimulant',\n",
       " 'thyrotropin_releasing_hormone_receptor_agonist',\n",
       " 'tissue_transglutaminase_inhibitor',\n",
       " 'topical_sunscreen_agent',\n",
       " 'trace_amine_associated_receptor_agonist',\n",
       " 'triacylglycerol_lipase_inhibitor',\n",
       " 'tricyclic_antidepressant',\n",
       " 'tryptophan_hydroxylase_inhibitor',\n",
       " 'tyrosinase_inhibitor',\n",
       " 'tyrosine_hydroxylase_inhibitor',\n",
       " 'tyrosine_phosphatase_inhibitor',\n",
       " 'ubiquitin-conjugating_enzyme_inhibitor',\n",
       " 'urease_inhibitor',\n",
       " 'uricase_inhibitor',\n",
       " 'uricosuric',\n",
       " 'urotensin_receptor_antagonist',\n",
       " 'vasoconstrictor',\n",
       " 'vasodilator',\n",
       " 'vasopressin_receptor_agonist',\n",
       " 'vasopressin_receptor_antagonist',\n",
       " 've-cadherin_antagonist',\n",
       " 'vesicular_monoamine_transporter_inhibitor',\n",
       " 'vitamin_k_antagonist',\n",
       " 'voltage-gated_potassium_channel_activator',\n",
       " 'voltage-gated_sodium_channel_blocker',\n",
       " 'wdr5_mll_interaction_inhibitor',\n",
       " 'xanthine_oxidase_inhibitor',\n",
       " 'xiap_inhibitor']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonscored_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:02.564050Z",
     "iopub.status.busy": "2020-11-26T05:40:02.562960Z",
     "iopub.status.idle": "2020-11-26T05:40:03.022693Z",
     "shell.execute_reply": "2020-11-26T05:40:03.023417Z"
    },
    "papermill": {
     "duration": 0.889915,
     "end_time": "2020-11-26T05:40:03.023643",
     "exception": false,
     "start_time": "2020-11-26T05:40:02.133728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle(f\"{INT_DIR}/{NB}-train_nonscore_pred.pkl\")\n",
    "test = pd.read_pickle(f\"{INT_DIR}/{NB}-test_nonscore_pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:03.707055Z",
     "iopub.status.busy": "2020-11-26T05:40:03.705517Z",
     "iopub.status.idle": "2020-11-26T05:40:04.283291Z",
     "shell.execute_reply": "2020-11-26T05:40:04.282677Z"
    },
    "papermill": {
     "duration": 0.869438,
     "end_time": "2020-11-26T05:40:04.283456",
     "exception": false,
     "start_time": "2020-11-26T05:40:03.414018",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use nonscored target in the given file as feature\n",
    "# if comment out below, use predicted nonscored target\n",
    "# train = train.drop(nonscored_target, axis=1)\n",
    "# train = train.merge(train_targets_nonscored, on=\"sig_id\")\n",
    "# train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train.merge(train_targets_scored, on='sig_id')\n",
    "# train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "# test = test[test['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "# target = train[train_targets_scored.columns]\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:04.865551Z",
     "iopub.status.busy": "2020-11-26T05:40:04.864402Z",
     "iopub.status.idle": "2020-11-26T05:40:08.872837Z",
     "shell.execute_reply": "2020-11-26T05:40:08.872145Z"
    },
    "papermill": {
     "duration": 4.307941,
     "end_time": "2020-11-26T05:40:08.872977",
     "exception": false,
     "start_time": "2020-11-26T05:40:04.565036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "for col in (nonscored_target):\n",
    "\n",
    "    vec_len = len(train[col].values)\n",
    "    vec_len_test = len(test[col].values)\n",
    "    raw_vec = train[col].values.reshape(vec_len, 1)\n",
    "    if IS_TRAIN:\n",
    "        transformer = QuantileTransformer(n_quantiles=100, random_state=0, output_distribution=\"normal\")\n",
    "        transformer.fit(raw_vec)\n",
    "        pd.to_pickle(transformer, f\"{MODEL_DIR}/{NB}_{col}_quantile_nonscored.pkl\")\n",
    "    else:\n",
    "        transformer = pd.read_pickle(f\"{MODEL_DIR}/{NB}_{col}_quantile_nonscored.pkl\")\n",
    "\n",
    "    train[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test[col] = transformer.transform(test[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:09.653694Z",
     "iopub.status.busy": "2020-11-26T05:40:09.652673Z",
     "iopub.status.idle": "2020-11-26T05:40:09.658705Z",
     "shell.execute_reply": "2020-11-26T05:40:09.657606Z"
    },
    "papermill": {
     "duration": 0.445001,
     "end_time": "2020-11-26T05:40:09.658873",
     "exception": false,
     "start_time": "2020-11-26T05:40:09.213872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:10.591487Z",
     "iopub.status.busy": "2020-11-26T05:40:10.590370Z",
     "iopub.status.idle": "2020-11-26T05:40:10.646480Z",
     "shell.execute_reply": "2020-11-26T05:40:10.647818Z"
    },
    "papermill": {
     "duration": 0.537008,
     "end_time": "2020-11-26T05:40:10.648040",
     "exception": false,
     "start_time": "2020-11-26T05:40:10.111032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.146806</td>\n",
       "      <td>0.902075</td>\n",
       "      <td>-0.418339</td>\n",
       "      <td>-0.961202</td>\n",
       "      <td>-0.254770</td>\n",
       "      <td>-1.021300</td>\n",
       "      <td>-1.369236</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.128824</td>\n",
       "      <td>0.676862</td>\n",
       "      <td>0.274345</td>\n",
       "      <td>0.090495</td>\n",
       "      <td>1.208863</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>0.316734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.790372</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>1.428097</td>\n",
       "      <td>-0.121817</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>1.495091</td>\n",
       "      <td>0.238763</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.729866</td>\n",
       "      <td>-0.277163</td>\n",
       "      <td>-0.441200</td>\n",
       "      <td>0.766612</td>\n",
       "      <td>2.347817</td>\n",
       "      <td>-0.862761</td>\n",
       "      <td>-2.308829</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.444558</td>\n",
       "      <td>-0.481202</td>\n",
       "      <td>0.974729</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>1.468304</td>\n",
       "      <td>-0.874772</td>\n",
       "      <td>-0.372682</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.247623</td>\n",
       "      <td>-1.231184</td>\n",
       "      <td>0.221572</td>\n",
       "      <td>-0.354096</td>\n",
       "      <td>-0.332073</td>\n",
       "      <td>0.570635</td>\n",
       "      <td>-0.150125</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.217613</td>\n",
       "      <td>-0.027031</td>\n",
       "      <td>-0.237430</td>\n",
       "      <td>-0.787215</td>\n",
       "      <td>-0.677817</td>\n",
       "      <td>0.919474</td>\n",
       "      <td>0.742866</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.914666</td>\n",
       "      <td>0.581880</td>\n",
       "      <td>-0.588706</td>\n",
       "      <td>1.303439</td>\n",
       "      <td>-1.009079</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>-0.302814</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.826302</td>\n",
       "      <td>0.411235</td>\n",
       "      <td>0.433297</td>\n",
       "      <td>0.307575</td>\n",
       "      <td>1.075324</td>\n",
       "      <td>-0.024425</td>\n",
       "      <td>0.051483</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.245739</td>\n",
       "      <td>1.567230</td>\n",
       "      <td>-0.269829</td>\n",
       "      <td>1.092958</td>\n",
       "      <td>-0.515819</td>\n",
       "      <td>-2.091765</td>\n",
       "      <td>-1.627645</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1622 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  cp_time cp_dose       g-0       g-1       g-2       g-3  \\\n",
       "0      id_000644bb2       24      D1  1.146806  0.902075 -0.418339 -0.961202   \n",
       "1      id_000779bfc       72      D1  0.128824  0.676862  0.274345  0.090495   \n",
       "2      id_000a6266a       48      D1  0.790372  0.939951  1.428097 -0.121817   \n",
       "3      id_0015fd391       48      D1 -0.729866 -0.277163 -0.441200  0.766612   \n",
       "4      id_001626bd3       72      D2 -0.444558 -0.481202  0.974729  0.977467   \n",
       "...             ...      ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444       72      D1  0.247623 -1.231184  0.221572 -0.354096   \n",
       "21944  id_fffb1ceed       24      D2  0.217613 -0.027031 -0.237430 -0.787215   \n",
       "21945  id_fffb70c0c       24      D2 -1.914666  0.581880 -0.588706  1.303439   \n",
       "21946  id_fffcb9e7c       24      D1  0.826302  0.411235  0.433297  0.307575   \n",
       "21947  id_ffffdd77b       72      D1 -1.245739  1.567230 -0.269829  1.092958   \n",
       "\n",
       "            g-4       g-5       g-6  ...  \\\n",
       "0     -0.254770 -1.021300 -1.369236  ...   \n",
       "1      1.208863  0.688965  0.316734  ...   \n",
       "2     -0.002067  1.495091  0.238763  ...   \n",
       "3      2.347817 -0.862761 -2.308829  ...   \n",
       "4      1.468304 -0.874772 -0.372682  ...   \n",
       "...         ...       ...       ...  ...   \n",
       "21943 -0.332073  0.570635 -0.150125  ...   \n",
       "21944 -0.677817  0.919474  0.742866  ...   \n",
       "21945 -1.009079  0.852202 -0.302814  ...   \n",
       "21946  1.075324 -0.024425  0.051483  ...   \n",
       "21947 -0.515819 -2.091765 -1.627645  ...   \n",
       "\n",
       "       tropomyosin_receptor_kinase_inhibitor  trpv_agonist  trpv_antagonist  \\\n",
       "0                                          0             0                0   \n",
       "1                                          0             0                0   \n",
       "2                                          0             0                0   \n",
       "3                                          0             0                0   \n",
       "4                                          0             0                0   \n",
       "...                                      ...           ...              ...   \n",
       "21943                                      0             0                0   \n",
       "21944                                      0             0                0   \n",
       "21945                                      0             0                0   \n",
       "21946                                      0             0                0   \n",
       "21947                                      0             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "21943                  0                          0   \n",
       "21944                  0                          0   \n",
       "21945                  0                          0   \n",
       "21946                  0                          0   \n",
       "21947                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                      0                0          0   \n",
       "21944                                      0                0          0   \n",
       "21945                                      0                0          0   \n",
       "21946                                      0                0          0   \n",
       "21947                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                               0              0  \n",
       "1                               0              0  \n",
       "2                               0              0  \n",
       "3                               0              0  \n",
       "4                               0              0  \n",
       "...                           ...            ...  \n",
       "21943                           0              0  \n",
       "21944                           0              0  \n",
       "21945                           0              0  \n",
       "21946                           0              0  \n",
       "21947                           0              0  \n",
       "\n",
       "[21948 rows x 1622 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:11.348840Z",
     "iopub.status.busy": "2020-11-26T05:40:11.347393Z",
     "iopub.status.idle": "2020-11-26T05:40:15.029908Z",
     "shell.execute_reply": "2020-11-26T05:40:15.030560Z"
    },
    "papermill": {
     "duration": 4.014318,
     "end_time": "2020-11-26T05:40:15.030729",
     "exception": false,
     "start_time": "2020-11-26T05:40:11.016411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=False, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.146806</td>\n",
       "      <td>0.902075</td>\n",
       "      <td>-0.418339</td>\n",
       "      <td>-0.961202</td>\n",
       "      <td>-0.254770</td>\n",
       "      <td>-1.021300</td>\n",
       "      <td>-1.369236</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.128824</td>\n",
       "      <td>0.676862</td>\n",
       "      <td>0.274345</td>\n",
       "      <td>0.090495</td>\n",
       "      <td>1.208863</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>0.316734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.790372</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>1.428097</td>\n",
       "      <td>-0.121817</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>1.495091</td>\n",
       "      <td>0.238763</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.729866</td>\n",
       "      <td>-0.277163</td>\n",
       "      <td>-0.441200</td>\n",
       "      <td>0.766612</td>\n",
       "      <td>2.347817</td>\n",
       "      <td>-0.862761</td>\n",
       "      <td>-2.308829</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.444558</td>\n",
       "      <td>-0.481202</td>\n",
       "      <td>0.974729</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>1.468304</td>\n",
       "      <td>-0.874772</td>\n",
       "      <td>-0.372682</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.247623</td>\n",
       "      <td>-1.231184</td>\n",
       "      <td>0.221572</td>\n",
       "      <td>-0.354096</td>\n",
       "      <td>-0.332073</td>\n",
       "      <td>0.570635</td>\n",
       "      <td>-0.150125</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.217613</td>\n",
       "      <td>-0.027031</td>\n",
       "      <td>-0.237430</td>\n",
       "      <td>-0.787215</td>\n",
       "      <td>-0.677817</td>\n",
       "      <td>0.919474</td>\n",
       "      <td>0.742866</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.914666</td>\n",
       "      <td>0.581880</td>\n",
       "      <td>-0.588706</td>\n",
       "      <td>1.303439</td>\n",
       "      <td>-1.009079</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>-0.302814</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.826302</td>\n",
       "      <td>0.411235</td>\n",
       "      <td>0.433297</td>\n",
       "      <td>0.307575</td>\n",
       "      <td>1.075324</td>\n",
       "      <td>-0.024425</td>\n",
       "      <td>0.051483</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.245739</td>\n",
       "      <td>1.567230</td>\n",
       "      <td>-0.269829</td>\n",
       "      <td>1.092958</td>\n",
       "      <td>-0.515819</td>\n",
       "      <td>-2.091765</td>\n",
       "      <td>-1.627645</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1623 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  cp_time cp_dose       g-0       g-1       g-2       g-3  \\\n",
       "0      id_000644bb2       24      D1  1.146806  0.902075 -0.418339 -0.961202   \n",
       "1      id_000779bfc       72      D1  0.128824  0.676862  0.274345  0.090495   \n",
       "2      id_000a6266a       48      D1  0.790372  0.939951  1.428097 -0.121817   \n",
       "3      id_0015fd391       48      D1 -0.729866 -0.277163 -0.441200  0.766612   \n",
       "4      id_001626bd3       72      D2 -0.444558 -0.481202  0.974729  0.977467   \n",
       "...             ...      ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444       72      D1  0.247623 -1.231184  0.221572 -0.354096   \n",
       "21944  id_fffb1ceed       24      D2  0.217613 -0.027031 -0.237430 -0.787215   \n",
       "21945  id_fffb70c0c       24      D2 -1.914666  0.581880 -0.588706  1.303439   \n",
       "21946  id_fffcb9e7c       24      D1  0.826302  0.411235  0.433297  0.307575   \n",
       "21947  id_ffffdd77b       72      D1 -1.245739  1.567230 -0.269829  1.092958   \n",
       "\n",
       "            g-4       g-5       g-6  ...  trpv_agonist  trpv_antagonist  \\\n",
       "0     -0.254770 -1.021300 -1.369236  ...             0                0   \n",
       "1      1.208863  0.688965  0.316734  ...             0                0   \n",
       "2     -0.002067  1.495091  0.238763  ...             0                0   \n",
       "3      2.347817 -0.862761 -2.308829  ...             0                0   \n",
       "4      1.468304 -0.874772 -0.372682  ...             0                0   \n",
       "...         ...       ...       ...  ...           ...              ...   \n",
       "21943 -0.332073  0.570635 -0.150125  ...             0                0   \n",
       "21944 -0.677817  0.919474  0.742866  ...             0                0   \n",
       "21945 -1.009079  0.852202 -0.302814  ...             0                0   \n",
       "21946  1.075324 -0.024425  0.051483  ...             0                0   \n",
       "21947 -0.515819 -2.091765 -1.627645  ...             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "21943                  0                          0   \n",
       "21944                  0                          0   \n",
       "21945                  0                          0   \n",
       "21946                  0                          0   \n",
       "21947                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                      0                0          0   \n",
       "21944                                      0                0          0   \n",
       "21945                                      0                0          0   \n",
       "21946                                      0                0          0   \n",
       "21947                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  kfold  \n",
       "0                               0              0      4  \n",
       "1                               0              0      4  \n",
       "2                               0              0      4  \n",
       "3                               0              0      4  \n",
       "4                               0              0      3  \n",
       "...                           ...            ...    ...  \n",
       "21943                           0              0      4  \n",
       "21944                           0              0      0  \n",
       "21945                           0              0      1  \n",
       "21946                           0              0      1  \n",
       "21947                           0              0      4  \n",
       "\n",
       "[21948 rows x 1623 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=NFOLDS)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:15.656087Z",
     "iopub.status.busy": "2020-11-26T05:40:15.655094Z",
     "iopub.status.idle": "2020-11-26T05:40:15.658947Z",
     "shell.execute_reply": "2020-11-26T05:40:15.656745Z"
    },
    "papermill": {
     "duration": 0.297372,
     "end_time": "2020-11-26T05:40:15.659108",
     "exception": false,
     "start_time": "2020-11-26T05:40:15.361736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1622)\n",
      "(21948, 1623)\n",
      "(3624, 1416)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:16.246436Z",
     "iopub.status.busy": "2020-11-26T05:40:16.245313Z",
     "iopub.status.idle": "2020-11-26T05:40:16.248611Z",
     "shell.execute_reply": "2020-11-26T05:40:16.248040Z"
    },
    "papermill": {
     "duration": 0.304774,
     "end_time": "2020-11-26T05:40:16.248739",
     "exception": false,
     "start_time": "2020-11-26T05:40:15.943965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    \n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "#     data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "#     data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "\n",
    "# --------------------- Normalize ---------------------\n",
    "#     for col in GENES:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#     for col in CELLS:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#--------------------- Removing Skewness ---------------------\n",
    "#     for col in GENES + CELLS:\n",
    "#         if(abs(data[col].skew()) > 0.75):\n",
    "            \n",
    "#             if(data[col].skew() < 0): # neg-skewness\n",
    "#                 data[col] = data[col].max() - data[col] + 1\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "            \n",
    "#             else:\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:16.867521Z",
     "iopub.status.busy": "2020-11-26T05:40:16.865976Z",
     "iopub.status.idle": "2020-11-26T05:40:17.070140Z",
     "shell.execute_reply": "2020-11-26T05:40:17.070740Z"
    },
    "papermill": {
     "duration": 0.52829,
     "end_time": "2020-11-26T05:40:17.070889",
     "exception": false,
     "start_time": "2020-11-26T05:40:16.542599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1418"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:17.675003Z",
     "iopub.status.busy": "2020-11-26T05:40:17.672841Z",
     "iopub.status.idle": "2020-11-26T05:40:17.675807Z",
     "shell.execute_reply": "2020-11-26T05:40:17.676377Z"
    },
    "papermill": {
     "duration": 0.296016,
     "end_time": "2020-11-26T05:40:17.676520",
     "exception": false,
     "start_time": "2020-11-26T05:40:17.380504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=2048\n",
    "# hidden_size=4096\n",
    "# hidden_size=9192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:18.279799Z",
     "iopub.status.busy": "2020-11-26T05:40:18.277743Z",
     "iopub.status.idle": "2020-11-26T05:40:18.280589Z",
     "shell.execute_reply": "2020-11-26T05:40:18.281147Z"
    },
    "papermill": {
     "duration": 0.31986,
     "end_time": "2020-11-26T05:40:18.281297",
     "exception": false,
     "start_time": "2020-11-26T05:40:17.961437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.2, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler,loss_fn,trainloader, DEVICE)\n",
    "        print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"SEED: {seed} ,FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"model/{NB}-scored1-SEED{seed}-FOLD{fold}_.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"model/{NB}-scored1-SEED{seed}-FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:18.862848Z",
     "iopub.status.busy": "2020-11-26T05:40:18.860747Z",
     "iopub.status.idle": "2020-11-26T05:40:18.863656Z",
     "shell.execute_reply": "2020-11-26T05:40:18.864217Z"
    },
    "papermill": {
     "duration": 0.296551,
     "end_time": "2020-11-26T05:40:18.864383",
     "exception": false,
     "start_time": "2020-11-26T05:40:18.567832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:19.480852Z",
     "iopub.status.busy": "2020-11-26T05:40:19.479059Z",
     "iopub.status.idle": "2020-11-26T06:01:11.744701Z",
     "shell.execute_reply": "2020-11-26T06:01:11.743449Z"
    },
    "papermill": {
     "duration": 1252.594071,
     "end_time": "2020-11-26T06:01:11.744849",
     "exception": false,
     "start_time": "2020-11-26T05:40:19.150778",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 940, FOLD: 0, EPOCH: 0, train_loss: 0.7134326108987781\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6106544733047485\n",
      "SEED: 940, FOLD: 0, EPOCH: 1, train_loss: 0.20464910828656907\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 1, valid_loss: 0.023062731967204146\n",
      "SEED: 940, FOLD: 0, EPOCH: 2, train_loss: 0.020830361496495163\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 2, valid_loss: 0.019220005669113662\n",
      "SEED: 940, FOLD: 0, EPOCH: 3, train_loss: 0.018650088162309883\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 3, valid_loss: 0.018326523765507672\n",
      "SEED: 940, FOLD: 0, EPOCH: 4, train_loss: 0.01793761108664499\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01863717448173298\n",
      "SEED: 940, FOLD: 0, EPOCH: 5, train_loss: 0.017398776554003143\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 5, valid_loss: 0.0172521504573524\n",
      "SEED: 940, FOLD: 0, EPOCH: 6, train_loss: 0.016641485558795757\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 6, valid_loss: 0.016687922231439088\n",
      "SEED: 940, FOLD: 0, EPOCH: 7, train_loss: 0.016411113390780014\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01761202183034685\n",
      "SEED: 940, FOLD: 0, EPOCH: 8, train_loss: 0.016321633928927822\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01682342557857434\n",
      "SEED: 940, FOLD: 0, EPOCH: 9, train_loss: 0.016250428473711876\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 9, valid_loss: 0.016527630233516295\n",
      "SEED: 940, FOLD: 0, EPOCH: 10, train_loss: 0.016087513956902683\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 10, valid_loss: 0.016459579165611003\n",
      "SEED: 940, FOLD: 0, EPOCH: 11, train_loss: 0.016026573984519295\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 11, valid_loss: 0.016491274452871747\n",
      "SEED: 940, FOLD: 0, EPOCH: 12, train_loss: 0.01589742557995993\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016391338935742777\n",
      "SEED: 940, FOLD: 0, EPOCH: 13, train_loss: 0.015699267022959564\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016213124566194084\n",
      "SEED: 940, FOLD: 0, EPOCH: 14, train_loss: 0.01553250855995693\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 14, valid_loss: 0.01617102237004373\n",
      "SEED: 940, FOLD: 0, EPOCH: 15, train_loss: 0.01532249110818341\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01613676470393936\n",
      "SEED: 940, FOLD: 0, EPOCH: 16, train_loss: 0.01497008718982123\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01600848888564441\n",
      "SEED: 940, FOLD: 0, EPOCH: 17, train_loss: 0.014685701389891514\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01587934476426906\n",
      "SEED: 940, FOLD: 0, EPOCH: 18, train_loss: 0.014197637205538542\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 18, valid_loss: 0.015983782553424437\n",
      "SEED: 940, FOLD: 0, EPOCH: 19, train_loss: 0.0137015368681455\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 19, valid_loss: 0.015769176443831787\n",
      "SEED: 940, FOLD: 0, EPOCH: 20, train_loss: 0.013056154011924198\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01577283912855718\n",
      "SEED: 940, FOLD: 0, EPOCH: 21, train_loss: 0.012306836784641811\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015738238684005208\n",
      "SEED: 940, FOLD: 0, EPOCH: 22, train_loss: 0.011648324763645296\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01568304483468334\n",
      "SEED: 940, FOLD: 0, EPOCH: 23, train_loss: 0.011113541916120743\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01568599407457643\n",
      "SEED: 940, FOLD: 0, EPOCH: 24, train_loss: 0.010947175148496593\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01567678267343177\n",
      "SEED: 940, FOLD: 1, EPOCH: 0, train_loss: 0.7134977976481119\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6053493950102065\n",
      "SEED: 940, FOLD: 1, EPOCH: 1, train_loss: 0.20471999664669452\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 1, valid_loss: 0.024500880493885942\n",
      "SEED: 940, FOLD: 1, EPOCH: 2, train_loss: 0.021247294663951016\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 2, valid_loss: 0.01929912943806913\n",
      "SEED: 940, FOLD: 1, EPOCH: 3, train_loss: 0.018950644502605217\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018286644481122494\n",
      "SEED: 940, FOLD: 1, EPOCH: 4, train_loss: 0.017905195932025494\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01747504776964585\n",
      "SEED: 940, FOLD: 1, EPOCH: 5, train_loss: 0.01713058271485826\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 5, valid_loss: 0.0171204244510995\n",
      "SEED: 940, FOLD: 1, EPOCH: 6, train_loss: 0.016584696855558002\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01712264037794537\n",
      "SEED: 940, FOLD: 1, EPOCH: 7, train_loss: 0.01632629796538664\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 7, valid_loss: 0.016757679275340505\n",
      "SEED: 940, FOLD: 1, EPOCH: 8, train_loss: 0.016341424479648686\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01825668952531285\n",
      "SEED: 940, FOLD: 1, EPOCH: 9, train_loss: 0.01625022212502317\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 9, valid_loss: 0.016570419900947146\n",
      "SEED: 940, FOLD: 1, EPOCH: 10, train_loss: 0.01613888641198476\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01632651872932911\n",
      "SEED: 940, FOLD: 1, EPOCH: 11, train_loss: 0.016024461137535778\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01653020332256953\n",
      "SEED: 940, FOLD: 1, EPOCH: 12, train_loss: 0.015957803789364254\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01646690981255637\n",
      "SEED: 940, FOLD: 1, EPOCH: 13, train_loss: 0.015759217323384422\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01627176943131619\n",
      "SEED: 940, FOLD: 1, EPOCH: 14, train_loss: 0.01558171411085388\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016349929177926645\n",
      "SEED: 940, FOLD: 1, EPOCH: 15, train_loss: 0.015420034635758055\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01609091315832403\n",
      "SEED: 940, FOLD: 1, EPOCH: 16, train_loss: 0.015062569910525412\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 16, valid_loss: 0.01596587063330743\n",
      "SEED: 940, FOLD: 1, EPOCH: 17, train_loss: 0.014691139058466408\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016032787298576698\n",
      "SEED: 940, FOLD: 1, EPOCH: 18, train_loss: 0.014311236842278984\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 18, valid_loss: 0.0159300714213815\n",
      "SEED: 940, FOLD: 1, EPOCH: 19, train_loss: 0.013755569693402967\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 19, valid_loss: 0.015800219339629013\n",
      "SEED: 940, FOLD: 1, EPOCH: 20, train_loss: 0.01309538319490958\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 20, valid_loss: 0.015705061248607106\n",
      "SEED: 940, FOLD: 1, EPOCH: 21, train_loss: 0.012396770097531271\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015635657952063613\n",
      "SEED: 940, FOLD: 1, EPOCH: 22, train_loss: 0.011728190263544304\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015667713350719877\n",
      "SEED: 940, FOLD: 1, EPOCH: 23, train_loss: 0.011214629166584084\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015670241322368383\n",
      "SEED: 940, FOLD: 1, EPOCH: 24, train_loss: 0.010993453768500383\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01566552645009425\n",
      "SEED: 940, FOLD: 2, EPOCH: 0, train_loss: 0.7131306131680807\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6142747037940555\n",
      "SEED: 940, FOLD: 2, EPOCH: 1, train_loss: 0.204502967307749\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 1, valid_loss: 0.022577246858014002\n",
      "SEED: 940, FOLD: 2, EPOCH: 2, train_loss: 0.021029448946532997\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 2, valid_loss: 0.01942209413068162\n",
      "SEED: 940, FOLD: 2, EPOCH: 3, train_loss: 0.01887836347779502\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01818795491837793\n",
      "SEED: 940, FOLD: 2, EPOCH: 4, train_loss: 0.017758123131225937\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01759237040662103\n",
      "SEED: 940, FOLD: 2, EPOCH: 5, train_loss: 0.019349188759815002\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 5, valid_loss: 0.021170380318330392\n",
      "SEED: 940, FOLD: 2, EPOCH: 6, train_loss: 0.017886142219430294\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017628938528812595\n",
      "SEED: 940, FOLD: 2, EPOCH: 7, train_loss: 0.01699367980810179\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01715423171925876\n",
      "SEED: 940, FOLD: 2, EPOCH: 8, train_loss: 0.016659059480804463\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01688224108268817\n",
      "SEED: 940, FOLD: 2, EPOCH: 9, train_loss: 0.0165134249659984\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01667245239433315\n",
      "SEED: 940, FOLD: 2, EPOCH: 10, train_loss: 0.016272198206380657\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 10, valid_loss: 0.016771336344795093\n",
      "SEED: 940, FOLD: 2, EPOCH: 11, train_loss: 0.016164314298742058\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016623282339423895\n",
      "SEED: 940, FOLD: 2, EPOCH: 12, train_loss: 0.01604366413169149\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016602186900046136\n",
      "SEED: 940, FOLD: 2, EPOCH: 13, train_loss: 0.015946971832950046\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01642785971570346\n",
      "SEED: 940, FOLD: 2, EPOCH: 14, train_loss: 0.015697311434516872\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01649399919228421\n",
      "SEED: 940, FOLD: 2, EPOCH: 15, train_loss: 0.015450837198590887\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016284913911173742\n",
      "SEED: 940, FOLD: 2, EPOCH: 16, train_loss: 0.015177991956580376\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016261014052563243\n",
      "SEED: 940, FOLD: 2, EPOCH: 17, train_loss: 0.014837239625985208\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01617451539884011\n",
      "SEED: 940, FOLD: 2, EPOCH: 18, train_loss: 0.014386279818912348\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016165453164527815\n",
      "SEED: 940, FOLD: 2, EPOCH: 19, train_loss: 0.01387262661549924\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016130182581643265\n",
      "SEED: 940, FOLD: 2, EPOCH: 20, train_loss: 0.013229790521596653\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01610044612445765\n",
      "SEED: 940, FOLD: 2, EPOCH: 21, train_loss: 0.012489536561179852\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016051213153534465\n",
      "SEED: 940, FOLD: 2, EPOCH: 22, train_loss: 0.011812524640581745\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01606251314903299\n",
      "SEED: 940, FOLD: 2, EPOCH: 23, train_loss: 0.011329541846677877\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 23, valid_loss: 0.016033000364485715\n",
      "SEED: 940, FOLD: 2, EPOCH: 24, train_loss: 0.01107032761733601\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016063177544209693\n",
      "SEED: 940, FOLD: 3, EPOCH: 0, train_loss: 0.7134175810261049\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6114772260189056\n",
      "SEED: 940, FOLD: 3, EPOCH: 1, train_loss: 0.2048828332428483\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 1, valid_loss: 0.02311809878382418\n",
      "SEED: 940, FOLD: 3, EPOCH: 2, train_loss: 0.021097804271224617\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 2, valid_loss: 0.019603414978418086\n",
      "SEED: 940, FOLD: 3, EPOCH: 3, train_loss: 0.01880942730476027\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 3, valid_loss: 0.01861150386846728\n",
      "SEED: 940, FOLD: 3, EPOCH: 4, train_loss: 0.017896697573039844\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017632175133460097\n",
      "SEED: 940, FOLD: 3, EPOCH: 5, train_loss: 0.01711901381233896\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017821810725662444\n",
      "SEED: 940, FOLD: 3, EPOCH: 6, train_loss: 0.017992581902206806\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017460326405449048\n",
      "SEED: 940, FOLD: 3, EPOCH: 7, train_loss: 0.016768010198206142\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 7, valid_loss: 0.016993292814327612\n",
      "SEED: 940, FOLD: 3, EPOCH: 8, train_loss: 0.016373955860626007\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 8, valid_loss: 0.016918769623670313\n",
      "SEED: 940, FOLD: 3, EPOCH: 9, train_loss: 0.01628701183674992\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01686391555186775\n",
      "SEED: 940, FOLD: 3, EPOCH: 10, train_loss: 0.01619712823489006\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016782982430110376\n",
      "SEED: 940, FOLD: 3, EPOCH: 11, train_loss: 0.016055700004748676\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016897668027215533\n",
      "SEED: 940, FOLD: 3, EPOCH: 12, train_loss: 0.015952960790499397\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 12, valid_loss: 0.0165605788740019\n",
      "SEED: 940, FOLD: 3, EPOCH: 13, train_loss: 0.015746883265134216\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016550901138948068\n",
      "SEED: 940, FOLD: 3, EPOCH: 14, train_loss: 0.015723386414996956\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016502305658327207\n",
      "SEED: 940, FOLD: 3, EPOCH: 15, train_loss: 0.015391826737618101\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016338927826533716\n",
      "SEED: 940, FOLD: 3, EPOCH: 16, train_loss: 0.015178332955616972\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016192731602738302\n",
      "SEED: 940, FOLD: 3, EPOCH: 17, train_loss: 0.014828344874515913\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01613235840987828\n",
      "SEED: 940, FOLD: 3, EPOCH: 18, train_loss: 0.014373508093041786\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 18, valid_loss: 0.015977082670562796\n",
      "SEED: 940, FOLD: 3, EPOCH: 19, train_loss: 0.013850701028022213\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 19, valid_loss: 0.015943872794095013\n",
      "SEED: 940, FOLD: 3, EPOCH: 20, train_loss: 0.01324277700505395\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 20, valid_loss: 0.015937832908497915\n",
      "SEED: 940, FOLD: 3, EPOCH: 21, train_loss: 0.012565310032147428\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 21, valid_loss: 0.015810157275862165\n",
      "SEED: 940, FOLD: 3, EPOCH: 22, train_loss: 0.011859084506505642\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 22, valid_loss: 0.015832091371218365\n",
      "SEED: 940, FOLD: 3, EPOCH: 23, train_loss: 0.01139457185037326\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 23, valid_loss: 0.015822195034060214\n",
      "SEED: 940, FOLD: 3, EPOCH: 24, train_loss: 0.011137114446340263\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 24, valid_loss: 0.015820030795617238\n",
      "SEED: 940, FOLD: 4, EPOCH: 0, train_loss: 0.713047660779262\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 0, valid_loss: 0.5989119907220205\n",
      "SEED: 940, FOLD: 4, EPOCH: 1, train_loss: 0.20496443229848924\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 1, valid_loss: 0.024422999057504866\n",
      "SEED: 940, FOLD: 4, EPOCH: 2, train_loss: 0.02080208114415839\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 2, valid_loss: 0.019366849938200578\n",
      "SEED: 940, FOLD: 4, EPOCH: 3, train_loss: 0.01885523568784845\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 3, valid_loss: 0.018344401174949274\n",
      "SEED: 940, FOLD: 4, EPOCH: 4, train_loss: 0.01782580833558155\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 4, valid_loss: 0.018274240299231477\n",
      "SEED: 940, FOLD: 4, EPOCH: 5, train_loss: 0.019958053351096485\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017978710122406483\n",
      "SEED: 940, FOLD: 4, EPOCH: 6, train_loss: 0.01747632526077222\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01714347530570295\n",
      "SEED: 940, FOLD: 4, EPOCH: 7, train_loss: 0.016848706329862278\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 7, valid_loss: 0.016880643502291705\n",
      "SEED: 940, FOLD: 4, EPOCH: 8, train_loss: 0.01650140542482984\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 8, valid_loss: 0.016814297944721248\n",
      "SEED: 940, FOLD: 4, EPOCH: 9, train_loss: 0.016358967816484146\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 9, valid_loss: 0.016563147616883118\n",
      "SEED: 940, FOLD: 4, EPOCH: 10, train_loss: 0.016175165138058903\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01658219802710745\n",
      "SEED: 940, FOLD: 4, EPOCH: 11, train_loss: 0.016130844967952675\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016477201082226303\n",
      "SEED: 940, FOLD: 4, EPOCH: 12, train_loss: 0.015955590319050396\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016438294616010454\n",
      "SEED: 940, FOLD: 4, EPOCH: 13, train_loss: 0.015723895403030125\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016181712297515735\n",
      "SEED: 940, FOLD: 4, EPOCH: 14, train_loss: 0.015623981106108513\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016387740150094032\n",
      "SEED: 940, FOLD: 4, EPOCH: 15, train_loss: 0.015399083225191504\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016207816182739206\n",
      "SEED: 940, FOLD: 4, EPOCH: 16, train_loss: 0.015070366808145807\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01603270560089085\n",
      "SEED: 940, FOLD: 4, EPOCH: 17, train_loss: 0.014715008613100086\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01596498339333468\n",
      "SEED: 940, FOLD: 4, EPOCH: 18, train_loss: 0.014270322964243267\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01581241599180632\n",
      "SEED: 940, FOLD: 4, EPOCH: 19, train_loss: 0.013713026527261389\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 19, valid_loss: 0.015865986545880634\n",
      "SEED: 940, FOLD: 4, EPOCH: 20, train_loss: 0.013100418640111668\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 20, valid_loss: 0.015768919191840623\n",
      "SEED: 940, FOLD: 4, EPOCH: 21, train_loss: 0.012371468411731546\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 21, valid_loss: 0.0157671463675797\n",
      "SEED: 940, FOLD: 4, EPOCH: 22, train_loss: 0.011656257863817871\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01577093421171109\n",
      "SEED: 940, FOLD: 4, EPOCH: 23, train_loss: 0.011159393774426502\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 23, valid_loss: 0.015781063431253035\n",
      "SEED: 940, FOLD: 4, EPOCH: 24, train_loss: 0.01091501736284598\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015777072714020807\n",
      "elapsed time: 208.89256191253662\n",
      "SEED: 1513, FOLD: 0, EPOCH: 0, train_loss: 0.712071380753448\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6024441321690878\n",
      "SEED: 1513, FOLD: 0, EPOCH: 1, train_loss: 0.20331494310411855\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 1, valid_loss: 0.023136003356840875\n",
      "SEED: 1513, FOLD: 0, EPOCH: 2, train_loss: 0.020880116338747135\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 2, valid_loss: 0.019221116219543748\n",
      "SEED: 1513, FOLD: 0, EPOCH: 3, train_loss: 0.01872482312762219\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 3, valid_loss: 0.0180584403893186\n",
      "SEED: 1513, FOLD: 0, EPOCH: 4, train_loss: 0.01793256080776885\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 4, valid_loss: 0.018543481309380796\n",
      "SEED: 1513, FOLD: 0, EPOCH: 5, train_loss: 0.017185795957735485\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017073779108209744\n",
      "SEED: 1513, FOLD: 0, EPOCH: 6, train_loss: 0.01656590484460627\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01700141482676069\n",
      "SEED: 1513, FOLD: 0, EPOCH: 7, train_loss: 0.016362047578761543\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01667597232800391\n",
      "SEED: 1513, FOLD: 0, EPOCH: 8, train_loss: 0.016292683645219044\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 8, valid_loss: 0.022398480369398992\n",
      "SEED: 1513, FOLD: 0, EPOCH: 9, train_loss: 0.016323770733847134\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 9, valid_loss: 0.016756554341150656\n",
      "SEED: 1513, FOLD: 0, EPOCH: 10, train_loss: 0.01613675879881434\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01650426671322849\n",
      "SEED: 1513, FOLD: 0, EPOCH: 11, train_loss: 0.016028613459480846\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01657582229624192\n",
      "SEED: 1513, FOLD: 0, EPOCH: 12, train_loss: 0.015893104162229145\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016403604661011033\n",
      "SEED: 1513, FOLD: 0, EPOCH: 13, train_loss: 0.015794909896625988\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016314247623085976\n",
      "SEED: 1513, FOLD: 0, EPOCH: 14, train_loss: 0.015564106053848198\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016164872329682112\n",
      "SEED: 1513, FOLD: 0, EPOCH: 15, train_loss: 0.015378606195251146\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016234822002136044\n",
      "SEED: 1513, FOLD: 0, EPOCH: 16, train_loss: 0.015117908598504204\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016010709572583437\n",
      "SEED: 1513, FOLD: 0, EPOCH: 17, train_loss: 0.01471488184525051\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 17, valid_loss: 0.015875387626389664\n",
      "SEED: 1513, FOLD: 0, EPOCH: 18, train_loss: 0.014264819590185863\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 18, valid_loss: 0.01576033581255211\n",
      "SEED: 1513, FOLD: 0, EPOCH: 19, train_loss: 0.01374285827404347\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01572969400634368\n",
      "SEED: 1513, FOLD: 0, EPOCH: 20, train_loss: 0.013107652236046135\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 20, valid_loss: 0.015686626753045455\n",
      "SEED: 1513, FOLD: 0, EPOCH: 21, train_loss: 0.012455283502197784\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015685700294044282\n",
      "SEED: 1513, FOLD: 0, EPOCH: 22, train_loss: 0.011770884641378687\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015658638077891536\n",
      "SEED: 1513, FOLD: 0, EPOCH: 23, train_loss: 0.011252738224963347\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015663368420468435\n",
      "SEED: 1513, FOLD: 0, EPOCH: 24, train_loss: 0.01102804047042045\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015659896553390555\n",
      "SEED: 1513, FOLD: 1, EPOCH: 0, train_loss: 0.7127753625745359\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6135145823160807\n",
      "SEED: 1513, FOLD: 1, EPOCH: 1, train_loss: 0.20492696160099644\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 1, valid_loss: 0.023816440150969558\n",
      "SEED: 1513, FOLD: 1, EPOCH: 2, train_loss: 0.020962039521638897\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 2, valid_loss: 0.01935511775728729\n",
      "SEED: 1513, FOLD: 1, EPOCH: 3, train_loss: 0.018770821743469307\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 3, valid_loss: 0.01825860059923596\n",
      "SEED: 1513, FOLD: 1, EPOCH: 4, train_loss: 0.017862198010518932\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017483919031090207\n",
      "SEED: 1513, FOLD: 1, EPOCH: 5, train_loss: 0.017166335284170033\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017329281609919336\n",
      "SEED: 1513, FOLD: 1, EPOCH: 6, train_loss: 0.01667780246909546\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017178827793233924\n",
      "SEED: 1513, FOLD: 1, EPOCH: 7, train_loss: 0.01653657568807619\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 7, valid_loss: 0.016713795976506338\n",
      "SEED: 1513, FOLD: 1, EPOCH: 8, train_loss: 0.016560501958904923\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 8, valid_loss: 0.016711339664955933\n",
      "SEED: 1513, FOLD: 1, EPOCH: 9, train_loss: 0.016328938872269962\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01675142492685053\n",
      "SEED: 1513, FOLD: 1, EPOCH: 10, train_loss: 0.01618194688057554\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016531840587655704\n",
      "SEED: 1513, FOLD: 1, EPOCH: 11, train_loss: 0.01612327847143878\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016406133615722258\n",
      "SEED: 1513, FOLD: 1, EPOCH: 12, train_loss: 0.015938216793364372\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016398895014491346\n",
      "SEED: 1513, FOLD: 1, EPOCH: 13, train_loss: 0.01586816034725179\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01637663019614087\n",
      "SEED: 1513, FOLD: 1, EPOCH: 14, train_loss: 0.015696176462739273\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 14, valid_loss: 0.01615714193839166\n",
      "SEED: 1513, FOLD: 1, EPOCH: 15, train_loss: 0.015469698127413141\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016112237185653713\n",
      "SEED: 1513, FOLD: 1, EPOCH: 16, train_loss: 0.015193771341464657\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016046562594258122\n",
      "SEED: 1513, FOLD: 1, EPOCH: 17, train_loss: 0.014872933467985064\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016030595120456483\n",
      "SEED: 1513, FOLD: 1, EPOCH: 18, train_loss: 0.014409657554242058\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01577373319822881\n",
      "SEED: 1513, FOLD: 1, EPOCH: 19, train_loss: 0.013934228434294893\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 19, valid_loss: 0.015702131411267653\n",
      "SEED: 1513, FOLD: 1, EPOCH: 20, train_loss: 0.01336432649227588\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 20, valid_loss: 0.015681479540136125\n",
      "SEED: 1513, FOLD: 1, EPOCH: 21, train_loss: 0.012713571645967339\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015664640348404646\n",
      "SEED: 1513, FOLD: 1, EPOCH: 22, train_loss: 0.012086265531463036\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015673471769938867\n",
      "SEED: 1513, FOLD: 1, EPOCH: 23, train_loss: 0.011590283229083254\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015642671483672328\n",
      "SEED: 1513, FOLD: 1, EPOCH: 24, train_loss: 0.011412382652254208\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015673222072008584\n",
      "SEED: 1513, FOLD: 2, EPOCH: 0, train_loss: 0.7124997126883355\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6187501351038615\n",
      "SEED: 1513, FOLD: 2, EPOCH: 1, train_loss: 0.2046745715095945\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 1, valid_loss: 0.022336447818411723\n",
      "SEED: 1513, FOLD: 2, EPOCH: 2, train_loss: 0.021056991880354675\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 2, valid_loss: 0.01985536174227794\n",
      "SEED: 1513, FOLD: 2, EPOCH: 3, train_loss: 0.01899826461854188\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 3, valid_loss: 0.018298869900819328\n",
      "SEED: 1513, FOLD: 2, EPOCH: 4, train_loss: 0.017802056991427704\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017573405988514423\n",
      "SEED: 1513, FOLD: 2, EPOCH: 5, train_loss: 0.017124492580583996\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017748427629056904\n",
      "SEED: 1513, FOLD: 2, EPOCH: 6, train_loss: 0.016780125017723312\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 6, valid_loss: 0.018107141988972824\n",
      "SEED: 1513, FOLD: 2, EPOCH: 7, train_loss: 0.01651112859447797\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 7, valid_loss: 0.016788723568121593\n",
      "SEED: 1513, FOLD: 2, EPOCH: 8, train_loss: 0.01621867601584265\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016820486221048567\n",
      "SEED: 1513, FOLD: 2, EPOCH: 9, train_loss: 0.016250932845624462\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016662004817691114\n",
      "SEED: 1513, FOLD: 2, EPOCH: 10, train_loss: 0.016111137966314953\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01721372056959404\n",
      "SEED: 1513, FOLD: 2, EPOCH: 11, train_loss: 0.016008940997762955\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01651941451968418\n",
      "SEED: 1513, FOLD: 2, EPOCH: 12, train_loss: 0.015866344983595005\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01637897055803074\n",
      "SEED: 1513, FOLD: 2, EPOCH: 13, train_loss: 0.015778772276488766\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016501905913982127\n",
      "SEED: 1513, FOLD: 2, EPOCH: 14, train_loss: 0.015577511011582354\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016468773130327463\n",
      "SEED: 1513, FOLD: 2, EPOCH: 15, train_loss: 0.015360801035295362\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01637849568699797\n",
      "SEED: 1513, FOLD: 2, EPOCH: 16, train_loss: 0.015098838931948378\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01631977843741576\n",
      "SEED: 1513, FOLD: 2, EPOCH: 17, train_loss: 0.01475095535641995\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016173590440303087\n",
      "SEED: 1513, FOLD: 2, EPOCH: 18, train_loss: 0.014320818680352058\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01617449749675062\n",
      "SEED: 1513, FOLD: 2, EPOCH: 19, train_loss: 0.013771284695552744\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016018566209822893\n",
      "SEED: 1513, FOLD: 2, EPOCH: 20, train_loss: 0.013173548491212769\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01600644401171141\n",
      "SEED: 1513, FOLD: 2, EPOCH: 21, train_loss: 0.012481362491414167\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016020802780985832\n",
      "SEED: 1513, FOLD: 2, EPOCH: 22, train_loss: 0.011812388033106707\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016014191684209637\n",
      "SEED: 1513, FOLD: 2, EPOCH: 23, train_loss: 0.011297139271661856\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01601522064043416\n",
      "SEED: 1513, FOLD: 2, EPOCH: 24, train_loss: 0.011092697351199129\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01603168176694049\n",
      "SEED: 1513, FOLD: 3, EPOCH: 0, train_loss: 0.712452561095141\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6111872692902883\n",
      "SEED: 1513, FOLD: 3, EPOCH: 1, train_loss: 0.20495785573038502\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 1, valid_loss: 0.022909599770274427\n",
      "SEED: 1513, FOLD: 3, EPOCH: 2, train_loss: 0.020919402737332428\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 2, valid_loss: 0.019240392682452995\n",
      "SEED: 1513, FOLD: 3, EPOCH: 3, train_loss: 0.018628250996487728\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018313635347618\n",
      "SEED: 1513, FOLD: 3, EPOCH: 4, train_loss: 0.018168935079829418\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017608811664912436\n",
      "SEED: 1513, FOLD: 3, EPOCH: 5, train_loss: 0.017105301167222038\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017231980235212378\n",
      "SEED: 1513, FOLD: 3, EPOCH: 6, train_loss: 0.016642785023735916\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017082661390304565\n",
      "SEED: 1513, FOLD: 3, EPOCH: 7, train_loss: 0.016914195178643517\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01715024984959099\n",
      "SEED: 1513, FOLD: 3, EPOCH: 8, train_loss: 0.01634880240358736\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 8, valid_loss: 0.016802175694869623\n",
      "SEED: 1513, FOLD: 3, EPOCH: 9, train_loss: 0.0162300203886369\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01673240850990017\n",
      "SEED: 1513, FOLD: 3, EPOCH: 10, train_loss: 0.016186038869014686\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01754819456901815\n",
      "SEED: 1513, FOLD: 3, EPOCH: 11, train_loss: 0.016243605105125385\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01663199905306101\n",
      "SEED: 1513, FOLD: 3, EPOCH: 12, train_loss: 0.01587430151530366\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016503704194393422\n",
      "SEED: 1513, FOLD: 3, EPOCH: 13, train_loss: 0.015732401779488377\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016451261058035824\n",
      "SEED: 1513, FOLD: 3, EPOCH: 14, train_loss: 0.01560537521119999\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01632147106445498\n",
      "SEED: 1513, FOLD: 3, EPOCH: 15, train_loss: 0.015363361011596693\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01621151493034429\n",
      "SEED: 1513, FOLD: 3, EPOCH: 16, train_loss: 0.01505751722910698\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016201876517799165\n",
      "SEED: 1513, FOLD: 3, EPOCH: 17, train_loss: 0.014706314446917479\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01600991603400972\n",
      "SEED: 1513, FOLD: 3, EPOCH: 18, train_loss: 0.01431365648581498\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 18, valid_loss: 0.015995337834788695\n",
      "SEED: 1513, FOLD: 3, EPOCH: 19, train_loss: 0.013834406891702742\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 19, valid_loss: 0.015935815456840727\n",
      "SEED: 1513, FOLD: 3, EPOCH: 20, train_loss: 0.013204764831217302\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 20, valid_loss: 0.015843009627941582\n",
      "SEED: 1513, FOLD: 3, EPOCH: 21, train_loss: 0.012509457767009735\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01579106588744455\n",
      "SEED: 1513, FOLD: 3, EPOCH: 22, train_loss: 0.011852182852833168\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 22, valid_loss: 0.015824832229150668\n",
      "SEED: 1513, FOLD: 3, EPOCH: 23, train_loss: 0.0113994467706568\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01581960368073649\n",
      "SEED: 1513, FOLD: 3, EPOCH: 24, train_loss: 0.011178801592061485\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01581618727909194\n",
      "SEED: 1513, FOLD: 4, EPOCH: 0, train_loss: 0.7124035349790601\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6043673819965787\n",
      "SEED: 1513, FOLD: 4, EPOCH: 1, train_loss: 0.20274285631983177\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 1, valid_loss: 0.024933491005665727\n",
      "SEED: 1513, FOLD: 4, EPOCH: 2, train_loss: 0.021084231796903885\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 2, valid_loss: 0.019648794498708513\n",
      "SEED: 1513, FOLD: 4, EPOCH: 3, train_loss: 0.018965805867227955\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01822870307498508\n",
      "SEED: 1513, FOLD: 4, EPOCH: 4, train_loss: 0.017936908896418587\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017369258010552988\n",
      "SEED: 1513, FOLD: 4, EPOCH: 5, train_loss: 0.019619571260999943\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017443438474502828\n",
      "SEED: 1513, FOLD: 4, EPOCH: 6, train_loss: 0.017043033925195534\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017049494820336502\n",
      "SEED: 1513, FOLD: 4, EPOCH: 7, train_loss: 0.016602580638035484\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01691355835646391\n",
      "SEED: 1513, FOLD: 4, EPOCH: 8, train_loss: 0.016456171478806198\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 8, valid_loss: 0.0166884313027064\n",
      "SEED: 1513, FOLD: 4, EPOCH: 9, train_loss: 0.01629438209414914\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 9, valid_loss: 0.016641169631232817\n",
      "SEED: 1513, FOLD: 4, EPOCH: 10, train_loss: 0.016133340993437214\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 10, valid_loss: 0.016538772576798994\n",
      "SEED: 1513, FOLD: 4, EPOCH: 11, train_loss: 0.016092585885654324\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016474139773183398\n",
      "SEED: 1513, FOLD: 4, EPOCH: 12, train_loss: 0.015991255883937298\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016615371995915968\n",
      "SEED: 1513, FOLD: 4, EPOCH: 13, train_loss: 0.015864772870596767\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01633175229653716\n",
      "SEED: 1513, FOLD: 4, EPOCH: 14, train_loss: 0.015630494317282802\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01638034327576558\n",
      "SEED: 1513, FOLD: 4, EPOCH: 15, train_loss: 0.015445093597298946\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016151087927735515\n",
      "SEED: 1513, FOLD: 4, EPOCH: 16, train_loss: 0.015208910583801891\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016011785094936688\n",
      "SEED: 1513, FOLD: 4, EPOCH: 17, train_loss: 0.014791605548690195\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01592537724516458\n",
      "SEED: 1513, FOLD: 4, EPOCH: 18, train_loss: 0.014356908509912699\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 18, valid_loss: 0.015854909188217588\n",
      "SEED: 1513, FOLD: 4, EPOCH: 19, train_loss: 0.013895447095991045\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01580860972818401\n",
      "SEED: 1513, FOLD: 4, EPOCH: 20, train_loss: 0.01325794457849385\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 20, valid_loss: 0.015671983050803345\n",
      "SEED: 1513, FOLD: 4, EPOCH: 21, train_loss: 0.012464935499904812\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01574575507806407\n",
      "SEED: 1513, FOLD: 4, EPOCH: 22, train_loss: 0.011753768849092117\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015696139850964148\n",
      "SEED: 1513, FOLD: 4, EPOCH: 23, train_loss: 0.011234600420879282\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 23, valid_loss: 0.015666730753663514\n",
      "SEED: 1513, FOLD: 4, EPOCH: 24, train_loss: 0.010985805774512499\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015673587667859264\n",
      "elapsed time: 406.8817994594574\n",
      "SEED: 1269, FOLD: 0, EPOCH: 0, train_loss: 0.7129519227622212\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6097046236197153\n",
      "SEED: 1269, FOLD: 0, EPOCH: 1, train_loss: 0.2042702418360589\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 1, valid_loss: 0.022634124072889488\n",
      "SEED: 1269, FOLD: 0, EPOCH: 2, train_loss: 0.021049176005349644\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01955158817064431\n",
      "SEED: 1269, FOLD: 0, EPOCH: 3, train_loss: 0.018897112000031746\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 3, valid_loss: 0.01821480815609296\n",
      "SEED: 1269, FOLD: 0, EPOCH: 4, train_loss: 0.01807484357361344\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017893449299865298\n",
      "SEED: 1269, FOLD: 0, EPOCH: 5, train_loss: 0.01724588757623797\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 5, valid_loss: 0.01725099960135089\n",
      "SEED: 1269, FOLD: 0, EPOCH: 6, train_loss: 0.01703895880854216\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 6, valid_loss: 0.02824689271963305\n",
      "SEED: 1269, FOLD: 0, EPOCH: 7, train_loss: 0.01701256492431613\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 7, valid_loss: 0.016830411325726245\n",
      "SEED: 1269, FOLD: 0, EPOCH: 8, train_loss: 0.01641200943107622\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 8, valid_loss: 0.016569580158425704\n",
      "SEED: 1269, FOLD: 0, EPOCH: 9, train_loss: 0.016373271109077377\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01651897027881609\n",
      "SEED: 1269, FOLD: 0, EPOCH: 10, train_loss: 0.01619871449319349\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 10, valid_loss: 0.016540749464184046\n",
      "SEED: 1269, FOLD: 0, EPOCH: 11, train_loss: 0.01610004349841156\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01644404951689972\n",
      "SEED: 1269, FOLD: 0, EPOCH: 12, train_loss: 0.01602644953822744\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01643412849969334\n",
      "SEED: 1269, FOLD: 0, EPOCH: 13, train_loss: 0.015863952672351963\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016416923712111182\n",
      "SEED: 1269, FOLD: 0, EPOCH: 14, train_loss: 0.015751259171984333\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016114704983515873\n",
      "SEED: 1269, FOLD: 0, EPOCH: 15, train_loss: 0.015415808536868164\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016055661719292402\n",
      "SEED: 1269, FOLD: 0, EPOCH: 16, train_loss: 0.015241224845142468\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016120845089770026\n",
      "SEED: 1269, FOLD: 0, EPOCH: 17, train_loss: 0.014897688278469486\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01590698165819049\n",
      "SEED: 1269, FOLD: 0, EPOCH: 18, train_loss: 0.014423740096390247\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 18, valid_loss: 0.015831578264219895\n",
      "SEED: 1269, FOLD: 0, EPOCH: 19, train_loss: 0.013930430446845898\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01571296238236957\n",
      "SEED: 1269, FOLD: 0, EPOCH: 20, train_loss: 0.013294786201331062\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 20, valid_loss: 0.015687560196965933\n",
      "SEED: 1269, FOLD: 0, EPOCH: 21, train_loss: 0.012620202954048696\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015699728650765285\n",
      "SEED: 1269, FOLD: 0, EPOCH: 22, train_loss: 0.01197284948674665\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01573359930059976\n",
      "SEED: 1269, FOLD: 0, EPOCH: 23, train_loss: 0.011488988469152348\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015686498696191445\n",
      "SEED: 1269, FOLD: 0, EPOCH: 24, train_loss: 0.011286448808791845\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01568940944141812\n",
      "SEED: 1269, FOLD: 1, EPOCH: 0, train_loss: 0.7127457114233486\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6155964798397489\n",
      "SEED: 1269, FOLD: 1, EPOCH: 1, train_loss: 0.20409114499562891\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 1, valid_loss: 0.023650718335476186\n",
      "SEED: 1269, FOLD: 1, EPOCH: 2, train_loss: 0.02105897125126659\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 2, valid_loss: 0.01950506627973583\n",
      "SEED: 1269, FOLD: 1, EPOCH: 3, train_loss: 0.018898827145281044\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 3, valid_loss: 0.01832224542482032\n",
      "SEED: 1269, FOLD: 1, EPOCH: 4, train_loss: 0.01793860600910325\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01752468157145712\n",
      "SEED: 1269, FOLD: 1, EPOCH: 5, train_loss: 0.017856004081018593\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 5, valid_loss: 0.01776599521852202\n",
      "SEED: 1269, FOLD: 1, EPOCH: 6, train_loss: 0.017072612298247608\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 6, valid_loss: 0.016763160936534405\n",
      "SEED: 1269, FOLD: 1, EPOCH: 7, train_loss: 0.016538099210331406\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 7, valid_loss: 0.016897379524177976\n",
      "SEED: 1269, FOLD: 1, EPOCH: 8, train_loss: 0.016501549442393192\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 8, valid_loss: 0.016784956885708704\n",
      "SEED: 1269, FOLD: 1, EPOCH: 9, train_loss: 0.016420095470612465\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 9, valid_loss: 0.016513691283762455\n",
      "SEED: 1269, FOLD: 1, EPOCH: 10, train_loss: 0.016222678259878918\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01685368259333902\n",
      "SEED: 1269, FOLD: 1, EPOCH: 11, train_loss: 0.016150631226491238\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016319537690530222\n",
      "SEED: 1269, FOLD: 1, EPOCH: 12, train_loss: 0.016028937438259953\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016456536948680878\n",
      "SEED: 1269, FOLD: 1, EPOCH: 13, train_loss: 0.015826560691862866\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016298228460881446\n",
      "SEED: 1269, FOLD: 1, EPOCH: 14, train_loss: 0.015657360260577305\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016131771883616846\n",
      "SEED: 1269, FOLD: 1, EPOCH: 15, train_loss: 0.015405467886855637\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016086409489313763\n",
      "SEED: 1269, FOLD: 1, EPOCH: 16, train_loss: 0.015126062921531822\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016022220978306398\n",
      "SEED: 1269, FOLD: 1, EPOCH: 17, train_loss: 0.014874648383778074\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01593272512157758\n",
      "SEED: 1269, FOLD: 1, EPOCH: 18, train_loss: 0.014485480209839518\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 18, valid_loss: 0.015761436014953587\n",
      "SEED: 1269, FOLD: 1, EPOCH: 19, train_loss: 0.013920413154730762\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01579088417606221\n",
      "SEED: 1269, FOLD: 1, EPOCH: 20, train_loss: 0.013252808240012846\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 20, valid_loss: 0.015624658928977119\n",
      "SEED: 1269, FOLD: 1, EPOCH: 21, train_loss: 0.01252356398364772\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015673535617275372\n",
      "SEED: 1269, FOLD: 1, EPOCH: 22, train_loss: 0.011913083183268705\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015651528878758352\n",
      "SEED: 1269, FOLD: 1, EPOCH: 23, train_loss: 0.011424485553541908\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015653286077496078\n",
      "SEED: 1269, FOLD: 1, EPOCH: 24, train_loss: 0.011187714713531128\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01565096817082829\n",
      "SEED: 1269, FOLD: 2, EPOCH: 0, train_loss: 0.7130055099293806\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6090638803111182\n",
      "SEED: 1269, FOLD: 2, EPOCH: 1, train_loss: 0.2036813736177873\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 1, valid_loss: 0.022844535091684923\n",
      "SEED: 1269, FOLD: 2, EPOCH: 2, train_loss: 0.021002522899188858\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 2, valid_loss: 0.019574767496022914\n",
      "SEED: 1269, FOLD: 2, EPOCH: 3, train_loss: 0.018972286306645558\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 3, valid_loss: 0.0184755546765195\n",
      "SEED: 1269, FOLD: 2, EPOCH: 4, train_loss: 0.017889648972862007\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 4, valid_loss: 0.018469959497451782\n",
      "SEED: 1269, FOLD: 2, EPOCH: 5, train_loss: 0.018019859557566437\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017234472195721336\n",
      "SEED: 1269, FOLD: 2, EPOCH: 6, train_loss: 0.016787320780365364\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 6, valid_loss: 0.016923786296198767\n",
      "SEED: 1269, FOLD: 2, EPOCH: 7, train_loss: 0.016436022584852966\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01671538698590464\n",
      "SEED: 1269, FOLD: 2, EPOCH: 8, train_loss: 0.016336756488443283\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01695791021403339\n",
      "SEED: 1269, FOLD: 2, EPOCH: 9, train_loss: 0.01620328511394884\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016852866082141798\n",
      "SEED: 1269, FOLD: 2, EPOCH: 10, train_loss: 0.016159020728715088\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01674799672845337\n",
      "SEED: 1269, FOLD: 2, EPOCH: 11, train_loss: 0.016046119799864464\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016565411299881008\n",
      "SEED: 1269, FOLD: 2, EPOCH: 12, train_loss: 0.015888477027740166\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016536424350407388\n",
      "SEED: 1269, FOLD: 2, EPOCH: 13, train_loss: 0.01569137676362542\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016452352568093274\n",
      "SEED: 1269, FOLD: 2, EPOCH: 14, train_loss: 0.01549603103025668\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016389470340477094\n",
      "SEED: 1269, FOLD: 2, EPOCH: 15, train_loss: 0.015316569246351719\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016311062085959647\n",
      "SEED: 1269, FOLD: 2, EPOCH: 16, train_loss: 0.015051818169329477\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016375105569346085\n",
      "SEED: 1269, FOLD: 2, EPOCH: 17, train_loss: 0.0146976077011314\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01606684597209096\n",
      "SEED: 1269, FOLD: 2, EPOCH: 18, train_loss: 0.014268676048495632\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016204567884819374\n",
      "SEED: 1269, FOLD: 2, EPOCH: 19, train_loss: 0.013718676901813866\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016162283563365538\n",
      "SEED: 1269, FOLD: 2, EPOCH: 20, train_loss: 0.013117343740726727\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016021394739962287\n",
      "SEED: 1269, FOLD: 2, EPOCH: 21, train_loss: 0.012397415409593479\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015992130101141002\n",
      "SEED: 1269, FOLD: 2, EPOCH: 22, train_loss: 0.01167869790578666\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016050795351879463\n",
      "SEED: 1269, FOLD: 2, EPOCH: 23, train_loss: 0.011155627789380758\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 23, valid_loss: 0.0160421309992671\n",
      "SEED: 1269, FOLD: 2, EPOCH: 24, train_loss: 0.010924006987741028\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01604587703736292\n",
      "SEED: 1269, FOLD: 3, EPOCH: 0, train_loss: 0.7127908770588861\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6067678862147861\n",
      "SEED: 1269, FOLD: 3, EPOCH: 1, train_loss: 0.20320509125789007\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 1, valid_loss: 0.023648638381726213\n",
      "SEED: 1269, FOLD: 3, EPOCH: 2, train_loss: 0.021139492537232414\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 2, valid_loss: 0.01966385232905547\n",
      "SEED: 1269, FOLD: 3, EPOCH: 3, train_loss: 0.018803512677550316\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018751149997115135\n",
      "SEED: 1269, FOLD: 3, EPOCH: 4, train_loss: 0.017866423852957676\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 4, valid_loss: 0.018652452259427972\n",
      "SEED: 1269, FOLD: 3, EPOCH: 5, train_loss: 0.017715585755481236\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 5, valid_loss: 0.01743959490623739\n",
      "SEED: 1269, FOLD: 3, EPOCH: 6, train_loss: 0.01667986359393251\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017075715069141652\n",
      "SEED: 1269, FOLD: 3, EPOCH: 7, train_loss: 0.016377779682153377\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 7, valid_loss: 0.016949334181845188\n",
      "SEED: 1269, FOLD: 3, EPOCH: 8, train_loss: 0.016264049498283344\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 8, valid_loss: 0.016808640470521316\n",
      "SEED: 1269, FOLD: 3, EPOCH: 9, train_loss: 0.016221865957629852\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 9, valid_loss: 0.016869513007501762\n",
      "SEED: 1269, FOLD: 3, EPOCH: 10, train_loss: 0.016208862602386787\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016682302113622427\n",
      "SEED: 1269, FOLD: 3, EPOCH: 11, train_loss: 0.015996797172271687\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016508031791696947\n",
      "SEED: 1269, FOLD: 3, EPOCH: 12, train_loss: 0.01588431417780078\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016603934889038403\n",
      "SEED: 1269, FOLD: 3, EPOCH: 13, train_loss: 0.015821177795853302\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016610858030617237\n",
      "SEED: 1269, FOLD: 3, EPOCH: 14, train_loss: 0.015589563108548738\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01637375308200717\n",
      "SEED: 1269, FOLD: 3, EPOCH: 15, train_loss: 0.015387707187429718\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01632480054265923\n",
      "SEED: 1269, FOLD: 3, EPOCH: 16, train_loss: 0.015096099534328434\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016304889642116096\n",
      "SEED: 1269, FOLD: 3, EPOCH: 17, train_loss: 0.014747626107671986\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016176764542857807\n",
      "SEED: 1269, FOLD: 3, EPOCH: 18, train_loss: 0.0143414541296121\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016116702204777136\n",
      "SEED: 1269, FOLD: 3, EPOCH: 19, train_loss: 0.013877554135262102\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 19, valid_loss: 0.015984012227919366\n",
      "SEED: 1269, FOLD: 3, EPOCH: 20, train_loss: 0.013228868593232355\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 20, valid_loss: 0.015921808779239655\n",
      "SEED: 1269, FOLD: 3, EPOCH: 21, train_loss: 0.012539877232326113\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 21, valid_loss: 0.015866483768655196\n",
      "SEED: 1269, FOLD: 3, EPOCH: 22, train_loss: 0.011882793603707914\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 22, valid_loss: 0.015854740515351295\n",
      "SEED: 1269, FOLD: 3, EPOCH: 23, train_loss: 0.011375313165827074\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 23, valid_loss: 0.015841011320137315\n",
      "SEED: 1269, FOLD: 3, EPOCH: 24, train_loss: 0.011135499222555023\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01585940457880497\n",
      "SEED: 1269, FOLD: 4, EPOCH: 0, train_loss: 0.7130638317785402\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6042292780346341\n",
      "SEED: 1269, FOLD: 4, EPOCH: 1, train_loss: 0.20325849647971167\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 1, valid_loss: 0.02324140899711185\n",
      "SEED: 1269, FOLD: 4, EPOCH: 2, train_loss: 0.020983191018087276\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 2, valid_loss: 0.019390630432301097\n",
      "SEED: 1269, FOLD: 4, EPOCH: 3, train_loss: 0.019040534677712814\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 3, valid_loss: 0.018223597047229607\n",
      "SEED: 1269, FOLD: 4, EPOCH: 4, train_loss: 0.01778095397774292\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 4, valid_loss: 0.01757175371878677\n",
      "SEED: 1269, FOLD: 4, EPOCH: 5, train_loss: 0.01734099981199572\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017226269158224266\n",
      "SEED: 1269, FOLD: 4, EPOCH: 6, train_loss: 0.016710085591868214\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 6, valid_loss: 0.018022261353002653\n",
      "SEED: 1269, FOLD: 4, EPOCH: 7, train_loss: 0.01653830088890981\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01680439482960436\n",
      "SEED: 1269, FOLD: 4, EPOCH: 8, train_loss: 0.016363547979921535\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 8, valid_loss: 0.016931828214890428\n",
      "SEED: 1269, FOLD: 4, EPOCH: 9, train_loss: 0.01630177440634672\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01666112383827567\n",
      "SEED: 1269, FOLD: 4, EPOCH: 10, train_loss: 0.01617831480351911\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 10, valid_loss: 0.016636504532976285\n",
      "SEED: 1269, FOLD: 4, EPOCH: 11, train_loss: 0.016068812689163547\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016439175388465326\n",
      "SEED: 1269, FOLD: 4, EPOCH: 12, train_loss: 0.015958313249807426\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 12, valid_loss: 0.01640995146913661\n",
      "SEED: 1269, FOLD: 4, EPOCH: 13, train_loss: 0.015789629999494206\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016214012013127405\n",
      "SEED: 1269, FOLD: 4, EPOCH: 14, train_loss: 0.015628158290317093\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016221231263544824\n",
      "SEED: 1269, FOLD: 4, EPOCH: 15, train_loss: 0.015363700485423855\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016113038692209456\n",
      "SEED: 1269, FOLD: 4, EPOCH: 16, train_loss: 0.015136308779103168\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016012735923545227\n",
      "SEED: 1269, FOLD: 4, EPOCH: 17, train_loss: 0.014801624258035335\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 17, valid_loss: 0.015937083090345066\n",
      "SEED: 1269, FOLD: 4, EPOCH: 18, train_loss: 0.014340864305478939\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 18, valid_loss: 0.015844460628512833\n",
      "SEED: 1269, FOLD: 4, EPOCH: 19, train_loss: 0.0138188015156682\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01573727631734477\n",
      "SEED: 1269, FOLD: 4, EPOCH: 20, train_loss: 0.013215849540479805\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01570806336692638\n",
      "SEED: 1269, FOLD: 4, EPOCH: 21, train_loss: 0.012497833660007387\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01563195392696394\n",
      "SEED: 1269, FOLD: 4, EPOCH: 22, train_loss: 0.011848144800118778\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015641224001430802\n",
      "SEED: 1269, FOLD: 4, EPOCH: 23, train_loss: 0.011323178267997244\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01563455816358328\n",
      "SEED: 1269, FOLD: 4, EPOCH: 24, train_loss: 0.011123062165427034\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015620836470690038\n",
      "elapsed time: 606.7501034736633\n",
      "SEED: 1392, FOLD: 0, EPOCH: 0, train_loss: 0.7138783586198005\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6193900307019552\n",
      "SEED: 1392, FOLD: 0, EPOCH: 1, train_loss: 0.20230062011683334\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 1, valid_loss: 0.023792489017877314\n",
      "SEED: 1392, FOLD: 0, EPOCH: 2, train_loss: 0.02098977770926296\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01929657409588496\n",
      "SEED: 1392, FOLD: 0, EPOCH: 3, train_loss: 0.018868451911038246\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 3, valid_loss: 0.01824262934840388\n",
      "SEED: 1392, FOLD: 0, EPOCH: 4, train_loss: 0.01785779977892188\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 4, valid_loss: 0.018246232118043635\n",
      "SEED: 1392, FOLD: 0, EPOCH: 5, train_loss: 0.01717206455119278\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 5, valid_loss: 0.01688137852276365\n",
      "SEED: 1392, FOLD: 0, EPOCH: 6, train_loss: 0.01680757745128611\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017072669851283234\n",
      "SEED: 1392, FOLD: 0, EPOCH: 7, train_loss: 0.016484385410296745\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 7, valid_loss: 0.016573846547140017\n",
      "SEED: 1392, FOLD: 0, EPOCH: 8, train_loss: 0.016285218257942925\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01668525461314453\n",
      "SEED: 1392, FOLD: 0, EPOCH: 9, train_loss: 0.016241186973301396\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01663774096717437\n",
      "SEED: 1392, FOLD: 0, EPOCH: 10, train_loss: 0.01618745192831409\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 10, valid_loss: 0.016525573200649686\n",
      "SEED: 1392, FOLD: 0, EPOCH: 11, train_loss: 0.016055662009487118\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01661896390012569\n",
      "SEED: 1392, FOLD: 0, EPOCH: 12, train_loss: 0.015931963974582977\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016232384265296988\n",
      "SEED: 1392, FOLD: 0, EPOCH: 13, train_loss: 0.015761695694232334\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01639426877308223\n",
      "SEED: 1392, FOLD: 0, EPOCH: 14, train_loss: 0.01564294657251541\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 14, valid_loss: 0.01611954527389672\n",
      "SEED: 1392, FOLD: 0, EPOCH: 15, train_loss: 0.015359779995312725\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01611935005833705\n",
      "SEED: 1392, FOLD: 0, EPOCH: 16, train_loss: 0.015060605791707834\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016033501364290714\n",
      "SEED: 1392, FOLD: 0, EPOCH: 17, train_loss: 0.014728374306814394\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 17, valid_loss: 0.015811420407974057\n",
      "SEED: 1392, FOLD: 0, EPOCH: 18, train_loss: 0.014270253088055313\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 18, valid_loss: 0.01585189729101128\n",
      "SEED: 1392, FOLD: 0, EPOCH: 19, train_loss: 0.013785861540531767\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01581366675802403\n",
      "SEED: 1392, FOLD: 0, EPOCH: 20, train_loss: 0.013164966137728829\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01565700438287523\n",
      "SEED: 1392, FOLD: 0, EPOCH: 21, train_loss: 0.012441126562223055\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015746990425719157\n",
      "SEED: 1392, FOLD: 0, EPOCH: 22, train_loss: 0.011787550240431143\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01569759737079342\n",
      "SEED: 1392, FOLD: 0, EPOCH: 23, train_loss: 0.011259481000403563\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01566547579649422\n",
      "SEED: 1392, FOLD: 0, EPOCH: 24, train_loss: 0.01103686271370321\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01567138069205814\n",
      "SEED: 1392, FOLD: 1, EPOCH: 0, train_loss: 0.7139476451320924\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6139115260707008\n",
      "SEED: 1392, FOLD: 1, EPOCH: 1, train_loss: 0.20421350150760534\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 1, valid_loss: 0.023538161896997027\n",
      "SEED: 1392, FOLD: 1, EPOCH: 2, train_loss: 0.02101279965237431\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 2, valid_loss: 0.01961977831605408\n",
      "SEED: 1392, FOLD: 1, EPOCH: 3, train_loss: 0.019087341303626697\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018866205174061988\n",
      "SEED: 1392, FOLD: 1, EPOCH: 4, train_loss: 0.017957614599794582\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017804942714671295\n",
      "SEED: 1392, FOLD: 1, EPOCH: 5, train_loss: 0.017070716503413692\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 5, valid_loss: 0.016917055265771017\n",
      "SEED: 1392, FOLD: 1, EPOCH: 6, train_loss: 0.020893690783692444\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 6, valid_loss: 0.018279194728367858\n",
      "SEED: 1392, FOLD: 1, EPOCH: 7, train_loss: 0.017900938843039498\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01765082621326049\n",
      "SEED: 1392, FOLD: 1, EPOCH: 8, train_loss: 0.017489690725030243\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017232795763346884\n",
      "SEED: 1392, FOLD: 1, EPOCH: 9, train_loss: 0.01720875077813432\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017155072858764067\n",
      "SEED: 1392, FOLD: 1, EPOCH: 10, train_loss: 0.017016650393497253\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01696058176457882\n",
      "SEED: 1392, FOLD: 1, EPOCH: 11, train_loss: 0.016810785020715084\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01677095465775993\n",
      "SEED: 1392, FOLD: 1, EPOCH: 12, train_loss: 0.01670766976810452\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016689169841508072\n",
      "SEED: 1392, FOLD: 1, EPOCH: 13, train_loss: 0.01657000224551429\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01662410878472858\n",
      "SEED: 1392, FOLD: 1, EPOCH: 14, train_loss: 0.016362613444958908\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016463431115779612\n",
      "SEED: 1392, FOLD: 1, EPOCH: 15, train_loss: 0.016207117033933384\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01635773376458221\n",
      "SEED: 1392, FOLD: 1, EPOCH: 16, train_loss: 0.015936284514980904\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016269307790531054\n",
      "SEED: 1392, FOLD: 1, EPOCH: 17, train_loss: 0.015698636274622833\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016149373518096075\n",
      "SEED: 1392, FOLD: 1, EPOCH: 18, train_loss: 0.015384135551858639\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 18, valid_loss: 0.015965239093121555\n",
      "SEED: 1392, FOLD: 1, EPOCH: 19, train_loss: 0.015067156890164251\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01584272076272302\n",
      "SEED: 1392, FOLD: 1, EPOCH: 20, train_loss: 0.0147188408030332\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 20, valid_loss: 0.01568096482919322\n",
      "SEED: 1392, FOLD: 1, EPOCH: 21, train_loss: 0.014300490432567354\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015601823416848978\n",
      "SEED: 1392, FOLD: 1, EPOCH: 22, train_loss: 0.013860563909553963\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015564744360744953\n",
      "SEED: 1392, FOLD: 1, EPOCH: 23, train_loss: 0.013544528961073662\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01554502634745505\n",
      "SEED: 1392, FOLD: 1, EPOCH: 24, train_loss: 0.013439393102906752\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015542495892279677\n",
      "SEED: 1392, FOLD: 2, EPOCH: 0, train_loss: 0.7142968894778818\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6020620399051242\n",
      "SEED: 1392, FOLD: 2, EPOCH: 1, train_loss: 0.2029055457400239\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 1, valid_loss: 0.023103791392511792\n",
      "SEED: 1392, FOLD: 2, EPOCH: 2, train_loss: 0.02104224321310935\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 2, valid_loss: 0.019383126662837133\n",
      "SEED: 1392, FOLD: 2, EPOCH: 3, train_loss: 0.018745318622044895\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01825443882909086\n",
      "SEED: 1392, FOLD: 2, EPOCH: 4, train_loss: 0.01783934848356074\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017748282342735264\n",
      "SEED: 1392, FOLD: 2, EPOCH: 5, train_loss: 0.017027076644202072\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017250837654703192\n",
      "SEED: 1392, FOLD: 2, EPOCH: 6, train_loss: 0.017050918448122517\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 6, valid_loss: 0.016895319386902783\n",
      "SEED: 1392, FOLD: 2, EPOCH: 7, train_loss: 0.016401062355093334\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01690819502497713\n",
      "SEED: 1392, FOLD: 2, EPOCH: 8, train_loss: 0.01630471851946651\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016688315922187433\n",
      "SEED: 1392, FOLD: 2, EPOCH: 9, train_loss: 0.016227697643140953\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016732966113421652\n",
      "SEED: 1392, FOLD: 2, EPOCH: 10, train_loss: 0.016114438721991104\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 10, valid_loss: 0.016696379468258884\n",
      "SEED: 1392, FOLD: 2, EPOCH: 11, train_loss: 0.01599671891418056\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 11, valid_loss: 0.0165990452385611\n",
      "SEED: 1392, FOLD: 2, EPOCH: 12, train_loss: 0.015936766521654266\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01648448035120964\n",
      "SEED: 1392, FOLD: 2, EPOCH: 13, train_loss: 0.015824278290181057\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016594306358860597\n",
      "SEED: 1392, FOLD: 2, EPOCH: 14, train_loss: 0.015609192243520763\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01634018262848258\n",
      "SEED: 1392, FOLD: 2, EPOCH: 15, train_loss: 0.015375896680938162\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016360989823523495\n",
      "SEED: 1392, FOLD: 2, EPOCH: 16, train_loss: 0.0150538994188326\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01626603522648414\n",
      "SEED: 1392, FOLD: 2, EPOCH: 17, train_loss: 0.014751731647529465\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016091355122625828\n",
      "SEED: 1392, FOLD: 2, EPOCH: 18, train_loss: 0.014408302142460278\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016110189207312133\n",
      "SEED: 1392, FOLD: 2, EPOCH: 19, train_loss: 0.013818800638335339\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016012439349045355\n",
      "SEED: 1392, FOLD: 2, EPOCH: 20, train_loss: 0.01319734764325878\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016023386787209246\n",
      "SEED: 1392, FOLD: 2, EPOCH: 21, train_loss: 0.01249565364981907\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016066676419642236\n",
      "SEED: 1392, FOLD: 2, EPOCH: 22, train_loss: 0.011851587710713131\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01602152471120159\n",
      "SEED: 1392, FOLD: 2, EPOCH: 23, train_loss: 0.011381716629409271\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01600293478825026\n",
      "SEED: 1392, FOLD: 2, EPOCH: 24, train_loss: 0.01112401224942743\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01600855899353822\n",
      "SEED: 1392, FOLD: 3, EPOCH: 0, train_loss: 0.7139632200849229\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 0, valid_loss: 0.608025355471505\n",
      "SEED: 1392, FOLD: 3, EPOCH: 1, train_loss: 0.20430832520883152\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 1, valid_loss: 0.02355887906418906\n",
      "SEED: 1392, FOLD: 3, EPOCH: 2, train_loss: 0.020774851458660072\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 2, valid_loss: 0.0194232730815808\n",
      "SEED: 1392, FOLD: 3, EPOCH: 3, train_loss: 0.01873213068946548\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018458073648313682\n",
      "SEED: 1392, FOLD: 3, EPOCH: 4, train_loss: 0.0183240942441035\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 4, valid_loss: 0.02063080109655857\n",
      "SEED: 1392, FOLD: 3, EPOCH: 5, train_loss: 0.01748315410931473\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017487128213461902\n",
      "SEED: 1392, FOLD: 3, EPOCH: 6, train_loss: 0.01662900015387846\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017119390683041677\n",
      "SEED: 1392, FOLD: 3, EPOCH: 7, train_loss: 0.016453401037100433\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01723150432937675\n",
      "SEED: 1392, FOLD: 3, EPOCH: 8, train_loss: 0.016376059704824635\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01671461911044187\n",
      "SEED: 1392, FOLD: 3, EPOCH: 9, train_loss: 0.01625586760000906\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01691938093346026\n",
      "SEED: 1392, FOLD: 3, EPOCH: 10, train_loss: 0.016132501588351486\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016661329919265375\n",
      "SEED: 1392, FOLD: 3, EPOCH: 11, train_loss: 0.016024903961173866\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016727223267985716\n",
      "SEED: 1392, FOLD: 3, EPOCH: 12, train_loss: 0.01587186163912217\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016556449751887057\n",
      "SEED: 1392, FOLD: 3, EPOCH: 13, train_loss: 0.015771969531973202\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016513269291155867\n",
      "SEED: 1392, FOLD: 3, EPOCH: 14, train_loss: 0.015620180999563225\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016429311854557857\n",
      "SEED: 1392, FOLD: 3, EPOCH: 15, train_loss: 0.015360347224750381\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016235283938133054\n",
      "SEED: 1392, FOLD: 3, EPOCH: 16, train_loss: 0.015126793564337751\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016219078563153744\n",
      "SEED: 1392, FOLD: 3, EPOCH: 17, train_loss: 0.01475729318200678\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016135174677603774\n",
      "SEED: 1392, FOLD: 3, EPOCH: 18, train_loss: 0.014349177142308243\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016053562311248645\n",
      "SEED: 1392, FOLD: 3, EPOCH: 19, train_loss: 0.013832585737649082\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 19, valid_loss: 0.015903941148685083\n",
      "SEED: 1392, FOLD: 3, EPOCH: 20, train_loss: 0.013226616398795792\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 20, valid_loss: 0.015861911336994834\n",
      "SEED: 1392, FOLD: 3, EPOCH: 21, train_loss: 0.012560934881153315\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 21, valid_loss: 0.015833470970392227\n",
      "SEED: 1392, FOLD: 3, EPOCH: 22, train_loss: 0.011877459298441376\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01582758982355396\n",
      "SEED: 1392, FOLD: 3, EPOCH: 23, train_loss: 0.011384214881969534\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01583009756480654\n",
      "SEED: 1392, FOLD: 3, EPOCH: 24, train_loss: 0.011164058998659037\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 24, valid_loss: 0.015845250907457538\n",
      "SEED: 1392, FOLD: 4, EPOCH: 0, train_loss: 0.7141049633855405\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6014575295978122\n",
      "SEED: 1392, FOLD: 4, EPOCH: 1, train_loss: 0.20382427559166716\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 1, valid_loss: 0.023027326083845563\n",
      "SEED: 1392, FOLD: 4, EPOCH: 2, train_loss: 0.020866066649340202\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 2, valid_loss: 0.01936732025610076\n",
      "SEED: 1392, FOLD: 4, EPOCH: 3, train_loss: 0.018786355961060177\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 3, valid_loss: 0.018083278814123735\n",
      "SEED: 1392, FOLD: 4, EPOCH: 4, train_loss: 0.0179055729691965\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 4, valid_loss: 0.01816097026069959\n",
      "SEED: 1392, FOLD: 4, EPOCH: 5, train_loss: 0.01742824461257112\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017105709554420576\n",
      "SEED: 1392, FOLD: 4, EPOCH: 6, train_loss: 0.01665142876352521\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 6, valid_loss: 0.016813119252522785\n",
      "SEED: 1392, FOLD: 4, EPOCH: 7, train_loss: 0.016372830499017586\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 7, valid_loss: 0.020000334622131452\n",
      "SEED: 1392, FOLD: 4, EPOCH: 8, train_loss: 0.01654323669609384\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 8, valid_loss: 0.016656592746989593\n",
      "SEED: 1392, FOLD: 4, EPOCH: 9, train_loss: 0.01619745494014975\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 9, valid_loss: 0.016646530530932877\n",
      "SEED: 1392, FOLD: 4, EPOCH: 10, train_loss: 0.016201102566243946\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 10, valid_loss: 0.016497789106021326\n",
      "SEED: 1392, FOLD: 4, EPOCH: 11, train_loss: 0.016021094284951687\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016574200708419085\n",
      "SEED: 1392, FOLD: 4, EPOCH: 12, train_loss: 0.015999630188056523\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016357529546237655\n",
      "SEED: 1392, FOLD: 4, EPOCH: 13, train_loss: 0.01576302973958461\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016328207734558318\n",
      "SEED: 1392, FOLD: 4, EPOCH: 14, train_loss: 0.015575406222563723\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016231911049948797\n",
      "SEED: 1392, FOLD: 4, EPOCH: 15, train_loss: 0.015430667883028154\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016161173530336883\n",
      "SEED: 1392, FOLD: 4, EPOCH: 16, train_loss: 0.015089335959350718\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016171012746377125\n",
      "SEED: 1392, FOLD: 4, EPOCH: 17, train_loss: 0.014790580999376118\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 17, valid_loss: 0.015909958061658673\n",
      "SEED: 1392, FOLD: 4, EPOCH: 18, train_loss: 0.014382276292620361\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01585753344827228\n",
      "SEED: 1392, FOLD: 4, EPOCH: 19, train_loss: 0.013816293086046759\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01574227110379272\n",
      "SEED: 1392, FOLD: 4, EPOCH: 20, train_loss: 0.013243661451058975\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01570476048315565\n",
      "SEED: 1392, FOLD: 4, EPOCH: 21, train_loss: 0.012560173828640709\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015635186133699283\n",
      "SEED: 1392, FOLD: 4, EPOCH: 22, train_loss: 0.011912147973434649\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015618010941478942\n",
      "SEED: 1392, FOLD: 4, EPOCH: 23, train_loss: 0.011422939814519192\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 23, valid_loss: 0.015634573271705046\n",
      "SEED: 1392, FOLD: 4, EPOCH: 24, train_loss: 0.011177643998593523\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015639430274152093\n",
      "elapsed time: 816.612309217453\n",
      "SEED: 1119, FOLD: 0, EPOCH: 0, train_loss: 0.7128307698429495\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6154682636260986\n",
      "SEED: 1119, FOLD: 0, EPOCH: 1, train_loss: 0.20362165656642636\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 1, valid_loss: 0.022700931876897812\n",
      "SEED: 1119, FOLD: 0, EPOCH: 2, train_loss: 0.02090369399798953\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 2, valid_loss: 0.019256447286655504\n",
      "SEED: 1119, FOLD: 0, EPOCH: 3, train_loss: 0.01874013269401115\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 3, valid_loss: 0.018220043534206018\n",
      "SEED: 1119, FOLD: 0, EPOCH: 4, train_loss: 0.01834825553215932\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01776594766933057\n",
      "SEED: 1119, FOLD: 0, EPOCH: 5, train_loss: 0.017265804165947266\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 5, valid_loss: 0.01730835846521788\n",
      "SEED: 1119, FOLD: 0, EPOCH: 6, train_loss: 0.016641298592414543\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 6, valid_loss: 0.016793825042744476\n",
      "SEED: 1119, FOLD: 0, EPOCH: 7, train_loss: 0.017144241883163002\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017341512255370617\n",
      "SEED: 1119, FOLD: 0, EPOCH: 8, train_loss: 0.01684896934075632\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01671481432600154\n",
      "SEED: 1119, FOLD: 0, EPOCH: 9, train_loss: 0.01641788302610318\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 9, valid_loss: 0.016648361252413854\n",
      "SEED: 1119, FOLD: 0, EPOCH: 10, train_loss: 0.016257089603206386\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 10, valid_loss: 0.016550967159370582\n",
      "SEED: 1119, FOLD: 0, EPOCH: 11, train_loss: 0.016136763644391212\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 11, valid_loss: 0.016511627472937107\n",
      "SEED: 1119, FOLD: 0, EPOCH: 12, train_loss: 0.015995741983794647\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016338044829252694\n",
      "SEED: 1119, FOLD: 0, EPOCH: 13, train_loss: 0.01590597795565491\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016270003229793575\n",
      "SEED: 1119, FOLD: 0, EPOCH: 14, train_loss: 0.01567086192738751\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016220007816122636\n",
      "SEED: 1119, FOLD: 0, EPOCH: 15, train_loss: 0.015425801115191502\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 15, valid_loss: 0.0161416024590532\n",
      "SEED: 1119, FOLD: 0, EPOCH: 16, train_loss: 0.015190608745467836\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 16, valid_loss: 0.015987121189634006\n",
      "SEED: 1119, FOLD: 0, EPOCH: 17, train_loss: 0.014910391369915527\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01593345460585422\n",
      "SEED: 1119, FOLD: 0, EPOCH: 18, train_loss: 0.01442379269586957\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 18, valid_loss: 0.015826478652242158\n",
      "SEED: 1119, FOLD: 0, EPOCH: 19, train_loss: 0.01390636658322984\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 19, valid_loss: 0.015937246951378055\n",
      "SEED: 1119, FOLD: 0, EPOCH: 20, train_loss: 0.013277012031471384\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 20, valid_loss: 0.015755600140740473\n",
      "SEED: 1119, FOLD: 0, EPOCH: 21, train_loss: 0.012608182009147562\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01572068387435542\n",
      "SEED: 1119, FOLD: 0, EPOCH: 22, train_loss: 0.011942302767673264\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015736872795969248\n",
      "SEED: 1119, FOLD: 0, EPOCH: 23, train_loss: 0.011394537958330002\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015733691967195935\n",
      "SEED: 1119, FOLD: 0, EPOCH: 24, train_loss: 0.011185960358251696\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01573153181622426\n",
      "SEED: 1119, FOLD: 1, EPOCH: 0, train_loss: 0.7125767944515615\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6004430684778426\n",
      "SEED: 1119, FOLD: 1, EPOCH: 1, train_loss: 0.20164551378052303\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 1, valid_loss: 0.023457070916063257\n",
      "SEED: 1119, FOLD: 1, EPOCH: 2, train_loss: 0.02116389113707819\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 2, valid_loss: 0.019756836713188224\n",
      "SEED: 1119, FOLD: 1, EPOCH: 3, train_loss: 0.019185990635035694\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 3, valid_loss: 0.022171485444737807\n",
      "SEED: 1119, FOLD: 1, EPOCH: 4, train_loss: 0.018464743524141933\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01777080963883135\n",
      "SEED: 1119, FOLD: 1, EPOCH: 5, train_loss: 0.017237139352853748\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017223974068959553\n",
      "SEED: 1119, FOLD: 1, EPOCH: 6, train_loss: 0.01681759263780238\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 6, valid_loss: 0.016819364080826443\n",
      "SEED: 1119, FOLD: 1, EPOCH: 7, train_loss: 0.016479007656807484\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 7, valid_loss: 0.016757154216368992\n",
      "SEED: 1119, FOLD: 1, EPOCH: 8, train_loss: 0.01675024415379849\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 8, valid_loss: 0.016658860569198925\n",
      "SEED: 1119, FOLD: 1, EPOCH: 9, train_loss: 0.016346648672892563\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 9, valid_loss: 0.016654488630592823\n",
      "SEED: 1119, FOLD: 1, EPOCH: 10, train_loss: 0.01620376308489105\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016689516914387543\n",
      "SEED: 1119, FOLD: 1, EPOCH: 11, train_loss: 0.01620838654807944\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01638648896995518\n",
      "SEED: 1119, FOLD: 1, EPOCH: 12, train_loss: 0.016020596040871696\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016531156582964793\n",
      "SEED: 1119, FOLD: 1, EPOCH: 13, train_loss: 0.015896768930057686\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 13, valid_loss: 0.0162728449019293\n",
      "SEED: 1119, FOLD: 1, EPOCH: 14, train_loss: 0.01571731645937847\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 14, valid_loss: 0.01639629165745444\n",
      "SEED: 1119, FOLD: 1, EPOCH: 15, train_loss: 0.01555342688832594\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01612550237526496\n",
      "SEED: 1119, FOLD: 1, EPOCH: 16, train_loss: 0.015284223886935608\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016039513879352145\n",
      "SEED: 1119, FOLD: 1, EPOCH: 17, train_loss: 0.014919018845303335\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 17, valid_loss: 0.015948480202092066\n",
      "SEED: 1119, FOLD: 1, EPOCH: 18, train_loss: 0.014487238668337248\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01577478378183312\n",
      "SEED: 1119, FOLD: 1, EPOCH: 19, train_loss: 0.014044814783593883\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 19, valid_loss: 0.015720700586421624\n",
      "SEED: 1119, FOLD: 1, EPOCH: 20, train_loss: 0.013469747794063194\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 20, valid_loss: 0.015619481965485547\n",
      "SEED: 1119, FOLD: 1, EPOCH: 21, train_loss: 0.012791124078026716\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015629299709366426\n",
      "SEED: 1119, FOLD: 1, EPOCH: 22, train_loss: 0.012139818172200003\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015580983056376377\n",
      "SEED: 1119, FOLD: 1, EPOCH: 23, train_loss: 0.011641435379135435\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015600008010450337\n",
      "SEED: 1119, FOLD: 1, EPOCH: 24, train_loss: 0.01142858276548593\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015617964478830496\n",
      "SEED: 1119, FOLD: 2, EPOCH: 0, train_loss: 0.7135465499283611\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6073056194517348\n",
      "SEED: 1119, FOLD: 2, EPOCH: 1, train_loss: 0.20480582968372366\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 1, valid_loss: 0.022887102121280298\n",
      "SEED: 1119, FOLD: 2, EPOCH: 2, train_loss: 0.0210514299409545\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 2, valid_loss: 0.019745852901703782\n",
      "SEED: 1119, FOLD: 2, EPOCH: 3, train_loss: 0.01877467139907505\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 3, valid_loss: 0.018227334858642683\n",
      "SEED: 1119, FOLD: 2, EPOCH: 4, train_loss: 0.017884682351048443\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017734326008293364\n",
      "SEED: 1119, FOLD: 2, EPOCH: 5, train_loss: 0.017079994770819725\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017113547927389543\n",
      "SEED: 1119, FOLD: 2, EPOCH: 6, train_loss: 0.01649742152379907\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017148968815389607\n",
      "SEED: 1119, FOLD: 2, EPOCH: 7, train_loss: 0.017199980499951736\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 7, valid_loss: 0.016938277727199927\n",
      "SEED: 1119, FOLD: 2, EPOCH: 8, train_loss: 0.016422848811076172\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01673202309757471\n",
      "SEED: 1119, FOLD: 2, EPOCH: 9, train_loss: 0.016281433376497116\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 9, valid_loss: 0.0167516327670051\n",
      "SEED: 1119, FOLD: 2, EPOCH: 10, train_loss: 0.01614382001908793\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 10, valid_loss: 0.016742129551453724\n",
      "SEED: 1119, FOLD: 2, EPOCH: 11, train_loss: 0.016019033349078636\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016601831910924778\n",
      "SEED: 1119, FOLD: 2, EPOCH: 12, train_loss: 0.015939084529552772\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01673792028385732\n",
      "SEED: 1119, FOLD: 2, EPOCH: 13, train_loss: 0.015788624535544193\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01640058345057898\n",
      "SEED: 1119, FOLD: 2, EPOCH: 14, train_loss: 0.015574337077745493\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016506398665822215\n",
      "SEED: 1119, FOLD: 2, EPOCH: 15, train_loss: 0.015379682021296543\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01626828085217211\n",
      "SEED: 1119, FOLD: 2, EPOCH: 16, train_loss: 0.015193154859909977\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016193957688907783\n",
      "SEED: 1119, FOLD: 2, EPOCH: 17, train_loss: 0.01481230295114759\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016160243811706703\n",
      "SEED: 1119, FOLD: 2, EPOCH: 18, train_loss: 0.014386657530954782\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01611641225301557\n",
      "SEED: 1119, FOLD: 2, EPOCH: 19, train_loss: 0.013916358675645746\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016031121576411858\n",
      "SEED: 1119, FOLD: 2, EPOCH: 20, train_loss: 0.013258145393236824\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01598208589065406\n",
      "SEED: 1119, FOLD: 2, EPOCH: 21, train_loss: 0.01262442353249028\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015986758646451764\n",
      "SEED: 1119, FOLD: 2, EPOCH: 22, train_loss: 0.01198475193772195\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01600575948961907\n",
      "SEED: 1119, FOLD: 2, EPOCH: 23, train_loss: 0.011493994031047476\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015992083638492558\n",
      "SEED: 1119, FOLD: 2, EPOCH: 24, train_loss: 0.01126205711962952\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01600235721303357\n",
      "SEED: 1119, FOLD: 3, EPOCH: 0, train_loss: 0.7126142589942269\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6084416078196632\n",
      "SEED: 1119, FOLD: 3, EPOCH: 1, train_loss: 0.20267852930271107\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 1, valid_loss: 0.023432258723510638\n",
      "SEED: 1119, FOLD: 3, EPOCH: 2, train_loss: 0.02099528870936753\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 2, valid_loss: 0.01981368422922161\n",
      "SEED: 1119, FOLD: 3, EPOCH: 3, train_loss: 0.01889735195731771\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018436698139541678\n",
      "SEED: 1119, FOLD: 3, EPOCH: 4, train_loss: 0.01811279645324617\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017780276739762887\n",
      "SEED: 1119, FOLD: 3, EPOCH: 5, train_loss: 0.017174564166993336\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 5, valid_loss: 0.01722914766934183\n",
      "SEED: 1119, FOLD: 3, EPOCH: 6, train_loss: 0.01703377908932558\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017187110820992127\n",
      "SEED: 1119, FOLD: 3, EPOCH: 7, train_loss: 0.016457229177804962\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 7, valid_loss: 0.016882693239798147\n",
      "SEED: 1119, FOLD: 3, EPOCH: 8, train_loss: 0.016420781774365383\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01779682691105538\n",
      "SEED: 1119, FOLD: 3, EPOCH: 9, train_loss: 0.016447826801542786\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 9, valid_loss: 0.016680913511663675\n",
      "SEED: 1119, FOLD: 3, EPOCH: 10, train_loss: 0.016141945982108944\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016781257775922615\n",
      "SEED: 1119, FOLD: 3, EPOCH: 11, train_loss: 0.016047262276212376\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016602218099352386\n",
      "SEED: 1119, FOLD: 3, EPOCH: 12, train_loss: 0.015933756311626537\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016657220147964027\n",
      "SEED: 1119, FOLD: 3, EPOCH: 13, train_loss: 0.015838845430508904\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016468785961882934\n",
      "SEED: 1119, FOLD: 3, EPOCH: 14, train_loss: 0.015670358891720356\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01637490580065383\n",
      "SEED: 1119, FOLD: 3, EPOCH: 15, train_loss: 0.01542834774253593\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016296501374906965\n",
      "SEED: 1119, FOLD: 3, EPOCH: 16, train_loss: 0.0151488588636984\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016245985972798534\n",
      "SEED: 1119, FOLD: 3, EPOCH: 17, train_loss: 0.014763386596156202\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01615995422212614\n",
      "SEED: 1119, FOLD: 3, EPOCH: 18, train_loss: 0.014384640178278736\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 18, valid_loss: 0.015985390947510798\n",
      "SEED: 1119, FOLD: 3, EPOCH: 19, train_loss: 0.01389096805528886\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016035677244265873\n",
      "SEED: 1119, FOLD: 3, EPOCH: 20, train_loss: 0.013308299759375876\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 20, valid_loss: 0.01590445689443085\n",
      "SEED: 1119, FOLD: 3, EPOCH: 21, train_loss: 0.012619396644657936\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 21, valid_loss: 0.015888097644266155\n",
      "SEED: 1119, FOLD: 3, EPOCH: 22, train_loss: 0.011965762135451254\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01586711189399163\n",
      "SEED: 1119, FOLD: 3, EPOCH: 23, train_loss: 0.011513542883314085\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01585734925336308\n",
      "SEED: 1119, FOLD: 3, EPOCH: 24, train_loss: 0.011295110797104628\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01583923611582981\n",
      "SEED: 1119, FOLD: 4, EPOCH: 0, train_loss: 0.7130518158276876\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6038743191295199\n",
      "SEED: 1119, FOLD: 4, EPOCH: 1, train_loss: 0.20303264233297197\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 1, valid_loss: 0.023150779513849154\n",
      "SEED: 1119, FOLD: 4, EPOCH: 2, train_loss: 0.020873025194674297\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 2, valid_loss: 0.0193686101378666\n",
      "SEED: 1119, FOLD: 4, EPOCH: 3, train_loss: 0.01892211833509846\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01850816545387109\n",
      "SEED: 1119, FOLD: 4, EPOCH: 4, train_loss: 0.01795139493069787\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 4, valid_loss: 0.01971058381928338\n",
      "SEED: 1119, FOLD: 4, EPOCH: 5, train_loss: 0.017434011388947998\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017282459574441116\n",
      "SEED: 1119, FOLD: 4, EPOCH: 6, train_loss: 0.01658612335829631\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01674042481722103\n",
      "SEED: 1119, FOLD: 4, EPOCH: 7, train_loss: 0.016468509640274704\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 7, valid_loss: 0.016784759497063026\n",
      "SEED: 1119, FOLD: 4, EPOCH: 8, train_loss: 0.016295220459932865\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 8, valid_loss: 0.01660725614055991\n",
      "SEED: 1119, FOLD: 4, EPOCH: 9, train_loss: 0.016241867243703724\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 9, valid_loss: 0.016630316722310252\n",
      "SEED: 1119, FOLD: 4, EPOCH: 10, train_loss: 0.01614444617829893\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 10, valid_loss: 0.016767944157537486\n",
      "SEED: 1119, FOLD: 4, EPOCH: 11, train_loss: 0.016058025841155777\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01653018630006247\n",
      "SEED: 1119, FOLD: 4, EPOCH: 12, train_loss: 0.016061877332411816\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 12, valid_loss: 0.01679731284578641\n",
      "SEED: 1119, FOLD: 4, EPOCH: 13, train_loss: 0.01586860958216847\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016335933986637328\n",
      "SEED: 1119, FOLD: 4, EPOCH: 14, train_loss: 0.015673470170493576\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01607430984990464\n",
      "SEED: 1119, FOLD: 4, EPOCH: 15, train_loss: 0.015414107577416344\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016195273492485285\n",
      "SEED: 1119, FOLD: 4, EPOCH: 16, train_loss: 0.015135466364090857\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01603331784200337\n",
      "SEED: 1119, FOLD: 4, EPOCH: 17, train_loss: 0.014792208357349686\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 17, valid_loss: 0.015983334380305476\n",
      "SEED: 1119, FOLD: 4, EPOCH: 18, train_loss: 0.0144182197695625\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 18, valid_loss: 0.015866463641739555\n",
      "SEED: 1119, FOLD: 4, EPOCH: 19, train_loss: 0.013925895054379234\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01574428312273489\n",
      "SEED: 1119, FOLD: 4, EPOCH: 20, train_loss: 0.013328552947960037\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 20, valid_loss: 0.015716037506030664\n",
      "SEED: 1119, FOLD: 4, EPOCH: 21, train_loss: 0.012651289084359356\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015714726203845605\n",
      "SEED: 1119, FOLD: 4, EPOCH: 22, train_loss: 0.01201840743854426\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01565851400502854\n",
      "SEED: 1119, FOLD: 4, EPOCH: 23, train_loss: 0.011522551202147768\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01567104220804241\n",
      "SEED: 1119, FOLD: 4, EPOCH: 24, train_loss: 0.011292506076827429\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01566238732387622\n",
      "elapsed time: 1040.2953033447266\n",
      "SEED: 1303, FOLD: 0, EPOCH: 0, train_loss: 0.7135066433229308\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6175176302591959\n",
      "SEED: 1303, FOLD: 0, EPOCH: 1, train_loss: 0.20423047398419483\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 1, valid_loss: 0.024339317344129086\n",
      "SEED: 1303, FOLD: 0, EPOCH: 2, train_loss: 0.020967103851338226\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01936118175379104\n",
      "SEED: 1303, FOLD: 0, EPOCH: 3, train_loss: 0.018827485541502636\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 3, valid_loss: 0.018164697465383343\n",
      "SEED: 1303, FOLD: 0, EPOCH: 4, train_loss: 0.018032878893764988\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017778265807363722\n",
      "SEED: 1303, FOLD: 0, EPOCH: 5, train_loss: 0.017376707137926765\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 5, valid_loss: 0.016994614619761705\n",
      "SEED: 1303, FOLD: 0, EPOCH: 6, train_loss: 0.017002468699238438\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01684928245635496\n",
      "SEED: 1303, FOLD: 0, EPOCH: 7, train_loss: 0.016455683222823383\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 7, valid_loss: 0.016694702880664006\n",
      "SEED: 1303, FOLD: 0, EPOCH: 8, train_loss: 0.016791846238724564\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01681861819492446\n",
      "SEED: 1303, FOLD: 0, EPOCH: 9, train_loss: 0.01625958225433377\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 9, valid_loss: 0.016585471005075507\n",
      "SEED: 1303, FOLD: 0, EPOCH: 10, train_loss: 0.016088618518973606\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 10, valid_loss: 0.016662938727272883\n",
      "SEED: 1303, FOLD: 0, EPOCH: 11, train_loss: 0.01606309071075225\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01656628425957428\n",
      "SEED: 1303, FOLD: 0, EPOCH: 12, train_loss: 0.015958605374655\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016366528295394447\n",
      "SEED: 1303, FOLD: 0, EPOCH: 13, train_loss: 0.01585807571646528\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016330469140989914\n",
      "SEED: 1303, FOLD: 0, EPOCH: 14, train_loss: 0.015600660424409569\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016146374969846673\n",
      "SEED: 1303, FOLD: 0, EPOCH: 15, train_loss: 0.015374085366509962\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 15, valid_loss: 0.015983754872447915\n",
      "SEED: 1303, FOLD: 0, EPOCH: 16, train_loss: 0.015112996020394823\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 16, valid_loss: 0.015977262208859127\n",
      "SEED: 1303, FOLD: 0, EPOCH: 17, train_loss: 0.0147787527302685\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 17, valid_loss: 0.015973194864475064\n",
      "SEED: 1303, FOLD: 0, EPOCH: 18, train_loss: 0.01442272481980963\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 18, valid_loss: 0.01586467084578342\n",
      "SEED: 1303, FOLD: 0, EPOCH: 19, train_loss: 0.013804988287713217\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 19, valid_loss: 0.015810233540832996\n",
      "SEED: 1303, FOLD: 0, EPOCH: 20, train_loss: 0.01311458814619244\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 20, valid_loss: 0.015753135085105896\n",
      "SEED: 1303, FOLD: 0, EPOCH: 21, train_loss: 0.012426562404826931\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015695511880848143\n",
      "SEED: 1303, FOLD: 0, EPOCH: 22, train_loss: 0.011778292043701462\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01571202686884337\n",
      "SEED: 1303, FOLD: 0, EPOCH: 23, train_loss: 0.01123940435818572\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015714674670663144\n",
      "SEED: 1303, FOLD: 0, EPOCH: 24, train_loss: 0.011025348151831524\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01572998468246725\n",
      "SEED: 1303, FOLD: 1, EPOCH: 0, train_loss: 0.7128863801126895\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6030980679723952\n",
      "SEED: 1303, FOLD: 1, EPOCH: 1, train_loss: 0.20269860489212949\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 1, valid_loss: 0.02265187694380681\n",
      "SEED: 1303, FOLD: 1, EPOCH: 2, train_loss: 0.021001747363935345\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 2, valid_loss: 0.0195586494066649\n",
      "SEED: 1303, FOLD: 1, EPOCH: 3, train_loss: 0.018926105691470962\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 3, valid_loss: 0.01830955936263005\n",
      "SEED: 1303, FOLD: 1, EPOCH: 4, train_loss: 0.018205195800333782\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017604173781971138\n",
      "SEED: 1303, FOLD: 1, EPOCH: 5, train_loss: 0.01718446515176607\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 5, valid_loss: 0.01707429366393222\n",
      "SEED: 1303, FOLD: 1, EPOCH: 6, train_loss: 0.016678136705920315\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01747585005230374\n",
      "SEED: 1303, FOLD: 1, EPOCH: 7, train_loss: 0.01663318738017393\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 7, valid_loss: 0.016526411184006266\n",
      "SEED: 1303, FOLD: 1, EPOCH: 8, train_loss: 0.016408489261200462\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 8, valid_loss: 0.016628124544190034\n",
      "SEED: 1303, FOLD: 1, EPOCH: 9, train_loss: 0.01631959396805884\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 9, valid_loss: 0.016554969569875136\n",
      "SEED: 1303, FOLD: 1, EPOCH: 10, train_loss: 0.016202913867174717\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01662567092312707\n",
      "SEED: 1303, FOLD: 1, EPOCH: 11, train_loss: 0.016128239086896614\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01661032417582141\n",
      "SEED: 1303, FOLD: 1, EPOCH: 12, train_loss: 0.01597624887590823\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01619324145010776\n",
      "SEED: 1303, FOLD: 1, EPOCH: 13, train_loss: 0.01580418302151172\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016397314974003367\n",
      "SEED: 1303, FOLD: 1, EPOCH: 14, train_loss: 0.015666331906897434\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016248126255555287\n",
      "SEED: 1303, FOLD: 1, EPOCH: 15, train_loss: 0.015441427182784115\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01616931541098489\n",
      "SEED: 1303, FOLD: 1, EPOCH: 16, train_loss: 0.015157995246134806\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 16, valid_loss: 0.015973082329663966\n",
      "SEED: 1303, FOLD: 1, EPOCH: 17, train_loss: 0.01482397575687239\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01594793413662248\n",
      "SEED: 1303, FOLD: 1, EPOCH: 18, train_loss: 0.014366613350052765\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 18, valid_loss: 0.015831183435188398\n",
      "SEED: 1303, FOLD: 1, EPOCH: 19, train_loss: 0.01388263147648262\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 19, valid_loss: 0.015790348406881094\n",
      "SEED: 1303, FOLD: 1, EPOCH: 20, train_loss: 0.013297142622911411\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 20, valid_loss: 0.015784442010853026\n",
      "SEED: 1303, FOLD: 1, EPOCH: 21, train_loss: 0.012611253888926643\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01565750429613723\n",
      "SEED: 1303, FOLD: 1, EPOCH: 22, train_loss: 0.011993925613553627\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015697397705581453\n",
      "SEED: 1303, FOLD: 1, EPOCH: 23, train_loss: 0.01151305042963097\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01566854916099045\n",
      "SEED: 1303, FOLD: 1, EPOCH: 24, train_loss: 0.011278730763149435\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015687313189523086\n",
      "SEED: 1303, FOLD: 2, EPOCH: 0, train_loss: 0.7133374136427174\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 0, valid_loss: 0.618354770872328\n",
      "SEED: 1303, FOLD: 2, EPOCH: 1, train_loss: 0.2024163630237614\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 1, valid_loss: 0.02296400059842401\n",
      "SEED: 1303, FOLD: 2, EPOCH: 2, train_loss: 0.0209936810846346\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 2, valid_loss: 0.019352943119075563\n",
      "SEED: 1303, FOLD: 2, EPOCH: 3, train_loss: 0.018853364026416904\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01815552471412553\n",
      "SEED: 1303, FOLD: 2, EPOCH: 4, train_loss: 0.018073178530819176\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017606565832263894\n",
      "SEED: 1303, FOLD: 2, EPOCH: 5, train_loss: 0.01695016242455745\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 5, valid_loss: 0.016960465918398566\n",
      "SEED: 1303, FOLD: 2, EPOCH: 6, train_loss: 0.016817739935240883\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 6, valid_loss: 0.016845904756337404\n",
      "SEED: 1303, FOLD: 2, EPOCH: 7, train_loss: 0.016403734549016193\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 7, valid_loss: 0.016898655901766486\n",
      "SEED: 1303, FOLD: 2, EPOCH: 8, train_loss: 0.016202529352428257\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016583580575469468\n",
      "SEED: 1303, FOLD: 2, EPOCH: 9, train_loss: 0.016162933457804764\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01667154109519389\n",
      "SEED: 1303, FOLD: 2, EPOCH: 10, train_loss: 0.016114871098619442\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 10, valid_loss: 0.016976129522340164\n",
      "SEED: 1303, FOLD: 2, EPOCH: 11, train_loss: 0.015969955321887264\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016434003702468343\n",
      "SEED: 1303, FOLD: 2, EPOCH: 12, train_loss: 0.01583853907937157\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016763449594792392\n",
      "SEED: 1303, FOLD: 2, EPOCH: 13, train_loss: 0.015650625367635403\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016396778118279245\n",
      "SEED: 1303, FOLD: 2, EPOCH: 14, train_loss: 0.015511355497806833\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01640638688372241\n",
      "SEED: 1303, FOLD: 2, EPOCH: 15, train_loss: 0.015282485769062803\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01637647771793935\n",
      "SEED: 1303, FOLD: 2, EPOCH: 16, train_loss: 0.015008688755873321\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016360407643434074\n",
      "SEED: 1303, FOLD: 2, EPOCH: 17, train_loss: 0.014642050584265287\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016163945094578795\n",
      "SEED: 1303, FOLD: 2, EPOCH: 18, train_loss: 0.014234822000498358\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016053599615891773\n",
      "SEED: 1303, FOLD: 2, EPOCH: 19, train_loss: 0.013686515876780386\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016038642471863165\n",
      "SEED: 1303, FOLD: 2, EPOCH: 20, train_loss: 0.01305373176338448\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016027525946911838\n",
      "SEED: 1303, FOLD: 2, EPOCH: 21, train_loss: 0.012379131603824057\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01599625518752469\n",
      "SEED: 1303, FOLD: 2, EPOCH: 22, train_loss: 0.011734597897831944\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 22, valid_loss: 0.0159744569617841\n",
      "SEED: 1303, FOLD: 2, EPOCH: 23, train_loss: 0.011193618002901043\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01600604188731975\n",
      "SEED: 1303, FOLD: 2, EPOCH: 24, train_loss: 0.011006197392724562\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016003881218946643\n",
      "SEED: 1303, FOLD: 3, EPOCH: 0, train_loss: 0.7134197043335956\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6088356706831191\n",
      "SEED: 1303, FOLD: 3, EPOCH: 1, train_loss: 0.20339440924209962\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 1, valid_loss: 0.02309418014354176\n",
      "SEED: 1303, FOLD: 3, EPOCH: 2, train_loss: 0.020945570067219112\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 2, valid_loss: 0.019431021581921313\n",
      "SEED: 1303, FOLD: 3, EPOCH: 3, train_loss: 0.018698994583193806\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018451044335961342\n",
      "SEED: 1303, FOLD: 3, EPOCH: 4, train_loss: 0.017842842481922413\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017839957752989397\n",
      "SEED: 1303, FOLD: 3, EPOCH: 5, train_loss: 0.017245271121678146\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 5, valid_loss: 0.01728356841744648\n",
      "SEED: 1303, FOLD: 3, EPOCH: 6, train_loss: 0.01652112623433704\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01717099081724882\n",
      "SEED: 1303, FOLD: 3, EPOCH: 7, train_loss: 0.016882288917575195\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017063016227136057\n",
      "SEED: 1303, FOLD: 3, EPOCH: 8, train_loss: 0.016390805321651093\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01689829822215769\n",
      "SEED: 1303, FOLD: 3, EPOCH: 9, train_loss: 0.01626093719370555\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01675022905692458\n",
      "SEED: 1303, FOLD: 3, EPOCH: 10, train_loss: 0.016092503713308903\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016653455949078005\n",
      "SEED: 1303, FOLD: 3, EPOCH: 11, train_loss: 0.01604744441051414\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01675541481624047\n",
      "SEED: 1303, FOLD: 3, EPOCH: 12, train_loss: 0.015941046313315197\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016625709055612486\n",
      "SEED: 1303, FOLD: 3, EPOCH: 13, train_loss: 0.015774770275406216\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016611457388434146\n",
      "SEED: 1303, FOLD: 3, EPOCH: 14, train_loss: 0.015609382543766844\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01655312870732612\n",
      "SEED: 1303, FOLD: 3, EPOCH: 15, train_loss: 0.015417290918960951\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016284176096734073\n",
      "SEED: 1303, FOLD: 3, EPOCH: 16, train_loss: 0.015141530529312466\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016232136740452714\n",
      "SEED: 1303, FOLD: 3, EPOCH: 17, train_loss: 0.014754056053209131\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016151377362095647\n",
      "SEED: 1303, FOLD: 3, EPOCH: 18, train_loss: 0.014361017019204472\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 18, valid_loss: 0.0160644483856029\n",
      "SEED: 1303, FOLD: 3, EPOCH: 19, train_loss: 0.013856119192812754\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 19, valid_loss: 0.015956415225648217\n",
      "SEED: 1303, FOLD: 3, EPOCH: 20, train_loss: 0.013235534878744595\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 20, valid_loss: 0.015895477185646694\n",
      "SEED: 1303, FOLD: 3, EPOCH: 21, train_loss: 0.012537314678015917\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 21, valid_loss: 0.015945496606744\n",
      "SEED: 1303, FOLD: 3, EPOCH: 22, train_loss: 0.011858545905114084\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01583467972361379\n",
      "SEED: 1303, FOLD: 3, EPOCH: 23, train_loss: 0.011360373186028522\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 23, valid_loss: 0.015861234886364803\n",
      "SEED: 1303, FOLD: 3, EPOCH: 24, train_loss: 0.011109313009765701\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01586194269152151\n",
      "SEED: 1303, FOLD: 4, EPOCH: 0, train_loss: 0.7134796406911768\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6149158775806427\n",
      "SEED: 1303, FOLD: 4, EPOCH: 1, train_loss: 0.20350849709433058\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 1, valid_loss: 0.024430898432102468\n",
      "SEED: 1303, FOLD: 4, EPOCH: 2, train_loss: 0.020959943775897442\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 2, valid_loss: 0.019523599081569247\n",
      "SEED: 1303, FOLD: 4, EPOCH: 3, train_loss: 0.018836680772727814\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01850353895376126\n",
      "SEED: 1303, FOLD: 4, EPOCH: 4, train_loss: 0.01797279224231623\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 4, valid_loss: 0.018293205855621233\n",
      "SEED: 1303, FOLD: 4, EPOCH: 5, train_loss: 0.017093001729876236\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01720265842353304\n",
      "SEED: 1303, FOLD: 4, EPOCH: 6, train_loss: 0.016537302484114964\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01686334004625678\n",
      "SEED: 1303, FOLD: 4, EPOCH: 7, train_loss: 0.016340476042334583\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 7, valid_loss: 0.016766451247450378\n",
      "SEED: 1303, FOLD: 4, EPOCH: 8, train_loss: 0.016365218799615253\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 8, valid_loss: 0.01719277145134078\n",
      "SEED: 1303, FOLD: 4, EPOCH: 9, train_loss: 0.01633972474846287\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 9, valid_loss: 0.016440468478120036\n",
      "SEED: 1303, FOLD: 4, EPOCH: 10, train_loss: 0.016158909145472706\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01640661997306678\n",
      "SEED: 1303, FOLD: 4, EPOCH: 11, train_loss: 0.015989693192144234\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 11, valid_loss: 0.0164133515726361\n",
      "SEED: 1303, FOLD: 4, EPOCH: 12, train_loss: 0.01593268732877745\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016399219839109316\n",
      "SEED: 1303, FOLD: 4, EPOCH: 13, train_loss: 0.01573068699866965\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01648861076682806\n",
      "SEED: 1303, FOLD: 4, EPOCH: 14, train_loss: 0.015615441674447578\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01617725897166464\n",
      "SEED: 1303, FOLD: 4, EPOCH: 15, train_loss: 0.015385946879784266\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016086722931100264\n",
      "SEED: 1303, FOLD: 4, EPOCH: 16, train_loss: 0.015092898659624052\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 16, valid_loss: 0.015992585103958845\n",
      "SEED: 1303, FOLD: 4, EPOCH: 17, train_loss: 0.014763108508634394\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 17, valid_loss: 0.015847179624769423\n",
      "SEED: 1303, FOLD: 4, EPOCH: 18, train_loss: 0.014321829786227234\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01600598321399755\n",
      "SEED: 1303, FOLD: 4, EPOCH: 19, train_loss: 0.013842837277637876\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 19, valid_loss: 0.015756253980927996\n",
      "SEED: 1303, FOLD: 4, EPOCH: 20, train_loss: 0.013234568867778433\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01568884676736262\n",
      "SEED: 1303, FOLD: 4, EPOCH: 21, train_loss: 0.012561210957558258\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01569311134517193\n",
      "SEED: 1303, FOLD: 4, EPOCH: 22, train_loss: 0.011889443894767242\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01565852290433314\n",
      "SEED: 1303, FOLD: 4, EPOCH: 23, train_loss: 0.011411999514245468\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 23, valid_loss: 0.015684763331794076\n",
      "SEED: 1303, FOLD: 4, EPOCH: 24, train_loss: 0.011163288052531256\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015635564509365294\n",
      "elapsed time: 1248.6638026237488\n"
     ]
    }
   ],
   "source": [
    "SEED = [940, 1513, 1269,1392,1119,1303]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "    print(f\"elapsed time: {time.time() - time_start}\")\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:13.616982Z",
     "iopub.status.busy": "2020-11-26T06:01:13.615723Z",
     "iopub.status.idle": "2020-11-26T06:01:14.398511Z",
     "shell.execute_reply": "2020-11-26T06:01:14.400153Z"
    },
    "papermill": {
     "duration": 1.997645,
     "end_time": "2020-11-26T06:01:14.400404",
     "exception": false,
     "start_time": "2020-11-26T06:01:12.402759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.to_pickle(f\"{INT_DIR}/{NB}-train-score-pred.pkl\")\n",
    "test.to_pickle(f\"{INT_DIR}/{NB}-test-score-pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:16.325441Z",
     "iopub.status.busy": "2020-11-26T06:01:16.323178Z",
     "iopub.status.idle": "2020-11-26T06:01:16.328165Z",
     "shell.execute_reply": "2020-11-26T06:01:16.327557Z"
    },
    "papermill": {
     "duration": 0.859033,
     "end_time": "2020-11-26T06:01:16.328276",
     "exception": false,
     "start_time": "2020-11-26T06:01:15.469243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:17.712118Z",
     "iopub.status.busy": "2020-11-26T06:01:17.710514Z",
     "iopub.status.idle": "2020-11-26T06:01:19.176359Z",
     "shell.execute_reply": "2020-11-26T06:01:19.177266Z"
    },
    "papermill": {
     "duration": 2.153899,
     "end_time": "2020-11-26T06:01:19.177502",
     "exception": false,
     "start_time": "2020-11-26T06:01:17.023603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.014299113941268274\n"
     ]
    }
   ],
   "source": [
    "train[target_cols] = np.maximum(PMIN, np.minimum(PMAX, train[target_cols]))\n",
    "\n",
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_true = y_true > 0.5\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.627064,
     "end_time": "2020-11-26T06:01:20.507437",
     "exception": false,
     "start_time": "2020-11-26T06:01:19.880373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- CV log_loss:  0.014761779358699672\n",
    "- CV log_loss:  0.014519859174255039\n",
    "- CV log_loss:  0.014525173864593479\n",
    "- CV log_loss:  0.014354930596928602 # 3 umap features\n",
    "- CV log_loss:  0.014353604854355429 # more umap features\n",
    "- CV log_loss:  0.01436484670778641 # more hidden nodes\n",
    "- CV log_loss:  0.014344688083211073\n",
    "  - using predicted unscored targets as feature \n",
    "- CV log_loss:  0.013368097791623873\n",
    "  - using given unscored targets as feature\n",
    "  - bad in public lb\n",
    "- CV log_loss:  0.01434373547175235\n",
    "  - rankgauss predicted unscored targets\n",
    "- CV log_loss:  0.014346100008158216\n",
    "  - unscored targets pca/umap\n",
    "- CV log_loss:  0.014328486629791769\n",
    "  - NFOLDS=10, Epoch=20\n",
    "- CV log_loss:  0.014299741080816082\n",
    "  - NFOLDS=10, Epoch=20, 25\n",
    "- CV log_loss:  0.014311301224480969\n",
    "  - NFOLDS=10, Epoch=25\n",
    "- CV log_loss:  0.01429269446076626\n",
    "  - NFOLDS=10, Epoch=15, 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:21.755147Z",
     "iopub.status.busy": "2020-11-26T06:01:21.754200Z",
     "iopub.status.idle": "2020-11-26T06:01:21.759141Z",
     "shell.execute_reply": "2020-11-26T06:01:21.758497Z"
    },
    "papermill": {
     "duration": 0.631618,
     "end_time": "2020-11-26T06:01:21.759258",
     "exception": false,
     "start_time": "2020-11-26T06:01:21.127640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train = pd.read_pickle(f\"../interim/23-train-score-pred.pkl\")\n",
    "# test = pd.read_pickle(f\"../interim/23-test-score-pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:23.016410Z",
     "iopub.status.busy": "2020-11-26T06:01:23.015094Z",
     "iopub.status.idle": "2020-11-26T06:01:23.478577Z",
     "shell.execute_reply": "2020-11-26T06:01:23.477851Z"
    },
    "papermill": {
     "duration": 1.093868,
     "end_time": "2020-11-26T06:01:23.478713",
     "exception": false,
     "start_time": "2020-11-26T06:01:22.384845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle(f\"{INT_DIR}/{NB}-train-score-pred.pkl\")\n",
    "test = pd.read_pickle(f\"{INT_DIR}/{NB}-test-score-pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:24.747114Z",
     "iopub.status.busy": "2020-11-26T06:01:24.746295Z",
     "iopub.status.idle": "2020-11-26T06:01:24.751826Z",
     "shell.execute_reply": "2020-11-26T06:01:24.751204Z"
    },
    "papermill": {
     "duration": 0.649495,
     "end_time": "2020-11-26T06:01:24.751946",
     "exception": false,
     "start_time": "2020-11-26T06:01:24.102451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "# NFOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:26.284371Z",
     "iopub.status.busy": "2020-11-26T06:01:26.282269Z",
     "iopub.status.idle": "2020-11-26T06:01:27.208820Z",
     "shell.execute_reply": "2020-11-26T06:01:27.208112Z"
    },
    "papermill": {
     "duration": 1.719857,
     "end_time": "2020-11-26T06:01:27.208942",
     "exception": false,
     "start_time": "2020-11-26T06:01:25.489085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PMIN = 0.0005\n",
    "PMAX = 0.9995\n",
    "for c in train_targets_scored.columns:\n",
    "    if c != \"sig_id\":\n",
    "        train_targets_scored[c] = np.maximum(PMIN, np.minimum(PMAX, train_targets_scored[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:28.464915Z",
     "iopub.status.busy": "2020-11-26T06:01:28.463868Z",
     "iopub.status.idle": "2020-11-26T06:01:28.468971Z",
     "shell.execute_reply": "2020-11-26T06:01:28.469665Z"
    },
    "papermill": {
     "duration": 0.638334,
     "end_time": "2020-11-26T06:01:28.469825",
     "exception": false,
     "start_time": "2020-11-26T06:01:27.831491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sig_id', '5-alpha_reductase_inhibitor', '11-beta-hsd1_inhibitor',\n",
       "       'acat_inhibitor', 'acetylcholine_receptor_agonist',\n",
       "       'acetylcholine_receptor_antagonist', 'acetylcholinesterase_inhibitor',\n",
       "       'adenosine_receptor_agonist', 'adenosine_receptor_antagonist',\n",
       "       'adenylyl_cyclase_activator',\n",
       "       ...\n",
       "       'tropomyosin_receptor_kinase_inhibitor', 'trpv_agonist',\n",
       "       'trpv_antagonist', 'tubulin_inhibitor', 'tyrosine_kinase_inhibitor',\n",
       "       'ubiquitin_specific_protease_inhibitor', 'vegfr_inhibitor', 'vitamin_b',\n",
       "       'vitamin_d_receptor_agonist', 'wnt_inhibitor'],\n",
       "      dtype='object', length=207)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_scored.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:29.738230Z",
     "iopub.status.busy": "2020-11-26T06:01:29.736762Z",
     "iopub.status.idle": "2020-11-26T06:01:30.082169Z",
     "shell.execute_reply": "2020-11-26T06:01:30.081567Z"
    },
    "papermill": {
     "duration": 0.989108,
     "end_time": "2020-11-26T06:01:30.082296",
     "exception": false,
     "start_time": "2020-11-26T06:01:29.093188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train_targets_scored.columns]\n",
    "train.columns = [c + \"_pred\" if (c != 'sig_id' and c in train_targets_scored.columns) else c for c in train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:31.345699Z",
     "iopub.status.busy": "2020-11-26T06:01:31.343862Z",
     "iopub.status.idle": "2020-11-26T06:01:31.346544Z",
     "shell.execute_reply": "2020-11-26T06:01:31.347129Z"
    },
    "papermill": {
     "duration": 0.635984,
     "end_time": "2020-11-26T06:01:31.347288",
     "exception": false,
     "start_time": "2020-11-26T06:01:30.711304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = test[train_targets_scored.columns]\n",
    "test.columns = [c + \"_pred\" if (c != 'sig_id' and c in train_targets_scored.columns) else c for c in test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:32.598000Z",
     "iopub.status.busy": "2020-11-26T06:01:32.596935Z",
     "iopub.status.idle": "2020-11-26T06:01:32.639776Z",
     "shell.execute_reply": "2020-11-26T06:01:32.640437Z"
    },
    "papermill": {
     "duration": 0.673501,
     "end_time": "2020-11-26T06:01:32.640612",
     "exception": false,
     "start_time": "2020-11-26T06:01:31.967111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor_pred</th>\n",
       "      <th>11-beta-hsd1_inhibitor_pred</th>\n",
       "      <th>acat_inhibitor_pred</th>\n",
       "      <th>acetylcholine_receptor_agonist_pred</th>\n",
       "      <th>acetylcholine_receptor_antagonist_pred</th>\n",
       "      <th>acetylcholinesterase_inhibitor_pred</th>\n",
       "      <th>adenosine_receptor_agonist_pred</th>\n",
       "      <th>adenosine_receptor_antagonist_pred</th>\n",
       "      <th>adenylyl_cyclase_activator_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor_pred</th>\n",
       "      <th>trpv_agonist_pred</th>\n",
       "      <th>trpv_antagonist_pred</th>\n",
       "      <th>tubulin_inhibitor_pred</th>\n",
       "      <th>tyrosine_kinase_inhibitor_pred</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor_pred</th>\n",
       "      <th>vegfr_inhibitor_pred</th>\n",
       "      <th>vitamin_b_pred</th>\n",
       "      <th>vitamin_d_receptor_agonist_pred</th>\n",
       "      <th>wnt_inhibitor_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>0.046037</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.001270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.016051</td>\n",
       "      <td>0.015803</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.001952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>0.009875</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>0.016152</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.044607</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.001548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.010402</td>\n",
       "      <td>0.010414</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.038662</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.011430</td>\n",
       "      <td>0.010408</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.001167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.033893</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.011063</td>\n",
       "      <td>0.033664</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.004457</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.001185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.004503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.008948</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor_pred  \\\n",
       "0      id_000644bb2                          0.000650   \n",
       "1      id_000779bfc                          0.000470   \n",
       "2      id_000a6266a                          0.001245   \n",
       "3      id_0015fd391                          0.000305   \n",
       "4      id_001626bd3                          0.000325   \n",
       "...             ...                               ...   \n",
       "21943  id_fff8c2444                          0.003864   \n",
       "21944  id_fffb1ceed                          0.001501   \n",
       "21945  id_fffb70c0c                          0.000865   \n",
       "21946  id_fffcb9e7c                          0.000276   \n",
       "21947  id_ffffdd77b                          0.000237   \n",
       "\n",
       "       11-beta-hsd1_inhibitor_pred  acat_inhibitor_pred  \\\n",
       "0                         0.000407             0.001056   \n",
       "1                         0.000582             0.001193   \n",
       "2                         0.002134             0.001011   \n",
       "3                         0.000633             0.001642   \n",
       "4                         0.000588             0.002882   \n",
       "...                            ...                  ...   \n",
       "21943                     0.002146             0.000467   \n",
       "21944                     0.001076             0.001139   \n",
       "21945                     0.000797             0.001951   \n",
       "21946                     0.000295             0.000341   \n",
       "21947                     0.000279             0.000505   \n",
       "\n",
       "       acetylcholine_receptor_agonist_pred  \\\n",
       "0                                 0.014523   \n",
       "1                                 0.016051   \n",
       "2                                 0.003338   \n",
       "3                                 0.010402   \n",
       "4                                 0.011430   \n",
       "...                                    ...   \n",
       "21943                             0.005645   \n",
       "21944                             0.011063   \n",
       "21945                             0.003430   \n",
       "21946                             0.002052   \n",
       "21947                             0.002124   \n",
       "\n",
       "       acetylcholine_receptor_antagonist_pred  \\\n",
       "0                                    0.046037   \n",
       "1                                    0.015803   \n",
       "2                                    0.009875   \n",
       "3                                    0.010414   \n",
       "4                                    0.010408   \n",
       "...                                       ...   \n",
       "21943                                0.033893   \n",
       "21944                                0.033664   \n",
       "21945                                0.004149   \n",
       "21946                                0.002650   \n",
       "21947                                0.004573   \n",
       "\n",
       "       acetylcholinesterase_inhibitor_pred  adenosine_receptor_agonist_pred  \\\n",
       "0                                 0.005095                         0.004229   \n",
       "1                                 0.004169                         0.002928   \n",
       "2                                 0.002004                         0.001475   \n",
       "3                                 0.001913                         0.002580   \n",
       "4                                 0.001821                         0.005062   \n",
       "...                                    ...                              ...   \n",
       "21943                             0.003897                         0.001029   \n",
       "21944                             0.004069                         0.002337   \n",
       "21945                             0.003843                         0.001893   \n",
       "21946                             0.000875                         0.000743   \n",
       "21947                             0.000990                         0.000490   \n",
       "\n",
       "       adenosine_receptor_antagonist_pred  adenylyl_cyclase_activator_pred  \\\n",
       "0                                0.003785                         0.000288   \n",
       "1                                0.003964                         0.000360   \n",
       "2                                0.006138                         0.000762   \n",
       "3                                0.002211                         0.000266   \n",
       "4                                0.002897                         0.000520   \n",
       "...                                   ...                              ...   \n",
       "21943                            0.003164                         0.000197   \n",
       "21944                            0.004457                         0.000299   \n",
       "21945                            0.011016                         0.000831   \n",
       "21946                            0.001091                         0.000100   \n",
       "21947                            0.001217                         0.000093   \n",
       "\n",
       "       ...  tropomyosin_receptor_kinase_inhibitor_pred  trpv_agonist_pred  \\\n",
       "0      ...                                    0.000428           0.000403   \n",
       "1      ...                                    0.000623           0.001061   \n",
       "2      ...                                    0.000306           0.001553   \n",
       "3      ...                                    0.000572           0.002320   \n",
       "4      ...                                    0.000811           0.001467   \n",
       "...    ...                                         ...                ...   \n",
       "21943  ...                                    0.000412           0.000283   \n",
       "21944  ...                                    0.000452           0.000299   \n",
       "21945  ...                                    0.000403           0.001359   \n",
       "21946  ...                                    0.000130           0.000249   \n",
       "21947  ...                                    0.000183           0.000695   \n",
       "\n",
       "       trpv_antagonist_pred  tubulin_inhibitor_pred  \\\n",
       "0                  0.002018                0.001835   \n",
       "1                  0.001272                0.003519   \n",
       "2                  0.002890                0.005609   \n",
       "3                  0.001868                0.038662   \n",
       "4                  0.001869                0.002159   \n",
       "...                     ...                     ...   \n",
       "21943              0.003942                0.000471   \n",
       "21944              0.002046                0.000932   \n",
       "21945              0.002742                0.000531   \n",
       "21946              0.000701                0.001685   \n",
       "21947              0.000573                0.008948   \n",
       "\n",
       "       tyrosine_kinase_inhibitor_pred  \\\n",
       "0                            0.000876   \n",
       "1                            0.001297   \n",
       "2                            0.016152   \n",
       "3                            0.003058   \n",
       "4                            0.001477   \n",
       "...                               ...   \n",
       "21943                        0.000543   \n",
       "21944                        0.001383   \n",
       "21945                        0.008149   \n",
       "21946                        0.002266   \n",
       "21947                        0.001396   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor_pred  vegfr_inhibitor_pred  \\\n",
       "0                                        0.000351              0.000769   \n",
       "1                                        0.000291              0.001067   \n",
       "2                                        0.000584              0.044607   \n",
       "3                                        0.000605              0.001781   \n",
       "4                                        0.000513              0.001180   \n",
       "...                                           ...                   ...   \n",
       "21943                                    0.000675              0.004110   \n",
       "21944                                    0.000313              0.001904   \n",
       "21945                                    0.000254              0.002202   \n",
       "21946                                    0.000156              0.001131   \n",
       "21947                                    0.000415              0.001090   \n",
       "\n",
       "       vitamin_b_pred  vitamin_d_receptor_agonist_pred  wnt_inhibitor_pred  \n",
       "0            0.001819                         0.000285            0.001270  \n",
       "1            0.002909                         0.000723            0.001952  \n",
       "2            0.004205                         0.000281            0.001548  \n",
       "3            0.001963                         0.000244            0.000547  \n",
       "4            0.001949                         0.000463            0.001167  \n",
       "...               ...                              ...                 ...  \n",
       "21943        0.000812                         0.000521            0.000377  \n",
       "21944        0.001251                         0.000460            0.001185  \n",
       "21945        0.001224                         0.006601            0.004503  \n",
       "21946        0.000391                         0.000137            0.000461  \n",
       "21947        0.000765                         0.000280            0.000239  \n",
       "\n",
       "[21948 rows x 207 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:33.889150Z",
     "iopub.status.busy": "2020-11-26T06:01:33.887547Z",
     "iopub.status.idle": "2020-11-26T06:01:34.053938Z",
     "shell.execute_reply": "2020-11-26T06:01:34.053307Z"
    },
    "papermill": {
     "duration": 0.793132,
     "end_time": "2020-11-26T06:01:34.054077",
     "exception": false,
     "start_time": "2020-11-26T06:01:33.260945",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use nonscored target in the given file as feature\n",
    "# if comment out below, use predicted nonscored target\n",
    "# train = train.drop(nonscored_target, axis=1)\n",
    "# train = train.merge(train_targets_nonscored, on=\"sig_id\")\n",
    "# train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train.merge(train_targets_scored, on='sig_id')\n",
    "# train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "# test = test[test['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "# target = train[train_targets_scored.columns]\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:35.362823Z",
     "iopub.status.busy": "2020-11-26T06:01:35.360442Z",
     "iopub.status.idle": "2020-11-26T06:01:35.363705Z",
     "shell.execute_reply": "2020-11-26T06:01:35.364270Z"
    },
    "papermill": {
     "duration": 0.647934,
     "end_time": "2020-11-26T06:01:35.364469",
     "exception": false,
     "start_time": "2020-11-26T06:01:34.716535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train[\"cp_time\"] = train_features[train_features[\"cp_type\"]==\"trt_cp\"].reset_index(drop=True)[\"cp_time\"]\n",
    "# train[\"cp_dose\"] = train_features[train_features[\"cp_type\"]==\"trt_cp\"].reset_index(drop=True)[\"cp_dose\"]\n",
    "# test[\"cp_time\"] = test_features[test_features[\"cp_type\"]==\"trt_cp\"].reset_index(drop=True)[\"cp_time\"]\n",
    "# test[\"cp_dose\"] = test_features[test_features[\"cp_type\"]==\"trt_cp\"].reset_index(drop=True)[\"cp_dose\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:36.967386Z",
     "iopub.status.busy": "2020-11-26T06:01:36.965915Z",
     "iopub.status.idle": "2020-11-26T06:01:39.447702Z",
     "shell.execute_reply": "2020-11-26T06:01:39.446487Z"
    },
    "papermill": {
     "duration": 3.437977,
     "end_time": "2020-11-26T06:01:39.447830",
     "exception": false,
     "start_time": "2020-11-26T06:01:36.009853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "scored_target_pred = [c + \"_pred\" for c in train_targets_scored.columns if c != 'sig_id']\n",
    "\n",
    "for col in (scored_target_pred):\n",
    "\n",
    "#     transformer = QuantileTransformer(n_quantiles=100, random_state=0, output_distribution=\"normal\")\n",
    "    vec_len = len(train[col].values)\n",
    "    vec_len_test = len(test[col].values)\n",
    "    raw_vec = train[col].values.reshape(vec_len, 1)\n",
    "#     transformer.fit(raw_vec)\n",
    "    if IS_TRAIN:\n",
    "        transformer = QuantileTransformer(n_quantiles=100, random_state=0, output_distribution=\"normal\")\n",
    "        transformer.fit(raw_vec)\n",
    "        pd.to_pickle(transformer, f\"{MODEL_DIR}/{NB}_{col}_quantile_scored.pkl\")\n",
    "    else:\n",
    "        transformer = pd.read_pickle(f\"{MODEL_DIR}/{NB}_{col}_quantile_scored.pkl\")\n",
    "\n",
    "    train[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test[col] = transformer.transform(test[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:40.709446Z",
     "iopub.status.busy": "2020-11-26T06:01:40.708681Z",
     "iopub.status.idle": "2020-11-26T06:01:40.713494Z",
     "shell.execute_reply": "2020-11-26T06:01:40.712838Z"
    },
    "papermill": {
     "duration": 0.630182,
     "end_time": "2020-11-26T06:01:40.713614",
     "exception": false,
     "start_time": "2020-11-26T06:01:40.083432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train = train.drop('cp_type', axis=1)\n",
    "# test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:41.982506Z",
     "iopub.status.busy": "2020-11-26T06:01:41.981605Z",
     "iopub.status.idle": "2020-11-26T06:01:41.985915Z",
     "shell.execute_reply": "2020-11-26T06:01:41.985342Z"
    },
    "papermill": {
     "duration": 0.647589,
     "end_time": "2020-11-26T06:01:41.986035",
     "exception": false,
     "start_time": "2020-11-26T06:01:41.338446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:43.243692Z",
     "iopub.status.busy": "2020-11-26T06:01:43.242592Z",
     "iopub.status.idle": "2020-11-26T06:01:43.285461Z",
     "shell.execute_reply": "2020-11-26T06:01:43.286108Z"
    },
    "papermill": {
     "duration": 0.676294,
     "end_time": "2020-11-26T06:01:43.286273",
     "exception": false,
     "start_time": "2020-11-26T06:01:42.609979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor_pred</th>\n",
       "      <th>11-beta-hsd1_inhibitor_pred</th>\n",
       "      <th>acat_inhibitor_pred</th>\n",
       "      <th>acetylcholine_receptor_agonist_pred</th>\n",
       "      <th>acetylcholine_receptor_antagonist_pred</th>\n",
       "      <th>acetylcholinesterase_inhibitor_pred</th>\n",
       "      <th>adenosine_receptor_agonist_pred</th>\n",
       "      <th>adenosine_receptor_antagonist_pred</th>\n",
       "      <th>adenylyl_cyclase_activator_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>-0.686643</td>\n",
       "      <td>-0.035590</td>\n",
       "      <td>0.852882</td>\n",
       "      <td>1.956241</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>1.089614</td>\n",
       "      <td>0.156629</td>\n",
       "      <td>0.208169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>-0.172458</td>\n",
       "      <td>-0.211519</td>\n",
       "      <td>0.186410</td>\n",
       "      <td>0.985108</td>\n",
       "      <td>0.135584</td>\n",
       "      <td>0.378215</td>\n",
       "      <td>0.605459</td>\n",
       "      <td>0.220750</td>\n",
       "      <td>0.576051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>1.077243</td>\n",
       "      <td>1.449984</td>\n",
       "      <td>-0.120273</td>\n",
       "      <td>-0.697052</td>\n",
       "      <td>-0.349476</td>\n",
       "      <td>-0.517079</td>\n",
       "      <td>-0.257762</td>\n",
       "      <td>0.825560</td>\n",
       "      <td>1.587220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>-0.716649</td>\n",
       "      <td>-0.086812</td>\n",
       "      <td>0.781953</td>\n",
       "      <td>0.418828</td>\n",
       "      <td>-0.307002</td>\n",
       "      <td>-0.553324</td>\n",
       "      <td>0.433879</td>\n",
       "      <td>-0.533703</td>\n",
       "      <td>0.076889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>-0.647452</td>\n",
       "      <td>-0.197038</td>\n",
       "      <td>1.767731</td>\n",
       "      <td>0.538918</td>\n",
       "      <td>-0.307476</td>\n",
       "      <td>-0.589463</td>\n",
       "      <td>1.314964</td>\n",
       "      <td>-0.210142</td>\n",
       "      <td>1.128933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>2.161669</td>\n",
       "      <td>1.457933</td>\n",
       "      <td>-1.363605</td>\n",
       "      <td>-0.255803</td>\n",
       "      <td>1.383198</td>\n",
       "      <td>0.270271</td>\n",
       "      <td>-0.631043</td>\n",
       "      <td>-0.096340</td>\n",
       "      <td>-0.455718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>1.292156</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.497966</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.338321</td>\n",
       "      <td>0.300445</td>\n",
       "      <td>0.383632</td>\n",
       "      <td>0.269661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>0.644685</td>\n",
       "      <td>0.244274</td>\n",
       "      <td>1.091844</td>\n",
       "      <td>-0.675820</td>\n",
       "      <td>-0.859166</td>\n",
       "      <td>0.248729</td>\n",
       "      <td>0.032107</td>\n",
       "      <td>1.555131</td>\n",
       "      <td>1.674891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>-0.816541</td>\n",
       "      <td>-1.027311</td>\n",
       "      <td>-1.831150</td>\n",
       "      <td>-1.051518</td>\n",
       "      <td>-1.187846</td>\n",
       "      <td>-1.045939</td>\n",
       "      <td>-0.918460</td>\n",
       "      <td>-1.097907</td>\n",
       "      <td>-1.324022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>-0.969996</td>\n",
       "      <td>-1.075307</td>\n",
       "      <td>-1.249552</td>\n",
       "      <td>-1.023304</td>\n",
       "      <td>-0.804183</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>-1.331299</td>\n",
       "      <td>-1.027077</td>\n",
       "      <td>-1.400592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 413 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor_pred  \\\n",
       "0      id_000644bb2                          0.263800   \n",
       "1      id_000779bfc                         -0.172458   \n",
       "2      id_000a6266a                          1.077243   \n",
       "3      id_0015fd391                         -0.716649   \n",
       "4      id_001626bd3                         -0.647452   \n",
       "...             ...                               ...   \n",
       "21943  id_fff8c2444                          2.161669   \n",
       "21944  id_fffb1ceed                          1.292156   \n",
       "21945  id_fffb70c0c                          0.644685   \n",
       "21946  id_fffcb9e7c                         -0.816541   \n",
       "21947  id_ffffdd77b                         -0.969996   \n",
       "\n",
       "       11-beta-hsd1_inhibitor_pred  acat_inhibitor_pred  \\\n",
       "0                        -0.686643            -0.035590   \n",
       "1                        -0.211519             0.186410   \n",
       "2                         1.449984            -0.120273   \n",
       "3                        -0.086812             0.781953   \n",
       "4                        -0.197038             1.767731   \n",
       "...                            ...                  ...   \n",
       "21943                     1.457933            -1.363605   \n",
       "21944                     0.637390             0.100840   \n",
       "21945                     0.244274             1.091844   \n",
       "21946                    -1.027311            -1.831150   \n",
       "21947                    -1.075307            -1.249552   \n",
       "\n",
       "       acetylcholine_receptor_agonist_pred  \\\n",
       "0                                 0.852882   \n",
       "1                                 0.985108   \n",
       "2                                -0.697052   \n",
       "3                                 0.418828   \n",
       "4                                 0.538918   \n",
       "...                                    ...   \n",
       "21943                            -0.255803   \n",
       "21944                             0.497966   \n",
       "21945                            -0.675820   \n",
       "21946                            -1.051518   \n",
       "21947                            -1.023304   \n",
       "\n",
       "       acetylcholine_receptor_antagonist_pred  \\\n",
       "0                                    1.956241   \n",
       "1                                    0.135584   \n",
       "2                                   -0.349476   \n",
       "3                                   -0.307002   \n",
       "4                                   -0.307476   \n",
       "...                                       ...   \n",
       "21943                                1.383198   \n",
       "21944                                1.368214   \n",
       "21945                               -0.859166   \n",
       "21946                               -1.187846   \n",
       "21947                               -0.804183   \n",
       "\n",
       "       acetylcholinesterase_inhibitor_pred  adenosine_receptor_agonist_pred  \\\n",
       "0                                 0.714940                         1.089614   \n",
       "1                                 0.378215                         0.605459   \n",
       "2                                -0.517079                        -0.257762   \n",
       "3                                -0.553324                         0.433879   \n",
       "4                                -0.589463                         1.314964   \n",
       "...                                    ...                              ...   \n",
       "21943                             0.270271                        -0.631043   \n",
       "21944                             0.338321                         0.300445   \n",
       "21945                             0.248729                         0.032107   \n",
       "21946                            -1.045939                        -0.918460   \n",
       "21947                            -0.966330                        -1.331299   \n",
       "\n",
       "       adenosine_receptor_antagonist_pred  adenylyl_cyclase_activator_pred  \\\n",
       "0                                0.156629                         0.208169   \n",
       "1                                0.220750                         0.576051   \n",
       "2                                0.825560                         1.587220   \n",
       "3                               -0.533703                         0.076889   \n",
       "4                               -0.210142                         1.128933   \n",
       "...                                   ...                              ...   \n",
       "21943                           -0.096340                        -0.455718   \n",
       "21944                            0.383632                         0.269661   \n",
       "21945                            1.555131                         1.674891   \n",
       "21946                           -1.097907                        -1.324022   \n",
       "21947                           -1.027077                        -1.400592   \n",
       "\n",
       "       ...  tropomyosin_receptor_kinase_inhibitor  trpv_agonist  \\\n",
       "0      ...                                 0.0005        0.0005   \n",
       "1      ...                                 0.0005        0.0005   \n",
       "2      ...                                 0.0005        0.0005   \n",
       "3      ...                                 0.0005        0.0005   \n",
       "4      ...                                 0.0005        0.0005   \n",
       "...    ...                                    ...           ...   \n",
       "21943  ...                                 0.0005        0.0005   \n",
       "21944  ...                                 0.0005        0.0005   \n",
       "21945  ...                                 0.0005        0.0005   \n",
       "21946  ...                                 0.0005        0.0005   \n",
       "21947  ...                                 0.0005        0.0005   \n",
       "\n",
       "       trpv_antagonist  tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0               0.0005             0.0005                     0.0005   \n",
       "1               0.0005             0.0005                     0.0005   \n",
       "2               0.0005             0.0005                     0.0005   \n",
       "3               0.0005             0.0005                     0.0005   \n",
       "4               0.0005             0.0005                     0.0005   \n",
       "...                ...                ...                        ...   \n",
       "21943           0.0005             0.0005                     0.0005   \n",
       "21944           0.0005             0.0005                     0.0005   \n",
       "21945           0.0005             0.0005                     0.0005   \n",
       "21946           0.0005             0.0005                     0.0005   \n",
       "21947           0.0005             0.0005                     0.0005   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                     0.0005           0.0005     0.0005   \n",
       "1                                     0.0005           0.0005     0.0005   \n",
       "2                                     0.0005           0.0005     0.0005   \n",
       "3                                     0.0005           0.0005     0.0005   \n",
       "4                                     0.0005           0.0005     0.0005   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                 0.0005           0.0005     0.0005   \n",
       "21944                                 0.0005           0.0005     0.0005   \n",
       "21945                                 0.0005           0.0005     0.0005   \n",
       "21946                                 0.0005           0.0005     0.0005   \n",
       "21947                                 0.0005           0.0005     0.0005   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                          0.0005         0.0005  \n",
       "1                          0.0005         0.0005  \n",
       "2                          0.0005         0.0005  \n",
       "3                          0.0005         0.0005  \n",
       "4                          0.0005         0.0005  \n",
       "...                           ...            ...  \n",
       "21943                      0.0005         0.0005  \n",
       "21944                      0.0005         0.0005  \n",
       "21945                      0.0005         0.0005  \n",
       "21946                      0.0005         0.0005  \n",
       "21947                      0.0005         0.0005  \n",
       "\n",
       "[21948 rows x 413 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:44.641760Z",
     "iopub.status.busy": "2020-11-26T06:01:44.640258Z",
     "iopub.status.idle": "2020-11-26T06:01:46.859865Z",
     "shell.execute_reply": "2020-11-26T06:01:46.861281Z"
    },
    "papermill": {
     "duration": 2.856402,
     "end_time": "2020-11-26T06:01:46.861540",
     "exception": false,
     "start_time": "2020-11-26T06:01:44.005138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=False, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor_pred</th>\n",
       "      <th>11-beta-hsd1_inhibitor_pred</th>\n",
       "      <th>acat_inhibitor_pred</th>\n",
       "      <th>acetylcholine_receptor_agonist_pred</th>\n",
       "      <th>acetylcholine_receptor_antagonist_pred</th>\n",
       "      <th>acetylcholinesterase_inhibitor_pred</th>\n",
       "      <th>adenosine_receptor_agonist_pred</th>\n",
       "      <th>adenosine_receptor_antagonist_pred</th>\n",
       "      <th>adenylyl_cyclase_activator_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>-0.686643</td>\n",
       "      <td>-0.035590</td>\n",
       "      <td>0.852882</td>\n",
       "      <td>1.956241</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>1.089614</td>\n",
       "      <td>0.156629</td>\n",
       "      <td>0.208169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>-0.172458</td>\n",
       "      <td>-0.211519</td>\n",
       "      <td>0.186410</td>\n",
       "      <td>0.985108</td>\n",
       "      <td>0.135584</td>\n",
       "      <td>0.378215</td>\n",
       "      <td>0.605459</td>\n",
       "      <td>0.220750</td>\n",
       "      <td>0.576051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>1.077243</td>\n",
       "      <td>1.449984</td>\n",
       "      <td>-0.120273</td>\n",
       "      <td>-0.697052</td>\n",
       "      <td>-0.349476</td>\n",
       "      <td>-0.517079</td>\n",
       "      <td>-0.257762</td>\n",
       "      <td>0.825560</td>\n",
       "      <td>1.587220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>-0.716649</td>\n",
       "      <td>-0.086812</td>\n",
       "      <td>0.781953</td>\n",
       "      <td>0.418828</td>\n",
       "      <td>-0.307002</td>\n",
       "      <td>-0.553324</td>\n",
       "      <td>0.433879</td>\n",
       "      <td>-0.533703</td>\n",
       "      <td>0.076889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>-0.647452</td>\n",
       "      <td>-0.197038</td>\n",
       "      <td>1.767731</td>\n",
       "      <td>0.538918</td>\n",
       "      <td>-0.307476</td>\n",
       "      <td>-0.589463</td>\n",
       "      <td>1.314964</td>\n",
       "      <td>-0.210142</td>\n",
       "      <td>1.128933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>2.161669</td>\n",
       "      <td>1.457933</td>\n",
       "      <td>-1.363605</td>\n",
       "      <td>-0.255803</td>\n",
       "      <td>1.383198</td>\n",
       "      <td>0.270271</td>\n",
       "      <td>-0.631043</td>\n",
       "      <td>-0.096340</td>\n",
       "      <td>-0.455718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>1.292156</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.497966</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.338321</td>\n",
       "      <td>0.300445</td>\n",
       "      <td>0.383632</td>\n",
       "      <td>0.269661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>0.644685</td>\n",
       "      <td>0.244274</td>\n",
       "      <td>1.091844</td>\n",
       "      <td>-0.675820</td>\n",
       "      <td>-0.859166</td>\n",
       "      <td>0.248729</td>\n",
       "      <td>0.032107</td>\n",
       "      <td>1.555131</td>\n",
       "      <td>1.674891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>-0.816541</td>\n",
       "      <td>-1.027311</td>\n",
       "      <td>-1.831150</td>\n",
       "      <td>-1.051518</td>\n",
       "      <td>-1.187846</td>\n",
       "      <td>-1.045939</td>\n",
       "      <td>-0.918460</td>\n",
       "      <td>-1.097907</td>\n",
       "      <td>-1.324022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>-0.969996</td>\n",
       "      <td>-1.075307</td>\n",
       "      <td>-1.249552</td>\n",
       "      <td>-1.023304</td>\n",
       "      <td>-0.804183</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>-1.331299</td>\n",
       "      <td>-1.027077</td>\n",
       "      <td>-1.400592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 414 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor_pred  \\\n",
       "0      id_000644bb2                          0.263800   \n",
       "1      id_000779bfc                         -0.172458   \n",
       "2      id_000a6266a                          1.077243   \n",
       "3      id_0015fd391                         -0.716649   \n",
       "4      id_001626bd3                         -0.647452   \n",
       "...             ...                               ...   \n",
       "21943  id_fff8c2444                          2.161669   \n",
       "21944  id_fffb1ceed                          1.292156   \n",
       "21945  id_fffb70c0c                          0.644685   \n",
       "21946  id_fffcb9e7c                         -0.816541   \n",
       "21947  id_ffffdd77b                         -0.969996   \n",
       "\n",
       "       11-beta-hsd1_inhibitor_pred  acat_inhibitor_pred  \\\n",
       "0                        -0.686643            -0.035590   \n",
       "1                        -0.211519             0.186410   \n",
       "2                         1.449984            -0.120273   \n",
       "3                        -0.086812             0.781953   \n",
       "4                        -0.197038             1.767731   \n",
       "...                            ...                  ...   \n",
       "21943                     1.457933            -1.363605   \n",
       "21944                     0.637390             0.100840   \n",
       "21945                     0.244274             1.091844   \n",
       "21946                    -1.027311            -1.831150   \n",
       "21947                    -1.075307            -1.249552   \n",
       "\n",
       "       acetylcholine_receptor_agonist_pred  \\\n",
       "0                                 0.852882   \n",
       "1                                 0.985108   \n",
       "2                                -0.697052   \n",
       "3                                 0.418828   \n",
       "4                                 0.538918   \n",
       "...                                    ...   \n",
       "21943                            -0.255803   \n",
       "21944                             0.497966   \n",
       "21945                            -0.675820   \n",
       "21946                            -1.051518   \n",
       "21947                            -1.023304   \n",
       "\n",
       "       acetylcholine_receptor_antagonist_pred  \\\n",
       "0                                    1.956241   \n",
       "1                                    0.135584   \n",
       "2                                   -0.349476   \n",
       "3                                   -0.307002   \n",
       "4                                   -0.307476   \n",
       "...                                       ...   \n",
       "21943                                1.383198   \n",
       "21944                                1.368214   \n",
       "21945                               -0.859166   \n",
       "21946                               -1.187846   \n",
       "21947                               -0.804183   \n",
       "\n",
       "       acetylcholinesterase_inhibitor_pred  adenosine_receptor_agonist_pred  \\\n",
       "0                                 0.714940                         1.089614   \n",
       "1                                 0.378215                         0.605459   \n",
       "2                                -0.517079                        -0.257762   \n",
       "3                                -0.553324                         0.433879   \n",
       "4                                -0.589463                         1.314964   \n",
       "...                                    ...                              ...   \n",
       "21943                             0.270271                        -0.631043   \n",
       "21944                             0.338321                         0.300445   \n",
       "21945                             0.248729                         0.032107   \n",
       "21946                            -1.045939                        -0.918460   \n",
       "21947                            -0.966330                        -1.331299   \n",
       "\n",
       "       adenosine_receptor_antagonist_pred  adenylyl_cyclase_activator_pred  \\\n",
       "0                                0.156629                         0.208169   \n",
       "1                                0.220750                         0.576051   \n",
       "2                                0.825560                         1.587220   \n",
       "3                               -0.533703                         0.076889   \n",
       "4                               -0.210142                         1.128933   \n",
       "...                                   ...                              ...   \n",
       "21943                           -0.096340                        -0.455718   \n",
       "21944                            0.383632                         0.269661   \n",
       "21945                            1.555131                         1.674891   \n",
       "21946                           -1.097907                        -1.324022   \n",
       "21947                           -1.027077                        -1.400592   \n",
       "\n",
       "       ...  trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      ...        0.0005           0.0005             0.0005   \n",
       "1      ...        0.0005           0.0005             0.0005   \n",
       "2      ...        0.0005           0.0005             0.0005   \n",
       "3      ...        0.0005           0.0005             0.0005   \n",
       "4      ...        0.0005           0.0005             0.0005   \n",
       "...    ...           ...              ...                ...   \n",
       "21943  ...        0.0005           0.0005             0.0005   \n",
       "21944  ...        0.0005           0.0005             0.0005   \n",
       "21945  ...        0.0005           0.0005             0.0005   \n",
       "21946  ...        0.0005           0.0005             0.0005   \n",
       "21947  ...        0.0005           0.0005             0.0005   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                         0.0005                                 0.0005   \n",
       "1                         0.0005                                 0.0005   \n",
       "2                         0.0005                                 0.0005   \n",
       "3                         0.0005                                 0.0005   \n",
       "4                         0.0005                                 0.0005   \n",
       "...                          ...                                    ...   \n",
       "21943                     0.0005                                 0.0005   \n",
       "21944                     0.0005                                 0.0005   \n",
       "21945                     0.0005                                 0.0005   \n",
       "21946                     0.0005                                 0.0005   \n",
       "21947                     0.0005                                 0.0005   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0               0.0005     0.0005                      0.0005         0.0005   \n",
       "1               0.0005     0.0005                      0.0005         0.0005   \n",
       "2               0.0005     0.0005                      0.0005         0.0005   \n",
       "3               0.0005     0.0005                      0.0005         0.0005   \n",
       "4               0.0005     0.0005                      0.0005         0.0005   \n",
       "...                ...        ...                         ...            ...   \n",
       "21943           0.0005     0.0005                      0.0005         0.0005   \n",
       "21944           0.0005     0.0005                      0.0005         0.0005   \n",
       "21945           0.0005     0.0005                      0.0005         0.0005   \n",
       "21946           0.0005     0.0005                      0.0005         0.0005   \n",
       "21947           0.0005     0.0005                      0.0005         0.0005   \n",
       "\n",
       "       kfold  \n",
       "0          2  \n",
       "1          4  \n",
       "2          0  \n",
       "3          3  \n",
       "4          1  \n",
       "...      ...  \n",
       "21943      4  \n",
       "21944      0  \n",
       "21945      4  \n",
       "21946      3  \n",
       "21947      1  \n",
       "\n",
       "[21948 rows x 414 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=NFOLDS)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:49.033106Z",
     "iopub.status.busy": "2020-11-26T06:01:49.030412Z",
     "iopub.status.idle": "2020-11-26T06:01:49.036620Z",
     "shell.execute_reply": "2020-11-26T06:01:49.035704Z"
    },
    "papermill": {
     "duration": 0.722189,
     "end_time": "2020-11-26T06:01:49.036794",
     "exception": false,
     "start_time": "2020-11-26T06:01:48.314605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 413)\n",
      "(21948, 414)\n",
      "(3624, 207)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:50.875719Z",
     "iopub.status.busy": "2020-11-26T06:01:50.874667Z",
     "iopub.status.idle": "2020-11-26T06:01:50.917423Z",
     "shell.execute_reply": "2020-11-26T06:01:50.918032Z"
    },
    "papermill": {
     "duration": 0.67909,
     "end_time": "2020-11-26T06:01:50.918187",
     "exception": false,
     "start_time": "2020-11-26T06:01:50.239097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor_pred</th>\n",
       "      <th>11-beta-hsd1_inhibitor_pred</th>\n",
       "      <th>acat_inhibitor_pred</th>\n",
       "      <th>acetylcholine_receptor_agonist_pred</th>\n",
       "      <th>acetylcholine_receptor_antagonist_pred</th>\n",
       "      <th>acetylcholinesterase_inhibitor_pred</th>\n",
       "      <th>adenosine_receptor_agonist_pred</th>\n",
       "      <th>adenosine_receptor_antagonist_pred</th>\n",
       "      <th>adenylyl_cyclase_activator_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>-0.686643</td>\n",
       "      <td>-0.035590</td>\n",
       "      <td>0.852882</td>\n",
       "      <td>1.956241</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>1.089614</td>\n",
       "      <td>0.156629</td>\n",
       "      <td>0.208169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>-0.172458</td>\n",
       "      <td>-0.211519</td>\n",
       "      <td>0.186410</td>\n",
       "      <td>0.985108</td>\n",
       "      <td>0.135584</td>\n",
       "      <td>0.378215</td>\n",
       "      <td>0.605459</td>\n",
       "      <td>0.220750</td>\n",
       "      <td>0.576051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>1.077243</td>\n",
       "      <td>1.449984</td>\n",
       "      <td>-0.120273</td>\n",
       "      <td>-0.697052</td>\n",
       "      <td>-0.349476</td>\n",
       "      <td>-0.517079</td>\n",
       "      <td>-0.257762</td>\n",
       "      <td>0.825560</td>\n",
       "      <td>1.587220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>-0.716649</td>\n",
       "      <td>-0.086812</td>\n",
       "      <td>0.781953</td>\n",
       "      <td>0.418828</td>\n",
       "      <td>-0.307002</td>\n",
       "      <td>-0.553324</td>\n",
       "      <td>0.433879</td>\n",
       "      <td>-0.533703</td>\n",
       "      <td>0.076889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>-0.647452</td>\n",
       "      <td>-0.197038</td>\n",
       "      <td>1.767731</td>\n",
       "      <td>0.538918</td>\n",
       "      <td>-0.307476</td>\n",
       "      <td>-0.589463</td>\n",
       "      <td>1.314964</td>\n",
       "      <td>-0.210142</td>\n",
       "      <td>1.128933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>2.161669</td>\n",
       "      <td>1.457933</td>\n",
       "      <td>-1.363605</td>\n",
       "      <td>-0.255803</td>\n",
       "      <td>1.383198</td>\n",
       "      <td>0.270271</td>\n",
       "      <td>-0.631043</td>\n",
       "      <td>-0.096340</td>\n",
       "      <td>-0.455718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>1.292156</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.497966</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.338321</td>\n",
       "      <td>0.300445</td>\n",
       "      <td>0.383632</td>\n",
       "      <td>0.269661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>0.644685</td>\n",
       "      <td>0.244274</td>\n",
       "      <td>1.091844</td>\n",
       "      <td>-0.675820</td>\n",
       "      <td>-0.859166</td>\n",
       "      <td>0.248729</td>\n",
       "      <td>0.032107</td>\n",
       "      <td>1.555131</td>\n",
       "      <td>1.674891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>-0.816541</td>\n",
       "      <td>-1.027311</td>\n",
       "      <td>-1.831150</td>\n",
       "      <td>-1.051518</td>\n",
       "      <td>-1.187846</td>\n",
       "      <td>-1.045939</td>\n",
       "      <td>-0.918460</td>\n",
       "      <td>-1.097907</td>\n",
       "      <td>-1.324022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>-0.969996</td>\n",
       "      <td>-1.075307</td>\n",
       "      <td>-1.249552</td>\n",
       "      <td>-1.023304</td>\n",
       "      <td>-0.804183</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>-1.331299</td>\n",
       "      <td>-1.027077</td>\n",
       "      <td>-1.400592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 414 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor_pred  \\\n",
       "0      id_000644bb2                          0.263800   \n",
       "1      id_000779bfc                         -0.172458   \n",
       "2      id_000a6266a                          1.077243   \n",
       "3      id_0015fd391                         -0.716649   \n",
       "4      id_001626bd3                         -0.647452   \n",
       "...             ...                               ...   \n",
       "21943  id_fff8c2444                          2.161669   \n",
       "21944  id_fffb1ceed                          1.292156   \n",
       "21945  id_fffb70c0c                          0.644685   \n",
       "21946  id_fffcb9e7c                         -0.816541   \n",
       "21947  id_ffffdd77b                         -0.969996   \n",
       "\n",
       "       11-beta-hsd1_inhibitor_pred  acat_inhibitor_pred  \\\n",
       "0                        -0.686643            -0.035590   \n",
       "1                        -0.211519             0.186410   \n",
       "2                         1.449984            -0.120273   \n",
       "3                        -0.086812             0.781953   \n",
       "4                        -0.197038             1.767731   \n",
       "...                            ...                  ...   \n",
       "21943                     1.457933            -1.363605   \n",
       "21944                     0.637390             0.100840   \n",
       "21945                     0.244274             1.091844   \n",
       "21946                    -1.027311            -1.831150   \n",
       "21947                    -1.075307            -1.249552   \n",
       "\n",
       "       acetylcholine_receptor_agonist_pred  \\\n",
       "0                                 0.852882   \n",
       "1                                 0.985108   \n",
       "2                                -0.697052   \n",
       "3                                 0.418828   \n",
       "4                                 0.538918   \n",
       "...                                    ...   \n",
       "21943                            -0.255803   \n",
       "21944                             0.497966   \n",
       "21945                            -0.675820   \n",
       "21946                            -1.051518   \n",
       "21947                            -1.023304   \n",
       "\n",
       "       acetylcholine_receptor_antagonist_pred  \\\n",
       "0                                    1.956241   \n",
       "1                                    0.135584   \n",
       "2                                   -0.349476   \n",
       "3                                   -0.307002   \n",
       "4                                   -0.307476   \n",
       "...                                       ...   \n",
       "21943                                1.383198   \n",
       "21944                                1.368214   \n",
       "21945                               -0.859166   \n",
       "21946                               -1.187846   \n",
       "21947                               -0.804183   \n",
       "\n",
       "       acetylcholinesterase_inhibitor_pred  adenosine_receptor_agonist_pred  \\\n",
       "0                                 0.714940                         1.089614   \n",
       "1                                 0.378215                         0.605459   \n",
       "2                                -0.517079                        -0.257762   \n",
       "3                                -0.553324                         0.433879   \n",
       "4                                -0.589463                         1.314964   \n",
       "...                                    ...                              ...   \n",
       "21943                             0.270271                        -0.631043   \n",
       "21944                             0.338321                         0.300445   \n",
       "21945                             0.248729                         0.032107   \n",
       "21946                            -1.045939                        -0.918460   \n",
       "21947                            -0.966330                        -1.331299   \n",
       "\n",
       "       adenosine_receptor_antagonist_pred  adenylyl_cyclase_activator_pred  \\\n",
       "0                                0.156629                         0.208169   \n",
       "1                                0.220750                         0.576051   \n",
       "2                                0.825560                         1.587220   \n",
       "3                               -0.533703                         0.076889   \n",
       "4                               -0.210142                         1.128933   \n",
       "...                                   ...                              ...   \n",
       "21943                           -0.096340                        -0.455718   \n",
       "21944                            0.383632                         0.269661   \n",
       "21945                            1.555131                         1.674891   \n",
       "21946                           -1.097907                        -1.324022   \n",
       "21947                           -1.027077                        -1.400592   \n",
       "\n",
       "       ...  trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      ...        0.0005           0.0005             0.0005   \n",
       "1      ...        0.0005           0.0005             0.0005   \n",
       "2      ...        0.0005           0.0005             0.0005   \n",
       "3      ...        0.0005           0.0005             0.0005   \n",
       "4      ...        0.0005           0.0005             0.0005   \n",
       "...    ...           ...              ...                ...   \n",
       "21943  ...        0.0005           0.0005             0.0005   \n",
       "21944  ...        0.0005           0.0005             0.0005   \n",
       "21945  ...        0.0005           0.0005             0.0005   \n",
       "21946  ...        0.0005           0.0005             0.0005   \n",
       "21947  ...        0.0005           0.0005             0.0005   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                         0.0005                                 0.0005   \n",
       "1                         0.0005                                 0.0005   \n",
       "2                         0.0005                                 0.0005   \n",
       "3                         0.0005                                 0.0005   \n",
       "4                         0.0005                                 0.0005   \n",
       "...                          ...                                    ...   \n",
       "21943                     0.0005                                 0.0005   \n",
       "21944                     0.0005                                 0.0005   \n",
       "21945                     0.0005                                 0.0005   \n",
       "21946                     0.0005                                 0.0005   \n",
       "21947                     0.0005                                 0.0005   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0               0.0005     0.0005                      0.0005         0.0005   \n",
       "1               0.0005     0.0005                      0.0005         0.0005   \n",
       "2               0.0005     0.0005                      0.0005         0.0005   \n",
       "3               0.0005     0.0005                      0.0005         0.0005   \n",
       "4               0.0005     0.0005                      0.0005         0.0005   \n",
       "...                ...        ...                         ...            ...   \n",
       "21943           0.0005     0.0005                      0.0005         0.0005   \n",
       "21944           0.0005     0.0005                      0.0005         0.0005   \n",
       "21945           0.0005     0.0005                      0.0005         0.0005   \n",
       "21946           0.0005     0.0005                      0.0005         0.0005   \n",
       "21947           0.0005     0.0005                      0.0005         0.0005   \n",
       "\n",
       "       kfold  \n",
       "0          2  \n",
       "1          4  \n",
       "2          0  \n",
       "3          3  \n",
       "4          1  \n",
       "...      ...  \n",
       "21943      4  \n",
       "21944      0  \n",
       "21945      4  \n",
       "21946      3  \n",
       "21947      1  \n",
       "\n",
       "[21948 rows x 414 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:52.210363Z",
     "iopub.status.busy": "2020-11-26T06:01:52.209471Z",
     "iopub.status.idle": "2020-11-26T06:01:52.213450Z",
     "shell.execute_reply": "2020-11-26T06:01:52.212801Z"
    },
    "papermill": {
     "duration": 0.639638,
     "end_time": "2020-11-26T06:01:52.213592",
     "exception": false,
     "start_time": "2020-11-26T06:01:51.573954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    \n",
    "#     data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "#     data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2, 0:0, 1:1, 2:2})\n",
    "#     data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1, 0:0, 1:1})\n",
    "\n",
    "# --------------------- Normalize ---------------------\n",
    "#     for col in GENES:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#     for col in CELLS:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#--------------------- Removing Skewness ---------------------\n",
    "#     for col in GENES + CELLS:\n",
    "#         if(abs(data[col].skew()) > 0.75):\n",
    "            \n",
    "#             if(data[col].skew() < 0): # neg-skewness\n",
    "#                 data[col] = data[col].max() - data[col] + 1\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "            \n",
    "#             else:\n",
    "#                 data[col] = np.sqrt(data[col])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:53.483713Z",
     "iopub.status.busy": "2020-11-26T06:01:53.482223Z",
     "iopub.status.idle": "2020-11-26T06:01:53.486554Z",
     "shell.execute_reply": "2020-11-26T06:01:53.487086Z"
    },
    "papermill": {
     "duration": 0.642814,
     "end_time": "2020-11-26T06:01:53.487235",
     "exception": false,
     "start_time": "2020-11-26T06:01:52.844421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in folds.columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:54.758540Z",
     "iopub.status.busy": "2020-11-26T06:01:54.757291Z",
     "iopub.status.idle": "2020-11-26T06:01:54.761658Z",
     "shell.execute_reply": "2020-11-26T06:01:54.762212Z"
    },
    "papermill": {
     "duration": 0.644469,
     "end_time": "2020-11-26T06:01:54.762394",
     "exception": false,
     "start_time": "2020-11-26T06:01:54.117925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5-alpha_reductase_inhibitor_pred',\n",
       " '11-beta-hsd1_inhibitor_pred',\n",
       " 'acat_inhibitor_pred',\n",
       " 'acetylcholine_receptor_agonist_pred',\n",
       " 'acetylcholine_receptor_antagonist_pred',\n",
       " 'acetylcholinesterase_inhibitor_pred',\n",
       " 'adenosine_receptor_agonist_pred',\n",
       " 'adenosine_receptor_antagonist_pred',\n",
       " 'adenylyl_cyclase_activator_pred',\n",
       " 'adrenergic_receptor_agonist_pred',\n",
       " 'adrenergic_receptor_antagonist_pred',\n",
       " 'akt_inhibitor_pred',\n",
       " 'aldehyde_dehydrogenase_inhibitor_pred',\n",
       " 'alk_inhibitor_pred',\n",
       " 'ampk_activator_pred',\n",
       " 'analgesic_pred',\n",
       " 'androgen_receptor_agonist_pred',\n",
       " 'androgen_receptor_antagonist_pred',\n",
       " 'anesthetic_-_local_pred',\n",
       " 'angiogenesis_inhibitor_pred',\n",
       " 'angiotensin_receptor_antagonist_pred',\n",
       " 'anti-inflammatory_pred',\n",
       " 'antiarrhythmic_pred',\n",
       " 'antibiotic_pred',\n",
       " 'anticonvulsant_pred',\n",
       " 'antifungal_pred',\n",
       " 'antihistamine_pred',\n",
       " 'antimalarial_pred',\n",
       " 'antioxidant_pred',\n",
       " 'antiprotozoal_pred',\n",
       " 'antiviral_pred',\n",
       " 'apoptosis_stimulant_pred',\n",
       " 'aromatase_inhibitor_pred',\n",
       " 'atm_kinase_inhibitor_pred',\n",
       " 'atp-sensitive_potassium_channel_antagonist_pred',\n",
       " 'atp_synthase_inhibitor_pred',\n",
       " 'atpase_inhibitor_pred',\n",
       " 'atr_kinase_inhibitor_pred',\n",
       " 'aurora_kinase_inhibitor_pred',\n",
       " 'autotaxin_inhibitor_pred',\n",
       " 'bacterial_30s_ribosomal_subunit_inhibitor_pred',\n",
       " 'bacterial_50s_ribosomal_subunit_inhibitor_pred',\n",
       " 'bacterial_antifolate_pred',\n",
       " 'bacterial_cell_wall_synthesis_inhibitor_pred',\n",
       " 'bacterial_dna_gyrase_inhibitor_pred',\n",
       " 'bacterial_dna_inhibitor_pred',\n",
       " 'bacterial_membrane_integrity_inhibitor_pred',\n",
       " 'bcl_inhibitor_pred',\n",
       " 'bcr-abl_inhibitor_pred',\n",
       " 'benzodiazepine_receptor_agonist_pred',\n",
       " 'beta_amyloid_inhibitor_pred',\n",
       " 'bromodomain_inhibitor_pred',\n",
       " 'btk_inhibitor_pred',\n",
       " 'calcineurin_inhibitor_pred',\n",
       " 'calcium_channel_blocker_pred',\n",
       " 'cannabinoid_receptor_agonist_pred',\n",
       " 'cannabinoid_receptor_antagonist_pred',\n",
       " 'carbonic_anhydrase_inhibitor_pred',\n",
       " 'casein_kinase_inhibitor_pred',\n",
       " 'caspase_activator_pred',\n",
       " 'catechol_o_methyltransferase_inhibitor_pred',\n",
       " 'cc_chemokine_receptor_antagonist_pred',\n",
       " 'cck_receptor_antagonist_pred',\n",
       " 'cdk_inhibitor_pred',\n",
       " 'chelating_agent_pred',\n",
       " 'chk_inhibitor_pred',\n",
       " 'chloride_channel_blocker_pred',\n",
       " 'cholesterol_inhibitor_pred',\n",
       " 'cholinergic_receptor_antagonist_pred',\n",
       " 'coagulation_factor_inhibitor_pred',\n",
       " 'corticosteroid_agonist_pred',\n",
       " 'cyclooxygenase_inhibitor_pred',\n",
       " 'cytochrome_p450_inhibitor_pred',\n",
       " 'dihydrofolate_reductase_inhibitor_pred',\n",
       " 'dipeptidyl_peptidase_inhibitor_pred',\n",
       " 'diuretic_pred',\n",
       " 'dna_alkylating_agent_pred',\n",
       " 'dna_inhibitor_pred',\n",
       " 'dopamine_receptor_agonist_pred',\n",
       " 'dopamine_receptor_antagonist_pred',\n",
       " 'egfr_inhibitor_pred',\n",
       " 'elastase_inhibitor_pred',\n",
       " 'erbb2_inhibitor_pred',\n",
       " 'estrogen_receptor_agonist_pred',\n",
       " 'estrogen_receptor_antagonist_pred',\n",
       " 'faah_inhibitor_pred',\n",
       " 'farnesyltransferase_inhibitor_pred',\n",
       " 'fatty_acid_receptor_agonist_pred',\n",
       " 'fgfr_inhibitor_pred',\n",
       " 'flt3_inhibitor_pred',\n",
       " 'focal_adhesion_kinase_inhibitor_pred',\n",
       " 'free_radical_scavenger_pred',\n",
       " 'fungal_squalene_epoxidase_inhibitor_pred',\n",
       " 'gaba_receptor_agonist_pred',\n",
       " 'gaba_receptor_antagonist_pred',\n",
       " 'gamma_secretase_inhibitor_pred',\n",
       " 'glucocorticoid_receptor_agonist_pred',\n",
       " 'glutamate_inhibitor_pred',\n",
       " 'glutamate_receptor_agonist_pred',\n",
       " 'glutamate_receptor_antagonist_pred',\n",
       " 'gonadotropin_receptor_agonist_pred',\n",
       " 'gsk_inhibitor_pred',\n",
       " 'hcv_inhibitor_pred',\n",
       " 'hdac_inhibitor_pred',\n",
       " 'histamine_receptor_agonist_pred',\n",
       " 'histamine_receptor_antagonist_pred',\n",
       " 'histone_lysine_demethylase_inhibitor_pred',\n",
       " 'histone_lysine_methyltransferase_inhibitor_pred',\n",
       " 'hiv_inhibitor_pred',\n",
       " 'hmgcr_inhibitor_pred',\n",
       " 'hsp_inhibitor_pred',\n",
       " 'igf-1_inhibitor_pred',\n",
       " 'ikk_inhibitor_pred',\n",
       " 'imidazoline_receptor_agonist_pred',\n",
       " 'immunosuppressant_pred',\n",
       " 'insulin_secretagogue_pred',\n",
       " 'insulin_sensitizer_pred',\n",
       " 'integrin_inhibitor_pred',\n",
       " 'jak_inhibitor_pred',\n",
       " 'kit_inhibitor_pred',\n",
       " 'laxative_pred',\n",
       " 'leukotriene_inhibitor_pred',\n",
       " 'leukotriene_receptor_antagonist_pred',\n",
       " 'lipase_inhibitor_pred',\n",
       " 'lipoxygenase_inhibitor_pred',\n",
       " 'lxr_agonist_pred',\n",
       " 'mdm_inhibitor_pred',\n",
       " 'mek_inhibitor_pred',\n",
       " 'membrane_integrity_inhibitor_pred',\n",
       " 'mineralocorticoid_receptor_antagonist_pred',\n",
       " 'monoacylglycerol_lipase_inhibitor_pred',\n",
       " 'monoamine_oxidase_inhibitor_pred',\n",
       " 'monopolar_spindle_1_kinase_inhibitor_pred',\n",
       " 'mtor_inhibitor_pred',\n",
       " 'mucolytic_agent_pred',\n",
       " 'neuropeptide_receptor_antagonist_pred',\n",
       " 'nfkb_inhibitor_pred',\n",
       " 'nicotinic_receptor_agonist_pred',\n",
       " 'nitric_oxide_donor_pred',\n",
       " 'nitric_oxide_production_inhibitor_pred',\n",
       " 'nitric_oxide_synthase_inhibitor_pred',\n",
       " 'norepinephrine_reuptake_inhibitor_pred',\n",
       " 'nrf2_activator_pred',\n",
       " 'opioid_receptor_agonist_pred',\n",
       " 'opioid_receptor_antagonist_pred',\n",
       " 'orexin_receptor_antagonist_pred',\n",
       " 'p38_mapk_inhibitor_pred',\n",
       " 'p-glycoprotein_inhibitor_pred',\n",
       " 'parp_inhibitor_pred',\n",
       " 'pdgfr_inhibitor_pred',\n",
       " 'pdk_inhibitor_pred',\n",
       " 'phosphodiesterase_inhibitor_pred',\n",
       " 'phospholipase_inhibitor_pred',\n",
       " 'pi3k_inhibitor_pred',\n",
       " 'pkc_inhibitor_pred',\n",
       " 'potassium_channel_activator_pred',\n",
       " 'potassium_channel_antagonist_pred',\n",
       " 'ppar_receptor_agonist_pred',\n",
       " 'ppar_receptor_antagonist_pred',\n",
       " 'progesterone_receptor_agonist_pred',\n",
       " 'progesterone_receptor_antagonist_pred',\n",
       " 'prostaglandin_inhibitor_pred',\n",
       " 'prostanoid_receptor_antagonist_pred',\n",
       " 'proteasome_inhibitor_pred',\n",
       " 'protein_kinase_inhibitor_pred',\n",
       " 'protein_phosphatase_inhibitor_pred',\n",
       " 'protein_synthesis_inhibitor_pred',\n",
       " 'protein_tyrosine_kinase_inhibitor_pred',\n",
       " 'radiopaque_medium_pred',\n",
       " 'raf_inhibitor_pred',\n",
       " 'ras_gtpase_inhibitor_pred',\n",
       " 'retinoid_receptor_agonist_pred',\n",
       " 'retinoid_receptor_antagonist_pred',\n",
       " 'rho_associated_kinase_inhibitor_pred',\n",
       " 'ribonucleoside_reductase_inhibitor_pred',\n",
       " 'rna_polymerase_inhibitor_pred',\n",
       " 'serotonin_receptor_agonist_pred',\n",
       " 'serotonin_receptor_antagonist_pred',\n",
       " 'serotonin_reuptake_inhibitor_pred',\n",
       " 'sigma_receptor_agonist_pred',\n",
       " 'sigma_receptor_antagonist_pred',\n",
       " 'smoothened_receptor_antagonist_pred',\n",
       " 'sodium_channel_inhibitor_pred',\n",
       " 'sphingosine_receptor_agonist_pred',\n",
       " 'src_inhibitor_pred',\n",
       " 'steroid_pred',\n",
       " 'syk_inhibitor_pred',\n",
       " 'tachykinin_antagonist_pred',\n",
       " 'tgf-beta_receptor_inhibitor_pred',\n",
       " 'thrombin_inhibitor_pred',\n",
       " 'thymidylate_synthase_inhibitor_pred',\n",
       " 'tlr_agonist_pred',\n",
       " 'tlr_antagonist_pred',\n",
       " 'tnf_inhibitor_pred',\n",
       " 'topoisomerase_inhibitor_pred',\n",
       " 'transient_receptor_potential_channel_antagonist_pred',\n",
       " 'tropomyosin_receptor_kinase_inhibitor_pred',\n",
       " 'trpv_agonist_pred',\n",
       " 'trpv_antagonist_pred',\n",
       " 'tubulin_inhibitor_pred',\n",
       " 'tyrosine_kinase_inhibitor_pred',\n",
       " 'ubiquitin_specific_protease_inhibitor_pred',\n",
       " 'vegfr_inhibitor_pred',\n",
       " 'vitamin_b_pred',\n",
       " 'vitamin_d_receptor_agonist_pred',\n",
       " 'wnt_inhibitor_pred']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:56.048844Z",
     "iopub.status.busy": "2020-11-26T06:01:56.047773Z",
     "iopub.status.idle": "2020-11-26T06:01:56.091882Z",
     "shell.execute_reply": "2020-11-26T06:01:56.092691Z"
    },
    "papermill": {
     "duration": 0.683242,
     "end_time": "2020-11-26T06:01:56.092871",
     "exception": false,
     "start_time": "2020-11-26T06:01:55.409629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor_pred</th>\n",
       "      <th>11-beta-hsd1_inhibitor_pred</th>\n",
       "      <th>acat_inhibitor_pred</th>\n",
       "      <th>acetylcholine_receptor_agonist_pred</th>\n",
       "      <th>acetylcholine_receptor_antagonist_pred</th>\n",
       "      <th>acetylcholinesterase_inhibitor_pred</th>\n",
       "      <th>adenosine_receptor_agonist_pred</th>\n",
       "      <th>adenosine_receptor_antagonist_pred</th>\n",
       "      <th>adenylyl_cyclase_activator_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>-0.686643</td>\n",
       "      <td>-0.035590</td>\n",
       "      <td>0.852882</td>\n",
       "      <td>1.956241</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>1.089614</td>\n",
       "      <td>0.156629</td>\n",
       "      <td>0.208169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>-0.172458</td>\n",
       "      <td>-0.211519</td>\n",
       "      <td>0.186410</td>\n",
       "      <td>0.985108</td>\n",
       "      <td>0.135584</td>\n",
       "      <td>0.378215</td>\n",
       "      <td>0.605459</td>\n",
       "      <td>0.220750</td>\n",
       "      <td>0.576051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>1.077243</td>\n",
       "      <td>1.449984</td>\n",
       "      <td>-0.120273</td>\n",
       "      <td>-0.697052</td>\n",
       "      <td>-0.349476</td>\n",
       "      <td>-0.517079</td>\n",
       "      <td>-0.257762</td>\n",
       "      <td>0.825560</td>\n",
       "      <td>1.587220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>-0.716649</td>\n",
       "      <td>-0.086812</td>\n",
       "      <td>0.781953</td>\n",
       "      <td>0.418828</td>\n",
       "      <td>-0.307002</td>\n",
       "      <td>-0.553324</td>\n",
       "      <td>0.433879</td>\n",
       "      <td>-0.533703</td>\n",
       "      <td>0.076889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>-0.647452</td>\n",
       "      <td>-0.197038</td>\n",
       "      <td>1.767731</td>\n",
       "      <td>0.538918</td>\n",
       "      <td>-0.307476</td>\n",
       "      <td>-0.589463</td>\n",
       "      <td>1.314964</td>\n",
       "      <td>-0.210142</td>\n",
       "      <td>1.128933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>2.161669</td>\n",
       "      <td>1.457933</td>\n",
       "      <td>-1.363605</td>\n",
       "      <td>-0.255803</td>\n",
       "      <td>1.383198</td>\n",
       "      <td>0.270271</td>\n",
       "      <td>-0.631043</td>\n",
       "      <td>-0.096340</td>\n",
       "      <td>-0.455718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>1.292156</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.497966</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.338321</td>\n",
       "      <td>0.300445</td>\n",
       "      <td>0.383632</td>\n",
       "      <td>0.269661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>0.644685</td>\n",
       "      <td>0.244274</td>\n",
       "      <td>1.091844</td>\n",
       "      <td>-0.675820</td>\n",
       "      <td>-0.859166</td>\n",
       "      <td>0.248729</td>\n",
       "      <td>0.032107</td>\n",
       "      <td>1.555131</td>\n",
       "      <td>1.674891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>-0.816541</td>\n",
       "      <td>-1.027311</td>\n",
       "      <td>-1.831150</td>\n",
       "      <td>-1.051518</td>\n",
       "      <td>-1.187846</td>\n",
       "      <td>-1.045939</td>\n",
       "      <td>-0.918460</td>\n",
       "      <td>-1.097907</td>\n",
       "      <td>-1.324022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>-0.969996</td>\n",
       "      <td>-1.075307</td>\n",
       "      <td>-1.249552</td>\n",
       "      <td>-1.023304</td>\n",
       "      <td>-0.804183</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>-1.331299</td>\n",
       "      <td>-1.027077</td>\n",
       "      <td>-1.400592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 414 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor_pred  \\\n",
       "0      id_000644bb2                          0.263800   \n",
       "1      id_000779bfc                         -0.172458   \n",
       "2      id_000a6266a                          1.077243   \n",
       "3      id_0015fd391                         -0.716649   \n",
       "4      id_001626bd3                         -0.647452   \n",
       "...             ...                               ...   \n",
       "21943  id_fff8c2444                          2.161669   \n",
       "21944  id_fffb1ceed                          1.292156   \n",
       "21945  id_fffb70c0c                          0.644685   \n",
       "21946  id_fffcb9e7c                         -0.816541   \n",
       "21947  id_ffffdd77b                         -0.969996   \n",
       "\n",
       "       11-beta-hsd1_inhibitor_pred  acat_inhibitor_pred  \\\n",
       "0                        -0.686643            -0.035590   \n",
       "1                        -0.211519             0.186410   \n",
       "2                         1.449984            -0.120273   \n",
       "3                        -0.086812             0.781953   \n",
       "4                        -0.197038             1.767731   \n",
       "...                            ...                  ...   \n",
       "21943                     1.457933            -1.363605   \n",
       "21944                     0.637390             0.100840   \n",
       "21945                     0.244274             1.091844   \n",
       "21946                    -1.027311            -1.831150   \n",
       "21947                    -1.075307            -1.249552   \n",
       "\n",
       "       acetylcholine_receptor_agonist_pred  \\\n",
       "0                                 0.852882   \n",
       "1                                 0.985108   \n",
       "2                                -0.697052   \n",
       "3                                 0.418828   \n",
       "4                                 0.538918   \n",
       "...                                    ...   \n",
       "21943                            -0.255803   \n",
       "21944                             0.497966   \n",
       "21945                            -0.675820   \n",
       "21946                            -1.051518   \n",
       "21947                            -1.023304   \n",
       "\n",
       "       acetylcholine_receptor_antagonist_pred  \\\n",
       "0                                    1.956241   \n",
       "1                                    0.135584   \n",
       "2                                   -0.349476   \n",
       "3                                   -0.307002   \n",
       "4                                   -0.307476   \n",
       "...                                       ...   \n",
       "21943                                1.383198   \n",
       "21944                                1.368214   \n",
       "21945                               -0.859166   \n",
       "21946                               -1.187846   \n",
       "21947                               -0.804183   \n",
       "\n",
       "       acetylcholinesterase_inhibitor_pred  adenosine_receptor_agonist_pred  \\\n",
       "0                                 0.714940                         1.089614   \n",
       "1                                 0.378215                         0.605459   \n",
       "2                                -0.517079                        -0.257762   \n",
       "3                                -0.553324                         0.433879   \n",
       "4                                -0.589463                         1.314964   \n",
       "...                                    ...                              ...   \n",
       "21943                             0.270271                        -0.631043   \n",
       "21944                             0.338321                         0.300445   \n",
       "21945                             0.248729                         0.032107   \n",
       "21946                            -1.045939                        -0.918460   \n",
       "21947                            -0.966330                        -1.331299   \n",
       "\n",
       "       adenosine_receptor_antagonist_pred  adenylyl_cyclase_activator_pred  \\\n",
       "0                                0.156629                         0.208169   \n",
       "1                                0.220750                         0.576051   \n",
       "2                                0.825560                         1.587220   \n",
       "3                               -0.533703                         0.076889   \n",
       "4                               -0.210142                         1.128933   \n",
       "...                                   ...                              ...   \n",
       "21943                           -0.096340                        -0.455718   \n",
       "21944                            0.383632                         0.269661   \n",
       "21945                            1.555131                         1.674891   \n",
       "21946                           -1.097907                        -1.324022   \n",
       "21947                           -1.027077                        -1.400592   \n",
       "\n",
       "       ...  trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      ...        0.0005           0.0005             0.0005   \n",
       "1      ...        0.0005           0.0005             0.0005   \n",
       "2      ...        0.0005           0.0005             0.0005   \n",
       "3      ...        0.0005           0.0005             0.0005   \n",
       "4      ...        0.0005           0.0005             0.0005   \n",
       "...    ...           ...              ...                ...   \n",
       "21943  ...        0.0005           0.0005             0.0005   \n",
       "21944  ...        0.0005           0.0005             0.0005   \n",
       "21945  ...        0.0005           0.0005             0.0005   \n",
       "21946  ...        0.0005           0.0005             0.0005   \n",
       "21947  ...        0.0005           0.0005             0.0005   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                         0.0005                                 0.0005   \n",
       "1                         0.0005                                 0.0005   \n",
       "2                         0.0005                                 0.0005   \n",
       "3                         0.0005                                 0.0005   \n",
       "4                         0.0005                                 0.0005   \n",
       "...                          ...                                    ...   \n",
       "21943                     0.0005                                 0.0005   \n",
       "21944                     0.0005                                 0.0005   \n",
       "21945                     0.0005                                 0.0005   \n",
       "21946                     0.0005                                 0.0005   \n",
       "21947                     0.0005                                 0.0005   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0               0.0005     0.0005                      0.0005         0.0005   \n",
       "1               0.0005     0.0005                      0.0005         0.0005   \n",
       "2               0.0005     0.0005                      0.0005         0.0005   \n",
       "3               0.0005     0.0005                      0.0005         0.0005   \n",
       "4               0.0005     0.0005                      0.0005         0.0005   \n",
       "...                ...        ...                         ...            ...   \n",
       "21943           0.0005     0.0005                      0.0005         0.0005   \n",
       "21944           0.0005     0.0005                      0.0005         0.0005   \n",
       "21945           0.0005     0.0005                      0.0005         0.0005   \n",
       "21946           0.0005     0.0005                      0.0005         0.0005   \n",
       "21947           0.0005     0.0005                      0.0005         0.0005   \n",
       "\n",
       "       kfold  \n",
       "0          2  \n",
       "1          4  \n",
       "2          0  \n",
       "3          3  \n",
       "4          1  \n",
       "...      ...  \n",
       "21943      4  \n",
       "21944      0  \n",
       "21945      4  \n",
       "21946      3  \n",
       "21947      1  \n",
       "\n",
       "[21948 rows x 414 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:57.384708Z",
     "iopub.status.busy": "2020-11-26T06:01:57.382570Z",
     "iopub.status.idle": "2020-11-26T06:01:57.385478Z",
     "shell.execute_reply": "2020-11-26T06:01:57.386058Z"
    },
    "papermill": {
     "duration": 0.643554,
     "end_time": "2020-11-26T06:01:57.386201",
     "exception": false,
     "start_time": "2020-11-26T06:01:56.742647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=1024\n",
    "# hidden_size=4096\n",
    "# hidden_size=9192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:58.909061Z",
     "iopub.status.busy": "2020-11-26T06:01:58.907747Z",
     "iopub.status.idle": "2020-11-26T06:01:58.951308Z",
     "shell.execute_reply": "2020-11-26T06:01:58.952159Z"
    },
    "papermill": {
     "duration": 0.937579,
     "end_time": "2020-11-26T06:01:58.952408",
     "exception": false,
     "start_time": "2020-11-26T06:01:58.014829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = (folds)\n",
    "    test_ = (test)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.2, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler,loss_fn, trainloader, DEVICE)\n",
    "        print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"SEED: {seed} ,FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"model/{NB}-scored2-SEED{seed}-FOLD{fold}_.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    model.load_state_dict(torch.load(f\"model/{NB}-scored2-SEED{seed}-FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    " #   if not IS_TRAIN:\n",
    "   # valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "   # oof[val_idx] = valid_preds     \n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:02:00.240084Z",
     "iopub.status.busy": "2020-11-26T06:02:00.239158Z",
     "iopub.status.idle": "2020-11-26T06:02:00.243802Z",
     "shell.execute_reply": "2020-11-26T06:02:00.243153Z"
    },
    "papermill": {
     "duration": 0.647174,
     "end_time": "2020-11-26T06:02:00.243920",
     "exception": false,
     "start_time": "2020-11-26T06:01:59.596746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:02:01.520384Z",
     "iopub.status.busy": "2020-11-26T06:02:01.518623Z",
     "iopub.status.idle": "2020-11-26T06:15:08.199092Z",
     "shell.execute_reply": "2020-11-26T06:15:08.198426Z"
    },
    "papermill": {
     "duration": 787.323857,
     "end_time": "2020-11-26T06:15:08.199235",
     "exception": false,
     "start_time": "2020-11-26T06:02:00.875378",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 940, FOLD: 0, EPOCH: 0, train_loss: 0.7181326176809228\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6357580423355103\n",
      "SEED: 940, FOLD: 0, EPOCH: 1, train_loss: 0.2647488739719425\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 1, valid_loss: 0.03140339545077748\n",
      "SEED: 940, FOLD: 0, EPOCH: 2, train_loss: 0.024741355140787968\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 2, valid_loss: 0.021632916397518583\n",
      "SEED: 940, FOLD: 0, EPOCH: 3, train_loss: 0.021218745793769325\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 3, valid_loss: 0.02018266771402624\n",
      "SEED: 940, FOLD: 0, EPOCH: 4, train_loss: 0.02037945794670478\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 4, valid_loss: 0.019939849774042766\n",
      "SEED: 940, FOLD: 0, EPOCH: 5, train_loss: 0.019866417310592056\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 5, valid_loss: 0.019616762383116618\n",
      "SEED: 940, FOLD: 0, EPOCH: 6, train_loss: 0.01954017350099225\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 6, valid_loss: 0.019461500458419323\n",
      "SEED: 940, FOLD: 0, EPOCH: 7, train_loss: 0.01933725372604702\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 7, valid_loss: 0.0194080283658372\n",
      "SEED: 940, FOLD: 0, EPOCH: 8, train_loss: 0.019231106087133503\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01931653016557296\n",
      "SEED: 940, FOLD: 0, EPOCH: 9, train_loss: 0.019234640010889027\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 9, valid_loss: 0.019368883843223255\n",
      "SEED: 940, FOLD: 0, EPOCH: 10, train_loss: 0.01917797632083513\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01927317503011889\n",
      "SEED: 940, FOLD: 0, EPOCH: 11, train_loss: 0.019168764433783035\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 11, valid_loss: 0.019401342711514898\n",
      "SEED: 940, FOLD: 0, EPOCH: 12, train_loss: 0.019095726932088535\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 12, valid_loss: 0.019200654389957588\n",
      "SEED: 940, FOLD: 0, EPOCH: 13, train_loss: 0.019145651167069656\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 13, valid_loss: 0.019306744552320905\n",
      "SEED: 940, FOLD: 0, EPOCH: 14, train_loss: 0.01900385630627473\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 14, valid_loss: 0.019163571401602693\n",
      "SEED: 940, FOLD: 0, EPOCH: 15, train_loss: 0.018957881040979122\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 15, valid_loss: 0.019093185663223267\n",
      "SEED: 940, FOLD: 0, EPOCH: 16, train_loss: 0.018829341248973556\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01915403279579348\n",
      "SEED: 940, FOLD: 0, EPOCH: 17, train_loss: 0.018696281708021095\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 17, valid_loss: 0.018984427779085107\n",
      "SEED: 940, FOLD: 0, EPOCH: 18, train_loss: 0.018513191626339718\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 18, valid_loss: 0.018899521893925138\n",
      "SEED: 940, FOLD: 0, EPOCH: 19, train_loss: 0.018365158928909164\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 19, valid_loss: 0.018870610743761063\n",
      "SEED: 940, FOLD: 0, EPOCH: 20, train_loss: 0.018227966340339703\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 20, valid_loss: 0.018845766886240907\n",
      "SEED: 940, FOLD: 0, EPOCH: 21, train_loss: 0.01800665386237096\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 21, valid_loss: 0.018743150557080906\n",
      "SEED: 940, FOLD: 0, EPOCH: 22, train_loss: 0.017851256859907204\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 22, valid_loss: 0.018734138252006635\n",
      "SEED: 940, FOLD: 0, EPOCH: 23, train_loss: 0.017727147139932797\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01871209012137519\n",
      "SEED: 940, FOLD: 0, EPOCH: 24, train_loss: 0.01766863300640514\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 24, valid_loss: 0.018714946694672108\n",
      "SEED: 940, FOLD: 1, EPOCH: 0, train_loss: 0.7182271463283594\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6340157157844968\n",
      "SEED: 940, FOLD: 1, EPOCH: 1, train_loss: 0.26574415627165116\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 1, valid_loss: 0.03175989041725794\n",
      "SEED: 940, FOLD: 1, EPOCH: 2, train_loss: 0.024863329783513927\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 2, valid_loss: 0.021800331047011748\n",
      "SEED: 940, FOLD: 1, EPOCH: 3, train_loss: 0.021239090899842373\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 3, valid_loss: 0.020411116691927116\n",
      "SEED: 940, FOLD: 1, EPOCH: 4, train_loss: 0.020519411704246548\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 4, valid_loss: 0.020422825796736613\n",
      "SEED: 940, FOLD: 1, EPOCH: 5, train_loss: 0.020014085361491078\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 5, valid_loss: 0.0197365109084381\n",
      "SEED: 940, FOLD: 1, EPOCH: 6, train_loss: 0.01952616848807404\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01957042918850978\n",
      "SEED: 940, FOLD: 1, EPOCH: 7, train_loss: 0.019357905358723972\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01946377981868055\n",
      "SEED: 940, FOLD: 1, EPOCH: 8, train_loss: 0.019229102717793507\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 8, valid_loss: 0.019369779775540035\n",
      "SEED: 940, FOLD: 1, EPOCH: 9, train_loss: 0.01925850619116555\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01938638525704543\n",
      "SEED: 940, FOLD: 1, EPOCH: 10, train_loss: 0.019193525493576908\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01941479452782207\n",
      "SEED: 940, FOLD: 1, EPOCH: 11, train_loss: 0.01915648015404957\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01935514507608281\n",
      "SEED: 940, FOLD: 1, EPOCH: 12, train_loss: 0.019140500035406887\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01933991877983014\n",
      "SEED: 940, FOLD: 1, EPOCH: 13, train_loss: 0.01900872596256111\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01921991745216979\n",
      "SEED: 940, FOLD: 1, EPOCH: 14, train_loss: 0.01905431439155254\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 14, valid_loss: 0.019454839018483955\n",
      "SEED: 940, FOLD: 1, EPOCH: 15, train_loss: 0.018940701837772907\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01919690902448363\n",
      "SEED: 940, FOLD: 1, EPOCH: 16, train_loss: 0.018846353731941486\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 16, valid_loss: 0.019106699257261224\n",
      "SEED: 940, FOLD: 1, EPOCH: 17, train_loss: 0.01870357944373635\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01900290956513749\n",
      "SEED: 940, FOLD: 1, EPOCH: 18, train_loss: 0.01854090802911399\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 18, valid_loss: 0.018974653548664518\n",
      "SEED: 940, FOLD: 1, EPOCH: 19, train_loss: 0.01838476982885513\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01886959570563502\n",
      "SEED: 940, FOLD: 1, EPOCH: 20, train_loss: 0.018204796816343845\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 20, valid_loss: 0.018812816797031298\n",
      "SEED: 940, FOLD: 1, EPOCH: 21, train_loss: 0.018009564366893493\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 21, valid_loss: 0.018773894032670393\n",
      "SEED: 940, FOLD: 1, EPOCH: 22, train_loss: 0.017879252821423004\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 22, valid_loss: 0.018732633648647204\n",
      "SEED: 940, FOLD: 1, EPOCH: 23, train_loss: 0.017727258736672608\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 23, valid_loss: 0.018727188722954854\n",
      "SEED: 940, FOLD: 1, EPOCH: 24, train_loss: 0.017708342711346737\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 24, valid_loss: 0.018723135607110128\n",
      "SEED: 940, FOLD: 2, EPOCH: 0, train_loss: 0.7182313912156699\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6425741679138608\n",
      "SEED: 940, FOLD: 2, EPOCH: 1, train_loss: 0.26371920978029567\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 1, valid_loss: 0.03153367154300213\n",
      "SEED: 940, FOLD: 2, EPOCH: 2, train_loss: 0.024870054742348366\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 2, valid_loss: 0.021685708003739517\n",
      "SEED: 940, FOLD: 2, EPOCH: 3, train_loss: 0.02120639737425507\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 3, valid_loss: 0.020237439829442237\n",
      "SEED: 940, FOLD: 2, EPOCH: 4, train_loss: 0.020394118259782375\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 4, valid_loss: 0.019742268241114087\n",
      "SEED: 940, FOLD: 2, EPOCH: 5, train_loss: 0.019920498078715973\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 5, valid_loss: 0.019629644333488412\n",
      "SEED: 940, FOLD: 2, EPOCH: 6, train_loss: 0.019571144457744515\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 6, valid_loss: 0.019444362363881536\n",
      "SEED: 940, FOLD: 2, EPOCH: 7, train_loss: 0.01943058979468069\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 7, valid_loss: 0.019531451890038118\n",
      "SEED: 940, FOLD: 2, EPOCH: 8, train_loss: 0.01933948271840379\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 8, valid_loss: 0.019319612636334367\n",
      "SEED: 940, FOLD: 2, EPOCH: 9, train_loss: 0.01922159639281639\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 9, valid_loss: 0.019299310114648607\n",
      "SEED: 940, FOLD: 2, EPOCH: 10, train_loss: 0.019226202930229298\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 10, valid_loss: 0.019260467547509406\n",
      "SEED: 940, FOLD: 2, EPOCH: 11, train_loss: 0.019239831769811935\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01925089168879721\n",
      "SEED: 940, FOLD: 2, EPOCH: 12, train_loss: 0.019203365361992863\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 12, valid_loss: 0.019207497127354145\n",
      "SEED: 940, FOLD: 2, EPOCH: 13, train_loss: 0.019151444938303768\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01917300932109356\n",
      "SEED: 940, FOLD: 2, EPOCH: 14, train_loss: 0.019052728173741394\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 14, valid_loss: 0.019114999721447628\n",
      "SEED: 940, FOLD: 2, EPOCH: 15, train_loss: 0.019019581107557682\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 15, valid_loss: 0.019062931338946026\n",
      "SEED: 940, FOLD: 2, EPOCH: 16, train_loss: 0.018856469325829243\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 16, valid_loss: 0.019020437262952328\n",
      "SEED: 940, FOLD: 2, EPOCH: 17, train_loss: 0.018761900051132492\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 17, valid_loss: 0.018938666623499658\n",
      "SEED: 940, FOLD: 2, EPOCH: 18, train_loss: 0.01862074391565461\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 18, valid_loss: 0.018888990291290812\n",
      "SEED: 940, FOLD: 2, EPOCH: 19, train_loss: 0.018451290826002758\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 19, valid_loss: 0.018777734496527247\n",
      "SEED: 940, FOLD: 2, EPOCH: 20, train_loss: 0.01829041748483112\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01876295678731468\n",
      "SEED: 940, FOLD: 2, EPOCH: 21, train_loss: 0.018105981115629707\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 21, valid_loss: 0.018694282716347113\n",
      "SEED: 940, FOLD: 2, EPOCH: 22, train_loss: 0.01793694331486156\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01866415287885401\n",
      "SEED: 940, FOLD: 2, EPOCH: 23, train_loss: 0.017824973587108696\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01865101864354478\n",
      "SEED: 940, FOLD: 2, EPOCH: 24, train_loss: 0.017777524051674896\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 24, valid_loss: 0.018642294944988355\n",
      "SEED: 940, FOLD: 3, EPOCH: 0, train_loss: 0.718096383239912\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6321582992871603\n",
      "SEED: 940, FOLD: 3, EPOCH: 1, train_loss: 0.2639755341561808\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 1, valid_loss: 0.030832386575639248\n",
      "SEED: 940, FOLD: 3, EPOCH: 2, train_loss: 0.024692632446902386\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 2, valid_loss: 0.021348784988125164\n",
      "SEED: 940, FOLD: 3, EPOCH: 3, train_loss: 0.021071843182047207\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 3, valid_loss: 0.020085875255366165\n",
      "SEED: 940, FOLD: 3, EPOCH: 4, train_loss: 0.020379366353154182\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 4, valid_loss: 0.019996620404223602\n",
      "SEED: 940, FOLD: 3, EPOCH: 5, train_loss: 0.019869459738981896\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 5, valid_loss: 0.01955937873572111\n",
      "SEED: 940, FOLD: 3, EPOCH: 6, train_loss: 0.019500092535779095\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 6, valid_loss: 0.019281863338417478\n",
      "SEED: 940, FOLD: 3, EPOCH: 7, train_loss: 0.01931183355981889\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 7, valid_loss: 0.019447314346002206\n",
      "SEED: 940, FOLD: 3, EPOCH: 8, train_loss: 0.0192223457970481\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 8, valid_loss: 0.019383895728323195\n",
      "SEED: 940, FOLD: 3, EPOCH: 9, train_loss: 0.019220979479343994\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01921263989061117\n",
      "SEED: 940, FOLD: 3, EPOCH: 10, train_loss: 0.019185595673279487\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01928560497860114\n",
      "SEED: 940, FOLD: 3, EPOCH: 11, train_loss: 0.01912766557348811\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 11, valid_loss: 0.019180257597731218\n",
      "SEED: 940, FOLD: 3, EPOCH: 12, train_loss: 0.01913648060914399\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 12, valid_loss: 0.019237804226577282\n",
      "SEED: 940, FOLD: 3, EPOCH: 13, train_loss: 0.019115987895191578\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 13, valid_loss: 0.019128335536354117\n",
      "SEED: 940, FOLD: 3, EPOCH: 14, train_loss: 0.019064134040820427\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01919215162181192\n",
      "SEED: 940, FOLD: 3, EPOCH: 15, train_loss: 0.018893434463635735\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 15, valid_loss: 0.019087963013185397\n",
      "SEED: 940, FOLD: 3, EPOCH: 16, train_loss: 0.018816590525101925\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 16, valid_loss: 0.018995218806796603\n",
      "SEED: 940, FOLD: 3, EPOCH: 17, train_loss: 0.018706561295666557\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01890577965726455\n",
      "SEED: 940, FOLD: 3, EPOCH: 18, train_loss: 0.01856514441686264\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 18, valid_loss: 0.01889001816097233\n",
      "SEED: 940, FOLD: 3, EPOCH: 19, train_loss: 0.01840791886375434\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 19, valid_loss: 0.018795965653326776\n",
      "SEED: 940, FOLD: 3, EPOCH: 20, train_loss: 0.0181947848017233\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 20, valid_loss: 0.018722454603347514\n",
      "SEED: 940, FOLD: 3, EPOCH: 21, train_loss: 0.018021816441762276\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 21, valid_loss: 0.018705091180486813\n",
      "SEED: 940, FOLD: 3, EPOCH: 22, train_loss: 0.01785368820571381\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01866651802427239\n",
      "SEED: 940, FOLD: 3, EPOCH: 23, train_loss: 0.017734768489996593\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 23, valid_loss: 0.018659816589206457\n",
      "SEED: 940, FOLD: 3, EPOCH: 24, train_loss: 0.017665774669444214\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01865592495434814\n",
      "SEED: 940, FOLD: 4, EPOCH: 0, train_loss: 0.7179362151933752\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6327566272682614\n",
      "SEED: 940, FOLD: 4, EPOCH: 1, train_loss: 0.26334567130475806\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 1, valid_loss: 0.03170073787785239\n",
      "SEED: 940, FOLD: 4, EPOCH: 2, train_loss: 0.024717989499154297\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 2, valid_loss: 0.02177881480505069\n",
      "SEED: 940, FOLD: 4, EPOCH: 3, train_loss: 0.021099201201096825\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 3, valid_loss: 0.020562939656277496\n",
      "SEED: 940, FOLD: 4, EPOCH: 4, train_loss: 0.02043250451485316\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 4, valid_loss: 0.0202753987784187\n",
      "SEED: 940, FOLD: 4, EPOCH: 5, train_loss: 0.019935366792091423\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01979630005856355\n",
      "SEED: 940, FOLD: 4, EPOCH: 6, train_loss: 0.01954459995571254\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 6, valid_loss: 0.019627673861881096\n",
      "SEED: 940, FOLD: 4, EPOCH: 7, train_loss: 0.019338764007324757\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 7, valid_loss: 0.019471122986740537\n",
      "SEED: 940, FOLD: 4, EPOCH: 8, train_loss: 0.01921186922792939\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 8, valid_loss: 0.019545406724015873\n",
      "SEED: 940, FOLD: 4, EPOCH: 9, train_loss: 0.019277949911960655\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 9, valid_loss: 0.019313669556544885\n",
      "SEED: 940, FOLD: 4, EPOCH: 10, train_loss: 0.019216627719393677\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01944800362818771\n",
      "SEED: 940, FOLD: 4, EPOCH: 11, train_loss: 0.019159510785686798\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 11, valid_loss: 0.019426186569035053\n",
      "SEED: 940, FOLD: 4, EPOCH: 12, train_loss: 0.01913583826651608\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 12, valid_loss: 0.019465570027629536\n",
      "SEED: 940, FOLD: 4, EPOCH: 13, train_loss: 0.019037932508449623\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 13, valid_loss: 0.019402887258264754\n",
      "SEED: 940, FOLD: 4, EPOCH: 14, train_loss: 0.01907826134044191\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 14, valid_loss: 0.019349776518841583\n",
      "SEED: 940, FOLD: 4, EPOCH: 15, train_loss: 0.01893865414287733\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 15, valid_loss: 0.019250106169945665\n",
      "SEED: 940, FOLD: 4, EPOCH: 16, train_loss: 0.01888570005910984\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01916709014525016\n",
      "SEED: 940, FOLD: 4, EPOCH: 17, train_loss: 0.018732835201249607\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 17, valid_loss: 0.019101550699108176\n",
      "SEED: 940, FOLD: 4, EPOCH: 18, train_loss: 0.01858589517465536\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01903982512238953\n",
      "SEED: 940, FOLD: 4, EPOCH: 19, train_loss: 0.018451564148932263\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 19, valid_loss: 0.018951519599391356\n",
      "SEED: 940, FOLD: 4, EPOCH: 20, train_loss: 0.018263278259099392\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 20, valid_loss: 0.018869607502387628\n",
      "SEED: 940, FOLD: 4, EPOCH: 21, train_loss: 0.018070918872304585\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 21, valid_loss: 0.018786432325012155\n",
      "SEED: 940, FOLD: 4, EPOCH: 22, train_loss: 0.01791509078896564\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 22, valid_loss: 0.018738015244404476\n",
      "SEED: 940, FOLD: 4, EPOCH: 23, train_loss: 0.017786938805079113\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 23, valid_loss: 0.018731961130268045\n",
      "SEED: 940, FOLD: 4, EPOCH: 24, train_loss: 0.01774126078015652\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 24, valid_loss: 0.018726810192068417\n",
      "elapsed time: 132.20591378211975\n",
      "SEED: 1513, FOLD: 0, EPOCH: 0, train_loss: 0.7173801038576209\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6319520937071906\n",
      "SEED: 1513, FOLD: 0, EPOCH: 1, train_loss: 0.2612471038178689\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 1, valid_loss: 0.030218887453277905\n",
      "SEED: 1513, FOLD: 0, EPOCH: 2, train_loss: 0.024789249524474144\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 2, valid_loss: 0.021703765003217593\n",
      "SEED: 1513, FOLD: 0, EPOCH: 3, train_loss: 0.021193798118527386\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 3, valid_loss: 0.02031758510404163\n",
      "SEED: 1513, FOLD: 0, EPOCH: 4, train_loss: 0.020408638928463493\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 4, valid_loss: 0.02005342487245798\n",
      "SEED: 1513, FOLD: 0, EPOCH: 5, train_loss: 0.02001432556173076\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 5, valid_loss: 0.019736850530736975\n",
      "SEED: 1513, FOLD: 0, EPOCH: 6, train_loss: 0.01965963138618331\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 6, valid_loss: 0.019442735550304253\n",
      "SEED: 1513, FOLD: 0, EPOCH: 7, train_loss: 0.019398763073959213\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 7, valid_loss: 0.019428217990530863\n",
      "SEED: 1513, FOLD: 0, EPOCH: 8, train_loss: 0.019319186581001766\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 8, valid_loss: 0.019535194668504927\n",
      "SEED: 1513, FOLD: 0, EPOCH: 9, train_loss: 0.019277196080572365\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 9, valid_loss: 0.019393315849204857\n",
      "SEED: 1513, FOLD: 0, EPOCH: 10, train_loss: 0.019165548455456028\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 10, valid_loss: 0.019335864008300833\n",
      "SEED: 1513, FOLD: 0, EPOCH: 11, train_loss: 0.01913298658378746\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 11, valid_loss: 0.019236718407935567\n",
      "SEED: 1513, FOLD: 0, EPOCH: 12, train_loss: 0.01919800072800422\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01924167335447338\n",
      "SEED: 1513, FOLD: 0, EPOCH: 13, train_loss: 0.01909808042472687\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 13, valid_loss: 0.0192666147939033\n",
      "SEED: 1513, FOLD: 0, EPOCH: 14, train_loss: 0.019037185533755066\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 14, valid_loss: 0.019120236651764974\n",
      "SEED: 1513, FOLD: 0, EPOCH: 15, train_loss: 0.018931739194237667\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 15, valid_loss: 0.019107249048021104\n",
      "SEED: 1513, FOLD: 0, EPOCH: 16, train_loss: 0.018778361299115677\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 16, valid_loss: 0.018996902120610077\n",
      "SEED: 1513, FOLD: 0, EPOCH: 17, train_loss: 0.01867245537215385\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 17, valid_loss: 0.018944044080045488\n",
      "SEED: 1513, FOLD: 0, EPOCH: 18, train_loss: 0.018543503125724586\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 18, valid_loss: 0.01898589140425126\n",
      "SEED: 1513, FOLD: 0, EPOCH: 19, train_loss: 0.018350733768032944\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 19, valid_loss: 0.018894028539458912\n",
      "SEED: 1513, FOLD: 0, EPOCH: 20, train_loss: 0.018206846832797146\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 20, valid_loss: 0.018802152739630804\n",
      "SEED: 1513, FOLD: 0, EPOCH: 21, train_loss: 0.018017644008648567\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 21, valid_loss: 0.018817522149119113\n",
      "SEED: 1513, FOLD: 0, EPOCH: 22, train_loss: 0.017853627710238747\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 22, valid_loss: 0.018728905978302162\n",
      "SEED: 1513, FOLD: 0, EPOCH: 23, train_loss: 0.017723955160033875\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01872394761691491\n",
      "SEED: 1513, FOLD: 0, EPOCH: 24, train_loss: 0.017679761339356934\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01872721573130952\n",
      "SEED: 1513, FOLD: 1, EPOCH: 0, train_loss: 0.7181916850200598\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 0, valid_loss: 0.635058687792884\n",
      "SEED: 1513, FOLD: 1, EPOCH: 1, train_loss: 0.26294051062153734\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 1, valid_loss: 0.029941394821637206\n",
      "SEED: 1513, FOLD: 1, EPOCH: 2, train_loss: 0.02466701003520385\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 2, valid_loss: 0.021757569164037704\n",
      "SEED: 1513, FOLD: 1, EPOCH: 3, train_loss: 0.021190578306930653\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 3, valid_loss: 0.0202639719678296\n",
      "SEED: 1513, FOLD: 1, EPOCH: 4, train_loss: 0.020410917591357578\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 4, valid_loss: 0.019884314181076154\n",
      "SEED: 1513, FOLD: 1, EPOCH: 5, train_loss: 0.019917232132908226\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 5, valid_loss: 0.01961544342339039\n",
      "SEED: 1513, FOLD: 1, EPOCH: 6, train_loss: 0.01960509575471498\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 6, valid_loss: 0.019515186962154176\n",
      "SEED: 1513, FOLD: 1, EPOCH: 7, train_loss: 0.019339983850933502\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 7, valid_loss: 0.019340728409588337\n",
      "SEED: 1513, FOLD: 1, EPOCH: 8, train_loss: 0.019289737000413563\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 8, valid_loss: 0.019380243495106697\n",
      "SEED: 1513, FOLD: 1, EPOCH: 9, train_loss: 0.019300486514533775\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 9, valid_loss: 0.019292475138273504\n",
      "SEED: 1513, FOLD: 1, EPOCH: 10, train_loss: 0.01924296865320724\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01949451667153173\n",
      "SEED: 1513, FOLD: 1, EPOCH: 11, train_loss: 0.019152550242733265\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 11, valid_loss: 0.019347888107101124\n",
      "SEED: 1513, FOLD: 1, EPOCH: 12, train_loss: 0.01917946665291337\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01930060786091619\n",
      "SEED: 1513, FOLD: 1, EPOCH: 13, train_loss: 0.01913045735462852\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01925967861380842\n",
      "SEED: 1513, FOLD: 1, EPOCH: 14, train_loss: 0.019044778998131336\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 14, valid_loss: 0.019326528534293175\n",
      "SEED: 1513, FOLD: 1, EPOCH: 15, train_loss: 0.019017617960554966\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01909681171592739\n",
      "SEED: 1513, FOLD: 1, EPOCH: 16, train_loss: 0.018859255141106205\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 16, valid_loss: 0.019050339857737224\n",
      "SEED: 1513, FOLD: 1, EPOCH: 17, train_loss: 0.018705996185325195\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 17, valid_loss: 0.019068926779760256\n",
      "SEED: 1513, FOLD: 1, EPOCH: 18, train_loss: 0.01859947596339212\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 18, valid_loss: 0.018925201665196154\n",
      "SEED: 1513, FOLD: 1, EPOCH: 19, train_loss: 0.01843302823819112\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 19, valid_loss: 0.018867037983404264\n",
      "SEED: 1513, FOLD: 1, EPOCH: 20, train_loss: 0.018247414569275967\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 20, valid_loss: 0.01881148510922988\n",
      "SEED: 1513, FOLD: 1, EPOCH: 21, train_loss: 0.01806417215561521\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01878957377953662\n",
      "SEED: 1513, FOLD: 1, EPOCH: 22, train_loss: 0.01789992251365945\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 22, valid_loss: 0.01874948437843058\n",
      "SEED: 1513, FOLD: 1, EPOCH: 23, train_loss: 0.01779170412624228\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01873835538410478\n",
      "SEED: 1513, FOLD: 1, EPOCH: 24, train_loss: 0.01772830346464247\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 24, valid_loss: 0.018737398501899507\n",
      "SEED: 1513, FOLD: 2, EPOCH: 0, train_loss: 0.7177330169124879\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 0, valid_loss: 0.639351463980145\n",
      "SEED: 1513, FOLD: 2, EPOCH: 1, train_loss: 0.2625993050202943\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 1, valid_loss: 0.029852749986781016\n",
      "SEED: 1513, FOLD: 2, EPOCH: 2, train_loss: 0.024815253778428272\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 2, valid_loss: 0.02157222479581833\n",
      "SEED: 1513, FOLD: 2, EPOCH: 3, train_loss: 0.021174929145237675\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 3, valid_loss: 0.020158667013876967\n",
      "SEED: 1513, FOLD: 2, EPOCH: 4, train_loss: 0.020469225619150246\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01979500489930312\n",
      "SEED: 1513, FOLD: 2, EPOCH: 5, train_loss: 0.019951686910960987\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 5, valid_loss: 0.019555275121496782\n",
      "SEED: 1513, FOLD: 2, EPOCH: 6, train_loss: 0.019644167139262394\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 6, valid_loss: 0.019488200234870117\n",
      "SEED: 1513, FOLD: 2, EPOCH: 7, train_loss: 0.019426109809158505\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 7, valid_loss: 0.019365787816544373\n",
      "SEED: 1513, FOLD: 2, EPOCH: 8, train_loss: 0.019279475310358448\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01927024291621314\n",
      "SEED: 1513, FOLD: 2, EPOCH: 9, train_loss: 0.01921702278912931\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 9, valid_loss: 0.0193708221324616\n",
      "SEED: 1513, FOLD: 2, EPOCH: 10, train_loss: 0.019241297725534092\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01928872335702181\n",
      "SEED: 1513, FOLD: 2, EPOCH: 11, train_loss: 0.01920595900088117\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 11, valid_loss: 0.019265199080109596\n",
      "SEED: 1513, FOLD: 2, EPOCH: 12, train_loss: 0.019226626209590748\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 12, valid_loss: 0.0192150856471724\n",
      "SEED: 1513, FOLD: 2, EPOCH: 13, train_loss: 0.01913189302212086\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 13, valid_loss: 0.0192160051729944\n",
      "SEED: 1513, FOLD: 2, EPOCH: 14, train_loss: 0.01909059242925782\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01915854060401519\n",
      "SEED: 1513, FOLD: 2, EPOCH: 15, train_loss: 0.0190246956611889\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 15, valid_loss: 0.019086875952780247\n",
      "SEED: 1513, FOLD: 2, EPOCH: 16, train_loss: 0.018895294301319813\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01908004583997859\n",
      "SEED: 1513, FOLD: 2, EPOCH: 17, train_loss: 0.018728442841034004\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 17, valid_loss: 0.018931399203009076\n",
      "SEED: 1513, FOLD: 2, EPOCH: 18, train_loss: 0.01859034546583459\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01889660054196914\n",
      "SEED: 1513, FOLD: 2, EPOCH: 19, train_loss: 0.01843294633579427\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 19, valid_loss: 0.018811614873508613\n",
      "SEED: 1513, FOLD: 2, EPOCH: 20, train_loss: 0.018271984046568043\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 20, valid_loss: 0.018776076949305005\n",
      "SEED: 1513, FOLD: 2, EPOCH: 21, train_loss: 0.018090797129316605\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 21, valid_loss: 0.018716756978796587\n",
      "SEED: 1513, FOLD: 2, EPOCH: 22, train_loss: 0.01791191017390161\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 22, valid_loss: 0.018679011716610856\n",
      "SEED: 1513, FOLD: 2, EPOCH: 23, train_loss: 0.017794814554677494\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 23, valid_loss: 0.018654547424779996\n",
      "SEED: 1513, FOLD: 2, EPOCH: 24, train_loss: 0.017720301541081375\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01865002212838994\n",
      "SEED: 1513, FOLD: 3, EPOCH: 0, train_loss: 0.7180374316547228\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6314255760775672\n",
      "SEED: 1513, FOLD: 3, EPOCH: 1, train_loss: 0.2633720689817615\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 1, valid_loss: 0.029990992715789214\n",
      "SEED: 1513, FOLD: 3, EPOCH: 2, train_loss: 0.024643366589494373\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 2, valid_loss: 0.02135769608947966\n",
      "SEED: 1513, FOLD: 3, EPOCH: 3, train_loss: 0.021136372147694878\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 3, valid_loss: 0.02025525023539861\n",
      "SEED: 1513, FOLD: 3, EPOCH: 4, train_loss: 0.020347709565058998\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 4, valid_loss: 0.019775069939593475\n",
      "SEED: 1513, FOLD: 3, EPOCH: 5, train_loss: 0.019849900561182396\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 5, valid_loss: 0.020427352231409814\n",
      "SEED: 1513, FOLD: 3, EPOCH: 6, train_loss: 0.01953382374367852\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01958136943479379\n",
      "SEED: 1513, FOLD: 3, EPOCH: 7, train_loss: 0.01935645908225274\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 7, valid_loss: 0.019246922495464485\n",
      "SEED: 1513, FOLD: 3, EPOCH: 8, train_loss: 0.019283141967826996\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01946526538166735\n",
      "SEED: 1513, FOLD: 3, EPOCH: 9, train_loss: 0.019241385620789253\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 9, valid_loss: 0.019277619611885812\n",
      "SEED: 1513, FOLD: 3, EPOCH: 10, train_loss: 0.019204771524106247\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01934796975304683\n",
      "SEED: 1513, FOLD: 3, EPOCH: 11, train_loss: 0.019160278627405995\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 11, valid_loss: 0.019306430489652686\n",
      "SEED: 1513, FOLD: 3, EPOCH: 12, train_loss: 0.019132744331938633\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 12, valid_loss: 0.019165850865344208\n",
      "SEED: 1513, FOLD: 3, EPOCH: 13, train_loss: 0.019096811990375103\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01919929114066892\n",
      "SEED: 1513, FOLD: 3, EPOCH: 14, train_loss: 0.019008963166371635\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 14, valid_loss: 0.019154310122960143\n",
      "SEED: 1513, FOLD: 3, EPOCH: 15, train_loss: 0.018974205344051556\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 15, valid_loss: 0.0190627948484487\n",
      "SEED: 1513, FOLD: 3, EPOCH: 16, train_loss: 0.01885661339738231\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 16, valid_loss: 0.0190221495512459\n",
      "SEED: 1513, FOLD: 3, EPOCH: 17, train_loss: 0.018715384996671608\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 17, valid_loss: 0.018895267508924007\n",
      "SEED: 1513, FOLD: 3, EPOCH: 18, train_loss: 0.01856754242402056\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 18, valid_loss: 0.018866393094261486\n",
      "SEED: 1513, FOLD: 3, EPOCH: 19, train_loss: 0.018428326570901318\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 19, valid_loss: 0.018772322167125013\n",
      "SEED: 1513, FOLD: 3, EPOCH: 20, train_loss: 0.018272388132585995\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 20, valid_loss: 0.01872189725852675\n",
      "SEED: 1513, FOLD: 3, EPOCH: 21, train_loss: 0.018072368901060974\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 21, valid_loss: 0.018645698463337287\n",
      "SEED: 1513, FOLD: 3, EPOCH: 22, train_loss: 0.017907329389582508\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 22, valid_loss: 0.018645269744512107\n",
      "SEED: 1513, FOLD: 3, EPOCH: 23, train_loss: 0.01779327765647052\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 23, valid_loss: 0.018626714694417186\n",
      "SEED: 1513, FOLD: 3, EPOCH: 24, train_loss: 0.017767037926376728\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01862969094266494\n",
      "SEED: 1513, FOLD: 4, EPOCH: 0, train_loss: 0.7181647419929504\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6355234616332583\n",
      "SEED: 1513, FOLD: 4, EPOCH: 1, train_loss: 0.26317216553117917\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 1, valid_loss: 0.03154325681842036\n",
      "SEED: 1513, FOLD: 4, EPOCH: 2, train_loss: 0.0247354906430279\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 2, valid_loss: 0.022087461522056\n",
      "SEED: 1513, FOLD: 4, EPOCH: 3, train_loss: 0.021178572236195854\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 3, valid_loss: 0.020403861275149718\n",
      "SEED: 1513, FOLD: 4, EPOCH: 4, train_loss: 0.02041912184137365\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 4, valid_loss: 0.020089018262094922\n",
      "SEED: 1513, FOLD: 4, EPOCH: 5, train_loss: 0.01993657141060069\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 5, valid_loss: 0.019766675411827035\n",
      "SEED: 1513, FOLD: 4, EPOCH: 6, train_loss: 0.019562924955634102\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01965189476807912\n",
      "SEED: 1513, FOLD: 4, EPOCH: 7, train_loss: 0.019386586314742115\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01966069255852037\n",
      "SEED: 1513, FOLD: 4, EPOCH: 8, train_loss: 0.019292959538490875\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 8, valid_loss: 0.019486577870945137\n",
      "SEED: 1513, FOLD: 4, EPOCH: 9, train_loss: 0.019291149209374966\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 9, valid_loss: 0.0195455528381798\n",
      "SEED: 1513, FOLD: 4, EPOCH: 10, train_loss: 0.01922807629233685\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 10, valid_loss: 0.019336181382338207\n",
      "SEED: 1513, FOLD: 4, EPOCH: 11, train_loss: 0.019155597152269405\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01939390641119745\n",
      "SEED: 1513, FOLD: 4, EPOCH: 12, train_loss: 0.019195596970941708\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 12, valid_loss: 0.01932855850706498\n",
      "SEED: 1513, FOLD: 4, EPOCH: 13, train_loss: 0.019118107585371403\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 13, valid_loss: 0.019403051791919604\n",
      "SEED: 1513, FOLD: 4, EPOCH: 14, train_loss: 0.01905250182186348\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 14, valid_loss: 0.019333970215585496\n",
      "SEED: 1513, FOLD: 4, EPOCH: 15, train_loss: 0.01899478079724139\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 15, valid_loss: 0.019195890881949\n",
      "SEED: 1513, FOLD: 4, EPOCH: 16, train_loss: 0.01890103832103204\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 16, valid_loss: 0.019082610081467364\n",
      "SEED: 1513, FOLD: 4, EPOCH: 17, train_loss: 0.01878189406209234\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 17, valid_loss: 0.019117666097978752\n",
      "SEED: 1513, FOLD: 4, EPOCH: 18, train_loss: 0.018632473208118176\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01901893700576491\n",
      "SEED: 1513, FOLD: 4, EPOCH: 19, train_loss: 0.018434400035851242\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 19, valid_loss: 0.018916455511417653\n",
      "SEED: 1513, FOLD: 4, EPOCH: 20, train_loss: 0.018299317986205006\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 20, valid_loss: 0.018821734831564955\n",
      "SEED: 1513, FOLD: 4, EPOCH: 21, train_loss: 0.018118504866741707\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 21, valid_loss: 0.018770135214759245\n",
      "SEED: 1513, FOLD: 4, EPOCH: 22, train_loss: 0.017959922768067623\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 22, valid_loss: 0.018729206278092332\n",
      "SEED: 1513, FOLD: 4, EPOCH: 23, train_loss: 0.01780213828644027\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01873506336576409\n",
      "SEED: 1513, FOLD: 4, EPOCH: 24, train_loss: 0.017750546795086586\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 24, valid_loss: 0.018726268990172282\n",
      "elapsed time: 262.63102173805237\n",
      "SEED: 1269, FOLD: 0, EPOCH: 0, train_loss: 0.7208957862162936\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6387868854734633\n",
      "SEED: 1269, FOLD: 0, EPOCH: 1, train_loss: 0.26295647797161253\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 1, valid_loss: 0.030170547258522775\n",
      "SEED: 1269, FOLD: 0, EPOCH: 2, train_loss: 0.024870684829311096\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 2, valid_loss: 0.021762230123082798\n",
      "SEED: 1269, FOLD: 0, EPOCH: 3, train_loss: 0.021201946273230125\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 3, valid_loss: 0.0204287383498417\n",
      "SEED: 1269, FOLD: 0, EPOCH: 4, train_loss: 0.020421456032689068\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 4, valid_loss: 0.019906773438884154\n",
      "SEED: 1269, FOLD: 0, EPOCH: 5, train_loss: 0.019957859150093536\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 5, valid_loss: 0.019613474400507078\n",
      "SEED: 1269, FOLD: 0, EPOCH: 6, train_loss: 0.01956702131724012\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01965035746494929\n",
      "SEED: 1269, FOLD: 0, EPOCH: 7, train_loss: 0.019445250026773716\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 7, valid_loss: 0.019520107035835583\n",
      "SEED: 1269, FOLD: 0, EPOCH: 8, train_loss: 0.019270437216197235\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 8, valid_loss: 0.019307664905985195\n",
      "SEED: 1269, FOLD: 0, EPOCH: 9, train_loss: 0.01923119430632695\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01918424769408173\n",
      "SEED: 1269, FOLD: 0, EPOCH: 10, train_loss: 0.019201054548223812\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01936315331194136\n",
      "SEED: 1269, FOLD: 0, EPOCH: 11, train_loss: 0.01914211886300557\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01923691077778737\n",
      "SEED: 1269, FOLD: 0, EPOCH: 12, train_loss: 0.01914435673667037\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01929677515808079\n",
      "SEED: 1269, FOLD: 0, EPOCH: 13, train_loss: 0.01911612038595089\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 13, valid_loss: 0.019178398470911715\n",
      "SEED: 1269, FOLD: 0, EPOCH: 14, train_loss: 0.01903096394802349\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 14, valid_loss: 0.019278940848178334\n",
      "SEED: 1269, FOLD: 0, EPOCH: 15, train_loss: 0.018907731641893803\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 15, valid_loss: 0.019114844707979098\n",
      "SEED: 1269, FOLD: 0, EPOCH: 16, train_loss: 0.018837088503051495\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 16, valid_loss: 0.019054503076606326\n",
      "SEED: 1269, FOLD: 0, EPOCH: 17, train_loss: 0.018699018419652744\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01899794675409794\n",
      "SEED: 1269, FOLD: 0, EPOCH: 18, train_loss: 0.018569239320746368\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 18, valid_loss: 0.018964192209144432\n",
      "SEED: 1269, FOLD: 0, EPOCH: 19, train_loss: 0.018377874424492104\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 19, valid_loss: 0.018910313232077494\n",
      "SEED: 1269, FOLD: 0, EPOCH: 20, train_loss: 0.01818448880120464\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 20, valid_loss: 0.018881534226238728\n",
      "SEED: 1269, FOLD: 0, EPOCH: 21, train_loss: 0.01802358911305234\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01874940304292573\n",
      "SEED: 1269, FOLD: 0, EPOCH: 22, train_loss: 0.017886986605067184\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 22, valid_loss: 0.018734765756461356\n",
      "SEED: 1269, FOLD: 0, EPOCH: 23, train_loss: 0.017772336341980575\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 23, valid_loss: 0.018716278796394665\n",
      "SEED: 1269, FOLD: 0, EPOCH: 24, train_loss: 0.01768586528150068\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 24, valid_loss: 0.018714320431980822\n",
      "SEED: 1269, FOLD: 1, EPOCH: 0, train_loss: 0.7209904228431591\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6371134022871653\n",
      "SEED: 1269, FOLD: 1, EPOCH: 1, train_loss: 0.26424149898947147\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 1, valid_loss: 0.030538600145114794\n",
      "SEED: 1269, FOLD: 1, EPOCH: 2, train_loss: 0.02473764151226783\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 2, valid_loss: 0.02158102382802301\n",
      "SEED: 1269, FOLD: 1, EPOCH: 3, train_loss: 0.021154003973672356\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 3, valid_loss: 0.020296071656048298\n",
      "SEED: 1269, FOLD: 1, EPOCH: 4, train_loss: 0.020401173662664234\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 4, valid_loss: 0.020008966223233275\n",
      "SEED: 1269, FOLD: 1, EPOCH: 5, train_loss: 0.019963940659510918\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 5, valid_loss: 0.019656570421324834\n",
      "SEED: 1269, FOLD: 1, EPOCH: 6, train_loss: 0.019526463406889336\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 6, valid_loss: 0.019466397145556077\n",
      "SEED: 1269, FOLD: 1, EPOCH: 7, train_loss: 0.019353537104915882\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01934457415093978\n",
      "SEED: 1269, FOLD: 1, EPOCH: 8, train_loss: 0.019277576870028523\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01940192696121004\n",
      "SEED: 1269, FOLD: 1, EPOCH: 9, train_loss: 0.019233976558282757\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 9, valid_loss: 0.019372504101031356\n",
      "SEED: 1269, FOLD: 1, EPOCH: 10, train_loss: 0.01920053316955117\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 10, valid_loss: 0.019452084476749103\n",
      "SEED: 1269, FOLD: 1, EPOCH: 11, train_loss: 0.01915518604758857\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 11, valid_loss: 0.019340397376153205\n",
      "SEED: 1269, FOLD: 1, EPOCH: 12, train_loss: 0.01918433881972147\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01924654220541318\n",
      "SEED: 1269, FOLD: 1, EPOCH: 13, train_loss: 0.019105783353249233\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 13, valid_loss: 0.019247909490433004\n",
      "SEED: 1269, FOLD: 1, EPOCH: 14, train_loss: 0.019023364409804344\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 14, valid_loss: 0.019209996693664126\n",
      "SEED: 1269, FOLD: 1, EPOCH: 15, train_loss: 0.018966848867526954\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 15, valid_loss: 0.019124171179201867\n",
      "SEED: 1269, FOLD: 1, EPOCH: 16, train_loss: 0.018824511788029602\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 16, valid_loss: 0.01905086502018902\n",
      "SEED: 1269, FOLD: 1, EPOCH: 17, train_loss: 0.01870525641825752\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 17, valid_loss: 0.019021811481151316\n",
      "SEED: 1269, FOLD: 1, EPOCH: 18, train_loss: 0.018545252230504284\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 18, valid_loss: 0.018916142587032583\n",
      "SEED: 1269, FOLD: 1, EPOCH: 19, train_loss: 0.018394643953744915\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 19, valid_loss: 0.018912182086043887\n",
      "SEED: 1269, FOLD: 1, EPOCH: 20, train_loss: 0.01820922410790471\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 20, valid_loss: 0.018792649627559714\n",
      "SEED: 1269, FOLD: 1, EPOCH: 21, train_loss: 0.018027985036589096\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 21, valid_loss: 0.018748501522673502\n",
      "SEED: 1269, FOLD: 1, EPOCH: 22, train_loss: 0.01787845447551513\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 22, valid_loss: 0.018722998081809945\n",
      "SEED: 1269, FOLD: 1, EPOCH: 23, train_loss: 0.017738761002386826\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01871312999476989\n",
      "SEED: 1269, FOLD: 1, EPOCH: 24, train_loss: 0.017668341758890427\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 24, valid_loss: 0.018719101635118324\n",
      "SEED: 1269, FOLD: 2, EPOCH: 0, train_loss: 0.7207897054976311\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6406605839729309\n",
      "SEED: 1269, FOLD: 2, EPOCH: 1, train_loss: 0.26291819489088614\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 1, valid_loss: 0.030199074496825535\n",
      "SEED: 1269, FOLD: 2, EPOCH: 2, train_loss: 0.024935648142211678\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 2, valid_loss: 0.02160302156375514\n",
      "SEED: 1269, FOLD: 2, EPOCH: 3, train_loss: 0.02117361827497033\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 3, valid_loss: 0.02036768974115451\n",
      "SEED: 1269, FOLD: 2, EPOCH: 4, train_loss: 0.020560766556772633\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 4, valid_loss: 0.02010252844128344\n",
      "SEED: 1269, FOLD: 2, EPOCH: 5, train_loss: 0.019965319367854492\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 5, valid_loss: 0.019718218698269792\n",
      "SEED: 1269, FOLD: 2, EPOCH: 6, train_loss: 0.019675591771585354\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01967708518107732\n",
      "SEED: 1269, FOLD: 2, EPOCH: 7, train_loss: 0.019464917022033013\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01937392105658849\n",
      "SEED: 1269, FOLD: 2, EPOCH: 8, train_loss: 0.019329003503789074\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01945261201924748\n",
      "SEED: 1269, FOLD: 2, EPOCH: 9, train_loss: 0.019287720646547234\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01930066974212726\n",
      "SEED: 1269, FOLD: 2, EPOCH: 10, train_loss: 0.019254071583998375\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 10, valid_loss: 0.019255611735085647\n",
      "SEED: 1269, FOLD: 2, EPOCH: 11, train_loss: 0.01916317571548448\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 11, valid_loss: 0.019523231519593134\n",
      "SEED: 1269, FOLD: 2, EPOCH: 12, train_loss: 0.019180019048676975\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 12, valid_loss: 0.019177520647644997\n",
      "SEED: 1269, FOLD: 2, EPOCH: 13, train_loss: 0.019165761930787045\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 13, valid_loss: 0.019123401906755235\n",
      "SEED: 1269, FOLD: 2, EPOCH: 14, train_loss: 0.019082817613430645\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 14, valid_loss: 0.019247239972982142\n",
      "SEED: 1269, FOLD: 2, EPOCH: 15, train_loss: 0.018979149290185043\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01903206306613154\n",
      "SEED: 1269, FOLD: 2, EPOCH: 16, train_loss: 0.018899357297282288\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 16, valid_loss: 0.018963596059216395\n",
      "SEED: 1269, FOLD: 2, EPOCH: 17, train_loss: 0.018741910170385803\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 17, valid_loss: 0.018965873660312757\n",
      "SEED: 1269, FOLD: 2, EPOCH: 18, train_loss: 0.018620042751232784\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 18, valid_loss: 0.018907192991011672\n",
      "SEED: 1269, FOLD: 2, EPOCH: 19, train_loss: 0.018458898921591648\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 19, valid_loss: 0.018853083045946226\n",
      "SEED: 1269, FOLD: 2, EPOCH: 20, train_loss: 0.018304153062079265\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 20, valid_loss: 0.0187339810654521\n",
      "SEED: 1269, FOLD: 2, EPOCH: 21, train_loss: 0.01806165933932947\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01869778511010938\n",
      "SEED: 1269, FOLD: 2, EPOCH: 22, train_loss: 0.017939890046482502\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01867898553609848\n",
      "SEED: 1269, FOLD: 2, EPOCH: 23, train_loss: 0.017805535778187324\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 23, valid_loss: 0.018653378821909428\n",
      "SEED: 1269, FOLD: 2, EPOCH: 24, train_loss: 0.017734637052036713\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 24, valid_loss: 0.018658412827385798\n",
      "SEED: 1269, FOLD: 3, EPOCH: 0, train_loss: 0.7205770352612371\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6397028863430023\n",
      "SEED: 1269, FOLD: 3, EPOCH: 1, train_loss: 0.2633883454769418\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 1, valid_loss: 0.03230641627063354\n",
      "SEED: 1269, FOLD: 3, EPOCH: 2, train_loss: 0.025164196996585182\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 2, valid_loss: 0.021778722397155233\n",
      "SEED: 1269, FOLD: 3, EPOCH: 3, train_loss: 0.021232796535975693\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 3, valid_loss: 0.020270506540934246\n",
      "SEED: 1269, FOLD: 3, EPOCH: 4, train_loss: 0.02037636652264906\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 4, valid_loss: 0.019840129133727815\n",
      "SEED: 1269, FOLD: 3, EPOCH: 5, train_loss: 0.01992325592732084\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 5, valid_loss: 0.019612370990216732\n",
      "SEED: 1269, FOLD: 3, EPOCH: 6, train_loss: 0.019591667513916458\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 6, valid_loss: 0.019356577139761712\n",
      "SEED: 1269, FOLD: 3, EPOCH: 7, train_loss: 0.019368722117033558\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01935166482710176\n",
      "SEED: 1269, FOLD: 3, EPOCH: 8, train_loss: 0.019255983548751777\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 8, valid_loss: 0.019272431524263486\n",
      "SEED: 1269, FOLD: 3, EPOCH: 9, train_loss: 0.019226536181741867\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 9, valid_loss: 0.019233356643882062\n",
      "SEED: 1269, FOLD: 3, EPOCH: 10, train_loss: 0.019163045600272606\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 10, valid_loss: 0.019197058346536424\n",
      "SEED: 1269, FOLD: 3, EPOCH: 11, train_loss: 0.019153589814685394\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 11, valid_loss: 0.019248741782373853\n",
      "SEED: 1269, FOLD: 3, EPOCH: 12, train_loss: 0.01912060844293539\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01917276655634244\n",
      "SEED: 1269, FOLD: 3, EPOCH: 13, train_loss: 0.01906969940856747\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01913243563224872\n",
      "SEED: 1269, FOLD: 3, EPOCH: 14, train_loss: 0.018977666138738827\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01909899577084515\n",
      "SEED: 1269, FOLD: 3, EPOCH: 15, train_loss: 0.018893973901867867\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01906780753698614\n",
      "SEED: 1269, FOLD: 3, EPOCH: 16, train_loss: 0.018790593046856964\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 16, valid_loss: 0.018945728066480823\n",
      "SEED: 1269, FOLD: 3, EPOCH: 17, train_loss: 0.01870735683410928\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01889282578809394\n",
      "SEED: 1269, FOLD: 3, EPOCH: 18, train_loss: 0.018536649941318276\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 18, valid_loss: 0.018877957844071917\n",
      "SEED: 1269, FOLD: 3, EPOCH: 19, train_loss: 0.018352533191226532\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 19, valid_loss: 0.018780622269130416\n",
      "SEED: 1269, FOLD: 3, EPOCH: 20, train_loss: 0.018172942587862843\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 20, valid_loss: 0.018748288818945486\n",
      "SEED: 1269, FOLD: 3, EPOCH: 21, train_loss: 0.01798785321306491\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01868947610879938\n",
      "SEED: 1269, FOLD: 3, EPOCH: 22, train_loss: 0.01784269341632076\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 22, valid_loss: 0.018651598133146763\n",
      "SEED: 1269, FOLD: 3, EPOCH: 23, train_loss: 0.017691038683920666\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 23, valid_loss: 0.018638738431036472\n",
      "SEED: 1269, FOLD: 3, EPOCH: 24, train_loss: 0.017621974339303764\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 24, valid_loss: 0.018635188022421464\n",
      "SEED: 1269, FOLD: 4, EPOCH: 0, train_loss: 0.720880187076071\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 0, valid_loss: 0.634959167904324\n",
      "SEED: 1269, FOLD: 4, EPOCH: 1, train_loss: 0.2633925980847815\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 1, valid_loss: 0.031001702571908634\n",
      "SEED: 1269, FOLD: 4, EPOCH: 2, train_loss: 0.02473646186400151\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 2, valid_loss: 0.021968355195389852\n",
      "SEED: 1269, FOLD: 4, EPOCH: 3, train_loss: 0.021101061119765476\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 3, valid_loss: 0.020412404814528093\n",
      "SEED: 1269, FOLD: 4, EPOCH: 4, train_loss: 0.02038167271277179\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 4, valid_loss: 0.019944072804517217\n",
      "SEED: 1269, FOLD: 4, EPOCH: 5, train_loss: 0.019820609521390736\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01986682125263744\n",
      "SEED: 1269, FOLD: 4, EPOCH: 6, train_loss: 0.01953435948361521\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01942970934841368\n",
      "SEED: 1269, FOLD: 4, EPOCH: 7, train_loss: 0.01937887760932031\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01955156059314807\n",
      "SEED: 1269, FOLD: 4, EPOCH: 8, train_loss: 0.019264821530036304\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 8, valid_loss: 0.019561951359113056\n",
      "SEED: 1269, FOLD: 4, EPOCH: 9, train_loss: 0.0192504792433718\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 9, valid_loss: 0.019479450562761888\n",
      "SEED: 1269, FOLD: 4, EPOCH: 10, train_loss: 0.01919584537761799\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 10, valid_loss: 0.019377593468460772\n",
      "SEED: 1269, FOLD: 4, EPOCH: 11, train_loss: 0.019152316359290177\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 11, valid_loss: 0.019435249993370637\n",
      "SEED: 1269, FOLD: 4, EPOCH: 12, train_loss: 0.019151410816804222\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 12, valid_loss: 0.019443860587974388\n",
      "SEED: 1269, FOLD: 4, EPOCH: 13, train_loss: 0.019111481778647587\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 13, valid_loss: 0.019264627972410783\n",
      "SEED: 1269, FOLD: 4, EPOCH: 14, train_loss: 0.019016161318058552\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01912804755071799\n",
      "SEED: 1269, FOLD: 4, EPOCH: 15, train_loss: 0.01892272358679253\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01921695460461908\n",
      "SEED: 1269, FOLD: 4, EPOCH: 16, train_loss: 0.01884641765576342\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01912588460577859\n",
      "SEED: 1269, FOLD: 4, EPOCH: 17, train_loss: 0.018692369586315708\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 17, valid_loss: 0.019136644175483122\n",
      "SEED: 1269, FOLD: 4, EPOCH: 18, train_loss: 0.01857654140263364\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 18, valid_loss: 0.019030541285044618\n",
      "SEED: 1269, FOLD: 4, EPOCH: 19, train_loss: 0.018372516242274338\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 19, valid_loss: 0.018924573436379433\n",
      "SEED: 1269, FOLD: 4, EPOCH: 20, train_loss: 0.018217922525777332\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01885619366334544\n",
      "SEED: 1269, FOLD: 4, EPOCH: 21, train_loss: 0.01803716266716736\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 21, valid_loss: 0.018764620129432943\n",
      "SEED: 1269, FOLD: 4, EPOCH: 22, train_loss: 0.017852810278966808\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 22, valid_loss: 0.018735161051154137\n",
      "SEED: 1269, FOLD: 4, EPOCH: 23, train_loss: 0.017741055457272392\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 23, valid_loss: 0.018712210779388744\n",
      "SEED: 1269, FOLD: 4, EPOCH: 24, train_loss: 0.017689651256238205\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01870553826706277\n",
      "elapsed time: 394.2447910308838\n",
      "SEED: 1392, FOLD: 0, EPOCH: 0, train_loss: 0.7195622368135314\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6422824329800076\n",
      "SEED: 1392, FOLD: 0, EPOCH: 1, train_loss: 0.2630091806792695\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 1, valid_loss: 0.029751529606680076\n",
      "SEED: 1392, FOLD: 0, EPOCH: 2, train_loss: 0.02498864976392276\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 2, valid_loss: 0.02187652823825677\n",
      "SEED: 1392, FOLD: 0, EPOCH: 3, train_loss: 0.02119470708936021\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 3, valid_loss: 0.020242027214003935\n",
      "SEED: 1392, FOLD: 0, EPOCH: 4, train_loss: 0.02043050816417604\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 4, valid_loss: 0.020054569364421897\n",
      "SEED: 1392, FOLD: 0, EPOCH: 5, train_loss: 0.019895764229738194\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 5, valid_loss: 0.019571147652135953\n",
      "SEED: 1392, FOLD: 0, EPOCH: 6, train_loss: 0.01956730924438739\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 6, valid_loss: 0.019438756733304925\n",
      "SEED: 1392, FOLD: 0, EPOCH: 7, train_loss: 0.01938350644448529\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 7, valid_loss: 0.019290155006779566\n",
      "SEED: 1392, FOLD: 0, EPOCH: 8, train_loss: 0.019275851763676907\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 8, valid_loss: 0.019401294386221304\n",
      "SEED: 1392, FOLD: 0, EPOCH: 9, train_loss: 0.01923307833140311\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 9, valid_loss: 0.019258339164985552\n",
      "SEED: 1392, FOLD: 0, EPOCH: 10, train_loss: 0.019184054617864498\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 10, valid_loss: 0.019387990443242922\n",
      "SEED: 1392, FOLD: 0, EPOCH: 11, train_loss: 0.019166125848457432\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 11, valid_loss: 0.019352284053133592\n",
      "SEED: 1392, FOLD: 0, EPOCH: 12, train_loss: 0.019118986807871555\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 12, valid_loss: 0.019277802151110437\n",
      "SEED: 1392, FOLD: 0, EPOCH: 13, train_loss: 0.01911478176497031\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01922712330189016\n",
      "SEED: 1392, FOLD: 0, EPOCH: 14, train_loss: 0.01909685998723127\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 14, valid_loss: 0.019180428754124377\n",
      "SEED: 1392, FOLD: 0, EPOCH: 15, train_loss: 0.018948933622543362\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01916671482225259\n",
      "SEED: 1392, FOLD: 0, EPOCH: 16, train_loss: 0.0188352532306875\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 16, valid_loss: 0.019075418098105326\n",
      "SEED: 1392, FOLD: 0, EPOCH: 17, train_loss: 0.018711431059932362\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01900524056206147\n",
      "SEED: 1392, FOLD: 0, EPOCH: 18, train_loss: 0.018604856389372246\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 18, valid_loss: 0.018975767617424328\n",
      "SEED: 1392, FOLD: 0, EPOCH: 19, train_loss: 0.0184219179108091\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 19, valid_loss: 0.018905405679510698\n",
      "SEED: 1392, FOLD: 0, EPOCH: 20, train_loss: 0.018238450144080147\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 20, valid_loss: 0.018776674134035904\n",
      "SEED: 1392, FOLD: 0, EPOCH: 21, train_loss: 0.01803291761788769\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 21, valid_loss: 0.018750948417517874\n",
      "SEED: 1392, FOLD: 0, EPOCH: 22, train_loss: 0.017871339494983356\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 22, valid_loss: 0.018711795306040183\n",
      "SEED: 1392, FOLD: 0, EPOCH: 23, train_loss: 0.017751597853350468\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 23, valid_loss: 0.018711410359376006\n",
      "SEED: 1392, FOLD: 0, EPOCH: 24, train_loss: 0.017720198636685593\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01870105519062943\n",
      "SEED: 1392, FOLD: 1, EPOCH: 0, train_loss: 0.7197508777397267\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6395682824982537\n",
      "SEED: 1392, FOLD: 1, EPOCH: 1, train_loss: 0.2635285312282866\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 1, valid_loss: 0.03020844142884016\n",
      "SEED: 1392, FOLD: 1, EPOCH: 2, train_loss: 0.024844074837755466\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 2, valid_loss: 0.021797881772120793\n",
      "SEED: 1392, FOLD: 1, EPOCH: 3, train_loss: 0.021166722465684448\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 3, valid_loss: 0.02047404357128673\n",
      "SEED: 1392, FOLD: 1, EPOCH: 4, train_loss: 0.020468223030152527\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 4, valid_loss: 0.019865474767155118\n",
      "SEED: 1392, FOLD: 1, EPOCH: 5, train_loss: 0.019981238154181534\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 5, valid_loss: 0.019657316928108532\n",
      "SEED: 1392, FOLD: 1, EPOCH: 6, train_loss: 0.01960717497960381\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 6, valid_loss: 0.019605334744685225\n",
      "SEED: 1392, FOLD: 1, EPOCH: 7, train_loss: 0.01935534138718377\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 7, valid_loss: 0.019462946698897414\n",
      "SEED: 1392, FOLD: 1, EPOCH: 8, train_loss: 0.01925936611234278\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 8, valid_loss: 0.019405255922012858\n",
      "SEED: 1392, FOLD: 1, EPOCH: 9, train_loss: 0.019264261278769245\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01953043012569348\n",
      "SEED: 1392, FOLD: 1, EPOCH: 10, train_loss: 0.019201491459988167\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 10, valid_loss: 0.019312021012107532\n",
      "SEED: 1392, FOLD: 1, EPOCH: 11, train_loss: 0.019195268578503445\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 11, valid_loss: 0.0193662548230754\n",
      "SEED: 1392, FOLD: 1, EPOCH: 12, train_loss: 0.019110431300773136\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 12, valid_loss: 0.019241980380482145\n",
      "SEED: 1392, FOLD: 1, EPOCH: 13, train_loss: 0.019091636536345966\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01920442862643136\n",
      "SEED: 1392, FOLD: 1, EPOCH: 14, train_loss: 0.019052550088668217\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 14, valid_loss: 0.01918240108837684\n",
      "SEED: 1392, FOLD: 1, EPOCH: 15, train_loss: 0.018941685098452843\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01916636319624053\n",
      "SEED: 1392, FOLD: 1, EPOCH: 16, train_loss: 0.018809082823387092\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 16, valid_loss: 0.01903477694011397\n",
      "SEED: 1392, FOLD: 1, EPOCH: 17, train_loss: 0.018702747624205505\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01900935245470868\n",
      "SEED: 1392, FOLD: 1, EPOCH: 18, train_loss: 0.01856918705870276\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01890693956779109\n",
      "SEED: 1392, FOLD: 1, EPOCH: 19, train_loss: 0.018384532301106316\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 19, valid_loss: 0.018849974187711876\n",
      "SEED: 1392, FOLD: 1, EPOCH: 20, train_loss: 0.018224783484702526\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 20, valid_loss: 0.018816805444657803\n",
      "SEED: 1392, FOLD: 1, EPOCH: 21, train_loss: 0.018036664234123367\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 21, valid_loss: 0.018742538885109954\n",
      "SEED: 1392, FOLD: 1, EPOCH: 22, train_loss: 0.017849808801775394\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 22, valid_loss: 0.01871589209056563\n",
      "SEED: 1392, FOLD: 1, EPOCH: 23, train_loss: 0.01773618679979573\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 23, valid_loss: 0.018690052959654067\n",
      "SEED: 1392, FOLD: 1, EPOCH: 24, train_loss: 0.017702275158270546\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 24, valid_loss: 0.018704269598755572\n",
      "SEED: 1392, FOLD: 2, EPOCH: 0, train_loss: 0.7196888111639714\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 0, valid_loss: 0.650574846400155\n",
      "SEED: 1392, FOLD: 2, EPOCH: 1, train_loss: 0.26366602499847824\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 1, valid_loss: 0.029741432414286666\n",
      "SEED: 1392, FOLD: 2, EPOCH: 2, train_loss: 0.024920119107633396\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 2, valid_loss: 0.021693022404279973\n",
      "SEED: 1392, FOLD: 2, EPOCH: 3, train_loss: 0.021401259886181873\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 3, valid_loss: 0.020697286042074364\n",
      "SEED: 1392, FOLD: 2, EPOCH: 4, train_loss: 0.020571201256867767\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 4, valid_loss: 0.019908564682635996\n",
      "SEED: 1392, FOLD: 2, EPOCH: 5, train_loss: 0.020070365157680237\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01956954939911763\n",
      "SEED: 1392, FOLD: 2, EPOCH: 6, train_loss: 0.019653882858329925\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 6, valid_loss: 0.019542257198029094\n",
      "SEED: 1392, FOLD: 2, EPOCH: 7, train_loss: 0.019453406441902767\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 7, valid_loss: 0.019474360160529613\n",
      "SEED: 1392, FOLD: 2, EPOCH: 8, train_loss: 0.019405592178952866\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01936988915420241\n",
      "SEED: 1392, FOLD: 2, EPOCH: 9, train_loss: 0.019328809653719265\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 9, valid_loss: 0.019356797656251326\n",
      "SEED: 1392, FOLD: 2, EPOCH: 10, train_loss: 0.019247783968846004\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 10, valid_loss: 0.019320142041477893\n",
      "SEED: 1392, FOLD: 2, EPOCH: 11, train_loss: 0.019222211065715637\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 11, valid_loss: 0.019220771681931283\n",
      "SEED: 1392, FOLD: 2, EPOCH: 12, train_loss: 0.019162331208370735\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 12, valid_loss: 0.019224982294771407\n",
      "SEED: 1392, FOLD: 2, EPOCH: 13, train_loss: 0.019110995763237926\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 13, valid_loss: 0.019179683385623827\n",
      "SEED: 1392, FOLD: 2, EPOCH: 14, train_loss: 0.019093347200448963\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 14, valid_loss: 0.019161481513745256\n",
      "SEED: 1392, FOLD: 2, EPOCH: 15, train_loss: 0.018977492534811947\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01907346138937606\n",
      "SEED: 1392, FOLD: 2, EPOCH: 16, train_loss: 0.018867782411583954\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 16, valid_loss: 0.0189488118307458\n",
      "SEED: 1392, FOLD: 2, EPOCH: 17, train_loss: 0.018706634451729664\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 17, valid_loss: 0.018935072132282786\n",
      "SEED: 1392, FOLD: 2, EPOCH: 18, train_loss: 0.0186089553154897\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 18, valid_loss: 0.018888310322331056\n",
      "SEED: 1392, FOLD: 2, EPOCH: 19, train_loss: 0.01844598830718061\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 19, valid_loss: 0.018811249174177647\n",
      "SEED: 1392, FOLD: 2, EPOCH: 20, train_loss: 0.018251603199304012\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01872806954714987\n",
      "SEED: 1392, FOLD: 2, EPOCH: 21, train_loss: 0.018095666191716125\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 21, valid_loss: 0.018685952656798892\n",
      "SEED: 1392, FOLD: 2, EPOCH: 22, train_loss: 0.017919486941958683\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 22, valid_loss: 0.018648894710673228\n",
      "SEED: 1392, FOLD: 2, EPOCH: 23, train_loss: 0.017811617557553276\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 23, valid_loss: 0.018641226614514988\n",
      "SEED: 1392, FOLD: 2, EPOCH: 24, train_loss: 0.01775792883574099\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 24, valid_loss: 0.018641821522679593\n",
      "SEED: 1392, FOLD: 3, EPOCH: 0, train_loss: 0.7197160323460897\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 0, valid_loss: 0.642787880367703\n",
      "SEED: 1392, FOLD: 3, EPOCH: 1, train_loss: 0.2643574949731861\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 1, valid_loss: 0.029959727078676224\n",
      "SEED: 1392, FOLD: 3, EPOCH: 2, train_loss: 0.024860498751851097\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 2, valid_loss: 0.021773439832031727\n",
      "SEED: 1392, FOLD: 3, EPOCH: 3, train_loss: 0.021199306203187374\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 3, valid_loss: 0.020248043971757095\n",
      "SEED: 1392, FOLD: 3, EPOCH: 4, train_loss: 0.020407219700839207\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 4, valid_loss: 0.019781675293213792\n",
      "SEED: 1392, FOLD: 3, EPOCH: 5, train_loss: 0.019936574488014416\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 5, valid_loss: 0.019982058347927198\n",
      "SEED: 1392, FOLD: 3, EPOCH: 6, train_loss: 0.019616288794339565\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 6, valid_loss: 0.019440847552484937\n",
      "SEED: 1392, FOLD: 3, EPOCH: 7, train_loss: 0.019392499511224636\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 7, valid_loss: 0.019339191106458504\n",
      "SEED: 1392, FOLD: 3, EPOCH: 8, train_loss: 0.01932121381379556\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 8, valid_loss: 0.019305162649187777\n",
      "SEED: 1392, FOLD: 3, EPOCH: 9, train_loss: 0.019243796450504357\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 9, valid_loss: 0.019266813062131405\n",
      "SEED: 1392, FOLD: 3, EPOCH: 10, train_loss: 0.019201106945241707\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 10, valid_loss: 0.019542508551643953\n",
      "SEED: 1392, FOLD: 3, EPOCH: 11, train_loss: 0.019235927206666573\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 11, valid_loss: 0.019163136577440634\n",
      "SEED: 1392, FOLD: 3, EPOCH: 12, train_loss: 0.019136134697043377\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 12, valid_loss: 0.019221081708868343\n",
      "SEED: 1392, FOLD: 3, EPOCH: 13, train_loss: 0.019111898039346157\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 13, valid_loss: 0.019100792085131008\n",
      "SEED: 1392, FOLD: 3, EPOCH: 14, train_loss: 0.01904183801641499\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 14, valid_loss: 0.019090830762353208\n",
      "SEED: 1392, FOLD: 3, EPOCH: 15, train_loss: 0.01898447837194671\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 15, valid_loss: 0.019006750753356352\n",
      "SEED: 1392, FOLD: 3, EPOCH: 16, train_loss: 0.018836676561530086\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01904636797391706\n",
      "SEED: 1392, FOLD: 3, EPOCH: 17, train_loss: 0.018739377701843994\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 17, valid_loss: 0.018917194774581328\n",
      "SEED: 1392, FOLD: 3, EPOCH: 18, train_loss: 0.01857520510321078\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 18, valid_loss: 0.018878947529527876\n",
      "SEED: 1392, FOLD: 3, EPOCH: 19, train_loss: 0.01838206151581329\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01878435578611162\n",
      "SEED: 1392, FOLD: 3, EPOCH: 20, train_loss: 0.01825599237412646\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 20, valid_loss: 0.01869843455238475\n",
      "SEED: 1392, FOLD: 3, EPOCH: 21, train_loss: 0.01804099256253761\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 21, valid_loss: 0.018654488854938082\n",
      "SEED: 1392, FOLD: 3, EPOCH: 22, train_loss: 0.01786987370123034\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 22, valid_loss: 0.018633805267098878\n",
      "SEED: 1392, FOLD: 3, EPOCH: 23, train_loss: 0.017770837776470875\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 23, valid_loss: 0.018618473162253697\n",
      "SEED: 1392, FOLD: 3, EPOCH: 24, train_loss: 0.017692747674342514\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 24, valid_loss: 0.018618286690778203\n",
      "SEED: 1392, FOLD: 4, EPOCH: 0, train_loss: 0.7195577336394269\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6417335503631167\n",
      "SEED: 1392, FOLD: 4, EPOCH: 1, train_loss: 0.26336595421468\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 1, valid_loss: 0.030975328033996954\n",
      "SEED: 1392, FOLD: 4, EPOCH: 2, train_loss: 0.024986546270657276\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 2, valid_loss: 0.02217483955125014\n",
      "SEED: 1392, FOLD: 4, EPOCH: 3, train_loss: 0.02123206999638806\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 3, valid_loss: 0.020575596226586237\n",
      "SEED: 1392, FOLD: 4, EPOCH: 4, train_loss: 0.020390685404772343\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 4, valid_loss: 0.0198740115803149\n",
      "SEED: 1392, FOLD: 4, EPOCH: 5, train_loss: 0.01992301329754401\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01974187780999475\n",
      "SEED: 1392, FOLD: 4, EPOCH: 6, train_loss: 0.019574764009187187\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 6, valid_loss: 0.019578093559377722\n",
      "SEED: 1392, FOLD: 4, EPOCH: 7, train_loss: 0.019350270862164703\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 7, valid_loss: 0.019504557467169233\n",
      "SEED: 1392, FOLD: 4, EPOCH: 8, train_loss: 0.0192777913171744\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 8, valid_loss: 0.019534225368665323\n",
      "SEED: 1392, FOLD: 4, EPOCH: 9, train_loss: 0.019262924412454384\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 9, valid_loss: 0.019877036929958396\n",
      "SEED: 1392, FOLD: 4, EPOCH: 10, train_loss: 0.019211093962624454\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01936941169616249\n",
      "SEED: 1392, FOLD: 4, EPOCH: 11, train_loss: 0.019169759923133297\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01948575975580348\n",
      "SEED: 1392, FOLD: 4, EPOCH: 12, train_loss: 0.01911126781740914\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 12, valid_loss: 0.019385200097329087\n",
      "SEED: 1392, FOLD: 4, EPOCH: 13, train_loss: 0.01908593605933846\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01924178645842605\n",
      "SEED: 1392, FOLD: 4, EPOCH: 14, train_loss: 0.019007251854392067\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 14, valid_loss: 0.019244447764423158\n",
      "SEED: 1392, FOLD: 4, EPOCH: 15, train_loss: 0.018945633339277214\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 15, valid_loss: 0.019223347306251526\n",
      "SEED: 1392, FOLD: 4, EPOCH: 16, train_loss: 0.018827573814685795\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 16, valid_loss: 0.019252881821658876\n",
      "SEED: 1392, FOLD: 4, EPOCH: 17, train_loss: 0.018709875265325325\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01910299238645368\n",
      "SEED: 1392, FOLD: 4, EPOCH: 18, train_loss: 0.018588154698195664\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01900871346394221\n",
      "SEED: 1392, FOLD: 4, EPOCH: 19, train_loss: 0.018399050999162853\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 19, valid_loss: 0.018915278009242482\n",
      "SEED: 1392, FOLD: 4, EPOCH: 20, train_loss: 0.018207847343190857\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 20, valid_loss: 0.018825640591482323\n",
      "SEED: 1392, FOLD: 4, EPOCH: 21, train_loss: 0.018041562693922417\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 21, valid_loss: 0.018790569777290028\n",
      "SEED: 1392, FOLD: 4, EPOCH: 22, train_loss: 0.017870906956385876\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01872433080441422\n",
      "SEED: 1392, FOLD: 4, EPOCH: 23, train_loss: 0.017737944839873176\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 23, valid_loss: 0.018724350258708\n",
      "SEED: 1392, FOLD: 4, EPOCH: 24, train_loss: 0.01769738498589267\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 24, valid_loss: 0.018725140434172418\n",
      "elapsed time: 524.201318025589\n",
      "SEED: 1119, FOLD: 0, EPOCH: 0, train_loss: 0.7190531043038852\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 0, valid_loss: 0.641297095351749\n",
      "SEED: 1119, FOLD: 0, EPOCH: 1, train_loss: 0.26487305819772294\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 1, valid_loss: 0.029961843250526324\n",
      "SEED: 1119, FOLD: 0, EPOCH: 2, train_loss: 0.0247995811312095\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 2, valid_loss: 0.021712397846082847\n",
      "SEED: 1119, FOLD: 0, EPOCH: 3, train_loss: 0.021082526288818623\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 3, valid_loss: 0.02033936998082532\n",
      "SEED: 1119, FOLD: 0, EPOCH: 4, train_loss: 0.020473365766414696\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 4, valid_loss: 0.020261628035869863\n",
      "SEED: 1119, FOLD: 0, EPOCH: 5, train_loss: 0.01989862449683141\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 5, valid_loss: 0.019580093315905996\n",
      "SEED: 1119, FOLD: 0, EPOCH: 6, train_loss: 0.01956308660083923\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01965364006658395\n",
      "SEED: 1119, FOLD: 0, EPOCH: 7, train_loss: 0.01939369603127673\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 7, valid_loss: 0.019381970995002322\n",
      "SEED: 1119, FOLD: 0, EPOCH: 8, train_loss: 0.01925496406097343\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 8, valid_loss: 0.019475320561064616\n",
      "SEED: 1119, FOLD: 0, EPOCH: 9, train_loss: 0.019278997609364815\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 9, valid_loss: 0.019440329633653164\n",
      "SEED: 1119, FOLD: 0, EPOCH: 10, train_loss: 0.019208523485323658\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01941518040580882\n",
      "SEED: 1119, FOLD: 0, EPOCH: 11, train_loss: 0.019227510156190914\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 11, valid_loss: 0.019190316502418783\n",
      "SEED: 1119, FOLD: 0, EPOCH: 12, train_loss: 0.019144592104830604\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 12, valid_loss: 0.019237219045559566\n",
      "SEED: 1119, FOLD: 0, EPOCH: 13, train_loss: 0.01910211410427439\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 13, valid_loss: 0.019203631000386343\n",
      "SEED: 1119, FOLD: 0, EPOCH: 14, train_loss: 0.019054745391443157\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 14, valid_loss: 0.019266142406397395\n",
      "SEED: 1119, FOLD: 0, EPOCH: 15, train_loss: 0.01894374434714732\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01908701068411271\n",
      "SEED: 1119, FOLD: 0, EPOCH: 16, train_loss: 0.018843747297490852\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01903129948510064\n",
      "SEED: 1119, FOLD: 0, EPOCH: 17, train_loss: 0.01871345497235872\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01897827225426833\n",
      "SEED: 1119, FOLD: 0, EPOCH: 18, train_loss: 0.018553834543495937\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 18, valid_loss: 0.01899251114163134\n",
      "SEED: 1119, FOLD: 0, EPOCH: 19, train_loss: 0.018407979683167694\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 19, valid_loss: 0.018866110903521378\n",
      "SEED: 1119, FOLD: 0, EPOCH: 20, train_loss: 0.018241930024131485\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 20, valid_loss: 0.018831520962218445\n",
      "SEED: 1119, FOLD: 0, EPOCH: 21, train_loss: 0.0180255317169687\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01880011148750782\n",
      "SEED: 1119, FOLD: 0, EPOCH: 22, train_loss: 0.01788136881330739\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 22, valid_loss: 0.018744566891756322\n",
      "SEED: 1119, FOLD: 0, EPOCH: 23, train_loss: 0.017741125265973202\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 23, valid_loss: 0.018720956415765815\n",
      "SEED: 1119, FOLD: 0, EPOCH: 24, train_loss: 0.01770131534262412\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01874539318184058\n",
      "SEED: 1119, FOLD: 1, EPOCH: 0, train_loss: 0.718820105428281\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6325736840566\n",
      "SEED: 1119, FOLD: 1, EPOCH: 1, train_loss: 0.2628419500492189\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 1, valid_loss: 0.029956905481715996\n",
      "SEED: 1119, FOLD: 1, EPOCH: 2, train_loss: 0.02482146108388037\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 2, valid_loss: 0.02180229789680905\n",
      "SEED: 1119, FOLD: 1, EPOCH: 3, train_loss: 0.021116280064418697\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 3, valid_loss: 0.020561763395865757\n",
      "SEED: 1119, FOLD: 1, EPOCH: 4, train_loss: 0.020393538221284962\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 4, valid_loss: 0.019885942960778873\n",
      "SEED: 1119, FOLD: 1, EPOCH: 5, train_loss: 0.019920364211218945\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 5, valid_loss: 0.019557187126742467\n",
      "SEED: 1119, FOLD: 1, EPOCH: 6, train_loss: 0.01958903173605601\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 6, valid_loss: 0.019483532756567\n",
      "SEED: 1119, FOLD: 1, EPOCH: 7, train_loss: 0.019364606778042904\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 7, valid_loss: 0.019401987083256245\n",
      "SEED: 1119, FOLD: 1, EPOCH: 8, train_loss: 0.019236415786587673\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 8, valid_loss: 0.019358595108820334\n",
      "SEED: 1119, FOLD: 1, EPOCH: 9, train_loss: 0.01919367944524772\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 9, valid_loss: 0.019413572425643604\n",
      "SEED: 1119, FOLD: 1, EPOCH: 10, train_loss: 0.01919630545096985\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 10, valid_loss: 0.019393860983351868\n",
      "SEED: 1119, FOLD: 1, EPOCH: 11, train_loss: 0.019181989214342575\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 11, valid_loss: 0.019334162585437298\n",
      "SEED: 1119, FOLD: 1, EPOCH: 12, train_loss: 0.019115889013029526\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01944702284203635\n",
      "SEED: 1119, FOLD: 1, EPOCH: 13, train_loss: 0.019049730097901993\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01916297794216209\n",
      "SEED: 1119, FOLD: 1, EPOCH: 14, train_loss: 0.019011650855342548\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 14, valid_loss: 0.019250783344937697\n",
      "SEED: 1119, FOLD: 1, EPOCH: 15, train_loss: 0.018943475370389828\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 15, valid_loss: 0.019117778581049707\n",
      "SEED: 1119, FOLD: 1, EPOCH: 16, train_loss: 0.01884830402939216\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 16, valid_loss: 0.019010448931819864\n",
      "SEED: 1119, FOLD: 1, EPOCH: 17, train_loss: 0.01868840504059757\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 17, valid_loss: 0.019062652045653924\n",
      "SEED: 1119, FOLD: 1, EPOCH: 18, train_loss: 0.018541282420788986\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 18, valid_loss: 0.018940277501112886\n",
      "SEED: 1119, FOLD: 1, EPOCH: 19, train_loss: 0.0183771554434645\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 19, valid_loss: 0.018864589122434456\n",
      "SEED: 1119, FOLD: 1, EPOCH: 20, train_loss: 0.018191080135495766\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 20, valid_loss: 0.018824061585797205\n",
      "SEED: 1119, FOLD: 1, EPOCH: 21, train_loss: 0.018004155434344127\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 21, valid_loss: 0.018804010624686878\n",
      "SEED: 1119, FOLD: 1, EPOCH: 22, train_loss: 0.017851695836778137\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 22, valid_loss: 0.018726299930777814\n",
      "SEED: 1119, FOLD: 1, EPOCH: 23, train_loss: 0.017732374748026115\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01872311635977692\n",
      "SEED: 1119, FOLD: 1, EPOCH: 24, train_loss: 0.017671212149055107\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01872757501486275\n",
      "SEED: 1119, FOLD: 2, EPOCH: 0, train_loss: 0.7190731038217959\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6344886819521586\n",
      "SEED: 1119, FOLD: 2, EPOCH: 1, train_loss: 0.2635528349682041\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 1, valid_loss: 0.030140079247454803\n",
      "SEED: 1119, FOLD: 2, EPOCH: 2, train_loss: 0.02482805276910464\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 2, valid_loss: 0.02144691761997011\n",
      "SEED: 1119, FOLD: 2, EPOCH: 3, train_loss: 0.021075036997596424\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 3, valid_loss: 0.020174215858181316\n",
      "SEED: 1119, FOLD: 2, EPOCH: 4, train_loss: 0.020432606096500935\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 4, valid_loss: 0.0201472622445888\n",
      "SEED: 1119, FOLD: 2, EPOCH: 5, train_loss: 0.019895653685797817\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 5, valid_loss: 0.019498749532633357\n",
      "SEED: 1119, FOLD: 2, EPOCH: 6, train_loss: 0.019522890637534252\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 6, valid_loss: 0.0195067109954026\n",
      "SEED: 1119, FOLD: 2, EPOCH: 7, train_loss: 0.0194070380774961\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 7, valid_loss: 0.019534315913915634\n",
      "SEED: 1119, FOLD: 2, EPOCH: 8, train_loss: 0.019308201239808746\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 8, valid_loss: 0.019312260775930352\n",
      "SEED: 1119, FOLD: 2, EPOCH: 9, train_loss: 0.019221907751499744\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 9, valid_loss: 0.019339908121360674\n",
      "SEED: 1119, FOLD: 2, EPOCH: 10, train_loss: 0.019227447582111843\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 10, valid_loss: 0.019181719981133938\n",
      "SEED: 1119, FOLD: 2, EPOCH: 11, train_loss: 0.01921785860389903\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 11, valid_loss: 0.019312566249734826\n",
      "SEED: 1119, FOLD: 2, EPOCH: 12, train_loss: 0.019182212083883907\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 12, valid_loss: 0.019211542482177418\n",
      "SEED: 1119, FOLD: 2, EPOCH: 13, train_loss: 0.01916611818191798\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01921189876480235\n",
      "SEED: 1119, FOLD: 2, EPOCH: 14, train_loss: 0.019058283445411835\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 14, valid_loss: 0.019157219988604385\n",
      "SEED: 1119, FOLD: 2, EPOCH: 15, train_loss: 0.01896617888216523\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 15, valid_loss: 0.019094035546812747\n",
      "SEED: 1119, FOLD: 2, EPOCH: 16, train_loss: 0.018898760656947674\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01906312546796269\n",
      "SEED: 1119, FOLD: 2, EPOCH: 17, train_loss: 0.01872700828033081\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01894859576390849\n",
      "SEED: 1119, FOLD: 2, EPOCH: 18, train_loss: 0.018611334804175556\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 18, valid_loss: 0.018941616432534322\n",
      "SEED: 1119, FOLD: 2, EPOCH: 19, train_loss: 0.01844204136210939\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 19, valid_loss: 0.018809002720647387\n",
      "SEED: 1119, FOLD: 2, EPOCH: 20, train_loss: 0.01827086200532706\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01876565244876676\n",
      "SEED: 1119, FOLD: 2, EPOCH: 21, train_loss: 0.01805950701236725\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 21, valid_loss: 0.018697460802892845\n",
      "SEED: 1119, FOLD: 2, EPOCH: 22, train_loss: 0.017902833180151123\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 22, valid_loss: 0.018685372960236337\n",
      "SEED: 1119, FOLD: 2, EPOCH: 23, train_loss: 0.017806020956756412\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01866263451261653\n",
      "SEED: 1119, FOLD: 2, EPOCH: 24, train_loss: 0.017756061115558597\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01867096322692103\n",
      "SEED: 1119, FOLD: 3, EPOCH: 0, train_loss: 0.718997035337531\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6392794317669339\n",
      "SEED: 1119, FOLD: 3, EPOCH: 1, train_loss: 0.2643674932744192\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 1, valid_loss: 0.030665822844538424\n",
      "SEED: 1119, FOLD: 3, EPOCH: 2, train_loss: 0.02481342190741629\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 2, valid_loss: 0.021586997744937737\n",
      "SEED: 1119, FOLD: 3, EPOCH: 3, train_loss: 0.021116273342699245\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 3, valid_loss: 0.020281996060576703\n",
      "SEED: 1119, FOLD: 3, EPOCH: 4, train_loss: 0.02033590541585632\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 4, valid_loss: 0.019893417341841593\n",
      "SEED: 1119, FOLD: 3, EPOCH: 5, train_loss: 0.019920372201696686\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 5, valid_loss: 0.019549141431020364\n",
      "SEED: 1119, FOLD: 3, EPOCH: 6, train_loss: 0.01953221204272215\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 6, valid_loss: 0.019459960257841483\n",
      "SEED: 1119, FOLD: 3, EPOCH: 7, train_loss: 0.019355995688533436\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01927504502236843\n",
      "SEED: 1119, FOLD: 3, EPOCH: 8, train_loss: 0.019250444473995678\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 8, valid_loss: 0.019271058237387076\n",
      "SEED: 1119, FOLD: 3, EPOCH: 9, train_loss: 0.019168137964131176\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 9, valid_loss: 0.019232208737068705\n",
      "SEED: 1119, FOLD: 3, EPOCH: 10, train_loss: 0.01918927094210749\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 10, valid_loss: 0.019251827978425555\n",
      "SEED: 1119, FOLD: 3, EPOCH: 11, train_loss: 0.019179764487173245\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01921509164902899\n",
      "SEED: 1119, FOLD: 3, EPOCH: 12, train_loss: 0.019140791930798172\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 12, valid_loss: 0.019162960453993745\n",
      "SEED: 1119, FOLD: 3, EPOCH: 13, train_loss: 0.019085078054796093\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 13, valid_loss: 0.019129811579154596\n",
      "SEED: 1119, FOLD: 3, EPOCH: 14, train_loss: 0.019047450598167336\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 14, valid_loss: 0.019134660044478044\n",
      "SEED: 1119, FOLD: 3, EPOCH: 15, train_loss: 0.018939227999552437\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 15, valid_loss: 0.019027642698751554\n",
      "SEED: 1119, FOLD: 3, EPOCH: 16, train_loss: 0.018832082495741222\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 16, valid_loss: 0.018886040275295574\n",
      "SEED: 1119, FOLD: 3, EPOCH: 17, train_loss: 0.018685904884899872\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01887375209480524\n",
      "SEED: 1119, FOLD: 3, EPOCH: 18, train_loss: 0.01857370626775251\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 18, valid_loss: 0.01883823766062657\n",
      "SEED: 1119, FOLD: 3, EPOCH: 19, train_loss: 0.018383345877130825\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01876687165349722\n",
      "SEED: 1119, FOLD: 3, EPOCH: 20, train_loss: 0.01817438659676607\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 20, valid_loss: 0.018747661573191483\n",
      "SEED: 1119, FOLD: 3, EPOCH: 21, train_loss: 0.01803660962352718\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 21, valid_loss: 0.018681579476429358\n",
      "SEED: 1119, FOLD: 3, EPOCH: 22, train_loss: 0.01786159275882486\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 22, valid_loss: 0.018657801517595846\n",
      "SEED: 1119, FOLD: 3, EPOCH: 23, train_loss: 0.017752539798401405\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01864197886445456\n",
      "SEED: 1119, FOLD: 3, EPOCH: 24, train_loss: 0.017652533192565475\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 24, valid_loss: 0.0186449169802169\n",
      "SEED: 1119, FOLD: 4, EPOCH: 0, train_loss: 0.7190594724986864\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6403565241230859\n",
      "SEED: 1119, FOLD: 4, EPOCH: 1, train_loss: 0.26518975360238034\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 1, valid_loss: 0.03117963516463836\n",
      "SEED: 1119, FOLD: 4, EPOCH: 2, train_loss: 0.02477493493453316\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 2, valid_loss: 0.021749984059068892\n",
      "SEED: 1119, FOLD: 4, EPOCH: 3, train_loss: 0.021126404917542484\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 3, valid_loss: 0.020657833044727642\n",
      "SEED: 1119, FOLD: 4, EPOCH: 4, train_loss: 0.020526067745210468\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 4, valid_loss: 0.0199928835241331\n",
      "SEED: 1119, FOLD: 4, EPOCH: 5, train_loss: 0.01988795923366063\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 5, valid_loss: 0.019926897664037015\n",
      "SEED: 1119, FOLD: 4, EPOCH: 6, train_loss: 0.01958638240677723\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 6, valid_loss: 0.019804096780717373\n",
      "SEED: 1119, FOLD: 4, EPOCH: 7, train_loss: 0.019392205942152203\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 7, valid_loss: 0.019532088707718585\n",
      "SEED: 1119, FOLD: 4, EPOCH: 8, train_loss: 0.019210506824479587\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 8, valid_loss: 0.019450231972667906\n",
      "SEED: 1119, FOLD: 4, EPOCH: 9, train_loss: 0.019231619745276977\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 9, valid_loss: 0.021251271064910624\n",
      "SEED: 1119, FOLD: 4, EPOCH: 10, train_loss: 0.019265048745749653\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01947867466757695\n",
      "SEED: 1119, FOLD: 4, EPOCH: 11, train_loss: 0.019201067181817\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 11, valid_loss: 0.019407183552781742\n",
      "SEED: 1119, FOLD: 4, EPOCH: 12, train_loss: 0.019145826903590256\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 12, valid_loss: 0.01941192750301626\n",
      "SEED: 1119, FOLD: 4, EPOCH: 13, train_loss: 0.01908130984267463\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01925384687880675\n",
      "SEED: 1119, FOLD: 4, EPOCH: 14, train_loss: 0.0190043440223604\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 14, valid_loss: 0.019200825339390173\n",
      "SEED: 1119, FOLD: 4, EPOCH: 15, train_loss: 0.01885384666746941\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01923212967813015\n",
      "SEED: 1119, FOLD: 4, EPOCH: 16, train_loss: 0.01884283322463001\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 16, valid_loss: 0.019114764407277107\n",
      "SEED: 1119, FOLD: 4, EPOCH: 17, train_loss: 0.018673098065714905\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 17, valid_loss: 0.019094894122746255\n",
      "SEED: 1119, FOLD: 4, EPOCH: 18, train_loss: 0.01856117922326793\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01895031188097265\n",
      "SEED: 1119, FOLD: 4, EPOCH: 19, train_loss: 0.018425687688632286\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 19, valid_loss: 0.018886112194094393\n",
      "SEED: 1119, FOLD: 4, EPOCH: 20, train_loss: 0.01823344389381616\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01886111663447486\n",
      "SEED: 1119, FOLD: 4, EPOCH: 21, train_loss: 0.01801412332587052\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 21, valid_loss: 0.018795591882533498\n",
      "SEED: 1119, FOLD: 4, EPOCH: 22, train_loss: 0.017863157947642216\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 22, valid_loss: 0.018737163808610704\n",
      "SEED: 1119, FOLD: 4, EPOCH: 23, train_loss: 0.017723485152574554\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01874510571360588\n",
      "SEED: 1119, FOLD: 4, EPOCH: 24, train_loss: 0.017663422270097595\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 24, valid_loss: 0.018740432543887034\n",
      "elapsed time: 654.09042096138\n",
      "SEED: 1303, FOLD: 0, EPOCH: 0, train_loss: 0.719876047493755\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6430289712217119\n",
      "SEED: 1303, FOLD: 0, EPOCH: 1, train_loss: 0.26296838329754013\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 1, valid_loss: 0.030742322094738483\n",
      "SEED: 1303, FOLD: 0, EPOCH: 2, train_loss: 0.024823468961361526\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 2, valid_loss: 0.021696462709870603\n",
      "SEED: 1303, FOLD: 0, EPOCH: 3, train_loss: 0.02122334139826505\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 3, valid_loss: 0.020288050174713135\n",
      "SEED: 1303, FOLD: 0, EPOCH: 4, train_loss: 0.02047442158927088\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 4, valid_loss: 0.019825822156336572\n",
      "SEED: 1303, FOLD: 0, EPOCH: 5, train_loss: 0.019875541977260425\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 5, valid_loss: 0.019570162726773158\n",
      "SEED: 1303, FOLD: 0, EPOCH: 6, train_loss: 0.019560328131352646\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 6, valid_loss: 0.019619905286365084\n",
      "SEED: 1303, FOLD: 0, EPOCH: 7, train_loss: 0.019377101374709087\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 7, valid_loss: 0.019380137013892334\n",
      "SEED: 1303, FOLD: 0, EPOCH: 8, train_loss: 0.019298242971948956\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01956907877077659\n",
      "SEED: 1303, FOLD: 0, EPOCH: 9, train_loss: 0.01920735628168652\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 9, valid_loss: 0.019372991286218166\n",
      "SEED: 1303, FOLD: 0, EPOCH: 10, train_loss: 0.01919471421211526\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01926138076103396\n",
      "SEED: 1303, FOLD: 0, EPOCH: 11, train_loss: 0.019153553101679554\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01933242432359192\n",
      "SEED: 1303, FOLD: 0, EPOCH: 12, train_loss: 0.019134122770333637\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 12, valid_loss: 0.019291318849556975\n",
      "SEED: 1303, FOLD: 0, EPOCH: 13, train_loss: 0.019097137386384216\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 13, valid_loss: 0.019335809267229505\n",
      "SEED: 1303, FOLD: 0, EPOCH: 14, train_loss: 0.019009957144009895\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 14, valid_loss: 0.019160090531739924\n",
      "SEED: 1303, FOLD: 0, EPOCH: 15, train_loss: 0.018927431516889213\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 15, valid_loss: 0.019142020493745804\n",
      "SEED: 1303, FOLD: 0, EPOCH: 16, train_loss: 0.018802061973922493\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 16, valid_loss: 0.019001889663438003\n",
      "SEED: 1303, FOLD: 0, EPOCH: 17, train_loss: 0.01870280666195828\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01898757813291417\n",
      "SEED: 1303, FOLD: 0, EPOCH: 18, train_loss: 0.01855823033205841\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 18, valid_loss: 0.018883490624527138\n",
      "SEED: 1303, FOLD: 0, EPOCH: 19, train_loss: 0.018372565507888794\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01884487323049042\n",
      "SEED: 1303, FOLD: 0, EPOCH: 20, train_loss: 0.018206937481527744\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 20, valid_loss: 0.018793335184454918\n",
      "SEED: 1303, FOLD: 0, EPOCH: 21, train_loss: 0.018023420773122623\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 21, valid_loss: 0.018791159200999472\n",
      "SEED: 1303, FOLD: 0, EPOCH: 22, train_loss: 0.01784077775327192\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 22, valid_loss: 0.0187228557964166\n",
      "SEED: 1303, FOLD: 0, EPOCH: 23, train_loss: 0.017736558464990147\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01869604705522458\n",
      "SEED: 1303, FOLD: 0, EPOCH: 24, train_loss: 0.017674757842568382\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 24, valid_loss: 0.018698585219681263\n",
      "SEED: 1303, FOLD: 1, EPOCH: 0, train_loss: 0.7201291167217753\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6450617015361786\n",
      "SEED: 1303, FOLD: 1, EPOCH: 1, train_loss: 0.2620648827025856\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 1, valid_loss: 0.030885708414845996\n",
      "SEED: 1303, FOLD: 1, EPOCH: 2, train_loss: 0.02511392047871714\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 2, valid_loss: 0.021959875296387408\n",
      "SEED: 1303, FOLD: 1, EPOCH: 3, train_loss: 0.021270211165150005\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 3, valid_loss: 0.02017406974401739\n",
      "SEED: 1303, FOLD: 1, EPOCH: 4, train_loss: 0.020447586973508198\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01992810538245572\n",
      "SEED: 1303, FOLD: 1, EPOCH: 5, train_loss: 0.019975491353999012\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 5, valid_loss: 0.01955179839084546\n",
      "SEED: 1303, FOLD: 1, EPOCH: 6, train_loss: 0.01955909249575242\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 6, valid_loss: 0.019471379617849987\n",
      "SEED: 1303, FOLD: 1, EPOCH: 7, train_loss: 0.019402838325586872\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 7, valid_loss: 0.019416813428203266\n",
      "SEED: 1303, FOLD: 1, EPOCH: 8, train_loss: 0.019304131495131962\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 8, valid_loss: 0.019418782865007717\n",
      "SEED: 1303, FOLD: 1, EPOCH: 9, train_loss: 0.019236264426423157\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 9, valid_loss: 0.019286112032002874\n",
      "SEED: 1303, FOLD: 1, EPOCH: 10, train_loss: 0.019161478818758675\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 10, valid_loss: 0.019347060057852004\n",
      "SEED: 1303, FOLD: 1, EPOCH: 11, train_loss: 0.019200357379040855\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01929037490238746\n",
      "SEED: 1303, FOLD: 1, EPOCH: 12, train_loss: 0.019123625118231426\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 12, valid_loss: 0.019304900844064023\n",
      "SEED: 1303, FOLD: 1, EPOCH: 13, train_loss: 0.019073220725724663\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 13, valid_loss: 0.019299337433444128\n",
      "SEED: 1303, FOLD: 1, EPOCH: 14, train_loss: 0.019028270374173702\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 14, valid_loss: 0.0192417088482115\n",
      "SEED: 1303, FOLD: 1, EPOCH: 15, train_loss: 0.01889892446174138\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 15, valid_loss: 0.019174688806136448\n",
      "SEED: 1303, FOLD: 1, EPOCH: 16, train_loss: 0.018820795514013455\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 16, valid_loss: 0.019093988773723442\n",
      "SEED: 1303, FOLD: 1, EPOCH: 17, train_loss: 0.018713269787638084\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 17, valid_loss: 0.019069999352925353\n",
      "SEED: 1303, FOLD: 1, EPOCH: 18, train_loss: 0.018544084378990574\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 18, valid_loss: 0.018937284851239786\n",
      "SEED: 1303, FOLD: 1, EPOCH: 19, train_loss: 0.018399487613983776\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01892352093838983\n",
      "SEED: 1303, FOLD: 1, EPOCH: 20, train_loss: 0.018180399755204933\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 20, valid_loss: 0.018823096735609904\n",
      "SEED: 1303, FOLD: 1, EPOCH: 21, train_loss: 0.018008547335647156\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 21, valid_loss: 0.018782868256999388\n",
      "SEED: 1303, FOLD: 1, EPOCH: 22, train_loss: 0.01783317724323791\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 22, valid_loss: 0.018732588013841048\n",
      "SEED: 1303, FOLD: 1, EPOCH: 23, train_loss: 0.017709610281863075\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 23, valid_loss: 0.018745827488601208\n",
      "SEED: 1303, FOLD: 1, EPOCH: 24, train_loss: 0.01765918256579966\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01874151753468646\n",
      "SEED: 1303, FOLD: 2, EPOCH: 0, train_loss: 0.7204062696816265\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6448690891265869\n",
      "SEED: 1303, FOLD: 2, EPOCH: 1, train_loss: 0.26496681268664374\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 1, valid_loss: 0.030775568034085963\n",
      "SEED: 1303, FOLD: 2, EPOCH: 2, train_loss: 0.024971349434792133\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 2, valid_loss: 0.02172690350562334\n",
      "SEED: 1303, FOLD: 2, EPOCH: 3, train_loss: 0.02120166288121887\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 3, valid_loss: 0.02031799519641532\n",
      "SEED: 1303, FOLD: 2, EPOCH: 4, train_loss: 0.02051986942904583\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 4, valid_loss: 0.019925645966496732\n",
      "SEED: 1303, FOLD: 2, EPOCH: 5, train_loss: 0.019951392694011978\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 5, valid_loss: 0.020045368725226984\n",
      "SEED: 1303, FOLD: 2, EPOCH: 6, train_loss: 0.019596866993368534\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01941633617712392\n",
      "SEED: 1303, FOLD: 2, EPOCH: 7, train_loss: 0.019413274294440296\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01940217376169231\n",
      "SEED: 1303, FOLD: 2, EPOCH: 8, train_loss: 0.019290111230119415\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 8, valid_loss: 0.019398793060746457\n",
      "SEED: 1303, FOLD: 2, EPOCH: 9, train_loss: 0.019246877454545185\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01932253036648035\n",
      "SEED: 1303, FOLD: 2, EPOCH: 10, train_loss: 0.019217198336685913\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 10, valid_loss: 0.019355032282571\n",
      "SEED: 1303, FOLD: 2, EPOCH: 11, train_loss: 0.01917038204661314\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 11, valid_loss: 0.019273472639421623\n",
      "SEED: 1303, FOLD: 2, EPOCH: 12, train_loss: 0.01916581637941409\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01932726169211997\n",
      "SEED: 1303, FOLD: 2, EPOCH: 13, train_loss: 0.01909814899166425\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 13, valid_loss: 0.019172268091804452\n",
      "SEED: 1303, FOLD: 2, EPOCH: 14, train_loss: 0.019031576569313587\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01913379246575965\n",
      "SEED: 1303, FOLD: 2, EPOCH: 15, train_loss: 0.018963778040547302\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 15, valid_loss: 0.019070939160883427\n",
      "SEED: 1303, FOLD: 2, EPOCH: 16, train_loss: 0.018894499599717667\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 16, valid_loss: 0.019020486002167065\n",
      "SEED: 1303, FOLD: 2, EPOCH: 17, train_loss: 0.018729461383992348\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 17, valid_loss: 0.018939709704783227\n",
      "SEED: 1303, FOLD: 2, EPOCH: 18, train_loss: 0.01860104773895464\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 18, valid_loss: 0.018861478194594383\n",
      "SEED: 1303, FOLD: 2, EPOCH: 19, train_loss: 0.01842286580822606\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01880103608386384\n",
      "SEED: 1303, FOLD: 2, EPOCH: 20, train_loss: 0.018251287413464077\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 20, valid_loss: 0.018749377690255642\n",
      "SEED: 1303, FOLD: 2, EPOCH: 21, train_loss: 0.018064368597191315\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01869966286338038\n",
      "SEED: 1303, FOLD: 2, EPOCH: 22, train_loss: 0.017911578569075336\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01865378415418996\n",
      "SEED: 1303, FOLD: 2, EPOCH: 23, train_loss: 0.017782918433996216\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01864784738669793\n",
      "SEED: 1303, FOLD: 2, EPOCH: 24, train_loss: 0.017726145306791084\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 24, valid_loss: 0.018647176420523062\n",
      "SEED: 1303, FOLD: 3, EPOCH: 0, train_loss: 0.7200348480888035\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6458891994423337\n",
      "SEED: 1303, FOLD: 3, EPOCH: 1, train_loss: 0.26110463972756826\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 1, valid_loss: 0.03107520265297757\n",
      "SEED: 1303, FOLD: 3, EPOCH: 2, train_loss: 0.024944534633254658\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 2, valid_loss: 0.02153631630871031\n",
      "SEED: 1303, FOLD: 3, EPOCH: 3, train_loss: 0.021185113063109093\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 3, valid_loss: 0.02005893261068397\n",
      "SEED: 1303, FOLD: 3, EPOCH: 4, train_loss: 0.020361559087599533\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 4, valid_loss: 0.019816731930606894\n",
      "SEED: 1303, FOLD: 3, EPOCH: 5, train_loss: 0.019957417136301166\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 5, valid_loss: 0.019454055465757847\n",
      "SEED: 1303, FOLD: 3, EPOCH: 6, train_loss: 0.019524042724051338\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 6, valid_loss: 0.019356750676201448\n",
      "SEED: 1303, FOLD: 3, EPOCH: 7, train_loss: 0.019334084610792175\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 7, valid_loss: 0.019301119674411085\n",
      "SEED: 1303, FOLD: 3, EPOCH: 8, train_loss: 0.019219504804282948\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 8, valid_loss: 0.019304988388386037\n",
      "SEED: 1303, FOLD: 3, EPOCH: 9, train_loss: 0.019205470501944637\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01935767785956462\n",
      "SEED: 1303, FOLD: 3, EPOCH: 10, train_loss: 0.01918905849258105\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 10, valid_loss: 0.019240490574803617\n",
      "SEED: 1303, FOLD: 3, EPOCH: 11, train_loss: 0.019148705122263535\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 11, valid_loss: 0.019374768456651106\n",
      "SEED: 1303, FOLD: 3, EPOCH: 12, train_loss: 0.019121589247083317\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 12, valid_loss: 0.019167811506324343\n",
      "SEED: 1303, FOLD: 3, EPOCH: 13, train_loss: 0.01908285934747993\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 13, valid_loss: 0.019099356399642095\n",
      "SEED: 1303, FOLD: 3, EPOCH: 14, train_loss: 0.01904259068702442\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 14, valid_loss: 0.019107986758980487\n",
      "SEED: 1303, FOLD: 3, EPOCH: 15, train_loss: 0.01893119657061238\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 15, valid_loss: 0.019040058677395184\n",
      "SEED: 1303, FOLD: 3, EPOCH: 16, train_loss: 0.01886952970770822\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 16, valid_loss: 0.018996532385547955\n",
      "SEED: 1303, FOLD: 3, EPOCH: 17, train_loss: 0.01872037812743498\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01890516457044416\n",
      "SEED: 1303, FOLD: 3, EPOCH: 18, train_loss: 0.01851466049750646\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 18, valid_loss: 0.018837966438796785\n",
      "SEED: 1303, FOLD: 3, EPOCH: 19, train_loss: 0.018358370451175648\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 19, valid_loss: 0.018794969241652224\n",
      "SEED: 1303, FOLD: 3, EPOCH: 20, train_loss: 0.018184704841047093\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 20, valid_loss: 0.018731556988010805\n",
      "SEED: 1303, FOLD: 3, EPOCH: 21, train_loss: 0.018009492182645245\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01868631990833415\n",
      "SEED: 1303, FOLD: 3, EPOCH: 22, train_loss: 0.017822363386875477\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 22, valid_loss: 0.0186593282657365\n",
      "SEED: 1303, FOLD: 3, EPOCH: 23, train_loss: 0.017709656443068947\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01864748355001211\n",
      "SEED: 1303, FOLD: 3, EPOCH: 24, train_loss: 0.017662952357120273\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 24, valid_loss: 0.018637226428836584\n",
      "SEED: 1303, FOLD: 4, EPOCH: 0, train_loss: 0.7204426380171292\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 0, valid_loss: 0.644672069284651\n",
      "SEED: 1303, FOLD: 4, EPOCH: 1, train_loss: 0.2633230069085308\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 1, valid_loss: 0.030519454843468137\n",
      "SEED: 1303, FOLD: 4, EPOCH: 2, train_loss: 0.024991556705124138\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 2, valid_loss: 0.02211153817673524\n",
      "SEED: 1303, FOLD: 4, EPOCH: 3, train_loss: 0.02120851698345032\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 3, valid_loss: 0.020670554600656033\n",
      "SEED: 1303, FOLD: 4, EPOCH: 4, train_loss: 0.02040087005150491\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 4, valid_loss: 0.020041298017733626\n",
      "SEED: 1303, FOLD: 4, EPOCH: 5, train_loss: 0.019926871915442356\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 5, valid_loss: 0.02006720058206055\n",
      "SEED: 1303, FOLD: 4, EPOCH: 6, train_loss: 0.01953926026497198\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01954754628241062\n",
      "SEED: 1303, FOLD: 4, EPOCH: 7, train_loss: 0.019421687835584515\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 7, valid_loss: 0.019502644944522116\n",
      "SEED: 1303, FOLD: 4, EPOCH: 8, train_loss: 0.019316586841275726\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 8, valid_loss: 0.019690228315691154\n",
      "SEED: 1303, FOLD: 4, EPOCH: 9, train_loss: 0.019195082556942234\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 9, valid_loss: 0.019559795243872538\n",
      "SEED: 1303, FOLD: 4, EPOCH: 10, train_loss: 0.019220355439229286\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01944781777759393\n",
      "SEED: 1303, FOLD: 4, EPOCH: 11, train_loss: 0.019122161133133846\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01934945945524507\n",
      "SEED: 1303, FOLD: 4, EPOCH: 12, train_loss: 0.019110301482504692\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 12, valid_loss: 0.01929648665504323\n",
      "SEED: 1303, FOLD: 4, EPOCH: 13, train_loss: 0.019043616329630215\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 13, valid_loss: 0.019301445947753057\n",
      "SEED: 1303, FOLD: 4, EPOCH: 14, train_loss: 0.0190208758349004\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01931851553834147\n",
      "SEED: 1303, FOLD: 4, EPOCH: 15, train_loss: 0.018940651303400165\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 15, valid_loss: 0.019255789721177682\n",
      "SEED: 1303, FOLD: 4, EPOCH: 16, train_loss: 0.018804286377153534\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 16, valid_loss: 0.019164493307471275\n",
      "SEED: 1303, FOLD: 4, EPOCH: 17, train_loss: 0.01868495839121549\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 17, valid_loss: 0.019060355714625783\n",
      "SEED: 1303, FOLD: 4, EPOCH: 18, train_loss: 0.018531246542714645\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 18, valid_loss: 0.018961567535168596\n",
      "SEED: 1303, FOLD: 4, EPOCH: 19, train_loss: 0.01839095197510028\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01891751266602013\n",
      "SEED: 1303, FOLD: 4, EPOCH: 20, train_loss: 0.01820341138628082\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01881098850733704\n",
      "SEED: 1303, FOLD: 4, EPOCH: 21, train_loss: 0.0180096500215755\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01874379523926311\n",
      "SEED: 1303, FOLD: 4, EPOCH: 22, train_loss: 0.017842278721323913\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 22, valid_loss: 0.018709214197264776\n",
      "SEED: 1303, FOLD: 4, EPOCH: 23, train_loss: 0.017725674381506615\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01870147997720374\n",
      "SEED: 1303, FOLD: 4, EPOCH: 24, train_loss: 0.017698229196062988\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01869559795078304\n",
      "elapsed time: 784.4708824157715\n"
     ]
    }
   ],
   "source": [
    "SEED = [940, 1513, 1269,1392,1119,1303]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "    print(f\"elapsed time: {time.time() - time_start}\")\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:15:10.434067Z",
     "iopub.status.busy": "2020-11-26T06:15:10.432856Z",
     "iopub.status.idle": "2020-11-26T06:15:11.048605Z",
     "shell.execute_reply": "2020-11-26T06:15:11.036104Z"
    },
    "papermill": {
     "duration": 1.896525,
     "end_time": "2020-11-26T06:15:11.048797",
     "exception": false,
     "start_time": "2020-11-26T06:15:09.152272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.to_pickle(f\"{INT_DIR}/{NB}-train-score-stack-pred.pkl\")\n",
    "test.to_pickle(f\"{INT_DIR}/{NB}-test-score-stack-pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:15:13.639130Z",
     "iopub.status.busy": "2020-11-26T06:15:13.637906Z",
     "iopub.status.idle": "2020-11-26T06:15:14.901819Z",
     "shell.execute_reply": "2020-11-26T06:15:14.900887Z"
    },
    "papermill": {
     "duration": 2.257493,
     "end_time": "2020-11-26T06:15:14.901943",
     "exception": false,
     "start_time": "2020-11-26T06:15:12.644450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.014311818899129448\n"
     ]
    }
   ],
   "source": [
    "train[target_cols] = np.maximum(PMIN, np.minimum(PMAX, train[target_cols]))\n",
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_true = y_true > 0.5\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "y_pred = np.minimum(SMAX, np.maximum(SMIN, y_pred))\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:15:17.085148Z",
     "iopub.status.busy": "2020-11-26T06:15:17.083691Z",
     "iopub.status.idle": "2020-11-26T06:15:19.335222Z",
     "shell.execute_reply": "2020-11-26T06:15:19.334277Z"
    },
    "papermill": {
     "duration": 3.451146,
     "end_time": "2020-11-26T06:15:19.335391",
     "exception": false,
     "start_time": "2020-11-26T06:15:15.884245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for c in test.columns:\n",
    "#     if c != \"sig_id\":\n",
    "#         test[c] = np.maximum(PMIN, np.minimum(PMAX, test[c]))\n",
    "\n",
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub.to_csv('submission_kibuna_nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:15:21.447491Z",
     "iopub.status.busy": "2020-11-26T06:15:21.444929Z",
     "iopub.status.idle": "2020-11-26T06:15:21.510280Z",
     "shell.execute_reply": "2020-11-26T06:15:21.511669Z"
    },
    "papermill": {
     "duration": 1.20979,
     "end_time": "2020-11-26T06:15:21.511971",
     "exception": false,
     "start_time": "2020-11-26T06:15:20.302181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>0.019790</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.005125</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>0.001596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.006207</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.015149</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.002056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.009565</td>\n",
       "      <td>0.018549</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.004051</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.004552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.016203</td>\n",
       "      <td>0.023527</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>0.002832</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.008787</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.232095</td>\n",
       "      <td>0.006727</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.001424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.011931</td>\n",
       "      <td>0.019176</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.006432</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.002394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>0.022226</td>\n",
       "      <td>0.007054</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.004727</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.001447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.020515</td>\n",
       "      <td>0.021964</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.008292</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.003523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.009751</td>\n",
       "      <td>0.019448</td>\n",
       "      <td>0.005443</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.001350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                     0.001229                0.001587   \n",
       "1     id_001897cda                     0.000459                0.001623   \n",
       "2     id_002429b5b                     0.000000                0.000000   \n",
       "3     id_00276f245                     0.001371                0.001614   \n",
       "4     id_0027f1083                     0.001542                0.001852   \n",
       "...            ...                          ...                     ...   \n",
       "3977  id_ff7004b87                     0.001295                0.001802   \n",
       "3978  id_ff925dd0d                     0.007792                0.002940   \n",
       "3979  id_ffb710450                     0.001687                0.001814   \n",
       "3980  id_ffbb869f2                     0.002892                0.001610   \n",
       "3981  id_ffd5800b6                     0.001154                0.001580   \n",
       "\n",
       "      acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0           0.002212                        0.011637   \n",
       "1           0.001309                        0.003625   \n",
       "2           0.000000                        0.000000   \n",
       "3           0.001500                        0.009565   \n",
       "4           0.002821                        0.016203   \n",
       "...              ...                             ...   \n",
       "3977        0.001788                        0.005092   \n",
       "3978        0.001483                        0.011931   \n",
       "3979        0.001956                        0.012075   \n",
       "3980        0.001380                        0.020515   \n",
       "3981        0.001936                        0.009751   \n",
       "\n",
       "      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                              0.019790                        0.004841   \n",
       "1                              0.001444                        0.001768   \n",
       "2                              0.000000                        0.000000   \n",
       "3                              0.018549                        0.005714   \n",
       "4                              0.023527                        0.004723   \n",
       "...                                 ...                             ...   \n",
       "3977                           0.008787                        0.003685   \n",
       "3978                           0.019176                        0.006195   \n",
       "3979                           0.022226                        0.007054   \n",
       "3980                           0.021964                        0.006312   \n",
       "3981                           0.019448                        0.005443   \n",
       "\n",
       "      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                       0.002894                       0.005125   \n",
       "1                       0.003833                       0.007138   \n",
       "2                       0.000000                       0.000000   \n",
       "3                       0.003507                       0.004230   \n",
       "4                       0.003847                       0.002988   \n",
       "...                          ...                            ...   \n",
       "3977                    0.002049                       0.003876   \n",
       "3978                    0.004788                       0.004155   \n",
       "3979                    0.003338                       0.004425   \n",
       "3980                    0.008292                       0.003225   \n",
       "3981                    0.002425                       0.004640   \n",
       "\n",
       "      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                       0.000671  ...                               0.000972   \n",
       "1                       0.003316  ...                               0.000744   \n",
       "2                       0.000000  ...                               0.000000   \n",
       "3                       0.000601  ...                               0.000741   \n",
       "4                       0.000666  ...                               0.001092   \n",
       "...                          ...  ...                                    ...   \n",
       "3977                    0.000822  ...                               0.000969   \n",
       "3978                    0.001043  ...                               0.001095   \n",
       "3979                    0.000723  ...                               0.000958   \n",
       "3980                    0.000773  ...                               0.000808   \n",
       "3981                    0.000666  ...                               0.000936   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.001236         0.002852           0.001953   \n",
       "1         0.000494         0.006207           0.000485   \n",
       "2         0.000000         0.000000           0.000000   \n",
       "3         0.001247         0.004051           0.005778   \n",
       "4         0.000919         0.004059           0.002832   \n",
       "...            ...              ...                ...   \n",
       "3977      0.004864         0.003405           0.232095   \n",
       "3978      0.001045         0.003679           0.003319   \n",
       "3979      0.001348         0.003200           0.004727   \n",
       "3980      0.000770         0.003498           0.002070   \n",
       "3981      0.001594         0.002647           0.005041   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.001773                               0.000963   \n",
       "1                      0.015149                               0.000456   \n",
       "2                      0.000000                               0.000000   \n",
       "3                      0.005729                               0.000969   \n",
       "4                      0.001974                               0.001008   \n",
       "...                         ...                                    ...   \n",
       "3977                   0.006727                               0.001556   \n",
       "3978                   0.003556                               0.001231   \n",
       "3979                   0.002361                               0.000917   \n",
       "3980                   0.001511                               0.000872   \n",
       "3981                   0.002329                               0.001035   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.001984   0.001903                    0.004005       0.001596  \n",
       "1            0.004326   0.000790                    0.001170       0.002056  \n",
       "2            0.000000   0.000000                    0.000000       0.000000  \n",
       "3            0.002270   0.002191                    0.000885       0.004552  \n",
       "4            0.001774   0.001788                    0.000818       0.001200  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977         0.004299   0.001536                    0.000915       0.001424  \n",
       "3978         0.006432   0.002863                    0.001017       0.002394  \n",
       "3979         0.002261   0.002237                    0.001003       0.001447  \n",
       "3980         0.002085   0.002186                    0.001107       0.003523  \n",
       "3981         0.002231   0.002141                    0.001134       0.001350  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.992223,
     "end_time": "2020-11-26T06:15:23.785992",
     "exception": false,
     "start_time": "2020-11-26T06:15:22.793769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.955568,
     "end_time": "2020-11-26T06:15:25.770268",
     "exception": false,
     "start_time": "2020-11-26T06:15:24.814700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.949747,
     "end_time": "2020-11-26T06:15:27.681528",
     "exception": false,
     "start_time": "2020-11-26T06:15:26.731781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.952765,
     "end_time": "2020-11-26T06:15:29.594300",
     "exception": false,
     "start_time": "2020-11-26T06:15:28.641535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 3351.245322,
   "end_time": "2020-11-26T06:15:31.060496",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-26T05:19:39.815174",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
