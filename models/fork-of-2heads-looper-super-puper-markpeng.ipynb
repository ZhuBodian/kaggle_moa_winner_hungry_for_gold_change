{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference:\n",
    "# https://www.kaggle.com/demetrypascal/fork-of-2heads-looper-super-puper-plate/notebook\n",
    "\n",
    "kernel_mode = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032594,
     "end_time": "2020-11-11T07:45:11.484416",
     "exception": false,
     "start_time": "2020-11-11T07:45:11.451822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032435,
     "end_time": "2020-11-11T07:45:11.549966",
     "exception": false,
     "start_time": "2020-11-11T07:45:11.517531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Letâ€™s load the packages and provide some constants for our script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:11.624887Z",
     "iopub.status.busy": "2020-11-11T07:45:11.623973Z",
     "iopub.status.idle": "2020-11-11T07:45:18.923587Z",
     "shell.execute_reply": "2020-11-11T07:45:18.922330Z"
    },
    "papermill": {
     "duration": 7.340999,
     "end_time": "2020-11-11T07:45:18.923723",
     "exception": false,
     "start_time": "2020-11-11T07:45:11.582724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras import layers, regularizers, Sequential, Model, backend, callbacks, optimizers, metrics, losses\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "sys.path.append('../input/iterative-stratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import pickle\n",
    "from pickle import dump, load\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:19.006735Z",
     "iopub.status.busy": "2020-11-11T07:45:19.004625Z",
     "iopub.status.idle": "2020-11-11T07:45:19.007534Z",
     "shell.execute_reply": "2020-11-11T07:45:19.008095Z"
    },
    "papermill": {
     "duration": 0.050102,
     "end_time": "2020-11-11T07:45:19.008235",
     "exception": false,
     "start_time": "2020-11-11T07:45:18.958133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = \"../input/lish-moa\" if kernel_mode else \"/workspace/Kaggle/MoA\"\n",
    "model_output_folder = \".\" if kernel_mode else f\"{PATH}/2heads-looper-super-puper\"\n",
    "os.makedirs(model_output_folder, exist_ok=True)\n",
    "\n",
    "# SEEDS = [23]\n",
    "SEEDS = [23, 228, 1488, 1998, 2208, 2077, 404]\n",
    "KFOLDS = 10\n",
    "\n",
    "label_smoothing_alpha = 0.0005\n",
    "\n",
    "P_MIN = label_smoothing_alpha\n",
    "P_MAX = 1 - P_MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:19.086097Z",
     "iopub.status.busy": "2020-11-11T07:45:19.084976Z",
     "iopub.status.idle": "2020-11-11T07:45:25.522055Z",
     "shell.execute_reply": "2020-11-11T07:45:25.518386Z"
    },
    "papermill": {
     "duration": 6.480782,
     "end_time": "2020-11-11T07:45:25.522253",
     "exception": false,
     "start_time": "2020-11-11T07:45:19.041471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import train data, drop sig_id, cp_type\n",
    "train_features = pd.read_csv(f'{PATH}/train_features.csv')\n",
    "\n",
    "non_ctl_idx = train_features.loc[\n",
    "    train_features['cp_type'] != 'ctl_vehicle'].index.to_list()\n",
    "\n",
    "# Drop training data with ctl vehicle\n",
    "tr = train_features.iloc[non_ctl_idx, :].reset_index(drop=True)\n",
    "\n",
    "test_features = pd.read_csv(f'{PATH}/test_features.csv')\n",
    "te = test_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets_scored = pd.read_csv(f'{PATH}/train_targets_scored.csv')\n",
    "Y = train_targets_scored.drop('sig_id', axis=1)\n",
    "Y = Y.iloc[non_ctl_idx, :].copy().reset_index(drop=True).values\n",
    "\n",
    "train_targets_nonscored = pd.read_csv(f'{PATH}/train_targets_nonscored.csv')\n",
    "Y0 = train_targets_nonscored.drop('sig_id', axis=1)\n",
    "Y0 = Y0.iloc[non_ctl_idx, :].copy().reset_index(drop=True).values\n",
    "\n",
    "sub = pd.read_csv(f'{PATH}/sample_submission.csv')\n",
    "sub.iloc[:, 1:] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03583,
     "end_time": "2020-11-11T07:45:28.303012",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.267182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Features from t.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036472,
     "end_time": "2020-11-11T07:45:28.375902",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.339430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here I am getting most important predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:28.455017Z",
     "iopub.status.busy": "2020-11-11T07:45:28.454184Z",
     "iopub.status.idle": "2020-11-11T07:45:28.461483Z",
     "shell.execute_reply": "2020-11-11T07:45:28.460844Z"
    },
    "papermill": {
     "duration": 0.049565,
     "end_time": "2020-11-11T07:45:28.461601",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.412036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import predictors from public kernel\n",
    "json_file_path = '../input/t-test-pca-rfe-logistic-regression/main_predictors.json' if kernel_mode \\\n",
    "    else \"/workspace/Kaggle/MoA/t-test-pca-rfe-logistic-regression/main_predictors.json\"\n",
    "\n",
    "with open(json_file_path, 'r') as j:\n",
    "    predictors = json.loads(j.read())\n",
    "    predictors = predictors['start_predictors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:28.573031Z",
     "iopub.status.busy": "2020-11-11T07:45:28.565161Z",
     "iopub.status.idle": "2020-11-11T07:45:28.576452Z",
     "shell.execute_reply": "2020-11-11T07:45:28.577030Z"
    },
    "papermill": {
     "duration": 0.0786,
     "end_time": "2020-11-11T07:45:28.577177",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.498577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21948, 447)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_Xtrain = tr[predictors].copy().values\n",
    "\n",
    "second_Xtest = te[predictors].copy().values\n",
    "second_Xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036297,
     "end_time": "2020-11-11T07:45:28.650577",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.614280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036666,
     "end_time": "2020-11-11T07:45:28.724069",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.687403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I got idea of **label smoothing** from this notebook: https://www.kaggle.com/kailex/moa-transfer-recipe-with-smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:28.804562Z",
     "iopub.status.busy": "2020-11-11T07:45:28.803696Z",
     "iopub.status.idle": "2020-11-11T07:45:28.808200Z",
     "shell.execute_reply": "2020-11-11T07:45:28.807569Z"
    },
    "papermill": {
     "duration": 0.047482,
     "end_time": "2020-11-11T07:45:28.808311",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.760829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def logloss(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred, P_MIN, P_MAX)\n",
    "    return -backend.mean(y_true * backend.log(y_pred) +\n",
    "                         (1 - y_true) * backend.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036797,
     "end_time": "2020-11-11T07:45:28.956193",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.919396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features = [c for c in train_features.columns if c != \"sig_id\"]\n",
    "gene_experssion_features = [c for c in numeric_features if c.startswith(\"g-\")]\n",
    "cell_viability_features = [c for c in numeric_features if c.startswith(\"c-\")]\n",
    "len(gene_experssion_features), len(cell_viability_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = tr.drop(['sig_id', 'cp_type', 'cp_time', 'cp_dose'], axis=1)\n",
    "te = test_features.drop(['sig_id', 'cp_type', 'cp_time', 'cp_dose'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:29.048267Z",
     "iopub.status.busy": "2020-11-11T07:45:29.046389Z",
     "iopub.status.idle": "2020-11-11T07:45:29.049041Z",
     "shell.execute_reply": "2020-11-11T07:45:29.049614Z"
    },
    "papermill": {
     "duration": 0.056399,
     "end_time": "2020-11-11T07:45:29.049751",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.993352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessor_1(train, valid, test, seed):\n",
    "    n_gs = 2\n",
    "    n_cs = 100\n",
    "\n",
    "    # g-mean, c-mean\n",
    "    train_g_mean = train[gene_experssion_features].mean(axis=1)\n",
    "    valid_g_mean = valid[gene_experssion_features].mean(axis=1)\n",
    "    test_g_mean = test[gene_experssion_features].mean(axis=1)\n",
    "\n",
    "    train_c_mean = train[cell_viability_features].mean(axis=1)\n",
    "    valid_c_mean = valid[cell_viability_features].mean(axis=1)\n",
    "    test_c_mean = test[cell_viability_features].mean(axis=1)\n",
    "\n",
    "    train_columns = train.columns.tolist()\n",
    "    test_columns = test.columns.tolist()\n",
    "\n",
    "    train = np.concatenate(\n",
    "        (train, train_g_mean[:, np.newaxis], train_c_mean[:, np.newaxis]),\n",
    "        axis=1)\n",
    "    valid = np.concatenate(\n",
    "        (valid, valid_g_mean[:, np.newaxis], valid_c_mean[:, np.newaxis]),\n",
    "        axis=1)\n",
    "    test = np.concatenate(\n",
    "        (test, test_g_mean[:, np.newaxis], test_c_mean[:, np.newaxis]), axis=1)\n",
    "\n",
    "    # Standard Scaler for Numerical Values\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    train = pd.DataFrame(data=scaler.fit_transform(train),\n",
    "                         columns=train_columns + [\"g_mean\", \"c_mean\"])\n",
    "    valid = pd.DataFrame(data=scaler.transform(valid),\n",
    "                         columns=train_columns + [\"g_mean\", \"c_mean\"])\n",
    "    test = pd.DataFrame(data=scaler.transform(test),\n",
    "                        columns=test_columns + [\"g_mean\", \"c_mean\"])\n",
    "\n",
    "    pca_gs = PCA(n_components=n_gs, random_state=seed)\n",
    "    train_pca_gs = pca_gs.fit_transform(train[gene_experssion_features].values)\n",
    "    valid_pca_gs = pca_gs.transform(valid[gene_experssion_features].values)\n",
    "    test_pca_gs = pca_gs.transform(test[gene_experssion_features].values)\n",
    "\n",
    "    pca_cs = PCA(n_components=n_cs, random_state=seed)\n",
    "    train_pca_cs = pca_cs.fit_transform(train[cell_viability_features].values)\n",
    "    valid_pca_cs = pca_cs.transform(valid[cell_viability_features].values)\n",
    "    test_pca_cs = pca_cs.transform(test[cell_viability_features].values)\n",
    "\n",
    "    # Append Features\n",
    "    train = np.concatenate((train, train_pca_gs, train_pca_cs), axis=1)\n",
    "    valid = np.concatenate((valid, valid_pca_gs, valid_pca_cs), axis=1)\n",
    "    test = np.concatenate((test, test_pca_gs, test_pca_cs), axis=1)\n",
    "\n",
    "    return train, valid, test, scaler, pca_gs, pca_cs\n",
    "\n",
    "\n",
    "def preprocessor_2(train, valid, test):\n",
    "    # Standard Scaler for Numerical Values\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    train = scaler.fit_transform(train)\n",
    "    valid = scaler.transform(valid)\n",
    "    test = scaler.transform(test)\n",
    "\n",
    "    return train, valid, test, scaler\n",
    "\n",
    "\n",
    "def save_pickle(obj, model_output_folder, name):\n",
    "    dump(obj, open(f\"{model_output_folder}/{name}.pkl\", 'wb'),\n",
    "         pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_pickle(model_output_folder, name):\n",
    "    return load(open(f\"{model_output_folder}/{name}.pkl\", 'rb'))\n",
    "\n",
    "\n",
    "def mean_logloss(y_pred, y_true):\n",
    "    logloss = (1 - y_true) * np.log(1 - y_pred +\n",
    "                                    1e-15) + y_true * np.log(y_pred + 1e-15)\n",
    "    return np.mean(-logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21948, 872), (3982, 872))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.shape, te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:30.295979Z",
     "iopub.status.busy": "2020-11-11T07:45:30.274930Z",
     "iopub.status.idle": "2020-11-11T08:45:30.221121Z",
     "shell.execute_reply": "2020-11-11T08:45:30.220025Z"
    },
    "papermill": {
     "duration": 3600.006513,
     "end_time": "2020-11-11T08:45:30.221259",
     "exception": false,
     "start_time": "2020-11-11T07:45:30.214746",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After non-scored training: validation_loss = 0.0063509270548820496\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "After scored training: validation_loss = 0.018065478652715683\n",
      "Before loop: validation_loss = 0.018065478652715683\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.018065478652715683 after 3 epochs \n",
      "\n",
      "Improved: 0.01804138906300068 from 0.018065478652715683\n",
      "Improved: 0.018026890233159065 from 0.01804138906300068\n",
      "Improved: 0.018016332760453224 from 0.018026890233159065\n",
      "Improved: 0.0180110614746809 from 0.018016332760453224\n",
      "Improved: 0.018007561564445496 from 0.0180110614746809\n",
      "Improved: 0.018004614859819412 from 0.018007561564445496\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.018004614859819412 after 6 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 6\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.018004614859819412 after 3 epochs \n",
      "\n",
      "Improved: 0.01800343580543995 from 0.018004614859819412\n",
      "Improved: 0.018002988770604134 from 0.01800343580543995\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.018002988770604134 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 2\n",
      "No Improvement, stopped\n",
      "3 loop ---> After Frozen-step best valid = 0.018002988770604134 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "3 loop ---> After Non-frozen-step best valid = 0.018002988770604134 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 0 score: 0.01632964032885722\n",
      "[[0.0008123  0.00058402 0.00228549 ... 0.00154254 0.00162531 0.00142975]\n",
      " [0.00059815 0.00099114 0.00128385 ... 0.00089363 0.00398045 0.00116435]\n",
      " [0.0004792  0.00048123 0.00185408 ... 0.00164205 0.00113764 0.00227184]\n",
      " [0.00064407 0.00108525 0.0016233  ... 0.00164496 0.00205458 0.0015665 ]\n",
      " [0.00128057 0.00147889 0.00162775 ... 0.00287425 0.000393   0.00182183]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.00616748770698905\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "After scored training: validation_loss = 0.018627187237143517\n",
      "Before loop: validation_loss = 0.018627187237143517\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.018627187237143517 after 3 epochs \n",
      "\n",
      "Improved: 0.018590372055768967 from 0.018627187237143517\n",
      "Improved: 0.018566995859146118 from 0.018590372055768967\n",
      "Improved: 0.018552159890532494 from 0.018566995859146118\n",
      "Improved: 0.018543696030974388 from 0.018552159890532494\n",
      "Improved: 0.018538227304816246 from 0.018543696030974388\n",
      "Improved: 0.018535783514380455 from 0.018538227304816246\n",
      "Improved: 0.018533911556005478 from 0.018535783514380455\n",
      "Improved: 0.018533162772655487 from 0.018533911556005478\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.018533162772655487 after 8 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 8\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.018533162772655487 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.018533162772655487 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 1 score: 0.01691227767408258\n",
      "[[0.0006849  0.00075827 0.0008936  ... 0.00143409 0.00319823 0.00190361]\n",
      " [0.00084317 0.00111237 0.00178729 ... 0.00116402 0.00535665 0.00720152]\n",
      " [0.00064396 0.00043785 0.00203258 ... 0.0016003  0.00068212 0.00287693]\n",
      " [0.00118077 0.00066706 0.00136761 ... 0.00336079 0.01204721 0.00314602]\n",
      " [0.00077731 0.00079914 0.00225061 ... 0.00174118 0.00137704 0.00065992]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.005936938337981701\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "After scored training: validation_loss = 0.018184049054980278\n",
      "Before loop: validation_loss = 0.018184049054980278\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.018184049054980278 after 3 epochs \n",
      "\n",
      "Improved: 0.018177300691604614 from 0.018184049054980278\n",
      "Improved: 0.01817440055310726 from 0.018177300691604614\n",
      "Improved: 0.018172945827245712 from 0.01817440055310726\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.018172945827245712 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 3\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.018172945827245712 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.018172945827245712 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 2 score: 0.016472260939687705\n",
      "[[2.8273676e-04 2.6214958e-04 1.0787002e-03 ... 3.4840300e-03\n",
      "  4.0186499e-03 1.0162654e-03]\n",
      " [1.8588318e-04 9.3975475e-05 1.2685891e-04 ... 3.9743035e-04\n",
      "  5.1228809e-03 2.2242025e-03]\n",
      " [5.1828398e-04 6.7625614e-04 3.6220502e-03 ... 5.3634006e-03\n",
      "  2.1054190e-04 5.6935442e-03]\n",
      " [1.3629813e-03 6.8414689e-04 3.7388410e-03 ... 2.2619835e-03\n",
      "  7.5668516e-04 6.2854718e-03]\n",
      " [1.8792150e-03 3.2427267e-03 5.4130908e-03 ... 3.3581262e-03\n",
      "  7.2206213e-04 2.5376894e-03]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.0064258999191224575\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "After scored training: validation_loss = 0.018204735592007637\n",
      "Before loop: validation_loss = 0.018204735592007637\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.018204735592007637 after 3 epochs \n",
      "\n",
      "Improved: 0.018197353929281235 from 0.018204735592007637\n",
      "Improved: 0.018194498494267464 from 0.018197353929281235\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.018194498494267464 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 2\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.018194498494267464 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.018194498494267464 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 3 score: 0.016518154850019912\n",
      "[[0.00026177 0.00029353 0.00318505 ... 0.00143648 0.00262198 0.00106482]\n",
      " [0.00017875 0.0003394  0.00043883 ... 0.00012302 0.00012936 0.00082869]\n",
      " [0.00109264 0.00083171 0.00169035 ... 0.00474279 0.00070752 0.00355481]\n",
      " [0.00271709 0.00068195 0.00084948 ... 0.00378453 0.00078147 0.0022499 ]\n",
      " [0.00181903 0.00394189 0.00413737 ... 0.00252287 0.00197342 0.0018325 ]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.005940946750342846\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "After scored training: validation_loss = 0.01893368549644947\n",
      "Before loop: validation_loss = 0.01893368549644947\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.01893368549644947 after 3 epochs \n",
      "\n",
      "Improved: 0.018920889124274254 from 0.01893368549644947\n",
      "Improved: 0.01891470141708851 from 0.018920889124274254\n",
      "Improved: 0.01891239732503891 from 0.01891470141708851\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.01891239732503891 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 3\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.01891239732503891 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.01891239732503891 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 4 score: 0.017270754245101105\n",
      "[[0.00022748 0.00079666 0.00257816 ... 0.00190312 0.00630079 0.00224034]\n",
      " [0.00045557 0.00165295 0.00157535 ... 0.00127574 0.00189796 0.00062741]\n",
      " [0.00049339 0.00045407 0.00090988 ... 0.0027231  0.00028505 0.00239008]\n",
      " [0.00079338 0.00061567 0.00094452 ... 0.00073694 0.00266924 0.00354704]\n",
      " [0.00069476 0.00296055 0.00232679 ... 0.00051934 0.00143987 0.00112201]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.005907036829739809\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "After scored training: validation_loss = 0.018421808257699013\n",
      "Before loop: validation_loss = 0.018421808257699013\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.018421808257699013 after 3 epochs \n",
      "\n",
      "Improved: 0.01840348355472088 from 0.018421808257699013\n",
      "Improved: 0.01839277893304825 from 0.01840348355472088\n",
      "Improved: 0.018388738855719566 from 0.01839277893304825\n",
      "Improved: 0.01838872581720352 from 0.018388738855719566\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.01838872581720352 after 4 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.01838872581720352 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.01838872581720352 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 5 score: 0.016703548910780634\n",
      "[[0.0007259  0.00046286 0.00091931 ... 0.00096548 0.0048996  0.00074796]\n",
      " [0.00030341 0.00236569 0.00122078 ... 0.00117699 0.00241267 0.01474033]\n",
      " [0.00065415 0.00035722 0.0022874  ... 0.00226548 0.00055242 0.00108833]\n",
      " [0.00121485 0.00257934 0.00237879 ... 0.0021229  0.0002904  0.00551382]\n",
      " [0.00071482 0.00061431 0.00058655 ... 0.00095223 0.00016148 0.00035941]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.00628742715343833\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "After scored training: validation_loss = 0.01772898994386196\n",
      "Before loop: validation_loss = 0.01772898994386196\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.01772898994386196 after 3 epochs \n",
      "\n",
      "Improved: 0.017721466720104218 from 0.01772898994386196\n",
      "Improved: 0.01771724782884121 from 0.017721466720104218\n",
      "Improved: 0.01771600916981697 from 0.01771724782884121\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.01771600916981697 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 3\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.01771600916981697 after 3 epochs \n",
      "\n",
      "Improved: 0.017715927213430405 from 0.01771600916981697\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.017715927213430405 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 1\n",
      "No Improvement, stopped\n",
      "3 loop ---> After Frozen-step best valid = 0.017715927213430405 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "3 loop ---> After Non-frozen-step best valid = 0.017715927213430405 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 6 score: 0.016100001288497496\n",
      "[[0.00217105 0.0026537  0.00092806 ... 0.00290052 0.00134452 0.00185882]\n",
      " [0.0011878  0.00074162 0.0028657  ... 0.00116817 0.0088936  0.00368389]\n",
      " [0.00245924 0.00128457 0.00644954 ... 0.0027467  0.0017138  0.00395653]\n",
      " [0.00146926 0.00078011 0.00330344 ... 0.00064398 0.00012312 0.00084188]\n",
      " [0.0029027  0.00062129 0.0013722  ... 0.00207337 0.00111448 0.00284183]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.006304688286036253\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "After scored training: validation_loss = 0.01824893057346344\n",
      "Before loop: validation_loss = 0.01824893057346344\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.01824893057346344 after 3 epochs \n",
      "\n",
      "Improved: 0.018236910924315453 from 0.01824893057346344\n",
      "Improved: 0.018228759989142418 from 0.018236910924315453\n",
      "Improved: 0.0182251688092947 from 0.018228759989142418\n",
      "Improved: 0.01822490617632866 from 0.0182251688092947\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.01822490617632866 after 4 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 4\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.01822490617632866 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.01822490617632866 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 7 score: 0.016599725592160764\n",
      "[[0.00145922 0.0004644  0.00088613 ... 0.00143321 0.00360372 0.00173679]\n",
      " [0.00092686 0.00031056 0.00268998 ... 0.00089498 0.03335764 0.0027104 ]\n",
      " [0.00040687 0.00014577 0.00090744 ... 0.00213985 0.00159561 0.00189279]\n",
      " [0.00101087 0.00078526 0.00143091 ... 0.00268526 0.00044494 0.0016627 ]\n",
      " [0.00116115 0.00063629 0.00337552 ... 0.00310243 0.00263242 0.00259268]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.00604100851342082\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "After scored training: validation_loss = 0.018358033150434494\n",
      "Before loop: validation_loss = 0.018358033150434494\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.018358033150434494 after 3 epochs \n",
      "\n",
      "Improved: 0.018327854573726654 from 0.018358033150434494\n",
      "Improved: 0.01830780878663063 from 0.018327854573726654\n",
      "Improved: 0.018296822905540466 from 0.01830780878663063\n",
      "Improved: 0.01828978769481182 from 0.018296822905540466\n",
      "Improved: 0.018285712227225304 from 0.01828978769481182\n",
      "Improved: 0.01828462816774845 from 0.018285712227225304\n",
      "Improved: 0.01828410103917122 from 0.01828462816774845\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.01828410103917122 after 7 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 7\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.01828410103917122 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.01828410103917122 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 8 score: 0.016604974222652998\n",
      "[[0.00020077 0.00068119 0.00114494 ... 0.00162868 0.00485193 0.00142383]\n",
      " [0.00031723 0.00027356 0.00450339 ... 0.0006639  0.0132664  0.00059436]\n",
      " [0.00063889 0.00089614 0.00268756 ... 0.00520939 0.00211386 0.00460385]\n",
      " [0.00160737 0.00154073 0.00425824 ... 0.00334313 0.00575237 0.00530189]\n",
      " [0.00209138 0.00217806 0.00356735 ... 0.00550353 0.00054893 0.00085091]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.006256408523768187\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "After scored training: validation_loss = 0.018437258899211884\n",
      "Before loop: validation_loss = 0.018437258899211884\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.018437258899211884 after 3 epochs \n",
      "\n",
      "Improved: 0.018428660929203033 from 0.018437258899211884\n",
      "Improved: 0.01842683181166649 from 0.018428660929203033\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.01842683181166649 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 2\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.01842683181166649 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.01842683181166649 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 9 score: 0.016758726734860178\n",
      "[[0.00117849 0.00204216 0.00172948 ... 0.0027206  0.00159762 0.00260771]\n",
      " [0.00045799 0.00053879 0.00123434 ... 0.00022342 0.0151411  0.00179703]\n",
      " [0.00150928 0.00131017 0.00470528 ... 0.00918034 0.0059196  0.00464543]\n",
      " [0.0006276  0.00142288 0.00347289 ... 0.00241881 0.0012927  0.00246758]\n",
      " [0.00467699 0.01134286 0.00214038 ... 0.00681472 0.00055963 0.00354869]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_predictions = np.zeros((tr.shape[0], Y.shape[1]))\n",
    "\n",
    "y_pred = np.zeros((te.shape[0], 206))\n",
    "for s in SEEDS:\n",
    "\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    tf.random.set_seed(s)\n",
    "\n",
    "    k = 0\n",
    "    kf = KFold(n_splits=KFOLDS, shuffle=True, random_state=s)\n",
    "    for train_index, valid_index in kf.split(tr):\n",
    "        file_name = f\"seed{s}_fold{k}\"\n",
    "\n",
    "        X_train_1, X_valid_1, X_test_1, scaler_1, pca_gs, pca_cs = preprocessor_1(\n",
    "            tr.iloc[train_index, :], tr.iloc[valid_index, :], te, s)\n",
    "        save_pickle(scaler_1, model_output_folder, f\"{file_name}_scaler_1\")\n",
    "        save_pickle(pca_gs, model_output_folder, f\"{file_name}_pca_gs\")\n",
    "        save_pickle(pca_cs, model_output_folder, f\"{file_name}_pca_cs\")\n",
    "\n",
    "        X_train_2, X_valid_2, X_test_2, scaler_2 = preprocessor_2(\n",
    "            second_Xtrain[train_index, :], second_Xtrain[valid_index, :],\n",
    "            second_Xtest)\n",
    "        save_pickle(scaler_2, model_output_folder, f\"{file_name}_scaler_2\")\n",
    "\n",
    "        y_train_1, y_valid_1 = Y[train_index, :], Y[valid_index, :]\n",
    "        y_train_2, y_valid_2 = Y0[train_index, :], Y0[valid_index, :]\n",
    "\n",
    "        n_features = X_train_1.shape[1]\n",
    "        n_features_2 = X_train_2.shape[1]\n",
    "\n",
    "        early_stopping = callbacks.EarlyStopping(min_delta=1e-5,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 patience=10,\n",
    "                                                 verbose=0,\n",
    "                                                 mode='min',\n",
    "                                                 restore_best_weights=True)\n",
    "        check_point = callbacks.ModelCheckpoint(\n",
    "            f\"{model_output_folder}/{file_name}_nonscore.h5\",\n",
    "            save_best_only=True,\n",
    "            verbose=0,\n",
    "            mode=\"min\")\n",
    "        reduce_lr = callbacks.ReduceLROnPlateau(factor=0.5,\n",
    "                                                patience=4,\n",
    "                                                verbose=0,\n",
    "                                                mode=\"auto\")\n",
    "\n",
    "        # Model Definition #\n",
    "\n",
    "        input1_ = layers.Input(shape=(n_features, ))\n",
    "        input2_ = layers.Input(shape=(n_features_2, ))\n",
    "\n",
    "        output1 = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(512, activation=\"elu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(256, activation=\"elu\")\n",
    "        ])(input1_)\n",
    "\n",
    "        answer1 = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(512, \"relu\")\n",
    "        ])(layers.Concatenate()([output1, input2_]))\n",
    "\n",
    "        answer2 = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(512, \"elu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(256, \"relu\")\n",
    "        ])(layers.Concatenate()([output1, input2_, answer1]))\n",
    "\n",
    "        answer3 = Sequential(\n",
    "            [layers.BatchNormalization(),\n",
    "             layers.Dense(256,\n",
    "                          \"elu\")])(layers.Concatenate()([answer1, answer2]))\n",
    "\n",
    "        answer3_ = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(256, \"relu\")\n",
    "        ])(layers.Concatenate()([answer1, answer2, answer3]))\n",
    "\n",
    "        answer4 = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(\n",
    "                256,\n",
    "                kernel_initializer=tf.keras.initializers.lecun_normal(seed=s),\n",
    "                activation='selu',\n",
    "                name='last_frozen'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(\n",
    "                206,\n",
    "                kernel_initializer=tf.keras.initializers.lecun_normal(seed=s),\n",
    "                activation='selu')\n",
    "        ])(layers.Concatenate()([output1, answer2, answer3, answer3_]))\n",
    "\n",
    "        # Non-scored Training #\n",
    "\n",
    "        answer5 = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(Y0.shape[1], \"sigmoid\")\n",
    "        ])(answer4)\n",
    "\n",
    "        m_nn = tf.keras.Model([input1_, input2_], answer5)\n",
    "\n",
    "        m_nn.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                     loss=losses.BinaryCrossentropy(\n",
    "                         label_smoothing=label_smoothing_alpha),\n",
    "                     metrics=logloss)\n",
    "\n",
    "        history = m_nn.fit([X_train_1, X_train_2],\n",
    "                           y_train_2,\n",
    "                           epochs=50,\n",
    "                           batch_size=128,\n",
    "                           validation_data=([X_valid_1, X_valid_2], y_valid_2),\n",
    "                           callbacks=[check_point, early_stopping, reduce_lr],\n",
    "                           verbose=0)\n",
    "        m_nn = tf.keras.models.load_model(\n",
    "            f\"{model_output_folder}/{file_name}_nonscore.h5\",\n",
    "            custom_objects={'logloss': logloss})\n",
    "\n",
    "        valid_metric_old = m_nn.evaluate([X_valid_1, X_valid_2],\n",
    "                                         y_valid_2,\n",
    "                                         verbose=0)[0]  # loss\n",
    "        print('After non-scored training: validation_loss =', valid_metric_old)\n",
    "\n",
    "        # Scored Training #\n",
    "\n",
    "        answer5 = Sequential(\n",
    "            [layers.BatchNormalization(),\n",
    "             layers.Dense(Y.shape[1], \"sigmoid\")])(answer4)\n",
    "\n",
    "        m_nn = tf.keras.Model([input1_, input2_], answer5)\n",
    "\n",
    "        m_nn.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                     loss=losses.BinaryCrossentropy(\n",
    "                         label_smoothing=label_smoothing_alpha),\n",
    "                     metrics=logloss)\n",
    "\n",
    "        early_stopping = callbacks.EarlyStopping(min_delta=1e-5,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 patience=10,\n",
    "                                                 verbose=1,\n",
    "                                                 mode='min',\n",
    "                                                 restore_best_weights=True)\n",
    "        check_point = callbacks.ModelCheckpoint(\n",
    "            f\"{model_output_folder}/{file_name}.h5\",\n",
    "            save_best_only=True,\n",
    "            verbose=0,\n",
    "            mode=\"min\")\n",
    "        reduce_lr = callbacks.ReduceLROnPlateau(factor=0.5,\n",
    "                                                patience=4,\n",
    "                                                verbose=0,\n",
    "                                                mode=\"auto\")\n",
    "\n",
    "        history = m_nn.fit([X_train_1, X_train_2],\n",
    "                           y_train_1,\n",
    "                           epochs=50,\n",
    "                           batch_size=128,\n",
    "                           validation_data=([X_valid_1, X_valid_2], y_valid_1),\n",
    "                           callbacks=[check_point, early_stopping, reduce_lr],\n",
    "                           verbose=0)\n",
    "        m_nn = tf.keras.models.load_model(\n",
    "            f\"{model_output_folder}/{file_name}.h5\",\n",
    "            custom_objects={'logloss': logloss})\n",
    "\n",
    "        # val_old = m_nn.predict([X_valid_1, X_valid_2])\n",
    "        # valid_metric_old = mean_logloss(val_old, y_valid_1)\n",
    "        valid_metric_old = m_nn.evaluate([X_valid_1, X_valid_2],\n",
    "                                         y_valid_1,\n",
    "                                         verbose=0)[0]  # loss\n",
    "        print('After scored training: validation_loss =', valid_metric_old)\n",
    "\n",
    "        m_nn.save(f'{model_output_folder}/tmp.h5')\n",
    "\n",
    "        print('Before loop: validation_loss =', valid_metric_old)\n",
    "\n",
    "        # big loop\n",
    "        loop = 1\n",
    "        while True:\n",
    "\n",
    "            # Freeze_weights(m_nn, to = 'last_frozen')\n",
    "            for i, layer in enumerate(m_nn.layers):\n",
    "                if layer.name == \"last_frozen\":\n",
    "                    layer.trainable = True\n",
    "                    break\n",
    "                else:\n",
    "                    layer.trainable = False\n",
    "\n",
    "            m_nn.compile(optimizer=tf.keras.optimizers.Adadelta(lr=0.001 / 3),\n",
    "                         loss=tf.losses.BinaryCrossentropy(\n",
    "                             label_smoothing=label_smoothing_alpha),\n",
    "                         metrics=logloss)\n",
    "\n",
    "            # Frozen Mode #\n",
    "\n",
    "            reps = 0\n",
    "            improved = 0\n",
    "            patience = 3\n",
    "            while True:\n",
    "                history = m_nn.fit([X_valid_1, X_valid_2],\n",
    "                                   y_valid_1,\n",
    "                                   epochs=1,\n",
    "                                   batch_size=128,\n",
    "                                   verbose=0)\n",
    "\n",
    "                # val_preds = m_nn.predict([X_valid_1, X_valid_2])\n",
    "                # valid_metric = mean_logloss(val_preds, y_valid_1)\n",
    "                valid_metric = m_nn.evaluate([X_valid_1, X_valid_2],\n",
    "                                             y_valid_1,\n",
    "                                             verbose=0)[0]\n",
    "\n",
    "                if valid_metric_old - valid_metric >= 1e-6:\n",
    "                    print('Improved:', valid_metric, 'from', valid_metric_old)\n",
    "                    reps += 1\n",
    "                    improved += 1\n",
    "                    valid_metric_old = valid_metric\n",
    "                    m_nn.save(f'{model_output_folder}/tmp.h5')\n",
    "                elif reps < patience:\n",
    "                    reps += 1\n",
    "                    pass\n",
    "                else:\n",
    "                    print('No Improvement, stopped')\n",
    "                    m_nn = tf.keras.models.load_model(\n",
    "                        f'{model_output_folder}/tmp.h5',\n",
    "                        custom_objects={'logloss': logloss})\n",
    "                    print(loop, 'loop ---> After Frozen-step best valid =',\n",
    "                          valid_metric_old, 'after', reps, 'epochs \\n')\n",
    "\n",
    "                    break\n",
    "\n",
    "            # Should continue training instead?\n",
    "            # if (improved == 0):  # no progress? STOP!\n",
    "            #     break\n",
    "\n",
    "            # Unfrozen Mode #\n",
    "\n",
    "            # Unfreeze all layers\n",
    "            for i, layer in enumerate(m_nn.layers):\n",
    "                layer.trainable = True\n",
    "\n",
    "            m_nn.compile(optimizer=tf.keras.optimizers.Adadelta(lr=0.001 / 5),\n",
    "                         loss=tf.losses.BinaryCrossentropy(\n",
    "                             label_smoothing=label_smoothing_alpha),\n",
    "                         metrics=logloss)\n",
    "\n",
    "            reps = 0\n",
    "            improved = 0\n",
    "            patience = 3\n",
    "            while True:\n",
    "                history = m_nn.fit([X_valid_1, X_valid_2],\n",
    "                                   y_valid_1,\n",
    "                                   epochs=1,\n",
    "                                   batch_size=128,\n",
    "                                   verbose=0)\n",
    "\n",
    "                # val_preds = m_nn.predict([X_valid_1, X_valid_2])\n",
    "                # valid_metric = mean_logloss(val_preds, y_valid_1)\n",
    "                valid_metric = m_nn.evaluate([X_valid_1, X_valid_2],\n",
    "                                             y_valid_1,\n",
    "                                             verbose=0)[0]\n",
    "\n",
    "                if valid_metric_old - valid_metric >= 1e-6:\n",
    "                    print('Improved:', valid_metric, 'from', valid_metric_old)\n",
    "                    reps += 1\n",
    "                    improved += 1\n",
    "                    valid_metric_old = valid_metric\n",
    "                    m_nn.save(f'{model_output_folder}/tmp.h5')\n",
    "                elif reps < patience:\n",
    "                    reps += 1\n",
    "                    pass\n",
    "                else:\n",
    "                    print('No Improvement, stopped')\n",
    "                    m_nn = tf.keras.models.load_model(\n",
    "                        f'{model_output_folder}/tmp.h5',\n",
    "                        custom_objects={'logloss': logloss})\n",
    "                    print(loop, 'loop ---> After Non-frozen-step best valid =',\n",
    "                          valid_metric_old, 'after', reps, 'epochs \\n')\n",
    "\n",
    "                    break\n",
    "\n",
    "            print(\"Total Non-frozen-step improved:\", improved)\n",
    "            if (improved == 0):\n",
    "                break\n",
    "\n",
    "            loop += 1\n",
    "\n",
    "        # Save Final Model\n",
    "        m_nn.save(f'{model_output_folder}/{file_name}_final.h5')\n",
    "\n",
    "        # OOF Predictions and Score #\n",
    "\n",
    "        val_preds = m_nn.predict([X_valid_1, X_valid_2])\n",
    "        fold_valid_score = mean_logloss(val_preds, y_valid_1)\n",
    "\n",
    "        oof_predictions[valid_index, :] += val_preds / len(SEEDS)\n",
    "        print('\\nSeed:', s, 'Fold:', k, 'score:', fold_valid_score)\n",
    "\n",
    "        # Generate Submission Prediction #\n",
    "        fold_submit_preds = m_nn.predict([X_test_1, X_test_2])\n",
    "        y_pred += fold_submit_preds / (KFOLDS * len(SEEDS))\n",
    "        print(fold_submit_preds[:5, :])\n",
    "\n",
    "        k += 1\n",
    "\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T08:46:27.991646Z",
     "iopub.status.busy": "2020-11-11T08:46:27.990901Z",
     "iopub.status.idle": "2020-11-11T08:46:28.000205Z",
     "shell.execute_reply": "2020-11-11T08:46:28.002353Z"
    },
    "papermill": {
     "duration": 14.092036,
     "end_time": "2020-11-11T08:46:28.002567",
     "exception": false,
     "start_time": "2020-11-11T08:46:13.910531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF Validation Loss: 0.016627\n"
     ]
    }
   ],
   "source": [
    "oof_loss = mean_logloss(oof_predictions, Y)\n",
    "print(f\"OOF Validation Loss: {oof_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 206)\n"
     ]
    }
   ],
   "source": [
    "with open(f'{model_output_folder}/oof_{oof_loss}.npy', 'wb') as f:\n",
    "    np.save(f, oof_predictions)\n",
    "\n",
    "with open(f'{model_output_folder}/oof_{oof_loss}.npy', 'rb') as f:\n",
    "    tmp = np.load(f)\n",
    "    print(tmp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 13.933663,
     "end_time": "2020-11-11T08:46:56.745720",
     "exception": false,
     "start_time": "2020-11-11T08:46:42.812057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T08:48:54.311631Z",
     "iopub.status.busy": "2020-11-11T08:48:54.310535Z",
     "iopub.status.idle": "2020-11-11T08:48:54.916705Z",
     "shell.execute_reply": "2020-11-11T08:48:54.916073Z"
    },
    "papermill": {
     "duration": 14.67484,
     "end_time": "2020-11-11T08:48:54.916824",
     "exception": false,
     "start_time": "2020-11-11T08:48:40.241984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.iloc[:, 1:] = y_pred\n",
    "# sub.iloc[:, 1:] = np.clip(y_pred, P_MIN, P_MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T08:49:24.916192Z",
     "iopub.status.busy": "2020-11-11T08:49:24.915133Z",
     "iopub.status.idle": "2020-11-11T08:49:24.955202Z",
     "shell.execute_reply": "2020-11-11T08:49:24.955799Z"
    },
    "papermill": {
     "duration": 14.848436,
     "end_time": "2020-11-11T08:49:24.955970",
     "exception": false,
     "start_time": "2020-11-11T08:49:10.107534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.010750</td>\n",
       "      <td>0.013554</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.009011</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.001603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.008476</td>\n",
       "      <td>0.027259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.008166</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.008956</td>\n",
       "      <td>0.003557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.019308</td>\n",
       "      <td>0.028073</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.003605</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.003297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.022331</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>0.003258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.023190</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.007312</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.001817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.007059</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.187986</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.001941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>0.031388</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.034434</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.018638</td>\n",
       "      <td>0.031592</td>\n",
       "      <td>0.005716</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.002242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0.008987</td>\n",
       "      <td>0.014330</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.001626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                     0.000800                0.000900   \n",
       "1     id_001897cda                     0.000545                0.000842   \n",
       "2     id_002429b5b                     0.000890                0.000687   \n",
       "3     id_00276f245                     0.001263                0.001084   \n",
       "4     id_0027f1083                     0.001800                0.002782   \n",
       "...            ...                          ...                     ...   \n",
       "3977  id_ff7004b87                     0.001328                0.001121   \n",
       "3978  id_ff925dd0d                     0.005291                0.005256   \n",
       "3979  id_ffb710450                     0.001538                0.000783   \n",
       "3980  id_ffbb869f2                     0.001700                0.001555   \n",
       "3981  id_ffd5800b6                     0.000828                0.000937   \n",
       "\n",
       "      acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0           0.001563                        0.010750   \n",
       "1           0.001773                        0.002029   \n",
       "2           0.002715                        0.019308   \n",
       "3           0.002337                        0.012640   \n",
       "4           0.002680                        0.009219   \n",
       "...              ...                             ...   \n",
       "3977        0.001210                        0.002892   \n",
       "3978        0.000734                        0.004724   \n",
       "3979        0.001085                        0.010156   \n",
       "3980        0.001386                        0.018638   \n",
       "3981        0.001872                        0.008987   \n",
       "\n",
       "      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                              0.013554                        0.004683   \n",
       "1                              0.001320                        0.001007   \n",
       "2                              0.028073                        0.002154   \n",
       "3                              0.005924                        0.005186   \n",
       "4                              0.023190                        0.004184   \n",
       "...                                 ...                             ...   \n",
       "3977                           0.003505                        0.002424   \n",
       "3978                           0.031388                        0.007436   \n",
       "3979                           0.034434                        0.006365   \n",
       "3980                           0.031592                        0.005716   \n",
       "3981                           0.014330                        0.004294   \n",
       "\n",
       "      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                       0.002604                       0.009011   \n",
       "1                       0.005260                       0.008476   \n",
       "2                       0.005411                       0.003151   \n",
       "3                       0.002243                       0.002578   \n",
       "4                       0.007312                       0.002337   \n",
       "...                          ...                            ...   \n",
       "3977                    0.001247                       0.003958   \n",
       "3978                    0.003471                       0.003694   \n",
       "3979                    0.003986                       0.003704   \n",
       "3980                    0.004542                       0.002255   \n",
       "3981                    0.003164                       0.008561   \n",
       "\n",
       "      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                       0.000581  ...                               0.001097   \n",
       "1                       0.027259  ...                               0.000715   \n",
       "2                       0.000895  ...                               0.001199   \n",
       "3                       0.000905  ...                               0.000765   \n",
       "4                       0.000827  ...                               0.001350   \n",
       "...                          ...  ...                                    ...   \n",
       "3977                    0.001410  ...                               0.000802   \n",
       "3978                    0.000671  ...                               0.000666   \n",
       "3979                    0.000456  ...                               0.000697   \n",
       "3980                    0.000713  ...                               0.000596   \n",
       "3981                    0.000433  ...                               0.000927   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.001546         0.003201           0.002629   \n",
       "1         0.001312         0.002860           0.000485   \n",
       "2         0.000926         0.003407           0.003467   \n",
       "3         0.001455         0.004415           0.022331   \n",
       "4         0.000934         0.005356           0.002665   \n",
       "...            ...              ...                ...   \n",
       "3977      0.007059         0.002322           0.187986   \n",
       "3978      0.001345         0.002383           0.003986   \n",
       "3979      0.000765         0.001911           0.002622   \n",
       "3980      0.000414         0.003927           0.001445   \n",
       "3981      0.001612         0.001663           0.003697   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.000531                               0.000783   \n",
       "1                      0.008166                               0.000799   \n",
       "2                      0.003605                               0.000776   \n",
       "3                      0.011840                               0.000955   \n",
       "4                      0.000973                               0.001137   \n",
       "...                         ...                                    ...   \n",
       "3977                   0.007531                               0.001321   \n",
       "3978                   0.001068                               0.001257   \n",
       "3979                   0.000843                               0.000563   \n",
       "3980                   0.000984                               0.000638   \n",
       "3981                   0.000822                               0.000782   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.002114   0.001945                    0.003406       0.001603  \n",
       "1            0.001529   0.000798                    0.008956       0.003557  \n",
       "2            0.001773   0.003761                    0.001492       0.003297  \n",
       "3            0.001901   0.002300                    0.002621       0.003258  \n",
       "4            0.002036   0.002946                    0.001092       0.001817  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977         0.004790   0.001488                    0.004269       0.001941  \n",
       "3978         0.002078   0.000965                    0.000620       0.000977  \n",
       "3979         0.001090   0.001217                    0.000999       0.001199  \n",
       "3980         0.001548   0.001275                    0.000646       0.002242  \n",
       "3981         0.001109   0.001707                    0.001038       0.001626  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T08:50:23.604717Z",
     "iopub.status.busy": "2020-11-11T08:50:23.601559Z",
     "iopub.status.idle": "2020-11-11T08:50:26.002857Z",
     "shell.execute_reply": "2020-11-11T08:50:26.001634Z"
    },
    "papermill": {
     "duration": 16.925683,
     "end_time": "2020-11-11T08:50:26.003039",
     "exception": false,
     "start_time": "2020-11-11T08:50:09.077356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set ctl_vehicle to 0\n",
    "sub.iloc[test_features['cp_type'] == 'ctl_vehicle', 1:] = 0\n",
    "\n",
    "# Save Submission\n",
    "sub.to_csv('submission_2heads-looper-super-puper.csv', index=False)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T08:50:54.604220Z",
     "iopub.status.busy": "2020-11-11T08:50:54.602918Z",
     "iopub.status.idle": "2020-11-11T08:50:54.644669Z",
     "shell.execute_reply": "2020-11-11T08:50:54.645356Z"
    },
    "papermill": {
     "duration": 14.756009,
     "end_time": "2020-11-11T08:50:54.645529",
     "exception": false,
     "start_time": "2020-11-11T08:50:39.889520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.010750</td>\n",
       "      <td>0.013554</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.009011</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.001603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.008476</td>\n",
       "      <td>0.027259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.008166</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.008956</td>\n",
       "      <td>0.003557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.022331</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>0.003258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.023190</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.007312</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.001817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.007059</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.187986</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.001941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>0.031388</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.034434</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.018638</td>\n",
       "      <td>0.031592</td>\n",
       "      <td>0.005716</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.002242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0.008987</td>\n",
       "      <td>0.014330</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.001626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                     0.000800                0.000900   \n",
       "1     id_001897cda                     0.000545                0.000842   \n",
       "2     id_002429b5b                     0.000000                0.000000   \n",
       "3     id_00276f245                     0.001263                0.001084   \n",
       "4     id_0027f1083                     0.001800                0.002782   \n",
       "...            ...                          ...                     ...   \n",
       "3977  id_ff7004b87                     0.001328                0.001121   \n",
       "3978  id_ff925dd0d                     0.005291                0.005256   \n",
       "3979  id_ffb710450                     0.001538                0.000783   \n",
       "3980  id_ffbb869f2                     0.001700                0.001555   \n",
       "3981  id_ffd5800b6                     0.000828                0.000937   \n",
       "\n",
       "      acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0           0.001563                        0.010750   \n",
       "1           0.001773                        0.002029   \n",
       "2           0.000000                        0.000000   \n",
       "3           0.002337                        0.012640   \n",
       "4           0.002680                        0.009219   \n",
       "...              ...                             ...   \n",
       "3977        0.001210                        0.002892   \n",
       "3978        0.000734                        0.004724   \n",
       "3979        0.001085                        0.010156   \n",
       "3980        0.001386                        0.018638   \n",
       "3981        0.001872                        0.008987   \n",
       "\n",
       "      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                              0.013554                        0.004683   \n",
       "1                              0.001320                        0.001007   \n",
       "2                              0.000000                        0.000000   \n",
       "3                              0.005924                        0.005186   \n",
       "4                              0.023190                        0.004184   \n",
       "...                                 ...                             ...   \n",
       "3977                           0.003505                        0.002424   \n",
       "3978                           0.031388                        0.007436   \n",
       "3979                           0.034434                        0.006365   \n",
       "3980                           0.031592                        0.005716   \n",
       "3981                           0.014330                        0.004294   \n",
       "\n",
       "      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                       0.002604                       0.009011   \n",
       "1                       0.005260                       0.008476   \n",
       "2                       0.000000                       0.000000   \n",
       "3                       0.002243                       0.002578   \n",
       "4                       0.007312                       0.002337   \n",
       "...                          ...                            ...   \n",
       "3977                    0.001247                       0.003958   \n",
       "3978                    0.003471                       0.003694   \n",
       "3979                    0.003986                       0.003704   \n",
       "3980                    0.004542                       0.002255   \n",
       "3981                    0.003164                       0.008561   \n",
       "\n",
       "      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                       0.000581  ...                               0.001097   \n",
       "1                       0.027259  ...                               0.000715   \n",
       "2                       0.000000  ...                               0.000000   \n",
       "3                       0.000905  ...                               0.000765   \n",
       "4                       0.000827  ...                               0.001350   \n",
       "...                          ...  ...                                    ...   \n",
       "3977                    0.001410  ...                               0.000802   \n",
       "3978                    0.000671  ...                               0.000666   \n",
       "3979                    0.000456  ...                               0.000697   \n",
       "3980                    0.000713  ...                               0.000596   \n",
       "3981                    0.000433  ...                               0.000927   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.001546         0.003201           0.002629   \n",
       "1         0.001312         0.002860           0.000485   \n",
       "2         0.000000         0.000000           0.000000   \n",
       "3         0.001455         0.004415           0.022331   \n",
       "4         0.000934         0.005356           0.002665   \n",
       "...            ...              ...                ...   \n",
       "3977      0.007059         0.002322           0.187986   \n",
       "3978      0.001345         0.002383           0.003986   \n",
       "3979      0.000765         0.001911           0.002622   \n",
       "3980      0.000414         0.003927           0.001445   \n",
       "3981      0.001612         0.001663           0.003697   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.000531                               0.000783   \n",
       "1                      0.008166                               0.000799   \n",
       "2                      0.000000                               0.000000   \n",
       "3                      0.011840                               0.000955   \n",
       "4                      0.000973                               0.001137   \n",
       "...                         ...                                    ...   \n",
       "3977                   0.007531                               0.001321   \n",
       "3978                   0.001068                               0.001257   \n",
       "3979                   0.000843                               0.000563   \n",
       "3980                   0.000984                               0.000638   \n",
       "3981                   0.000822                               0.000782   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.002114   0.001945                    0.003406       0.001603  \n",
       "1            0.001529   0.000798                    0.008956       0.003557  \n",
       "2            0.000000   0.000000                    0.000000       0.000000  \n",
       "3            0.001901   0.002300                    0.002621       0.003258  \n",
       "4            0.002036   0.002946                    0.001092       0.001817  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977         0.004790   0.001488                    0.004269       0.001941  \n",
       "3978         0.002078   0.000965                    0.000620       0.000977  \n",
       "3979         0.001090   0.001217                    0.000999       0.001199  \n",
       "3980         0.001548   0.001275                    0.000646       0.002242  \n",
       "3981         0.001109   0.001707                    0.001038       0.001626  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 3964.293061,
   "end_time": "2020-11-11T08:51:10.704042",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-11T07:45:06.410981",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
