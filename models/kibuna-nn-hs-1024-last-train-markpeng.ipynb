{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.067626,
     "end_time": "2020-11-26T05:19:44.582813",
     "exception": false,
     "start_time": "2020-11-26T05:19:44.515187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- a notebook to save preprocessing model and train/save NN models\n",
    "- all necessary ouputs are stored in MODEL_DIR = output/kaggle/working/model\n",
    "    - put those into dataset, and load it from inference notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_mode = False\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:19:44.738720Z",
     "iopub.status.busy": "2020-11-26T05:19:44.737831Z",
     "iopub.status.idle": "2020-11-26T05:19:51.950919Z",
     "shell.execute_reply": "2020-11-26T05:19:51.950264Z"
    },
    "papermill": {
     "duration": 7.302337,
     "end_time": "2020-11-26T05:19:51.951067",
     "exception": false,
     "start_time": "2020-11-26T05:19:44.648730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘model’: File exists\n",
      "mkdir: cannot create directory ‘interim’: File exists\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if kernel_mode:\n",
    "    sys.path.append(\n",
    "        '../input/iterative-stratification/iterative-stratification-master')\n",
    "    sys.path.append('../input/umaplearn/umap')\n",
    "\n",
    "%mkdir model\n",
    "%mkdir interim\n",
    "\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from umap import UMAP\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "print(torch.cuda.is_available())\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:19:52.101444Z",
     "iopub.status.busy": "2020-11-26T05:19:52.100472Z",
     "iopub.status.idle": "2020-11-26T05:19:52.104231Z",
     "shell.execute_reply": "2020-11-26T05:19:52.104811Z"
    },
    "papermill": {
     "duration": 0.086709,
     "end_time": "2020-11-26T05:19:52.104956",
     "exception": false,
     "start_time": "2020-11-26T05:19:52.018247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0+cu101'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"../input/lish-moa\" if kernel_mode else \"/workspace/Kaggle/MoA\"\n",
    "model_output_folder = \"../input/kibuna-nn-hs-1024-last-train-markpeng\" if kernel_mode \\\n",
    "    else f\"{dataset_folder}/kibuna-nn-hs-1024-last-train-markpeng\"\n",
    "BATCH_SIZE = 256\n",
    "INFER_BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:19:52.251927Z",
     "iopub.status.busy": "2020-11-26T05:19:52.250122Z",
     "iopub.status.idle": "2020-11-26T05:19:52.252715Z",
     "shell.execute_reply": "2020-11-26T05:19:52.253450Z"
    },
    "papermill": {
     "duration": 0.080754,
     "end_time": "2020-11-26T05:19:52.253626",
     "exception": false,
     "start_time": "2020-11-26T05:19:52.172872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NB = '25'\n",
    "\n",
    "IS_TRAIN = True\n",
    "MODEL_DIR = f\"{model_output_folder}/model\"\n",
    "INT_DIR = f\"{model_output_folder}/interim\"\n",
    "\n",
    "if IS_TRAIN:\n",
    "    os.makedirs(model_output_folder, exist_ok=True)\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    os.makedirs(INT_DIR, exist_ok=True)\n",
    "\n",
    "NSEEDS = 5  # 5\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 5e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "NFOLDS = 5  # 5\n",
    "\n",
    "PMIN = 0.0005\n",
    "PMAX = 0.9995\n",
    "SMIN = 0.0\n",
    "SMAX = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:19:52.407694Z",
     "iopub.status.busy": "2020-11-26T05:19:52.406698Z",
     "iopub.status.idle": "2020-11-26T05:19:59.744804Z",
     "shell.execute_reply": "2020-11-26T05:19:59.745992Z"
    },
    "papermill": {
     "duration": 7.421184,
     "end_time": "2020-11-26T05:19:59.746193",
     "exception": false,
     "start_time": "2020-11-26T05:19:52.325009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(f'{dataset_folder}/train_features.csv')\n",
    "train_targets_scored = pd.read_csv(f'{dataset_folder}/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv(f'{dataset_folder}/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv(f'{dataset_folder}/test_features.csv')\n",
    "sample_submission = pd.read_csv(f'{dataset_folder}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:19:59.938437Z",
     "iopub.status.busy": "2020-11-26T05:19:59.937312Z",
     "iopub.status.idle": "2020-11-26T05:20:00.170944Z",
     "shell.execute_reply": "2020-11-26T05:20:00.170023Z"
    },
    "papermill": {
     "duration": 0.323437,
     "end_time": "2020-11-26T05:20:00.171132",
     "exception": false,
     "start_time": "2020-11-26T05:19:59.847695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 332)\n"
     ]
    }
   ],
   "source": [
    "train_targets_nonscored = train_targets_nonscored.loc[:, train_targets_nonscored.sum() != 0]\n",
    "print(train_targets_nonscored.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:20:00.324626Z",
     "iopub.status.busy": "2020-11-26T05:20:00.323031Z",
     "iopub.status.idle": "2020-11-26T05:20:03.381176Z",
     "shell.execute_reply": "2020-11-26T05:20:03.380576Z"
    },
    "papermill": {
     "duration": 3.138803,
     "end_time": "2020-11-26T05:20:03.381302",
     "exception": false,
     "start_time": "2020-11-26T05:20:00.242499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for c in train_targets_scored.columns:\n",
    "#     if c != \"sig_id\":\n",
    "#         train_targets_scored[c] = np.maximum(PMIN, np.minimum(PMAX, train_targets_scored[c]))\n",
    "for c in train_targets_nonscored.columns:\n",
    "    if c != \"sig_id\":\n",
    "        train_targets_nonscored[c] = np.maximum(\n",
    "            PMIN, np.minimum(PMAX, train_targets_nonscored[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:20:03.525039Z",
     "iopub.status.busy": "2020-11-26T05:20:03.524000Z",
     "iopub.status.idle": "2020-11-26T05:20:03.529649Z",
     "shell.execute_reply": "2020-11-26T05:20:03.530565Z"
    },
    "papermill": {
     "duration": 0.08113,
     "end_time": "2020-11-26T05:20:03.530748",
     "exception": false,
     "start_time": "2020-11-26T05:20:03.449618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(nsamples, nfeatures)\n",
      "(23814, 876)\n",
      "(23814, 207)\n",
      "(23814, 332)\n",
      "(3982, 876)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(\"(nsamples, nfeatures)\")\n",
    "print(train_features.shape)\n",
    "print(train_targets_scored.shape)\n",
    "print(train_targets_nonscored.shape)\n",
    "print(test_features.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:20:03.693208Z",
     "iopub.status.busy": "2020-11-26T05:20:03.691544Z",
     "iopub.status.idle": "2020-11-26T05:20:03.693990Z",
     "shell.execute_reply": "2020-11-26T05:20:03.694557Z"
    },
    "papermill": {
     "duration": 0.095073,
     "end_time": "2020-11-26T05:20:03.694695",
     "exception": false,
     "start_time": "2020-11-26T05:20:03.599622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:20:03.842346Z",
     "iopub.status.busy": "2020-11-26T05:20:03.841456Z",
     "iopub.status.idle": "2020-11-26T05:20:03.848296Z",
     "shell.execute_reply": "2020-11-26T05:20:03.847675Z"
    },
    "papermill": {
     "duration": 0.084307,
     "end_time": "2020-11-26T05:20:03.848444",
     "exception": false,
     "start_time": "2020-11-26T05:20:03.764137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(seed=1903)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.068841,
     "end_time": "2020-11-26T05:20:03.986247",
     "exception": false,
     "start_time": "2020-11-26T05:20:03.917406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:20:04.156515Z",
     "iopub.status.busy": "2020-11-26T05:20:04.149606Z",
     "iopub.status.idle": "2020-11-26T05:25:57.500817Z",
     "shell.execute_reply": "2020-11-26T05:25:57.500054Z"
    },
    "papermill": {
     "duration": 353.445244,
     "end_time": "2020-11-26T05:25:57.500960",
     "exception": false,
     "start_time": "2020-11-26T05:20:04.055716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GENES\n",
    "n_comp = 90\n",
    "n_dim = 45\n",
    "\n",
    "data = pd.concat(\n",
    "    [pd.DataFrame(train_features[GENES]),\n",
    "     pd.DataFrame(test_features[GENES])])\n",
    "\n",
    "if IS_TRAIN:\n",
    "    fa = FactorAnalysis(n_components=n_comp,\n",
    "                        random_state=1903).fit(data[GENES])\n",
    "    pd.to_pickle(fa, f'{MODEL_DIR}/{NB}_factor_analysis_g.pkl')\n",
    "    umap = UMAP(n_components=n_dim, random_state=1903).fit(data[GENES])\n",
    "    pd.to_pickle(umap, f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "else:\n",
    "    fa = pd.read_pickle(f'{MODEL_DIR}/{NB}_factor_analysis_g.pkl')\n",
    "    umap = pd.read_pickle(f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "\n",
    "data2 = (fa.transform(data[GENES]))\n",
    "data3 = (umap.transform(data[GENES]))\n",
    "\n",
    "train2 = data2[:train_features.shape[0]]\n",
    "test2 = data2[-test_features.shape[0]:]\n",
    "train3 = data3[:train_features.shape[0]]\n",
    "test3 = data3[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'fa_G-{i}' for i in range(n_comp)])\n",
    "train3 = pd.DataFrame(train3, columns=[f'umap_G-{i}' for i in range(n_dim)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'fa_G-{i}' for i in range(n_comp)])\n",
    "test3 = pd.DataFrame(test3, columns=[f'umap_G-{i}' for i in range(n_dim)])\n",
    "\n",
    "train_features = pd.concat((train_features, train2, train3), axis=1)\n",
    "test_features = pd.concat((test_features, test2, test3), axis=1)\n",
    "\n",
    "#CELLS\n",
    "n_comp = 50\n",
    "n_dim = 25\n",
    "\n",
    "data = pd.concat(\n",
    "    [pd.DataFrame(train_features[CELLS]),\n",
    "     pd.DataFrame(test_features[CELLS])])\n",
    "\n",
    "if IS_TRAIN:\n",
    "    fa = FactorAnalysis(n_components=n_comp,\n",
    "                        random_state=1903).fit(data[CELLS])\n",
    "    pd.to_pickle(fa, f'{MODEL_DIR}/{NB}_factor_analysis_c.pkl')\n",
    "    umap = UMAP(n_components=n_dim, random_state=1903).fit(data[CELLS])\n",
    "    pd.to_pickle(umap, f'{MODEL_DIR}/{NB}_umap_c.pkl')\n",
    "else:\n",
    "    fa = pd.read_pickle(f'{MODEL_DIR}/{NB}_factor_analysis_c.pkl')\n",
    "    umap = pd.read_pickle(f'{MODEL_DIR}/{NB}_umap_c.pkl')\n",
    "\n",
    "data2 = (fa.transform(data[CELLS]))\n",
    "data3 = (umap.fit_transform(data[CELLS]))\n",
    "\n",
    "train2 = data2[:train_features.shape[0]]\n",
    "test2 = data2[-test_features.shape[0]:]\n",
    "train3 = data3[:train_features.shape[0]]\n",
    "test3 = data3[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'fa_C-{i}' for i in range(n_comp)])\n",
    "train3 = pd.DataFrame(train3, columns=[f'umap_C-{i}' for i in range(n_dim)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'fa_C-{i}' for i in range(n_comp)])\n",
    "test3 = pd.DataFrame(test3, columns=[f'umap_C-{i}' for i in range(n_dim)])\n",
    "\n",
    "train_features = pd.concat((train_features, train2, train3), axis=1)\n",
    "test_features = pd.concat((test_features, test2, test3), axis=1)\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.069099,
     "end_time": "2020-11-26T05:25:57.639838",
     "exception": false,
     "start_time": "2020-11-26T05:25:57.570739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:25:57.794066Z",
     "iopub.status.busy": "2020-11-26T05:25:57.792303Z",
     "iopub.status.idle": "2020-11-26T05:28:04.035606Z",
     "shell.execute_reply": "2020-11-26T05:28:04.034723Z"
    },
    "papermill": {
     "duration": 126.326427,
     "end_time": "2020-11-26T05:28:04.035817",
     "exception": false,
     "start_time": "2020-11-26T05:25:57.709390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "for col in (GENES + CELLS):\n",
    "    vec_len = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    raw_vec = pd.concat([train_features, test_features\n",
    "                         ])[col].values.reshape(vec_len + vec_len_test, 1)\n",
    "    if IS_TRAIN:\n",
    "        transformer = QuantileTransformer(n_quantiles=100,\n",
    "                                          random_state=123,\n",
    "                                          output_distribution=\"normal\")\n",
    "        transformer.fit(raw_vec)\n",
    "        pd.to_pickle(transformer,\n",
    "                     f'{MODEL_DIR}/{NB}_{col}_quantile_transformer.pkl')\n",
    "    else:\n",
    "        transformer = pd.read_pickle(\n",
    "            f'{MODEL_DIR}/{NB}_{col}_quantile_transformer.pkl')\n",
    "\n",
    "    train_features[col] = transformer.transform(\n",
    "        train_features[col].values.reshape(vec_len, 1)).reshape(1, vec_len)[0]\n",
    "    test_features[col] = transformer.transform(\n",
    "        test_features[col].values.reshape(vec_len_test,\n",
    "                                          1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:04.258054Z",
     "iopub.status.busy": "2020-11-26T05:28:04.255783Z",
     "iopub.status.idle": "2020-11-26T05:28:04.258942Z",
     "shell.execute_reply": "2020-11-26T05:28:04.259587Z"
    },
    "papermill": {
     "duration": 0.097692,
     "end_time": "2020-11-26T05:28:04.259739",
     "exception": false,
     "start_time": "2020-11-26T05:28:04.162047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PCAS = [col for col in train_features.columns if col.startswith('pca_')]\n",
    "# UMAPS = [col for col in train_features.columns if col.startswith('umap_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:04.414926Z",
     "iopub.status.busy": "2020-11-26T05:28:04.413073Z",
     "iopub.status.idle": "2020-11-26T05:28:04.416399Z",
     "shell.execute_reply": "2020-11-26T05:28:04.415725Z"
    },
    "papermill": {
     "duration": 0.083039,
     "end_time": "2020-11-26T05:28:04.416541",
     "exception": false,
     "start_time": "2020-11-26T05:28:04.333502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# n_deg = 2\n",
    "\n",
    "# data = pd.concat([pd.DataFrame(train_features[PCAS]), pd.DataFrame(test_features[PCAS])])\n",
    "# data2 = (PolynomialFeatures(degree=n_deg, include_bias=False).fit_transform(data[PCAS]))\n",
    "\n",
    "# # print(data2)\n",
    "# # data4 = (UMAP(n_components=n_dim, n_neighbors=5, random_state=1903).fit_transform(data[GENES]))\n",
    "# # data5 = (UMAP(n_components=n_dim, min_dist=0.01, random_state=1903).fit_transform(data[GENES]))\n",
    "\n",
    "# train2 = data2[:train_features.shape[0]]\n",
    "# test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "# # print(train2.shape)\n",
    "# train2 = pd.DataFrame(train2, columns=[f'poly_C-{i}' for i in range(train2.shape[1])])\n",
    "# test2 = pd.DataFrame(test2, columns=[f'poly_C-{i}' for i in range(train2.shape[1])])\n",
    "\n",
    "# # drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "# # train_features = pd.concat((train_features, train2, train3, train4, train5), axis=1)\n",
    "# # test_features = pd.concat((test_features, test2, test3, test4, test5), axis=1)\n",
    "# train_features = pd.concat((train_features, train2), axis=1)\n",
    "# test_features = pd.concat((test_features, test2), axis=1)\n",
    "\n",
    "\n",
    "# data = pd.concat([pd.DataFrame(train_features[UMAPS]), pd.DataFrame(test_features[UMAPS])])\n",
    "# data2 = (PolynomialFeatures(degree=n_deg, include_bias=False).fit_transform(data[UMAPS]))\n",
    "\n",
    "# # print(data2)\n",
    "# # data4 = (UMAP(n_components=n_dim, n_neighbors=5, random_state=1903).fit_transform(data[GENES]))\n",
    "# # data5 = (UMAP(n_components=n_dim, min_dist=0.01, random_state=1903).fit_transform(data[GENES]))\n",
    "\n",
    "# train2 = data2[:train_features.shape[0]]\n",
    "# test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "# # print(train2.shape)\n",
    "# train2 = pd.DataFrame(train2, columns=[f'poly_C-{i}' for i in range(train2.shape[1])])\n",
    "# test2 = pd.DataFrame(test2, columns=[f'poly_C-{i}' for i in range(train2.shape[1])])\n",
    "\n",
    "# # drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "# # train_features = pd.concat((train_features, train2, train3, train4, train5), axis=1)\n",
    "# # test_features = pd.concat((test_features, test2, test3, test4, test5), axis=1)\n",
    "# train_features = pd.concat((train_features, train2), axis=1)\n",
    "# test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:04.567693Z",
     "iopub.status.busy": "2020-11-26T05:28:04.566780Z",
     "iopub.status.idle": "2020-11-26T05:28:04.572411Z",
     "shell.execute_reply": "2020-11-26T05:28:04.573173Z"
    },
    "papermill": {
     "duration": 0.08439,
     "end_time": "2020-11-26T05:28:04.573375",
     "exception": false,
     "start_time": "2020-11-26T05:28:04.488985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 1086)\n",
      "(3982, 1086)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.074064,
     "end_time": "2020-11-26T05:28:04.721137",
     "exception": false,
     "start_time": "2020-11-26T05:28:04.647073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:04.877100Z",
     "iopub.status.busy": "2020-11-26T05:28:04.876180Z",
     "iopub.status.idle": "2020-11-26T05:28:05.570681Z",
     "shell.execute_reply": "2020-11-26T05:28:05.569763Z"
    },
    "papermill": {
     "duration": 0.775547,
     "end_time": "2020-11-26T05:28:05.570816",
     "exception": false,
     "start_time": "2020-11-26T05:28:04.795269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train_features.merge(train_targets_nonscored, on='sig_id')\n",
    "train = train[train['cp_type'] != 'ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type'] != 'ctl_vehicle'].reset_index(\n",
    "    drop=True)\n",
    "\n",
    "# target = train[train_targets_scored.columns]\n",
    "target = train[train_targets_nonscored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:05.803722Z",
     "iopub.status.busy": "2020-11-26T05:28:05.801418Z",
     "iopub.status.idle": "2020-11-26T05:28:05.812425Z",
     "shell.execute_reply": "2020-11-26T05:28:05.811744Z"
    },
    "papermill": {
     "duration": 0.168252,
     "end_time": "2020-11-26T05:28:05.812611",
     "exception": false,
     "start_time": "2020-11-26T05:28:05.644359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:05.970687Z",
     "iopub.status.busy": "2020-11-26T05:28:05.969358Z",
     "iopub.status.idle": "2020-11-26T05:28:05.973575Z",
     "shell.execute_reply": "2020-11-26T05:28:05.971394Z"
    },
    "papermill": {
     "duration": 0.087631,
     "end_time": "2020-11-26T05:28:05.973759",
     "exception": false,
     "start_time": "2020-11-26T05:28:05.886128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 332)\n",
      "(23814, 1086)\n",
      "(3982, 1086)\n",
      "(21948, 1416)\n",
      "(3624, 1085)\n"
     ]
    }
   ],
   "source": [
    "print(target.shape)\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:06.147024Z",
     "iopub.status.busy": "2020-11-26T05:28:06.145261Z",
     "iopub.status.idle": "2020-11-26T05:28:06.155218Z",
     "shell.execute_reply": "2020-11-26T05:28:06.156257Z"
    },
    "papermill": {
     "duration": 0.107011,
     "end_time": "2020-11-26T05:28:06.156496",
     "exception": false,
     "start_time": "2020-11-26T05:28:06.049485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:06.333485Z",
     "iopub.status.busy": "2020-11-26T05:28:06.331832Z",
     "iopub.status.idle": "2020-11-26T05:28:09.268803Z",
     "shell.execute_reply": "2020-11-26T05:28:09.269468Z"
    },
    "papermill": {
     "duration": 3.030392,
     "end_time": "2020-11-26T05:28:09.269668",
     "exception": false,
     "start_time": "2020-11-26T05:28:06.239276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=False, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>...</th>\n",
       "      <th>vasopressin_receptor_antagonist</th>\n",
       "      <th>ve-cadherin_antagonist</th>\n",
       "      <th>vesicular_monoamine_transporter_inhibitor</th>\n",
       "      <th>vitamin_k_antagonist</th>\n",
       "      <th>voltage-gated_potassium_channel_activator</th>\n",
       "      <th>voltage-gated_sodium_channel_blocker</th>\n",
       "      <th>wdr5_mll_interaction_inhibitor</th>\n",
       "      <th>xanthine_oxidase_inhibitor</th>\n",
       "      <th>xiap_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.146806</td>\n",
       "      <td>0.902075</td>\n",
       "      <td>-0.418339</td>\n",
       "      <td>-0.961202</td>\n",
       "      <td>-0.254770</td>\n",
       "      <td>-1.021300</td>\n",
       "      <td>-1.369236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.128824</td>\n",
       "      <td>0.676862</td>\n",
       "      <td>0.274345</td>\n",
       "      <td>0.090495</td>\n",
       "      <td>1.208863</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>0.316734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.790372</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>1.428097</td>\n",
       "      <td>-0.121817</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>1.495091</td>\n",
       "      <td>0.238763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.729866</td>\n",
       "      <td>-0.277163</td>\n",
       "      <td>-0.441200</td>\n",
       "      <td>0.766612</td>\n",
       "      <td>2.347817</td>\n",
       "      <td>-0.862761</td>\n",
       "      <td>-2.308829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.444558</td>\n",
       "      <td>-0.481202</td>\n",
       "      <td>0.974729</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>1.468304</td>\n",
       "      <td>-0.874772</td>\n",
       "      <td>-0.372682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.247623</td>\n",
       "      <td>-1.231184</td>\n",
       "      <td>0.221572</td>\n",
       "      <td>-0.354096</td>\n",
       "      <td>-0.332073</td>\n",
       "      <td>0.570635</td>\n",
       "      <td>-0.150125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.217613</td>\n",
       "      <td>-0.027031</td>\n",
       "      <td>-0.237430</td>\n",
       "      <td>-0.787215</td>\n",
       "      <td>-0.677817</td>\n",
       "      <td>0.919474</td>\n",
       "      <td>0.742866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.914666</td>\n",
       "      <td>0.581880</td>\n",
       "      <td>-0.588706</td>\n",
       "      <td>1.303439</td>\n",
       "      <td>-1.009079</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>-0.302814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.826302</td>\n",
       "      <td>0.411235</td>\n",
       "      <td>0.433297</td>\n",
       "      <td>0.307575</td>\n",
       "      <td>1.075324</td>\n",
       "      <td>-0.024425</td>\n",
       "      <td>0.051483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.245739</td>\n",
       "      <td>1.567230</td>\n",
       "      <td>-0.269829</td>\n",
       "      <td>1.092958</td>\n",
       "      <td>-0.515819</td>\n",
       "      <td>-2.091765</td>\n",
       "      <td>-1.627645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1417 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  cp_time cp_dose       g-0       g-1       g-2       g-3  \\\n",
       "0      id_000644bb2       24      D1  1.146806  0.902075 -0.418339 -0.961202   \n",
       "1      id_000779bfc       72      D1  0.128824  0.676862  0.274345  0.090495   \n",
       "2      id_000a6266a       48      D1  0.790372  0.939951  1.428097 -0.121817   \n",
       "3      id_0015fd391       48      D1 -0.729866 -0.277163 -0.441200  0.766612   \n",
       "4      id_001626bd3       72      D2 -0.444558 -0.481202  0.974729  0.977467   \n",
       "...             ...      ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444       72      D1  0.247623 -1.231184  0.221572 -0.354096   \n",
       "21944  id_fffb1ceed       24      D2  0.217613 -0.027031 -0.237430 -0.787215   \n",
       "21945  id_fffb70c0c       24      D2 -1.914666  0.581880 -0.588706  1.303439   \n",
       "21946  id_fffcb9e7c       24      D1  0.826302  0.411235  0.433297  0.307575   \n",
       "21947  id_ffffdd77b       72      D1 -1.245739  1.567230 -0.269829  1.092958   \n",
       "\n",
       "            g-4       g-5       g-6  ...  vasopressin_receptor_antagonist  \\\n",
       "0     -0.254770 -1.021300 -1.369236  ...                           0.0005   \n",
       "1      1.208863  0.688965  0.316734  ...                           0.0005   \n",
       "2     -0.002067  1.495091  0.238763  ...                           0.0005   \n",
       "3      2.347817 -0.862761 -2.308829  ...                           0.0005   \n",
       "4      1.468304 -0.874772 -0.372682  ...                           0.0005   \n",
       "...         ...       ...       ...  ...                              ...   \n",
       "21943 -0.332073  0.570635 -0.150125  ...                           0.0005   \n",
       "21944 -0.677817  0.919474  0.742866  ...                           0.0005   \n",
       "21945 -1.009079  0.852202 -0.302814  ...                           0.0005   \n",
       "21946  1.075324 -0.024425  0.051483  ...                           0.0005   \n",
       "21947 -0.515819 -2.091765 -1.627645  ...                           0.0005   \n",
       "\n",
       "       ve-cadherin_antagonist  vesicular_monoamine_transporter_inhibitor  \\\n",
       "0                      0.0005                                     0.0005   \n",
       "1                      0.0005                                     0.0005   \n",
       "2                      0.0005                                     0.0005   \n",
       "3                      0.0005                                     0.0005   \n",
       "4                      0.0005                                     0.0005   \n",
       "...                       ...                                        ...   \n",
       "21943                  0.0005                                     0.0005   \n",
       "21944                  0.0005                                     0.0005   \n",
       "21945                  0.0005                                     0.0005   \n",
       "21946                  0.0005                                     0.0005   \n",
       "21947                  0.0005                                     0.0005   \n",
       "\n",
       "       vitamin_k_antagonist  voltage-gated_potassium_channel_activator  \\\n",
       "0                    0.0005                                     0.0005   \n",
       "1                    0.0005                                     0.0005   \n",
       "2                    0.0005                                     0.0005   \n",
       "3                    0.0005                                     0.0005   \n",
       "4                    0.0005                                     0.0005   \n",
       "...                     ...                                        ...   \n",
       "21943                0.0005                                     0.0005   \n",
       "21944                0.0005                                     0.0005   \n",
       "21945                0.0005                                     0.0005   \n",
       "21946                0.0005                                     0.0005   \n",
       "21947                0.0005                                     0.0005   \n",
       "\n",
       "       voltage-gated_sodium_channel_blocker  wdr5_mll_interaction_inhibitor  \\\n",
       "0                                    0.0005                          0.0005   \n",
       "1                                    0.0005                          0.0005   \n",
       "2                                    0.0005                          0.0005   \n",
       "3                                    0.0005                          0.0005   \n",
       "4                                    0.0005                          0.0005   \n",
       "...                                     ...                             ...   \n",
       "21943                                0.0005                          0.0005   \n",
       "21944                                0.0005                          0.0005   \n",
       "21945                                0.0005                          0.0005   \n",
       "21946                                0.0005                          0.0005   \n",
       "21947                                0.0005                          0.0005   \n",
       "\n",
       "       xanthine_oxidase_inhibitor  xiap_inhibitor  kfold  \n",
       "0                          0.0005          0.0005      0  \n",
       "1                          0.0005          0.0005      3  \n",
       "2                          0.0005          0.0005      4  \n",
       "3                          0.0005          0.0005      2  \n",
       "4                          0.0005          0.0005      1  \n",
       "...                           ...             ...    ...  \n",
       "21943                      0.0005          0.0005      0  \n",
       "21944                      0.0005          0.0005      2  \n",
       "21945                      0.0005          0.0005      0  \n",
       "21946                      0.0005          0.0005      3  \n",
       "21947                      0.0005          0.0005      1  \n",
       "\n",
       "[21948 rows x 1417 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=NFOLDS)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:09.433877Z",
     "iopub.status.busy": "2020-11-26T05:28:09.432883Z",
     "iopub.status.idle": "2020-11-26T05:28:09.442544Z",
     "shell.execute_reply": "2020-11-26T05:28:09.443132Z"
    },
    "papermill": {
     "duration": 0.091037,
     "end_time": "2020-11-26T05:28:09.443294",
     "exception": false,
     "start_time": "2020-11-26T05:28:09.352257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1416)\n",
      "(21948, 1417)\n",
      "(3624, 1085)\n",
      "(21948, 332)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:09.606553Z",
     "iopub.status.busy": "2020-11-26T05:28:09.604376Z",
     "iopub.status.idle": "2020-11-26T05:28:09.607372Z",
     "shell.execute_reply": "2020-11-26T05:28:09.608114Z"
    },
    "papermill": {
     "duration": 0.091446,
     "end_time": "2020-11-26T05:28:09.608267",
     "exception": false,
     "start_time": "2020-11-26T05:28:09.516821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x': torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y': torch.tensor(self.targets[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "\n",
    "\n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dct = {'x': torch.tensor(self.features[idx, :], dtype=torch.float)}\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:09.775708Z",
     "iopub.status.busy": "2020-11-26T05:28:09.774627Z",
     "iopub.status.idle": "2020-11-26T05:28:09.777291Z",
     "shell.execute_reply": "2020-11-26T05:28:09.777884Z"
    },
    "papermill": {
     "duration": 0.095633,
     "end_time": "2020-11-26T05:28:09.778024",
     "exception": false,
     "start_time": "2020-11-26T05:28:09.682391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        #         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        final_loss += loss.item()\n",
    "\n",
    "    final_loss /= len(dataloader)\n",
    "\n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "\n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "\n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "\n",
    "    return final_loss, valid_preds\n",
    "\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:09.942018Z",
     "iopub.status.busy": "2020-11-26T05:28:09.940914Z",
     "iopub.status.idle": "2020-11-26T05:28:09.943651Z",
     "shell.execute_reply": "2020-11-26T05:28:09.944337Z"
    },
    "papermill": {
     "duration": 0.092238,
     "end_time": "2020-11-26T05:28:09.944483",
     "exception": false,
     "start_time": "2020-11-26T05:28:09.852245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(0.15)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features,\n",
    "                                                     hidden_size))\n",
    "\n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.dense2 = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.leaky_relu(self.dense1(x))\n",
    "\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.leaky_relu(self.dense2(x))\n",
    "\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:10.323279Z",
     "iopub.status.busy": "2020-11-26T05:28:10.319718Z",
     "iopub.status.idle": "2020-11-26T05:28:10.324499Z",
     "shell.execute_reply": "2020-11-26T05:28:10.325376Z"
    },
    "papermill": {
     "duration": 0.125648,
     "end_time": "2020-11-26T05:28:10.325587",
     "exception": false,
     "start_time": "2020-11-26T05:28:10.199939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "\n",
    "    data = pd.get_dummies(data, columns=['cp_time', 'cp_dose'])\n",
    "    #     data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "    #     data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "\n",
    "    # --------------------- Normalize ---------------------\n",
    "    #     for col in GENES:\n",
    "    #         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "\n",
    "    #     for col in CELLS:\n",
    "    #         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "\n",
    "    #--------------------- Removing Skewness ---------------------\n",
    "    #     for col in GENES + CELLS:\n",
    "    #         if(abs(data[col].skew()) > 0.75):\n",
    "\n",
    "    #             if(data[col].skew() < 0): # neg-skewness\n",
    "    #                 data[col] = data[col].max() - data[col] + 1\n",
    "    #                 data[col] = np.sqrt(data[col])\n",
    "\n",
    "    #             else:\n",
    "    #                 data[col] = np.sqrt(data[col])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:10.553740Z",
     "iopub.status.busy": "2020-11-26T05:28:10.552692Z",
     "iopub.status.idle": "2020-11-26T05:28:10.738373Z",
     "shell.execute_reply": "2020-11-26T05:28:10.739650Z"
    },
    "papermill": {
     "duration": 0.307386,
     "end_time": "2020-11-26T05:28:10.739875",
     "exception": false,
     "start_time": "2020-11-26T05:28:10.432489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1087"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold', 'sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:10.934351Z",
     "iopub.status.busy": "2020-11-26T05:28:10.933270Z",
     "iopub.status.idle": "2020-11-26T05:28:10.935958Z",
     "shell.execute_reply": "2020-11-26T05:28:10.936601Z"
    },
    "papermill": {
     "duration": 0.083777,
     "end_time": "2020-11-26T05:28:10.936745",
     "exception": false,
     "start_time": "2020-11-26T05:28:10.852968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = len(feature_cols)\n",
    "num_targets = len(target_cols)\n",
    "hidden_size = 2048\n",
    "# hidden_size=4096\n",
    "# hidden_size=9192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:11.122808Z",
     "iopub.status.busy": "2020-11-26T05:28:11.121666Z",
     "iopub.status.idle": "2020-11-26T05:28:11.151735Z",
     "shell.execute_reply": "2020-11-26T05:28:11.151016Z"
    },
    "papermill": {
     "duration": 0.139806,
     "end_time": "2020-11-26T05:28:11.151872",
     "exception": false,
     "start_time": "2020-11-26T05:28:11.012066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "\n",
    "    seed_everything(seed)\n",
    "\n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "\n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "\n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    x_train, y_train = train_df[feature_cols].values, train_df[\n",
    "        target_cols].values\n",
    "    x_valid, y_valid = valid_df[feature_cols].values, valid_df[\n",
    "        target_cols].values\n",
    "\n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                              batch_size=INFER_BATCH_SIZE,\n",
    "                                              shuffle=False)\n",
    "\n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=5e-3,\n",
    "                                 weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer,\n",
    "                                              pct_start=0.2,\n",
    "                                              div_factor=1e3,\n",
    "                                              max_lr=1e-2,\n",
    "                                              epochs=EPOCHS,\n",
    "                                              steps_per_epoch=len(trainloader))\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        train_loss = train_fn(model, optimizer, scheduler, loss_fn,\n",
    "                              trainloader, DEVICE)\n",
    "        print(\n",
    "            f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\"\n",
    "        )\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(\n",
    "            f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\"\n",
    "        )\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "\n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(),\n",
    "                       f\"{MODEL_DIR}/{NB}-nonscored1-SEED{seed}-FOLD{fold}_.pth\")\n",
    "\n",
    "        elif (EARLY_STOP == True):\n",
    "\n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "\n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset,\n",
    "                                             batch_size=INFER_BATCH_SIZE,\n",
    "                                             shuffle=False)\n",
    "\n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(\n",
    "        torch.load(f\"{MODEL_DIR}/{NB}-nonscored1-SEED{seed}-FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "\n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:11.321952Z",
     "iopub.status.busy": "2020-11-26T05:28:11.321040Z",
     "iopub.status.idle": "2020-11-26T05:28:11.325097Z",
     "shell.execute_reply": "2020-11-26T05:28:11.325648Z"
    },
    "papermill": {
     "duration": 0.087906,
     "end_time": "2020-11-26T05:28:11.325803",
     "exception": false,
     "start_time": "2020-11-26T05:28:11.237897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "\n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "\n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:28:11.489483Z",
     "iopub.status.busy": "2020-11-26T05:28:11.487773Z",
     "iopub.status.idle": "2020-11-26T05:39:54.203525Z",
     "shell.execute_reply": "2020-11-26T05:39:54.204298Z"
    },
    "papermill": {
     "duration": 702.8027,
     "end_time": "2020-11-26T05:39:54.204518",
     "exception": false,
     "start_time": "2020-11-26T05:28:11.401818",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 940, FOLD: 0, EPOCH: 0, train_loss: 0.6458044633053351\n",
      "SEED: 940, FOLD: 0, EPOCH: 0, valid_loss: 0.23897353808085123\n",
      "SEED: 940, FOLD: 0, EPOCH: 1, train_loss: 0.03576180375302616\n",
      "SEED: 940, FOLD: 0, EPOCH: 1, valid_loss: 0.009251730516552925\n",
      "SEED: 940, FOLD: 0, EPOCH: 2, train_loss: 0.00939711653020071\n",
      "SEED: 940, FOLD: 0, EPOCH: 2, valid_loss: 0.009194845540655984\n",
      "SEED: 940, FOLD: 0, EPOCH: 3, train_loss: 0.00933286329002484\n",
      "SEED: 940, FOLD: 0, EPOCH: 3, valid_loss: 0.009400543756783009\n",
      "SEED: 940, FOLD: 0, EPOCH: 4, train_loss: 0.009148614589070929\n",
      "SEED: 940, FOLD: 0, EPOCH: 4, valid_loss: 0.009084091625279851\n",
      "SEED: 940, FOLD: 0, EPOCH: 5, train_loss: 0.008975854771130758\n",
      "SEED: 940, FOLD: 0, EPOCH: 5, valid_loss: 0.009017287960482968\n",
      "SEED: 940, FOLD: 0, EPOCH: 6, train_loss: 0.009263736951718296\n",
      "SEED: 940, FOLD: 0, EPOCH: 6, valid_loss: 0.010180441559188895\n",
      "SEED: 940, FOLD: 0, EPOCH: 7, train_loss: 0.009065507411740828\n",
      "SEED: 940, FOLD: 0, EPOCH: 7, valid_loss: 0.008972486377590232\n",
      "SEED: 940, FOLD: 0, EPOCH: 8, train_loss: 0.008866744635599678\n",
      "SEED: 940, FOLD: 0, EPOCH: 8, valid_loss: 0.008936521286765734\n",
      "SEED: 940, FOLD: 0, EPOCH: 9, train_loss: 0.008783842092784851\n",
      "SEED: 940, FOLD: 0, EPOCH: 9, valid_loss: 0.008880904772215419\n",
      "SEED: 940, FOLD: 0, EPOCH: 10, train_loss: 0.008700150200098322\n",
      "SEED: 940, FOLD: 0, EPOCH: 10, valid_loss: 0.00884173841526111\n",
      "SEED: 940, FOLD: 0, EPOCH: 11, train_loss: 0.008591166953893675\n",
      "SEED: 940, FOLD: 0, EPOCH: 11, valid_loss: 0.008801645392345058\n",
      "SEED: 940, FOLD: 0, EPOCH: 12, train_loss: 0.008462620683122372\n",
      "SEED: 940, FOLD: 0, EPOCH: 12, valid_loss: 0.008769266100393401\n",
      "SEED: 940, FOLD: 0, EPOCH: 13, train_loss: 0.008324480527822954\n",
      "SEED: 940, FOLD: 0, EPOCH: 13, valid_loss: 0.008744211763971381\n",
      "SEED: 940, FOLD: 0, EPOCH: 14, train_loss: 0.00823303283718617\n",
      "SEED: 940, FOLD: 0, EPOCH: 14, valid_loss: 0.008736305249234041\n",
      "SEED: 940, FOLD: 1, EPOCH: 0, train_loss: 0.6477137588072515\n",
      "SEED: 940, FOLD: 1, EPOCH: 0, valid_loss: 0.24678095844056872\n",
      "SEED: 940, FOLD: 1, EPOCH: 1, train_loss: 0.03698636745305165\n",
      "SEED: 940, FOLD: 1, EPOCH: 1, valid_loss: 0.011859886762168672\n",
      "SEED: 940, FOLD: 1, EPOCH: 2, train_loss: 0.009666460795678955\n",
      "SEED: 940, FOLD: 1, EPOCH: 2, valid_loss: 0.009119562183817228\n",
      "SEED: 940, FOLD: 1, EPOCH: 3, train_loss: 0.00933309460895649\n",
      "SEED: 940, FOLD: 1, EPOCH: 3, valid_loss: 0.009200091370277934\n",
      "SEED: 940, FOLD: 1, EPOCH: 4, train_loss: 0.009122749304641848\n",
      "SEED: 940, FOLD: 1, EPOCH: 4, valid_loss: 0.009111861284408305\n",
      "SEED: 940, FOLD: 1, EPOCH: 5, train_loss: 0.009010098726097225\n",
      "SEED: 940, FOLD: 1, EPOCH: 5, valid_loss: 0.009010520039333237\n",
      "SEED: 940, FOLD: 1, EPOCH: 6, train_loss: 0.009450300380695557\n",
      "SEED: 940, FOLD: 1, EPOCH: 6, valid_loss: 0.009647541162040498\n",
      "SEED: 940, FOLD: 1, EPOCH: 7, train_loss: 0.009037650257780932\n",
      "SEED: 940, FOLD: 1, EPOCH: 7, valid_loss: 0.00899433706783586\n",
      "SEED: 940, FOLD: 1, EPOCH: 8, train_loss: 0.008814863664894432\n",
      "SEED: 940, FOLD: 1, EPOCH: 8, valid_loss: 0.008962463691002794\n",
      "SEED: 940, FOLD: 1, EPOCH: 9, train_loss: 0.008728665556164755\n",
      "SEED: 940, FOLD: 1, EPOCH: 9, valid_loss: 0.008876010154684385\n",
      "SEED: 940, FOLD: 1, EPOCH: 10, train_loss: 0.008656405742563631\n",
      "SEED: 940, FOLD: 1, EPOCH: 10, valid_loss: 0.00900589550534884\n",
      "SEED: 940, FOLD: 1, EPOCH: 11, train_loss: 0.008550361790896757\n",
      "SEED: 940, FOLD: 1, EPOCH: 11, valid_loss: 0.008790804487135675\n",
      "SEED: 940, FOLD: 1, EPOCH: 12, train_loss: 0.008422809261558712\n",
      "SEED: 940, FOLD: 1, EPOCH: 12, valid_loss: 0.008761676856213145\n",
      "SEED: 940, FOLD: 1, EPOCH: 13, train_loss: 0.008280923623807621\n",
      "SEED: 940, FOLD: 1, EPOCH: 13, valid_loss: 0.008745687082409859\n",
      "SEED: 940, FOLD: 1, EPOCH: 14, train_loss: 0.008193413511026596\n",
      "SEED: 940, FOLD: 1, EPOCH: 14, valid_loss: 0.008753955467707582\n",
      "SEED: 940, FOLD: 2, EPOCH: 0, train_loss: 0.6474345613648926\n",
      "SEED: 940, FOLD: 2, EPOCH: 0, valid_loss: 0.24718117548359764\n",
      "SEED: 940, FOLD: 2, EPOCH: 1, train_loss: 0.036015446378808956\n",
      "SEED: 940, FOLD: 2, EPOCH: 1, valid_loss: 0.009472452518012788\n",
      "SEED: 940, FOLD: 2, EPOCH: 2, train_loss: 0.009350001110114914\n",
      "SEED: 940, FOLD: 2, EPOCH: 2, valid_loss: 0.00927402399894264\n",
      "SEED: 940, FOLD: 2, EPOCH: 3, train_loss: 0.010435396805405617\n",
      "SEED: 940, FOLD: 2, EPOCH: 3, valid_loss: 0.07162241472138299\n",
      "SEED: 940, FOLD: 2, EPOCH: 4, train_loss: 0.009671286936255468\n",
      "SEED: 940, FOLD: 2, EPOCH: 4, valid_loss: 0.009293084653715292\n",
      "SEED: 940, FOLD: 2, EPOCH: 5, train_loss: 0.009154647278289\n",
      "SEED: 940, FOLD: 2, EPOCH: 5, valid_loss: 0.009111957107153203\n",
      "SEED: 940, FOLD: 2, EPOCH: 6, train_loss: 0.008985500890707624\n",
      "SEED: 940, FOLD: 2, EPOCH: 6, valid_loss: 0.00908092295544015\n",
      "SEED: 940, FOLD: 2, EPOCH: 7, train_loss: 0.008894580598596645\n",
      "SEED: 940, FOLD: 2, EPOCH: 7, valid_loss: 0.008977582781679101\n",
      "SEED: 940, FOLD: 2, EPOCH: 8, train_loss: 0.00880554134188139\n",
      "SEED: 940, FOLD: 2, EPOCH: 8, valid_loss: 0.008938957937061787\n",
      "SEED: 940, FOLD: 2, EPOCH: 9, train_loss: 0.008704039652872345\n",
      "SEED: 940, FOLD: 2, EPOCH: 9, valid_loss: 0.008896002235511938\n",
      "SEED: 940, FOLD: 2, EPOCH: 10, train_loss: 0.008596178738103397\n",
      "SEED: 940, FOLD: 2, EPOCH: 10, valid_loss: 0.008865307913058333\n",
      "SEED: 940, FOLD: 2, EPOCH: 11, train_loss: 0.008473961168657179\n",
      "SEED: 940, FOLD: 2, EPOCH: 11, valid_loss: 0.008849200896090932\n",
      "SEED: 940, FOLD: 2, EPOCH: 12, train_loss: 0.008317837694092937\n",
      "SEED: 940, FOLD: 2, EPOCH: 12, valid_loss: 0.008790154113537736\n",
      "SEED: 940, FOLD: 2, EPOCH: 13, train_loss: 0.008138796166125416\n",
      "SEED: 940, FOLD: 2, EPOCH: 13, valid_loss: 0.008771178623040518\n",
      "SEED: 940, FOLD: 2, EPOCH: 14, train_loss: 0.008025707427304293\n",
      "SEED: 940, FOLD: 2, EPOCH: 14, valid_loss: 0.008766290317806933\n",
      "SEED: 940, FOLD: 3, EPOCH: 0, train_loss: 0.6477155689743982\n",
      "SEED: 940, FOLD: 3, EPOCH: 0, valid_loss: 0.22163094911310408\n",
      "SEED: 940, FOLD: 3, EPOCH: 1, train_loss: 0.03579381798002599\n",
      "SEED: 940, FOLD: 3, EPOCH: 1, valid_loss: 0.009586944141321711\n",
      "SEED: 940, FOLD: 3, EPOCH: 2, train_loss: 0.009310091899680918\n",
      "SEED: 940, FOLD: 3, EPOCH: 2, valid_loss: 0.009444273283912076\n",
      "SEED: 940, FOLD: 3, EPOCH: 3, train_loss: 0.009161718263952196\n",
      "SEED: 940, FOLD: 3, EPOCH: 3, valid_loss: 0.00958287850436237\n",
      "SEED: 940, FOLD: 3, EPOCH: 4, train_loss: 0.009089211892822514\n",
      "SEED: 940, FOLD: 3, EPOCH: 4, valid_loss: 0.009255505373908414\n",
      "SEED: 940, FOLD: 3, EPOCH: 5, train_loss: 0.008932867782541376\n",
      "SEED: 940, FOLD: 3, EPOCH: 5, valid_loss: 0.009978421032428741\n",
      "SEED: 940, FOLD: 3, EPOCH: 6, train_loss: 0.009957670355620592\n",
      "SEED: 940, FOLD: 3, EPOCH: 6, valid_loss: 0.009423555495838324\n",
      "SEED: 940, FOLD: 3, EPOCH: 7, train_loss: 0.008991553029720333\n",
      "SEED: 940, FOLD: 3, EPOCH: 7, valid_loss: 0.009234628329674402\n",
      "SEED: 940, FOLD: 3, EPOCH: 8, train_loss: 0.008843366272639538\n",
      "SEED: 940, FOLD: 3, EPOCH: 8, valid_loss: 0.00917897859795226\n",
      "SEED: 940, FOLD: 3, EPOCH: 9, train_loss: 0.008776218556137621\n",
      "SEED: 940, FOLD: 3, EPOCH: 9, valid_loss: 0.009132583315173784\n",
      "SEED: 940, FOLD: 3, EPOCH: 10, train_loss: 0.008690996237261139\n",
      "SEED: 940, FOLD: 3, EPOCH: 10, valid_loss: 0.00909921092291673\n",
      "SEED: 940, FOLD: 3, EPOCH: 11, train_loss: 0.008594615405182476\n",
      "SEED: 940, FOLD: 3, EPOCH: 11, valid_loss: 0.009033793066110875\n",
      "SEED: 940, FOLD: 3, EPOCH: 12, train_loss: 0.008492866922439873\n",
      "SEED: 940, FOLD: 3, EPOCH: 12, valid_loss: 0.00901813991367817\n",
      "SEED: 940, FOLD: 3, EPOCH: 13, train_loss: 0.008369828513620989\n",
      "SEED: 940, FOLD: 3, EPOCH: 13, valid_loss: 0.009007121332817607\n",
      "SEED: 940, FOLD: 3, EPOCH: 14, train_loss: 0.008284239321137253\n",
      "SEED: 940, FOLD: 3, EPOCH: 14, valid_loss: 0.009001679718494415\n",
      "SEED: 940, FOLD: 4, EPOCH: 0, train_loss: 0.6484441079091334\n",
      "SEED: 940, FOLD: 4, EPOCH: 0, valid_loss: 0.2503463609351052\n",
      "SEED: 940, FOLD: 4, EPOCH: 1, train_loss: 0.036489894937561905\n",
      "SEED: 940, FOLD: 4, EPOCH: 1, valid_loss: 0.009290416518019306\n",
      "SEED: 940, FOLD: 4, EPOCH: 2, train_loss: 0.009506371830576572\n",
      "SEED: 940, FOLD: 4, EPOCH: 2, valid_loss: 0.00905747784094678\n",
      "SEED: 940, FOLD: 4, EPOCH: 3, train_loss: 0.00928330800725498\n",
      "SEED: 940, FOLD: 4, EPOCH: 3, valid_loss: 0.009070809413161542\n",
      "SEED: 940, FOLD: 4, EPOCH: 4, train_loss: 0.00924446584953778\n",
      "SEED: 940, FOLD: 4, EPOCH: 4, valid_loss: 0.00888034070117606\n",
      "SEED: 940, FOLD: 4, EPOCH: 5, train_loss: 0.009125426512859438\n",
      "SEED: 940, FOLD: 4, EPOCH: 5, valid_loss: 0.008816383468608061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 940, FOLD: 4, EPOCH: 6, train_loss: 0.008952772339293058\n",
      "SEED: 940, FOLD: 4, EPOCH: 6, valid_loss: 0.008799775917496946\n",
      "SEED: 940, FOLD: 4, EPOCH: 7, train_loss: 0.008867254244514566\n",
      "SEED: 940, FOLD: 4, EPOCH: 7, valid_loss: 0.008773985422319837\n",
      "SEED: 940, FOLD: 4, EPOCH: 8, train_loss: 0.008817838045997896\n",
      "SEED: 940, FOLD: 4, EPOCH: 8, valid_loss: 0.008596631698310375\n",
      "SEED: 940, FOLD: 4, EPOCH: 9, train_loss: 0.008740798651200274\n",
      "SEED: 940, FOLD: 4, EPOCH: 9, valid_loss: 0.008562602930598788\n",
      "SEED: 940, FOLD: 4, EPOCH: 10, train_loss: 0.00861561261927304\n",
      "SEED: 940, FOLD: 4, EPOCH: 10, valid_loss: 0.00852917641815212\n",
      "SEED: 940, FOLD: 4, EPOCH: 11, train_loss: 0.00849586079383026\n",
      "SEED: 940, FOLD: 4, EPOCH: 11, valid_loss: 0.008476049225363467\n",
      "SEED: 940, FOLD: 4, EPOCH: 12, train_loss: 0.008363409399770308\n",
      "SEED: 940, FOLD: 4, EPOCH: 12, valid_loss: 0.00843964951733748\n",
      "SEED: 940, FOLD: 4, EPOCH: 13, train_loss: 0.008220767467350199\n",
      "SEED: 940, FOLD: 4, EPOCH: 13, valid_loss: 0.008420105920069747\n",
      "SEED: 940, FOLD: 4, EPOCH: 14, train_loss: 0.008141571406167055\n",
      "SEED: 940, FOLD: 4, EPOCH: 14, valid_loss: 0.008408820256590843\n",
      "elapsed time: 68.71030950546265\n",
      "SEED: 1513, FOLD: 0, EPOCH: 0, train_loss: 0.6470375767220622\n",
      "SEED: 1513, FOLD: 0, EPOCH: 0, valid_loss: 0.22874678671360016\n",
      "SEED: 1513, FOLD: 0, EPOCH: 1, train_loss: 0.03616981231270061\n",
      "SEED: 1513, FOLD: 0, EPOCH: 1, valid_loss: 0.009292941126558516\n",
      "SEED: 1513, FOLD: 0, EPOCH: 2, train_loss: 0.009460649473349686\n",
      "SEED: 1513, FOLD: 0, EPOCH: 2, valid_loss: 0.009140892264743647\n",
      "SEED: 1513, FOLD: 0, EPOCH: 3, train_loss: 0.009188946147543797\n",
      "SEED: 1513, FOLD: 0, EPOCH: 3, valid_loss: 0.00926200569503837\n",
      "SEED: 1513, FOLD: 0, EPOCH: 4, train_loss: 0.009175369698230339\n",
      "SEED: 1513, FOLD: 0, EPOCH: 4, valid_loss: 0.009185984937681092\n",
      "SEED: 1513, FOLD: 0, EPOCH: 5, train_loss: 0.009045202136579632\n",
      "SEED: 1513, FOLD: 0, EPOCH: 5, valid_loss: 0.008992398675117228\n",
      "SEED: 1513, FOLD: 0, EPOCH: 6, train_loss: 0.008876379943736221\n",
      "SEED: 1513, FOLD: 0, EPOCH: 6, valid_loss: 0.008958426718082693\n",
      "SEED: 1513, FOLD: 0, EPOCH: 7, train_loss: 0.009007618350881165\n",
      "SEED: 1513, FOLD: 0, EPOCH: 7, valid_loss: 0.008930156628290812\n",
      "SEED: 1513, FOLD: 0, EPOCH: 8, train_loss: 0.008820364629660828\n",
      "SEED: 1513, FOLD: 0, EPOCH: 8, valid_loss: 0.008903545327484608\n",
      "SEED: 1513, FOLD: 0, EPOCH: 9, train_loss: 0.008702535054012053\n",
      "SEED: 1513, FOLD: 0, EPOCH: 9, valid_loss: 0.008837774499422975\n",
      "SEED: 1513, FOLD: 0, EPOCH: 10, train_loss: 0.00860950371682428\n",
      "SEED: 1513, FOLD: 0, EPOCH: 10, valid_loss: 0.008801582165890269\n",
      "SEED: 1513, FOLD: 0, EPOCH: 11, train_loss: 0.008491145534629839\n",
      "SEED: 1513, FOLD: 0, EPOCH: 11, valid_loss: 0.008791529366539584\n",
      "SEED: 1513, FOLD: 0, EPOCH: 12, train_loss: 0.008380584499758223\n",
      "SEED: 1513, FOLD: 0, EPOCH: 12, valid_loss: 0.008782623646159967\n",
      "SEED: 1513, FOLD: 0, EPOCH: 13, train_loss: 0.008221172693900871\n",
      "SEED: 1513, FOLD: 0, EPOCH: 13, valid_loss: 0.008720064949658182\n",
      "SEED: 1513, FOLD: 0, EPOCH: 14, train_loss: 0.008123285400316767\n",
      "SEED: 1513, FOLD: 0, EPOCH: 14, valid_loss: 0.008694974188175466\n",
      "SEED: 1513, FOLD: 1, EPOCH: 0, train_loss: 0.6476947056210559\n",
      "SEED: 1513, FOLD: 1, EPOCH: 0, valid_loss: 0.24407338599363962\n",
      "SEED: 1513, FOLD: 1, EPOCH: 1, train_loss: 0.03597930911928415\n",
      "SEED: 1513, FOLD: 1, EPOCH: 1, valid_loss: 0.009347609451247586\n",
      "SEED: 1513, FOLD: 1, EPOCH: 2, train_loss: 0.009701230239285074\n",
      "SEED: 1513, FOLD: 1, EPOCH: 2, valid_loss: 0.010224829013976786\n",
      "SEED: 1513, FOLD: 1, EPOCH: 3, train_loss: 0.009465581346033276\n",
      "SEED: 1513, FOLD: 1, EPOCH: 3, valid_loss: 0.009116543146471182\n",
      "SEED: 1513, FOLD: 1, EPOCH: 4, train_loss: 0.00908145590590826\n",
      "SEED: 1513, FOLD: 1, EPOCH: 4, valid_loss: 0.009068419018553363\n",
      "SEED: 1513, FOLD: 1, EPOCH: 5, train_loss: 0.009144126221645569\n",
      "SEED: 1513, FOLD: 1, EPOCH: 5, valid_loss: 0.009018283026913801\n",
      "SEED: 1513, FOLD: 1, EPOCH: 6, train_loss: 0.008879837350568909\n",
      "SEED: 1513, FOLD: 1, EPOCH: 6, valid_loss: 0.008963716319865651\n",
      "SEED: 1513, FOLD: 1, EPOCH: 7, train_loss: 0.008792807793487673\n",
      "SEED: 1513, FOLD: 1, EPOCH: 7, valid_loss: 0.008921948158078723\n",
      "SEED: 1513, FOLD: 1, EPOCH: 8, train_loss: 0.008744474871596996\n",
      "SEED: 1513, FOLD: 1, EPOCH: 8, valid_loss: 0.008880470568935076\n",
      "SEED: 1513, FOLD: 1, EPOCH: 9, train_loss: 0.008647275029047243\n",
      "SEED: 1513, FOLD: 1, EPOCH: 9, valid_loss: 0.008826040041943392\n",
      "SEED: 1513, FOLD: 1, EPOCH: 10, train_loss: 0.008565470171363457\n",
      "SEED: 1513, FOLD: 1, EPOCH: 10, valid_loss: 0.008783545138107406\n",
      "SEED: 1513, FOLD: 1, EPOCH: 11, train_loss: 0.008418862383974634\n",
      "SEED: 1513, FOLD: 1, EPOCH: 11, valid_loss: 0.008753648027777672\n",
      "SEED: 1513, FOLD: 1, EPOCH: 12, train_loss: 0.008278566648832697\n",
      "SEED: 1513, FOLD: 1, EPOCH: 12, valid_loss: 0.008687980886962678\n",
      "SEED: 1513, FOLD: 1, EPOCH: 13, train_loss: 0.00811847167737458\n",
      "SEED: 1513, FOLD: 1, EPOCH: 13, valid_loss: 0.008668514692948924\n",
      "SEED: 1513, FOLD: 1, EPOCH: 14, train_loss: 0.008021864830853714\n",
      "SEED: 1513, FOLD: 1, EPOCH: 14, valid_loss: 0.008664842177596357\n",
      "SEED: 1513, FOLD: 2, EPOCH: 0, train_loss: 0.6476613479679909\n",
      "SEED: 1513, FOLD: 2, EPOCH: 0, valid_loss: 0.2546249396271176\n",
      "SEED: 1513, FOLD: 2, EPOCH: 1, train_loss: 0.03655196015007686\n",
      "SEED: 1513, FOLD: 2, EPOCH: 1, valid_loss: 0.009402332517007986\n",
      "SEED: 1513, FOLD: 2, EPOCH: 2, train_loss: 0.009374997484079306\n",
      "SEED: 1513, FOLD: 2, EPOCH: 2, valid_loss: 0.009246876566774316\n",
      "SEED: 1513, FOLD: 2, EPOCH: 3, train_loss: 0.00926189915533515\n",
      "SEED: 1513, FOLD: 2, EPOCH: 3, valid_loss: 0.010041669321556887\n",
      "SEED: 1513, FOLD: 2, EPOCH: 4, train_loss: 0.009295454788683117\n",
      "SEED: 1513, FOLD: 2, EPOCH: 4, valid_loss: 0.009264581319358613\n",
      "SEED: 1513, FOLD: 2, EPOCH: 5, train_loss: 0.008982936595229135\n",
      "SEED: 1513, FOLD: 2, EPOCH: 5, valid_loss: 0.00907520360002915\n",
      "SEED: 1513, FOLD: 2, EPOCH: 6, train_loss: 0.00932967504216493\n",
      "SEED: 1513, FOLD: 2, EPOCH: 6, valid_loss: 0.009264466456241079\n",
      "SEED: 1513, FOLD: 2, EPOCH: 7, train_loss: 0.008977551384410564\n",
      "SEED: 1513, FOLD: 2, EPOCH: 7, valid_loss: 0.009014625309242142\n",
      "SEED: 1513, FOLD: 2, EPOCH: 8, train_loss: 0.008836769309920677\n",
      "SEED: 1513, FOLD: 2, EPOCH: 8, valid_loss: 0.008991643682950072\n",
      "SEED: 1513, FOLD: 2, EPOCH: 9, train_loss: 0.00872663243174337\n",
      "SEED: 1513, FOLD: 2, EPOCH: 9, valid_loss: 0.008947508823540475\n",
      "SEED: 1513, FOLD: 2, EPOCH: 10, train_loss: 0.008659198191826757\n",
      "SEED: 1513, FOLD: 2, EPOCH: 10, valid_loss: 0.008896273250381151\n",
      "SEED: 1513, FOLD: 2, EPOCH: 11, train_loss: 0.008540928033113048\n",
      "SEED: 1513, FOLD: 2, EPOCH: 11, valid_loss: 0.008823563241296344\n",
      "SEED: 1513, FOLD: 2, EPOCH: 12, train_loss: 0.008407544182694477\n",
      "SEED: 1513, FOLD: 2, EPOCH: 12, valid_loss: 0.008800689751903215\n",
      "SEED: 1513, FOLD: 2, EPOCH: 13, train_loss: 0.008273440527905157\n",
      "SEED: 1513, FOLD: 2, EPOCH: 13, valid_loss: 0.008777291617459722\n",
      "SEED: 1513, FOLD: 2, EPOCH: 14, train_loss: 0.008206307955518148\n",
      "SEED: 1513, FOLD: 2, EPOCH: 14, valid_loss: 0.008770452812314034\n",
      "SEED: 1513, FOLD: 3, EPOCH: 0, train_loss: 0.6475926477839982\n",
      "SEED: 1513, FOLD: 3, EPOCH: 0, valid_loss: 0.2232153614362081\n",
      "SEED: 1513, FOLD: 3, EPOCH: 1, train_loss: 0.035922645618194256\n",
      "SEED: 1513, FOLD: 3, EPOCH: 1, valid_loss: 0.00965492996490664\n",
      "SEED: 1513, FOLD: 3, EPOCH: 2, train_loss: 0.009311277351841547\n",
      "SEED: 1513, FOLD: 3, EPOCH: 2, valid_loss: 0.009355619239310423\n",
      "SEED: 1513, FOLD: 3, EPOCH: 3, train_loss: 0.009152791003926077\n",
      "SEED: 1513, FOLD: 3, EPOCH: 3, valid_loss: 0.009492801916268136\n",
      "SEED: 1513, FOLD: 3, EPOCH: 4, train_loss: 0.009142016978475494\n",
      "SEED: 1513, FOLD: 3, EPOCH: 4, valid_loss: 0.009428186445600457\n",
      "SEED: 1513, FOLD: 3, EPOCH: 5, train_loss: 0.008938441370222448\n",
      "SEED: 1513, FOLD: 3, EPOCH: 5, valid_loss: 0.00929993949830532\n",
      "SEED: 1513, FOLD: 3, EPOCH: 6, train_loss: 0.008807674232546402\n",
      "SEED: 1513, FOLD: 3, EPOCH: 6, valid_loss: 0.00918732231689824\n",
      "SEED: 1513, FOLD: 3, EPOCH: 7, train_loss: 0.00872615105944915\n",
      "SEED: 1513, FOLD: 3, EPOCH: 7, valid_loss: 0.009164015038145913\n",
      "SEED: 1513, FOLD: 3, EPOCH: 8, train_loss: 0.00866387229061861\n",
      "SEED: 1513, FOLD: 3, EPOCH: 8, valid_loss: 0.009198001378940212\n",
      "SEED: 1513, FOLD: 3, EPOCH: 9, train_loss: 0.008618437367882849\n",
      "SEED: 1513, FOLD: 3, EPOCH: 9, valid_loss: 0.009044589371316962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1513, FOLD: 3, EPOCH: 10, train_loss: 0.008510033444811901\n",
      "SEED: 1513, FOLD: 3, EPOCH: 10, valid_loss: 0.008998410672777228\n",
      "SEED: 1513, FOLD: 3, EPOCH: 11, train_loss: 0.008380469832353401\n",
      "SEED: 1513, FOLD: 3, EPOCH: 11, valid_loss: 0.008958581317630079\n",
      "SEED: 1513, FOLD: 3, EPOCH: 12, train_loss: 0.008260354055496662\n",
      "SEED: 1513, FOLD: 3, EPOCH: 12, valid_loss: 0.008916081446740363\n",
      "SEED: 1513, FOLD: 3, EPOCH: 13, train_loss: 0.008100920593015093\n",
      "SEED: 1513, FOLD: 3, EPOCH: 13, valid_loss: 0.008896990161803033\n",
      "SEED: 1513, FOLD: 3, EPOCH: 14, train_loss: 0.008023450394039568\n",
      "SEED: 1513, FOLD: 3, EPOCH: 14, valid_loss: 0.008887458696133561\n",
      "SEED: 1513, FOLD: 4, EPOCH: 0, train_loss: 0.6479944033899169\n",
      "SEED: 1513, FOLD: 4, EPOCH: 0, valid_loss: 0.25152041845851475\n",
      "SEED: 1513, FOLD: 4, EPOCH: 1, train_loss: 0.03594132327893074\n",
      "SEED: 1513, FOLD: 4, EPOCH: 1, valid_loss: 0.009253945408595933\n",
      "SEED: 1513, FOLD: 4, EPOCH: 2, train_loss: 0.009558766661886719\n",
      "SEED: 1513, FOLD: 4, EPOCH: 2, valid_loss: 0.009012790293329291\n",
      "SEED: 1513, FOLD: 4, EPOCH: 3, train_loss: 0.009263538478779188\n",
      "SEED: 1513, FOLD: 4, EPOCH: 3, valid_loss: 0.008970231749117374\n",
      "SEED: 1513, FOLD: 4, EPOCH: 4, train_loss: 0.009544019668322542\n",
      "SEED: 1513, FOLD: 4, EPOCH: 4, valid_loss: 0.008925099339750078\n",
      "SEED: 1513, FOLD: 4, EPOCH: 5, train_loss: 0.009131175006969252\n",
      "SEED: 1513, FOLD: 4, EPOCH: 5, valid_loss: 0.008839420042932034\n",
      "SEED: 1513, FOLD: 4, EPOCH: 6, train_loss: 0.00896714533260767\n",
      "SEED: 1513, FOLD: 4, EPOCH: 6, valid_loss: 0.008756407536566257\n",
      "SEED: 1513, FOLD: 4, EPOCH: 7, train_loss: 0.008898147962231567\n",
      "SEED: 1513, FOLD: 4, EPOCH: 7, valid_loss: 0.008705790258116193\n",
      "SEED: 1513, FOLD: 4, EPOCH: 8, train_loss: 0.008816164715782455\n",
      "SEED: 1513, FOLD: 4, EPOCH: 8, valid_loss: 0.008634653149379624\n",
      "SEED: 1513, FOLD: 4, EPOCH: 9, train_loss: 0.00871856943231778\n",
      "SEED: 1513, FOLD: 4, EPOCH: 9, valid_loss: 0.008638913122316202\n",
      "SEED: 1513, FOLD: 4, EPOCH: 10, train_loss: 0.008620893650188826\n",
      "SEED: 1513, FOLD: 4, EPOCH: 10, valid_loss: 0.00850750133395195\n",
      "SEED: 1513, FOLD: 4, EPOCH: 11, train_loss: 0.008494958382747744\n",
      "SEED: 1513, FOLD: 4, EPOCH: 11, valid_loss: 0.008482797278298272\n",
      "SEED: 1513, FOLD: 4, EPOCH: 12, train_loss: 0.008341296899901785\n",
      "SEED: 1513, FOLD: 4, EPOCH: 12, valid_loss: 0.0084262794504563\n",
      "SEED: 1513, FOLD: 4, EPOCH: 13, train_loss: 0.008184807874478292\n",
      "SEED: 1513, FOLD: 4, EPOCH: 13, valid_loss: 0.008413520124223497\n",
      "SEED: 1513, FOLD: 4, EPOCH: 14, train_loss: 0.008090239571596401\n",
      "SEED: 1513, FOLD: 4, EPOCH: 14, valid_loss: 0.00840820837765932\n",
      "elapsed time: 134.68975400924683\n",
      "SEED: 1269, FOLD: 0, EPOCH: 0, train_loss: 0.6462516115195509\n",
      "SEED: 1269, FOLD: 0, EPOCH: 0, valid_loss: 0.23004356026649475\n",
      "SEED: 1269, FOLD: 0, EPOCH: 1, train_loss: 0.035374933016904885\n",
      "SEED: 1269, FOLD: 0, EPOCH: 1, valid_loss: 0.00940940280755361\n",
      "SEED: 1269, FOLD: 0, EPOCH: 2, train_loss: 0.00939037945067537\n",
      "SEED: 1269, FOLD: 0, EPOCH: 2, valid_loss: 0.009173370897769928\n",
      "SEED: 1269, FOLD: 0, EPOCH: 3, train_loss: 0.009224498792942883\n",
      "SEED: 1269, FOLD: 0, EPOCH: 3, valid_loss: 0.009136126790609624\n",
      "SEED: 1269, FOLD: 0, EPOCH: 4, train_loss: 0.009083670213062695\n",
      "SEED: 1269, FOLD: 0, EPOCH: 4, valid_loss: 0.009030296570724912\n",
      "SEED: 1269, FOLD: 0, EPOCH: 5, train_loss: 0.009019794266508974\n",
      "SEED: 1269, FOLD: 0, EPOCH: 5, valid_loss: 0.009024673141539097\n",
      "SEED: 1269, FOLD: 0, EPOCH: 6, train_loss: 0.008840357689051956\n",
      "SEED: 1269, FOLD: 0, EPOCH: 6, valid_loss: 0.008939012885093689\n",
      "SEED: 1269, FOLD: 0, EPOCH: 7, train_loss: 0.00875898649700094\n",
      "SEED: 1269, FOLD: 0, EPOCH: 7, valid_loss: 0.008875440081788434\n",
      "SEED: 1269, FOLD: 0, EPOCH: 8, train_loss: 0.008719649570791618\n",
      "SEED: 1269, FOLD: 0, EPOCH: 8, valid_loss: 0.008834526149763001\n",
      "SEED: 1269, FOLD: 0, EPOCH: 9, train_loss: 0.008650335375273573\n",
      "SEED: 1269, FOLD: 0, EPOCH: 9, valid_loss: 0.00878931861370802\n",
      "SEED: 1269, FOLD: 0, EPOCH: 10, train_loss: 0.00855619832198473\n",
      "SEED: 1269, FOLD: 0, EPOCH: 10, valid_loss: 0.008785232487652037\n",
      "SEED: 1269, FOLD: 0, EPOCH: 11, train_loss: 0.008447965546308653\n",
      "SEED: 1269, FOLD: 0, EPOCH: 11, valid_loss: 0.008746562525629997\n",
      "SEED: 1269, FOLD: 0, EPOCH: 12, train_loss: 0.008300395014331392\n",
      "SEED: 1269, FOLD: 0, EPOCH: 12, valid_loss: 0.008694170870714717\n",
      "SEED: 1269, FOLD: 0, EPOCH: 13, train_loss: 0.008162776001499615\n",
      "SEED: 1269, FOLD: 0, EPOCH: 13, valid_loss: 0.008690965982774893\n",
      "SEED: 1269, FOLD: 0, EPOCH: 14, train_loss: 0.008081311198032421\n",
      "SEED: 1269, FOLD: 0, EPOCH: 14, valid_loss: 0.00868932768288586\n",
      "SEED: 1269, FOLD: 1, EPOCH: 0, train_loss: 0.6468379862498546\n",
      "SEED: 1269, FOLD: 1, EPOCH: 0, valid_loss: 0.24966183967060512\n",
      "SEED: 1269, FOLD: 1, EPOCH: 1, train_loss: 0.036339506250468716\n",
      "SEED: 1269, FOLD: 1, EPOCH: 1, valid_loss: 0.009312686924305227\n",
      "SEED: 1269, FOLD: 1, EPOCH: 2, train_loss: 0.009375812701772953\n",
      "SEED: 1269, FOLD: 1, EPOCH: 2, valid_loss: 0.009173281180361906\n",
      "SEED: 1269, FOLD: 1, EPOCH: 3, train_loss: 0.009333242311317852\n",
      "SEED: 1269, FOLD: 1, EPOCH: 3, valid_loss: 0.009191352667080032\n",
      "SEED: 1269, FOLD: 1, EPOCH: 4, train_loss: 0.009234611093458057\n",
      "SEED: 1269, FOLD: 1, EPOCH: 4, valid_loss: 0.00909411669191387\n",
      "SEED: 1269, FOLD: 1, EPOCH: 5, train_loss: 0.008977496740070806\n",
      "SEED: 1269, FOLD: 1, EPOCH: 5, valid_loss: 0.008998805346588293\n",
      "SEED: 1269, FOLD: 1, EPOCH: 6, train_loss: 0.008880020996582682\n",
      "SEED: 1269, FOLD: 1, EPOCH: 6, valid_loss: 0.009105071735878786\n",
      "SEED: 1269, FOLD: 1, EPOCH: 7, train_loss: 0.00883899749243173\n",
      "SEED: 1269, FOLD: 1, EPOCH: 7, valid_loss: 0.008923346797625223\n",
      "SEED: 1269, FOLD: 1, EPOCH: 8, train_loss: 0.008730102485666672\n",
      "SEED: 1269, FOLD: 1, EPOCH: 8, valid_loss: 0.00888286665495899\n",
      "SEED: 1269, FOLD: 1, EPOCH: 9, train_loss: 0.008658068578528322\n",
      "SEED: 1269, FOLD: 1, EPOCH: 9, valid_loss: 0.00881166797545221\n",
      "SEED: 1269, FOLD: 1, EPOCH: 10, train_loss: 0.008559513904586218\n",
      "SEED: 1269, FOLD: 1, EPOCH: 10, valid_loss: 0.00876987860020664\n",
      "SEED: 1269, FOLD: 1, EPOCH: 11, train_loss: 0.008439618372020946\n",
      "SEED: 1269, FOLD: 1, EPOCH: 11, valid_loss: 0.008722850638959143\n",
      "SEED: 1269, FOLD: 1, EPOCH: 12, train_loss: 0.008282433162726786\n",
      "SEED: 1269, FOLD: 1, EPOCH: 12, valid_loss: 0.008684732226861848\n",
      "SEED: 1269, FOLD: 1, EPOCH: 13, train_loss: 0.00814306133332244\n",
      "SEED: 1269, FOLD: 1, EPOCH: 13, valid_loss: 0.008654891513288021\n",
      "SEED: 1269, FOLD: 1, EPOCH: 14, train_loss: 0.00805972239839426\n",
      "SEED: 1269, FOLD: 1, EPOCH: 14, valid_loss: 0.00864795647147629\n",
      "SEED: 1269, FOLD: 2, EPOCH: 0, train_loss: 0.6462677343600038\n",
      "SEED: 1269, FOLD: 2, EPOCH: 0, valid_loss: 0.25163551833894515\n",
      "SEED: 1269, FOLD: 2, EPOCH: 1, train_loss: 0.03579040862403918\n",
      "SEED: 1269, FOLD: 2, EPOCH: 1, valid_loss: 0.011971093921197785\n",
      "SEED: 1269, FOLD: 2, EPOCH: 2, train_loss: 0.009796346578261127\n",
      "SEED: 1269, FOLD: 2, EPOCH: 2, valid_loss: 0.009267556688023938\n",
      "SEED: 1269, FOLD: 2, EPOCH: 3, train_loss: 0.009218502209346363\n",
      "SEED: 1269, FOLD: 2, EPOCH: 3, valid_loss: 0.009243387211528089\n",
      "SEED: 1269, FOLD: 2, EPOCH: 4, train_loss: 0.009141611947637537\n",
      "SEED: 1269, FOLD: 2, EPOCH: 4, valid_loss: 0.00923934785856141\n",
      "SEED: 1269, FOLD: 2, EPOCH: 5, train_loss: 0.009038876694883558\n",
      "SEED: 1269, FOLD: 2, EPOCH: 5, valid_loss: 0.009238040488627221\n",
      "SEED: 1269, FOLD: 2, EPOCH: 6, train_loss: 0.00887275234107738\n",
      "SEED: 1269, FOLD: 2, EPOCH: 6, valid_loss: 0.009046379166344801\n",
      "SEED: 1269, FOLD: 2, EPOCH: 7, train_loss: 0.008869630905489126\n",
      "SEED: 1269, FOLD: 2, EPOCH: 7, valid_loss: 0.008978895739548735\n",
      "SEED: 1269, FOLD: 2, EPOCH: 8, train_loss: 0.008715200528124536\n",
      "SEED: 1269, FOLD: 2, EPOCH: 8, valid_loss: 0.008936279867258336\n",
      "SEED: 1269, FOLD: 2, EPOCH: 9, train_loss: 0.008644212307273478\n",
      "SEED: 1269, FOLD: 2, EPOCH: 9, valid_loss: 0.008866159038411247\n",
      "SEED: 1269, FOLD: 2, EPOCH: 10, train_loss: 0.008524738002460504\n",
      "SEED: 1269, FOLD: 2, EPOCH: 10, valid_loss: 0.008846248707009686\n",
      "SEED: 1269, FOLD: 2, EPOCH: 11, train_loss: 0.008421580529893223\n",
      "SEED: 1269, FOLD: 2, EPOCH: 11, valid_loss: 0.0087978123790688\n",
      "SEED: 1269, FOLD: 2, EPOCH: 12, train_loss: 0.008260127663126459\n",
      "SEED: 1269, FOLD: 2, EPOCH: 12, valid_loss: 0.008739963380826844\n",
      "SEED: 1269, FOLD: 2, EPOCH: 13, train_loss: 0.008102851946824703\n",
      "SEED: 1269, FOLD: 2, EPOCH: 13, valid_loss: 0.008721876165105237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1269, FOLD: 2, EPOCH: 14, train_loss: 0.008013222751248142\n",
      "SEED: 1269, FOLD: 2, EPOCH: 14, valid_loss: 0.00871849525719881\n",
      "SEED: 1269, FOLD: 3, EPOCH: 0, train_loss: 0.6461189335239106\n",
      "SEED: 1269, FOLD: 3, EPOCH: 0, valid_loss: 0.263225300444497\n",
      "SEED: 1269, FOLD: 3, EPOCH: 1, train_loss: 0.03637226460420567\n",
      "SEED: 1269, FOLD: 3, EPOCH: 1, valid_loss: 0.009531344597538313\n",
      "SEED: 1269, FOLD: 3, EPOCH: 2, train_loss: 0.00934063554134058\n",
      "SEED: 1269, FOLD: 3, EPOCH: 2, valid_loss: 0.009372986128760709\n",
      "SEED: 1269, FOLD: 3, EPOCH: 3, train_loss: 0.009236673419566258\n",
      "SEED: 1269, FOLD: 3, EPOCH: 3, valid_loss: 0.009518314877318012\n",
      "SEED: 1269, FOLD: 3, EPOCH: 4, train_loss: 0.009156833254340767\n",
      "SEED: 1269, FOLD: 3, EPOCH: 4, valid_loss: 0.009590136922068067\n",
      "SEED: 1269, FOLD: 3, EPOCH: 5, train_loss: 0.009292908330056547\n",
      "SEED: 1269, FOLD: 3, EPOCH: 5, valid_loss: 0.009361680907507738\n",
      "SEED: 1269, FOLD: 3, EPOCH: 6, train_loss: 0.008883225367121075\n",
      "SEED: 1269, FOLD: 3, EPOCH: 6, valid_loss: 0.00921896741622024\n",
      "SEED: 1269, FOLD: 3, EPOCH: 7, train_loss: 0.008793528326719568\n",
      "SEED: 1269, FOLD: 3, EPOCH: 7, valid_loss: 0.009175955421394773\n",
      "SEED: 1269, FOLD: 3, EPOCH: 8, train_loss: 0.00871149217709899\n",
      "SEED: 1269, FOLD: 3, EPOCH: 8, valid_loss: 0.00911677142398225\n",
      "SEED: 1269, FOLD: 3, EPOCH: 9, train_loss: 0.00864700900822662\n",
      "SEED: 1269, FOLD: 3, EPOCH: 9, valid_loss: 0.00920139615320497\n",
      "SEED: 1269, FOLD: 3, EPOCH: 10, train_loss: 0.008604648010130379\n",
      "SEED: 1269, FOLD: 3, EPOCH: 10, valid_loss: 0.009077527560293674\n",
      "SEED: 1269, FOLD: 3, EPOCH: 11, train_loss: 0.008453296328746323\n",
      "SEED: 1269, FOLD: 3, EPOCH: 11, valid_loss: 0.009010200906131003\n",
      "SEED: 1269, FOLD: 3, EPOCH: 12, train_loss: 0.008283767680489067\n",
      "SEED: 1269, FOLD: 3, EPOCH: 12, valid_loss: 0.008958511468436983\n",
      "SEED: 1269, FOLD: 3, EPOCH: 13, train_loss: 0.008140269855874172\n",
      "SEED: 1269, FOLD: 3, EPOCH: 13, valid_loss: 0.00893165823072195\n",
      "SEED: 1269, FOLD: 3, EPOCH: 14, train_loss: 0.008059903155958307\n",
      "SEED: 1269, FOLD: 3, EPOCH: 14, valid_loss: 0.008928292120496431\n",
      "SEED: 1269, FOLD: 4, EPOCH: 0, train_loss: 0.6475137040234994\n",
      "SEED: 1269, FOLD: 4, EPOCH: 0, valid_loss: 0.24325000411934322\n",
      "SEED: 1269, FOLD: 4, EPOCH: 1, train_loss: 0.036423834756124714\n",
      "SEED: 1269, FOLD: 4, EPOCH: 1, valid_loss: 0.009215941859616173\n",
      "SEED: 1269, FOLD: 4, EPOCH: 2, train_loss: 0.009410138592879841\n",
      "SEED: 1269, FOLD: 4, EPOCH: 2, valid_loss: 0.008959653890795179\n",
      "SEED: 1269, FOLD: 4, EPOCH: 3, train_loss: 0.009319039628557537\n",
      "SEED: 1269, FOLD: 4, EPOCH: 3, valid_loss: 0.00895023149334722\n",
      "SEED: 1269, FOLD: 4, EPOCH: 4, train_loss: 0.00956014209035514\n",
      "SEED: 1269, FOLD: 4, EPOCH: 4, valid_loss: 0.00923103466629982\n",
      "SEED: 1269, FOLD: 4, EPOCH: 5, train_loss: 0.009155230920599855\n",
      "SEED: 1269, FOLD: 4, EPOCH: 5, valid_loss: 0.008804216670493284\n",
      "SEED: 1269, FOLD: 4, EPOCH: 6, train_loss: 0.008969557046404352\n",
      "SEED: 1269, FOLD: 4, EPOCH: 6, valid_loss: 0.008714663692646556\n",
      "SEED: 1269, FOLD: 4, EPOCH: 7, train_loss: 0.008865855013330778\n",
      "SEED: 1269, FOLD: 4, EPOCH: 7, valid_loss: 0.008656652126875188\n",
      "SEED: 1269, FOLD: 4, EPOCH: 8, train_loss: 0.008785824183428633\n",
      "SEED: 1269, FOLD: 4, EPOCH: 8, valid_loss: 0.008628984395828512\n",
      "SEED: 1269, FOLD: 4, EPOCH: 9, train_loss: 0.008705433370356543\n",
      "SEED: 1269, FOLD: 4, EPOCH: 9, valid_loss: 0.00866927309996552\n",
      "SEED: 1269, FOLD: 4, EPOCH: 10, train_loss: 0.008618923531764227\n",
      "SEED: 1269, FOLD: 4, EPOCH: 10, valid_loss: 0.008487283148699336\n",
      "SEED: 1269, FOLD: 4, EPOCH: 11, train_loss: 0.008457286256378975\n",
      "SEED: 1269, FOLD: 4, EPOCH: 11, valid_loss: 0.008471961236662336\n",
      "SEED: 1269, FOLD: 4, EPOCH: 12, train_loss: 0.00832487756818317\n",
      "SEED: 1269, FOLD: 4, EPOCH: 12, valid_loss: 0.00843576973097192\n",
      "SEED: 1269, FOLD: 4, EPOCH: 13, train_loss: 0.008169715852895077\n",
      "SEED: 1269, FOLD: 4, EPOCH: 13, valid_loss: 0.00842263942791356\n",
      "SEED: 1269, FOLD: 4, EPOCH: 14, train_loss: 0.008058462082745804\n",
      "SEED: 1269, FOLD: 4, EPOCH: 14, valid_loss: 0.008423476066026423\n",
      "elapsed time: 200.6985559463501\n",
      "SEED: 1392, FOLD: 0, EPOCH: 0, train_loss: 0.6458393091308898\n",
      "SEED: 1392, FOLD: 0, EPOCH: 0, valid_loss: 0.2277775373723772\n",
      "SEED: 1392, FOLD: 0, EPOCH: 1, train_loss: 0.03547210134295882\n",
      "SEED: 1392, FOLD: 0, EPOCH: 1, valid_loss: 0.009338020243578486\n",
      "SEED: 1392, FOLD: 0, EPOCH: 2, train_loss: 0.00938759412130584\n",
      "SEED: 1392, FOLD: 0, EPOCH: 2, valid_loss: 0.009307130239903927\n",
      "SEED: 1392, FOLD: 0, EPOCH: 3, train_loss: 0.013079094471058983\n",
      "SEED: 1392, FOLD: 0, EPOCH: 3, valid_loss: 0.24377070864041647\n",
      "SEED: 1392, FOLD: 0, EPOCH: 4, train_loss: 0.009499542887552061\n",
      "SEED: 1392, FOLD: 0, EPOCH: 4, valid_loss: 0.009159398368663259\n",
      "SEED: 1392, FOLD: 0, EPOCH: 5, train_loss: 0.009153172097074381\n",
      "SEED: 1392, FOLD: 0, EPOCH: 5, valid_loss: 0.009075567022793822\n",
      "SEED: 1392, FOLD: 0, EPOCH: 6, train_loss: 0.009078711203798868\n",
      "SEED: 1392, FOLD: 0, EPOCH: 6, valid_loss: 0.009067141347461276\n",
      "SEED: 1392, FOLD: 0, EPOCH: 7, train_loss: 0.009034691027541092\n",
      "SEED: 1392, FOLD: 0, EPOCH: 7, valid_loss: 0.009035816105703512\n",
      "SEED: 1392, FOLD: 0, EPOCH: 8, train_loss: 0.008976553242815577\n",
      "SEED: 1392, FOLD: 0, EPOCH: 8, valid_loss: 0.009021454283760654\n",
      "SEED: 1392, FOLD: 0, EPOCH: 9, train_loss: 0.008899097445596388\n",
      "SEED: 1392, FOLD: 0, EPOCH: 9, valid_loss: 0.00894182278878159\n",
      "SEED: 1392, FOLD: 0, EPOCH: 10, train_loss: 0.00881710161279509\n",
      "SEED: 1392, FOLD: 0, EPOCH: 10, valid_loss: 0.008895444062848886\n",
      "SEED: 1392, FOLD: 0, EPOCH: 11, train_loss: 0.008693349243992048\n",
      "SEED: 1392, FOLD: 0, EPOCH: 11, valid_loss: 0.008897192672722869\n",
      "SEED: 1392, FOLD: 0, EPOCH: 12, train_loss: 0.008577189408242702\n",
      "SEED: 1392, FOLD: 0, EPOCH: 12, valid_loss: 0.008818707325392298\n",
      "SEED: 1392, FOLD: 0, EPOCH: 13, train_loss: 0.008454270309944084\n",
      "SEED: 1392, FOLD: 0, EPOCH: 13, valid_loss: 0.008851620679100355\n",
      "SEED: 1392, FOLD: 0, EPOCH: 14, train_loss: 0.008373598554644032\n",
      "SEED: 1392, FOLD: 0, EPOCH: 14, valid_loss: 0.008845701192816099\n",
      "SEED: 1392, FOLD: 1, EPOCH: 0, train_loss: 0.6468249930851702\n",
      "SEED: 1392, FOLD: 1, EPOCH: 0, valid_loss: 0.2344867702987459\n",
      "SEED: 1392, FOLD: 1, EPOCH: 1, train_loss: 0.035787267839887005\n",
      "SEED: 1392, FOLD: 1, EPOCH: 1, valid_loss: 0.009413025755849149\n",
      "SEED: 1392, FOLD: 1, EPOCH: 2, train_loss: 0.009424111306451368\n",
      "SEED: 1392, FOLD: 1, EPOCH: 2, valid_loss: 0.009209490174220668\n",
      "SEED: 1392, FOLD: 1, EPOCH: 3, train_loss: 0.009240881094466085\n",
      "SEED: 1392, FOLD: 1, EPOCH: 3, valid_loss: 0.00934736140900188\n",
      "SEED: 1392, FOLD: 1, EPOCH: 4, train_loss: 0.009125755047020704\n",
      "SEED: 1392, FOLD: 1, EPOCH: 4, valid_loss: 0.00918057571268744\n",
      "SEED: 1392, FOLD: 1, EPOCH: 5, train_loss: 0.009076976851708647\n",
      "SEED: 1392, FOLD: 1, EPOCH: 5, valid_loss: 0.008996742881006665\n",
      "SEED: 1392, FOLD: 1, EPOCH: 6, train_loss: 0.0088776258846232\n",
      "SEED: 1392, FOLD: 1, EPOCH: 6, valid_loss: 0.009070204570889473\n",
      "SEED: 1392, FOLD: 1, EPOCH: 7, train_loss: 0.008808858874861313\n",
      "SEED: 1392, FOLD: 1, EPOCH: 7, valid_loss: 0.008925776618222395\n",
      "SEED: 1392, FOLD: 1, EPOCH: 8, train_loss: 0.008725334100587212\n",
      "SEED: 1392, FOLD: 1, EPOCH: 8, valid_loss: 0.00903425355338388\n",
      "SEED: 1392, FOLD: 1, EPOCH: 9, train_loss: 0.008672104878486067\n",
      "SEED: 1392, FOLD: 1, EPOCH: 9, valid_loss: 0.008824287603298822\n",
      "SEED: 1392, FOLD: 1, EPOCH: 10, train_loss: 0.008553292737274931\n",
      "SEED: 1392, FOLD: 1, EPOCH: 10, valid_loss: 0.008775591229399046\n",
      "SEED: 1392, FOLD: 1, EPOCH: 11, train_loss: 0.008408753943724045\n",
      "SEED: 1392, FOLD: 1, EPOCH: 11, valid_loss: 0.008729710761043761\n",
      "SEED: 1392, FOLD: 1, EPOCH: 12, train_loss: 0.008275890000758396\n",
      "SEED: 1392, FOLD: 1, EPOCH: 12, valid_loss: 0.008679543828798665\n",
      "SEED: 1392, FOLD: 1, EPOCH: 13, train_loss: 0.008128136234438938\n",
      "SEED: 1392, FOLD: 1, EPOCH: 13, valid_loss: 0.008658326023982631\n",
      "SEED: 1392, FOLD: 1, EPOCH: 14, train_loss: 0.008041665477651184\n",
      "SEED: 1392, FOLD: 1, EPOCH: 14, valid_loss: 0.008649253079460727\n",
      "SEED: 1392, FOLD: 2, EPOCH: 0, train_loss: 0.6461694640093956\n",
      "SEED: 1392, FOLD: 2, EPOCH: 0, valid_loss: 0.2269555793868171\n",
      "SEED: 1392, FOLD: 2, EPOCH: 1, train_loss: 0.03543150213047646\n",
      "SEED: 1392, FOLD: 2, EPOCH: 1, valid_loss: 0.009434939982990423\n",
      "SEED: 1392, FOLD: 2, EPOCH: 2, train_loss: 0.009350454515737036\n",
      "SEED: 1392, FOLD: 2, EPOCH: 2, valid_loss: 0.009243707896934615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1392, FOLD: 2, EPOCH: 3, train_loss: 0.009239957532912924\n",
      "SEED: 1392, FOLD: 2, EPOCH: 3, valid_loss: 0.009387786707116498\n",
      "SEED: 1392, FOLD: 2, EPOCH: 4, train_loss: 0.00951617966959442\n",
      "SEED: 1392, FOLD: 2, EPOCH: 4, valid_loss: 0.00919986381712887\n",
      "SEED: 1392, FOLD: 2, EPOCH: 5, train_loss: 0.00897587062386067\n",
      "SEED: 1392, FOLD: 2, EPOCH: 5, valid_loss: 0.00910305707818932\n",
      "SEED: 1392, FOLD: 2, EPOCH: 6, train_loss: 0.008860149015874966\n",
      "SEED: 1392, FOLD: 2, EPOCH: 6, valid_loss: 0.009136162905229462\n",
      "SEED: 1392, FOLD: 2, EPOCH: 7, train_loss: 0.008779163472354412\n",
      "SEED: 1392, FOLD: 2, EPOCH: 7, valid_loss: 0.008994622776905695\n",
      "SEED: 1392, FOLD: 2, EPOCH: 8, train_loss: 0.00871269326603067\n",
      "SEED: 1392, FOLD: 2, EPOCH: 8, valid_loss: 0.008904378861188889\n",
      "SEED: 1392, FOLD: 2, EPOCH: 9, train_loss: 0.008648195276981678\n",
      "SEED: 1392, FOLD: 2, EPOCH: 9, valid_loss: 0.008891833014786243\n",
      "SEED: 1392, FOLD: 2, EPOCH: 10, train_loss: 0.00856969038537447\n",
      "SEED: 1392, FOLD: 2, EPOCH: 10, valid_loss: 0.008844756107363436\n",
      "SEED: 1392, FOLD: 2, EPOCH: 11, train_loss: 0.008422136090803837\n",
      "SEED: 1392, FOLD: 2, EPOCH: 11, valid_loss: 0.008776389269365205\n",
      "SEED: 1392, FOLD: 2, EPOCH: 12, train_loss: 0.008276496595446613\n",
      "SEED: 1392, FOLD: 2, EPOCH: 12, valid_loss: 0.008768559640480412\n",
      "SEED: 1392, FOLD: 2, EPOCH: 13, train_loss: 0.008126030473605446\n",
      "SEED: 1392, FOLD: 2, EPOCH: 13, valid_loss: 0.008720753197040822\n",
      "SEED: 1392, FOLD: 2, EPOCH: 14, train_loss: 0.008049940589167501\n",
      "SEED: 1392, FOLD: 2, EPOCH: 14, valid_loss: 0.008715392090380192\n",
      "SEED: 1392, FOLD: 3, EPOCH: 0, train_loss: 0.6473189104294431\n",
      "SEED: 1392, FOLD: 3, EPOCH: 0, valid_loss: 0.21742752856678432\n",
      "SEED: 1392, FOLD: 3, EPOCH: 1, train_loss: 0.03619320390988951\n",
      "SEED: 1392, FOLD: 3, EPOCH: 1, valid_loss: 0.009649821246663729\n",
      "SEED: 1392, FOLD: 3, EPOCH: 2, train_loss: 0.009338471275902744\n",
      "SEED: 1392, FOLD: 3, EPOCH: 2, valid_loss: 0.009471686970856454\n",
      "SEED: 1392, FOLD: 3, EPOCH: 3, train_loss: 0.00921301924340103\n",
      "SEED: 1392, FOLD: 3, EPOCH: 3, valid_loss: 0.009401941465006934\n",
      "SEED: 1392, FOLD: 3, EPOCH: 4, train_loss: 0.009191686179542887\n",
      "SEED: 1392, FOLD: 3, EPOCH: 4, valid_loss: 0.009470517126222452\n",
      "SEED: 1392, FOLD: 3, EPOCH: 5, train_loss: 0.008958313168714876\n",
      "SEED: 1392, FOLD: 3, EPOCH: 5, valid_loss: 0.009250821649200387\n",
      "SEED: 1392, FOLD: 3, EPOCH: 6, train_loss: 0.008810042909791937\n",
      "SEED: 1392, FOLD: 3, EPOCH: 6, valid_loss: 0.00930462053252591\n",
      "SEED: 1392, FOLD: 3, EPOCH: 7, train_loss: 0.008761891724028881\n",
      "SEED: 1392, FOLD: 3, EPOCH: 7, valid_loss: 0.009184370748698711\n",
      "SEED: 1392, FOLD: 3, EPOCH: 8, train_loss: 0.00869312085400241\n",
      "SEED: 1392, FOLD: 3, EPOCH: 8, valid_loss: 0.00910490658134222\n",
      "SEED: 1392, FOLD: 3, EPOCH: 9, train_loss: 0.008589110289956781\n",
      "SEED: 1392, FOLD: 3, EPOCH: 9, valid_loss: 0.009059667276839415\n",
      "SEED: 1392, FOLD: 3, EPOCH: 10, train_loss: 0.0085231166643401\n",
      "SEED: 1392, FOLD: 3, EPOCH: 10, valid_loss: 0.009007649082276557\n",
      "SEED: 1392, FOLD: 3, EPOCH: 11, train_loss: 0.008363462242203346\n",
      "SEED: 1392, FOLD: 3, EPOCH: 11, valid_loss: 0.008943220600485802\n",
      "SEED: 1392, FOLD: 3, EPOCH: 12, train_loss: 0.008235535287446734\n",
      "SEED: 1392, FOLD: 3, EPOCH: 12, valid_loss: 0.008929716009232733\n",
      "SEED: 1392, FOLD: 3, EPOCH: 13, train_loss: 0.008087345655413641\n",
      "SEED: 1392, FOLD: 3, EPOCH: 13, valid_loss: 0.008910537283453677\n",
      "SEED: 1392, FOLD: 3, EPOCH: 14, train_loss: 0.007992632714086685\n",
      "SEED: 1392, FOLD: 3, EPOCH: 14, valid_loss: 0.008903844075070487\n",
      "SEED: 1392, FOLD: 4, EPOCH: 0, train_loss: 0.6462228414805039\n",
      "SEED: 1392, FOLD: 4, EPOCH: 0, valid_loss: 0.24144312408235338\n",
      "SEED: 1392, FOLD: 4, EPOCH: 1, train_loss: 0.035840351593451225\n",
      "SEED: 1392, FOLD: 4, EPOCH: 1, valid_loss: 0.009215871596501933\n",
      "SEED: 1392, FOLD: 4, EPOCH: 2, train_loss: 0.009423093249400457\n",
      "SEED: 1392, FOLD: 4, EPOCH: 2, valid_loss: 0.008936892160111003\n",
      "SEED: 1392, FOLD: 4, EPOCH: 3, train_loss: 0.009335137134336906\n",
      "SEED: 1392, FOLD: 4, EPOCH: 3, valid_loss: 0.009941440386076769\n",
      "SEED: 1392, FOLD: 4, EPOCH: 4, train_loss: 0.009612714696297611\n",
      "SEED: 1392, FOLD: 4, EPOCH: 4, valid_loss: 0.008880770040882958\n",
      "SEED: 1392, FOLD: 4, EPOCH: 5, train_loss: 0.009074310036511093\n",
      "SEED: 1392, FOLD: 4, EPOCH: 5, valid_loss: 0.008827636225355996\n",
      "SEED: 1392, FOLD: 4, EPOCH: 6, train_loss: 0.008964226034510395\n",
      "SEED: 1392, FOLD: 4, EPOCH: 6, valid_loss: 0.008754029766552977\n",
      "SEED: 1392, FOLD: 4, EPOCH: 7, train_loss: 0.008866753422425709\n",
      "SEED: 1392, FOLD: 4, EPOCH: 7, valid_loss: 0.008708085347380903\n",
      "SEED: 1392, FOLD: 4, EPOCH: 8, train_loss: 0.008811168534600216\n",
      "SEED: 1392, FOLD: 4, EPOCH: 8, valid_loss: 0.008625508906940619\n",
      "SEED: 1392, FOLD: 4, EPOCH: 9, train_loss: 0.008713657238885113\n",
      "SEED: 1392, FOLD: 4, EPOCH: 9, valid_loss: 0.008570239051348634\n",
      "SEED: 1392, FOLD: 4, EPOCH: 10, train_loss: 0.008610034948619812\n",
      "SEED: 1392, FOLD: 4, EPOCH: 10, valid_loss: 0.008531532043384181\n",
      "SEED: 1392, FOLD: 4, EPOCH: 11, train_loss: 0.008503203509726387\n",
      "SEED: 1392, FOLD: 4, EPOCH: 11, valid_loss: 0.008499282722671827\n",
      "SEED: 1392, FOLD: 4, EPOCH: 12, train_loss: 0.008350066240013077\n",
      "SEED: 1392, FOLD: 4, EPOCH: 12, valid_loss: 0.008450502426260047\n",
      "SEED: 1392, FOLD: 4, EPOCH: 13, train_loss: 0.008188285109033619\n",
      "SEED: 1392, FOLD: 4, EPOCH: 13, valid_loss: 0.008429290623300605\n",
      "SEED: 1392, FOLD: 4, EPOCH: 14, train_loss: 0.00809751000876228\n",
      "SEED: 1392, FOLD: 4, EPOCH: 14, valid_loss: 0.00842319977366262\n",
      "elapsed time: 266.97433257102966\n",
      "SEED: 1119, FOLD: 0, EPOCH: 0, train_loss: 0.6470641076996706\n",
      "SEED: 1119, FOLD: 0, EPOCH: 0, valid_loss: 0.2160993350876702\n",
      "SEED: 1119, FOLD: 0, EPOCH: 1, train_loss: 0.035793235633468284\n",
      "SEED: 1119, FOLD: 0, EPOCH: 1, valid_loss: 0.009506250628166728\n",
      "SEED: 1119, FOLD: 0, EPOCH: 2, train_loss: 0.009404954136065815\n",
      "SEED: 1119, FOLD: 0, EPOCH: 2, valid_loss: 0.009219064687689146\n",
      "SEED: 1119, FOLD: 0, EPOCH: 3, train_loss: 0.009292524874858234\n",
      "SEED: 1119, FOLD: 0, EPOCH: 3, valid_loss: 0.009431209932598803\n",
      "SEED: 1119, FOLD: 0, EPOCH: 4, train_loss: 0.009164445061722527\n",
      "SEED: 1119, FOLD: 0, EPOCH: 4, valid_loss: 0.009085877177615961\n",
      "SEED: 1119, FOLD: 0, EPOCH: 5, train_loss: 0.008978357612816752\n",
      "SEED: 1119, FOLD: 0, EPOCH: 5, valid_loss: 0.01121520706348949\n",
      "SEED: 1119, FOLD: 0, EPOCH: 6, train_loss: 0.009950114360106165\n",
      "SEED: 1119, FOLD: 0, EPOCH: 6, valid_loss: 0.009122325831817256\n",
      "SEED: 1119, FOLD: 0, EPOCH: 7, train_loss: 0.008998588685864124\n",
      "SEED: 1119, FOLD: 0, EPOCH: 7, valid_loss: 0.009010839689936902\n",
      "SEED: 1119, FOLD: 0, EPOCH: 8, train_loss: 0.008896418044046648\n",
      "SEED: 1119, FOLD: 0, EPOCH: 8, valid_loss: 0.008899863188465437\n",
      "SEED: 1119, FOLD: 0, EPOCH: 9, train_loss: 0.008790646969894136\n",
      "SEED: 1119, FOLD: 0, EPOCH: 9, valid_loss: 0.008909086179402139\n",
      "SEED: 1119, FOLD: 0, EPOCH: 10, train_loss: 0.008698275252042906\n",
      "SEED: 1119, FOLD: 0, EPOCH: 10, valid_loss: 0.008828750190635523\n",
      "SEED: 1119, FOLD: 0, EPOCH: 11, train_loss: 0.008605820025600817\n",
      "SEED: 1119, FOLD: 0, EPOCH: 11, valid_loss: 0.008775300863716338\n",
      "SEED: 1119, FOLD: 0, EPOCH: 12, train_loss: 0.008486604426002157\n",
      "SEED: 1119, FOLD: 0, EPOCH: 12, valid_loss: 0.008793773336542977\n",
      "SEED: 1119, FOLD: 0, EPOCH: 13, train_loss: 0.008374519666413898\n",
      "SEED: 1119, FOLD: 0, EPOCH: 13, valid_loss: 0.008776273371444808\n",
      "SEED: 1119, FOLD: 0, EPOCH: 14, train_loss: 0.008298456189695044\n",
      "SEED: 1119, FOLD: 0, EPOCH: 14, valid_loss: 0.008761539123952389\n",
      "SEED: 1119, FOLD: 1, EPOCH: 0, train_loss: 0.646098142300827\n",
      "SEED: 1119, FOLD: 1, EPOCH: 0, valid_loss: 0.21818347109688652\n",
      "SEED: 1119, FOLD: 1, EPOCH: 1, train_loss: 0.035514636829063514\n",
      "SEED: 1119, FOLD: 1, EPOCH: 1, valid_loss: 0.0094484549222721\n",
      "SEED: 1119, FOLD: 1, EPOCH: 2, train_loss: 0.009364037572041801\n",
      "SEED: 1119, FOLD: 1, EPOCH: 2, valid_loss: 0.00916474260803726\n",
      "SEED: 1119, FOLD: 1, EPOCH: 3, train_loss: 0.009205854457357655\n",
      "SEED: 1119, FOLD: 1, EPOCH: 3, valid_loss: 0.009198388498690393\n",
      "SEED: 1119, FOLD: 1, EPOCH: 4, train_loss: 0.009130356347431307\n",
      "SEED: 1119, FOLD: 1, EPOCH: 4, valid_loss: 0.009069580998685624\n",
      "SEED: 1119, FOLD: 1, EPOCH: 5, train_loss: 0.00896115225834259\n",
      "SEED: 1119, FOLD: 1, EPOCH: 5, valid_loss: 0.00898999927772416\n",
      "SEED: 1119, FOLD: 1, EPOCH: 6, train_loss: 0.00888792584663716\n",
      "SEED: 1119, FOLD: 1, EPOCH: 6, valid_loss: 0.008991153496834967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1119, FOLD: 1, EPOCH: 7, train_loss: 0.00877867470346931\n",
      "SEED: 1119, FOLD: 1, EPOCH: 7, valid_loss: 0.009343893267214298\n",
      "SEED: 1119, FOLD: 1, EPOCH: 8, train_loss: 0.008747352590865416\n",
      "SEED: 1119, FOLD: 1, EPOCH: 8, valid_loss: 0.008880674735539489\n",
      "SEED: 1119, FOLD: 1, EPOCH: 9, train_loss: 0.008638572487710178\n",
      "SEED: 1119, FOLD: 1, EPOCH: 9, valid_loss: 0.008848061060739888\n",
      "SEED: 1119, FOLD: 1, EPOCH: 10, train_loss: 0.008548322066232779\n",
      "SEED: 1119, FOLD: 1, EPOCH: 10, valid_loss: 0.008797477930784225\n",
      "SEED: 1119, FOLD: 1, EPOCH: 11, train_loss: 0.008415683300868757\n",
      "SEED: 1119, FOLD: 1, EPOCH: 11, valid_loss: 0.008750847230354944\n",
      "SEED: 1119, FOLD: 1, EPOCH: 12, train_loss: 0.008268682772050734\n",
      "SEED: 1119, FOLD: 1, EPOCH: 12, valid_loss: 0.008690587865809599\n",
      "SEED: 1119, FOLD: 1, EPOCH: 13, train_loss: 0.008126122229125189\n",
      "SEED: 1119, FOLD: 1, EPOCH: 13, valid_loss: 0.00867564096632931\n",
      "SEED: 1119, FOLD: 1, EPOCH: 14, train_loss: 0.008021276626411987\n",
      "SEED: 1119, FOLD: 1, EPOCH: 14, valid_loss: 0.008668726620574793\n",
      "SEED: 1119, FOLD: 2, EPOCH: 0, train_loss: 0.6481170831383138\n",
      "SEED: 1119, FOLD: 2, EPOCH: 0, valid_loss: 0.21758535338772667\n",
      "SEED: 1119, FOLD: 2, EPOCH: 1, train_loss: 0.03613200952447411\n",
      "SEED: 1119, FOLD: 2, EPOCH: 1, valid_loss: 0.009402391190330187\n",
      "SEED: 1119, FOLD: 2, EPOCH: 2, train_loss: 0.009336574489007826\n",
      "SEED: 1119, FOLD: 2, EPOCH: 2, valid_loss: 0.009218833823170926\n",
      "SEED: 1119, FOLD: 2, EPOCH: 3, train_loss: 0.009249738755001537\n",
      "SEED: 1119, FOLD: 2, EPOCH: 3, valid_loss: 0.00962650165375736\n",
      "SEED: 1119, FOLD: 2, EPOCH: 4, train_loss: 0.009147303070927012\n",
      "SEED: 1119, FOLD: 2, EPOCH: 4, valid_loss: 0.009112730208370421\n",
      "SEED: 1119, FOLD: 2, EPOCH: 5, train_loss: 0.009000083505837381\n",
      "SEED: 1119, FOLD: 2, EPOCH: 5, valid_loss: 0.009107238716549344\n",
      "SEED: 1119, FOLD: 2, EPOCH: 6, train_loss: 0.008896831247577633\n",
      "SEED: 1119, FOLD: 2, EPOCH: 6, valid_loss: 0.009718188602063391\n",
      "SEED: 1119, FOLD: 2, EPOCH: 7, train_loss: 0.00884281999795981\n",
      "SEED: 1119, FOLD: 2, EPOCH: 7, valid_loss: 0.008919530341194736\n",
      "SEED: 1119, FOLD: 2, EPOCH: 8, train_loss: 0.008708493919044302\n",
      "SEED: 1119, FOLD: 2, EPOCH: 8, valid_loss: 0.008895562961697578\n",
      "SEED: 1119, FOLD: 2, EPOCH: 9, train_loss: 0.008660400488778301\n",
      "SEED: 1119, FOLD: 2, EPOCH: 9, valid_loss: 0.008885857442186939\n",
      "SEED: 1119, FOLD: 2, EPOCH: 10, train_loss: 0.008561548162791609\n",
      "SEED: 1119, FOLD: 2, EPOCH: 10, valid_loss: 0.00883446354418993\n",
      "SEED: 1119, FOLD: 2, EPOCH: 11, train_loss: 0.008471002127381338\n",
      "SEED: 1119, FOLD: 2, EPOCH: 11, valid_loss: 0.008805774980121188\n",
      "SEED: 1119, FOLD: 2, EPOCH: 12, train_loss: 0.008334499203424522\n",
      "SEED: 1119, FOLD: 2, EPOCH: 12, valid_loss: 0.008754473800460497\n",
      "SEED: 1119, FOLD: 2, EPOCH: 13, train_loss: 0.008190502756801636\n",
      "SEED: 1119, FOLD: 2, EPOCH: 13, valid_loss: 0.008748808358278539\n",
      "SEED: 1119, FOLD: 2, EPOCH: 14, train_loss: 0.008103491266028605\n",
      "SEED: 1119, FOLD: 2, EPOCH: 14, valid_loss: 0.008745288476347923\n",
      "SEED: 1119, FOLD: 3, EPOCH: 0, train_loss: 0.6475539360789285\n",
      "SEED: 1119, FOLD: 3, EPOCH: 0, valid_loss: 0.22579418619473776\n",
      "SEED: 1119, FOLD: 3, EPOCH: 1, train_loss: 0.03595349956573783\n",
      "SEED: 1119, FOLD: 3, EPOCH: 1, valid_loss: 0.009634537104931142\n",
      "SEED: 1119, FOLD: 3, EPOCH: 2, train_loss: 0.00935319597846356\n",
      "SEED: 1119, FOLD: 3, EPOCH: 2, valid_loss: 0.009448797648979558\n",
      "SEED: 1119, FOLD: 3, EPOCH: 3, train_loss: 0.009245879327257475\n",
      "SEED: 1119, FOLD: 3, EPOCH: 3, valid_loss: 0.009741956575049294\n",
      "SEED: 1119, FOLD: 3, EPOCH: 4, train_loss: 0.009138897054599247\n",
      "SEED: 1119, FOLD: 3, EPOCH: 4, valid_loss: 0.009241957941816913\n",
      "SEED: 1119, FOLD: 3, EPOCH: 5, train_loss: 0.00894548384256769\n",
      "SEED: 1119, FOLD: 3, EPOCH: 5, valid_loss: 0.010010458218554655\n",
      "SEED: 1119, FOLD: 3, EPOCH: 6, train_loss: 0.008826662313894949\n",
      "SEED: 1119, FOLD: 3, EPOCH: 6, valid_loss: 0.00921628013667133\n",
      "SEED: 1119, FOLD: 3, EPOCH: 7, train_loss: 0.008735150071805801\n",
      "SEED: 1119, FOLD: 3, EPOCH: 7, valid_loss: 0.009155629927085506\n",
      "SEED: 1119, FOLD: 3, EPOCH: 8, train_loss: 0.008654409439127514\n",
      "SEED: 1119, FOLD: 3, EPOCH: 8, valid_loss: 0.009188815951347351\n",
      "SEED: 1119, FOLD: 3, EPOCH: 9, train_loss: 0.008581871875440296\n",
      "SEED: 1119, FOLD: 3, EPOCH: 9, valid_loss: 0.009047541456917921\n",
      "SEED: 1119, FOLD: 3, EPOCH: 10, train_loss: 0.008469880322345358\n",
      "SEED: 1119, FOLD: 3, EPOCH: 10, valid_loss: 0.008988481014966965\n",
      "SEED: 1119, FOLD: 3, EPOCH: 11, train_loss: 0.008339491625572893\n",
      "SEED: 1119, FOLD: 3, EPOCH: 11, valid_loss: 0.008938628973232375\n",
      "SEED: 1119, FOLD: 3, EPOCH: 12, train_loss: 0.008183052601373714\n",
      "SEED: 1119, FOLD: 3, EPOCH: 12, valid_loss: 0.008906513245569335\n",
      "SEED: 1119, FOLD: 3, EPOCH: 13, train_loss: 0.008033043758916681\n",
      "SEED: 1119, FOLD: 3, EPOCH: 13, valid_loss: 0.008885315515928797\n",
      "SEED: 1119, FOLD: 3, EPOCH: 14, train_loss: 0.007944492110307667\n",
      "SEED: 1119, FOLD: 3, EPOCH: 14, valid_loss: 0.008882804670267634\n",
      "SEED: 1119, FOLD: 4, EPOCH: 0, train_loss: 0.6477448177942331\n",
      "SEED: 1119, FOLD: 4, EPOCH: 0, valid_loss: 0.23243807752927145\n",
      "SEED: 1119, FOLD: 4, EPOCH: 1, train_loss: 0.036022553031427276\n",
      "SEED: 1119, FOLD: 4, EPOCH: 1, valid_loss: 0.009281146857473586\n",
      "SEED: 1119, FOLD: 4, EPOCH: 2, train_loss: 0.009491294878872408\n",
      "SEED: 1119, FOLD: 4, EPOCH: 2, valid_loss: 0.008907734002504084\n",
      "SEED: 1119, FOLD: 4, EPOCH: 3, train_loss: 0.009281322953925617\n",
      "SEED: 1119, FOLD: 4, EPOCH: 3, valid_loss: 0.008864912204444408\n",
      "SEED: 1119, FOLD: 4, EPOCH: 4, train_loss: 0.009424684987659904\n",
      "SEED: 1119, FOLD: 4, EPOCH: 4, valid_loss: 0.008839869354334142\n",
      "SEED: 1119, FOLD: 4, EPOCH: 5, train_loss: 0.00903948607004207\n",
      "SEED: 1119, FOLD: 4, EPOCH: 5, valid_loss: 0.008772473885781236\n",
      "SEED: 1119, FOLD: 4, EPOCH: 6, train_loss: 0.008917006650480671\n",
      "SEED: 1119, FOLD: 4, EPOCH: 6, valid_loss: 0.008679705982406935\n",
      "SEED: 1119, FOLD: 4, EPOCH: 7, train_loss: 0.008855486086205296\n",
      "SEED: 1119, FOLD: 4, EPOCH: 7, valid_loss: 0.008965103990501828\n",
      "SEED: 1119, FOLD: 4, EPOCH: 8, train_loss: 0.008832128731992798\n",
      "SEED: 1119, FOLD: 4, EPOCH: 8, valid_loss: 0.008655259592665566\n",
      "SEED: 1119, FOLD: 4, EPOCH: 9, train_loss: 0.008716130075787289\n",
      "SEED: 1119, FOLD: 4, EPOCH: 9, valid_loss: 0.00859446544200182\n",
      "SEED: 1119, FOLD: 4, EPOCH: 10, train_loss: 0.008617587920710228\n",
      "SEED: 1119, FOLD: 4, EPOCH: 10, valid_loss: 0.008554307123025259\n",
      "SEED: 1119, FOLD: 4, EPOCH: 11, train_loss: 0.008505867571448502\n",
      "SEED: 1119, FOLD: 4, EPOCH: 11, valid_loss: 0.008481458036435975\n",
      "SEED: 1119, FOLD: 4, EPOCH: 12, train_loss: 0.008365268231895954\n",
      "SEED: 1119, FOLD: 4, EPOCH: 12, valid_loss: 0.008440541931324534\n",
      "SEED: 1119, FOLD: 4, EPOCH: 13, train_loss: 0.008222275265101074\n",
      "SEED: 1119, FOLD: 4, EPOCH: 13, valid_loss: 0.008434013773997625\n",
      "SEED: 1119, FOLD: 4, EPOCH: 14, train_loss: 0.008134085988706869\n",
      "SEED: 1119, FOLD: 4, EPOCH: 14, valid_loss: 0.008425614486138025\n",
      "elapsed time: 332.6917419433594\n",
      "SEED: 1303, FOLD: 0, EPOCH: 0, train_loss: 0.6476845279120017\n",
      "SEED: 1303, FOLD: 0, EPOCH: 0, valid_loss: 0.21050490107801226\n",
      "SEED: 1303, FOLD: 0, EPOCH: 1, train_loss: 0.03622429153841475\n",
      "SEED: 1303, FOLD: 0, EPOCH: 1, valid_loss: 0.009430278299583329\n",
      "SEED: 1303, FOLD: 0, EPOCH: 2, train_loss: 0.009431750243664652\n",
      "SEED: 1303, FOLD: 0, EPOCH: 2, valid_loss: 0.009150346120198568\n",
      "SEED: 1303, FOLD: 0, EPOCH: 3, train_loss: 0.009294845069340174\n",
      "SEED: 1303, FOLD: 0, EPOCH: 3, valid_loss: 0.009419923648238182\n",
      "SEED: 1303, FOLD: 0, EPOCH: 4, train_loss: 0.009240738001476595\n",
      "SEED: 1303, FOLD: 0, EPOCH: 4, valid_loss: 0.00910514582776361\n",
      "SEED: 1303, FOLD: 0, EPOCH: 5, train_loss: 0.00897199983128171\n",
      "SEED: 1303, FOLD: 0, EPOCH: 5, valid_loss: 0.009028529023958577\n",
      "SEED: 1303, FOLD: 0, EPOCH: 6, train_loss: 0.008887353555663773\n",
      "SEED: 1303, FOLD: 0, EPOCH: 6, valid_loss: 0.008897204365995195\n",
      "SEED: 1303, FOLD: 0, EPOCH: 7, train_loss: 0.008772630993600773\n",
      "SEED: 1303, FOLD: 0, EPOCH: 7, valid_loss: 0.008890155495868789\n",
      "SEED: 1303, FOLD: 0, EPOCH: 8, train_loss: 0.008735910172749689\n",
      "SEED: 1303, FOLD: 0, EPOCH: 8, valid_loss: 0.008900427466465367\n",
      "SEED: 1303, FOLD: 0, EPOCH: 9, train_loss: 0.008682447208928457\n",
      "SEED: 1303, FOLD: 0, EPOCH: 9, valid_loss: 0.008849665108654235\n",
      "SEED: 1303, FOLD: 0, EPOCH: 10, train_loss: 0.00855607416588759\n",
      "SEED: 1303, FOLD: 0, EPOCH: 10, valid_loss: 0.008768788849314054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1303, FOLD: 0, EPOCH: 11, train_loss: 0.008439547746725704\n",
      "SEED: 1303, FOLD: 0, EPOCH: 11, valid_loss: 0.008684808181391822\n",
      "SEED: 1303, FOLD: 0, EPOCH: 12, train_loss: 0.0082702806043992\n",
      "SEED: 1303, FOLD: 0, EPOCH: 12, valid_loss: 0.008689545922809176\n",
      "SEED: 1303, FOLD: 0, EPOCH: 13, train_loss: 0.008129751728172752\n",
      "SEED: 1303, FOLD: 0, EPOCH: 13, valid_loss: 0.008669589646160603\n",
      "SEED: 1303, FOLD: 0, EPOCH: 14, train_loss: 0.008025898847836947\n",
      "SEED: 1303, FOLD: 0, EPOCH: 14, valid_loss: 0.00866048244966401\n",
      "SEED: 1303, FOLD: 1, EPOCH: 0, train_loss: 0.6479445661323658\n",
      "SEED: 1303, FOLD: 1, EPOCH: 0, valid_loss: 0.21327653527259827\n",
      "SEED: 1303, FOLD: 1, EPOCH: 1, train_loss: 0.03589669615030289\n",
      "SEED: 1303, FOLD: 1, EPOCH: 1, valid_loss: 0.009572753372291723\n",
      "SEED: 1303, FOLD: 1, EPOCH: 2, train_loss: 0.009462039728743443\n",
      "SEED: 1303, FOLD: 1, EPOCH: 2, valid_loss: 0.00924259444905652\n",
      "SEED: 1303, FOLD: 1, EPOCH: 3, train_loss: 0.009233669809781122\n",
      "SEED: 1303, FOLD: 1, EPOCH: 3, valid_loss: 0.00935017793542809\n",
      "SEED: 1303, FOLD: 1, EPOCH: 4, train_loss: 0.010256484042907106\n",
      "SEED: 1303, FOLD: 1, EPOCH: 4, valid_loss: 0.009526852000918653\n",
      "SEED: 1303, FOLD: 1, EPOCH: 5, train_loss: 0.009194255583798107\n",
      "SEED: 1303, FOLD: 1, EPOCH: 5, valid_loss: 0.009191035086082088\n",
      "SEED: 1303, FOLD: 1, EPOCH: 6, train_loss: 0.009003984606892302\n",
      "SEED: 1303, FOLD: 1, EPOCH: 6, valid_loss: 0.009022730402648449\n",
      "SEED: 1303, FOLD: 1, EPOCH: 7, train_loss: 0.008904082457656446\n",
      "SEED: 1303, FOLD: 1, EPOCH: 7, valid_loss: 0.008986065267688699\n",
      "SEED: 1303, FOLD: 1, EPOCH: 8, train_loss: 0.008833903380656156\n",
      "SEED: 1303, FOLD: 1, EPOCH: 8, valid_loss: 0.00896948989894655\n",
      "SEED: 1303, FOLD: 1, EPOCH: 9, train_loss: 0.008737510772071022\n",
      "SEED: 1303, FOLD: 1, EPOCH: 9, valid_loss: 0.00891365638623635\n",
      "SEED: 1303, FOLD: 1, EPOCH: 10, train_loss: 0.00863227023459647\n",
      "SEED: 1303, FOLD: 1, EPOCH: 10, valid_loss: 0.008819657377898693\n",
      "SEED: 1303, FOLD: 1, EPOCH: 11, train_loss: 0.008503366808366516\n",
      "SEED: 1303, FOLD: 1, EPOCH: 11, valid_loss: 0.00877712925689088\n",
      "SEED: 1303, FOLD: 1, EPOCH: 12, train_loss: 0.008323023493901112\n",
      "SEED: 1303, FOLD: 1, EPOCH: 12, valid_loss: 0.00873726544280847\n",
      "SEED: 1303, FOLD: 1, EPOCH: 13, train_loss: 0.00817038292956093\n",
      "SEED: 1303, FOLD: 1, EPOCH: 13, valid_loss: 0.008725135069754388\n",
      "SEED: 1303, FOLD: 1, EPOCH: 14, train_loss: 0.008052480211346478\n",
      "SEED: 1303, FOLD: 1, EPOCH: 14, valid_loss: 0.008716345557736026\n",
      "SEED: 1303, FOLD: 2, EPOCH: 0, train_loss: 0.6475224717371706\n",
      "SEED: 1303, FOLD: 2, EPOCH: 0, valid_loss: 0.22198798093530867\n",
      "SEED: 1303, FOLD: 2, EPOCH: 1, train_loss: 0.035828434011858444\n",
      "SEED: 1303, FOLD: 2, EPOCH: 1, valid_loss: 0.009500924601323076\n",
      "SEED: 1303, FOLD: 2, EPOCH: 2, train_loss: 0.00944739550460076\n",
      "SEED: 1303, FOLD: 2, EPOCH: 2, valid_loss: 0.009354401793744829\n",
      "SEED: 1303, FOLD: 2, EPOCH: 3, train_loss: 0.009560883166673391\n",
      "SEED: 1303, FOLD: 2, EPOCH: 3, valid_loss: 0.00941202582584487\n",
      "SEED: 1303, FOLD: 2, EPOCH: 4, train_loss: 0.009104550370703573\n",
      "SEED: 1303, FOLD: 2, EPOCH: 4, valid_loss: 0.009090680525534682\n",
      "SEED: 1303, FOLD: 2, EPOCH: 5, train_loss: 0.008954184204070032\n",
      "SEED: 1303, FOLD: 2, EPOCH: 5, valid_loss: 0.009147861868970923\n",
      "SEED: 1303, FOLD: 2, EPOCH: 6, train_loss: 0.008882888322831064\n",
      "SEED: 1303, FOLD: 2, EPOCH: 6, valid_loss: 0.008980771009292867\n",
      "SEED: 1303, FOLD: 2, EPOCH: 7, train_loss: 0.008769392906485693\n",
      "SEED: 1303, FOLD: 2, EPOCH: 7, valid_loss: 0.008985341216127077\n",
      "SEED: 1303, FOLD: 2, EPOCH: 8, train_loss: 0.008732968954828339\n",
      "SEED: 1303, FOLD: 2, EPOCH: 8, valid_loss: 0.008982446769045459\n",
      "SEED: 1303, FOLD: 2, EPOCH: 9, train_loss: 0.008653738279489504\n",
      "SEED: 1303, FOLD: 2, EPOCH: 9, valid_loss: 0.008870501381655535\n",
      "SEED: 1303, FOLD: 2, EPOCH: 10, train_loss: 0.008527418841486391\n",
      "SEED: 1303, FOLD: 2, EPOCH: 10, valid_loss: 0.008821369148790836\n",
      "SEED: 1303, FOLD: 2, EPOCH: 11, train_loss: 0.008408018414848957\n",
      "SEED: 1303, FOLD: 2, EPOCH: 11, valid_loss: 0.008838509519894918\n",
      "SEED: 1303, FOLD: 2, EPOCH: 12, train_loss: 0.008263606571362934\n",
      "SEED: 1303, FOLD: 2, EPOCH: 12, valid_loss: 0.008725223855839835\n",
      "SEED: 1303, FOLD: 2, EPOCH: 13, train_loss: 0.008108084279018036\n",
      "SEED: 1303, FOLD: 2, EPOCH: 13, valid_loss: 0.008710204002757868\n",
      "SEED: 1303, FOLD: 2, EPOCH: 14, train_loss: 0.008030532731040232\n",
      "SEED: 1303, FOLD: 2, EPOCH: 14, valid_loss: 0.008708261677788364\n",
      "SEED: 1303, FOLD: 3, EPOCH: 0, train_loss: 0.6474958308365034\n",
      "SEED: 1303, FOLD: 3, EPOCH: 0, valid_loss: 0.21152711576885647\n",
      "SEED: 1303, FOLD: 3, EPOCH: 1, train_loss: 0.035788048396183963\n",
      "SEED: 1303, FOLD: 3, EPOCH: 1, valid_loss: 0.009733653316895166\n",
      "SEED: 1303, FOLD: 3, EPOCH: 2, train_loss: 0.009313213416253742\n",
      "SEED: 1303, FOLD: 3, EPOCH: 2, valid_loss: 0.009392463705605932\n",
      "SEED: 1303, FOLD: 3, EPOCH: 3, train_loss: 0.009230303119166174\n",
      "SEED: 1303, FOLD: 3, EPOCH: 3, valid_loss: 0.009433101552228132\n",
      "SEED: 1303, FOLD: 3, EPOCH: 4, train_loss: 0.009103158576602953\n",
      "SEED: 1303, FOLD: 3, EPOCH: 4, valid_loss: 0.009373423643410206\n",
      "SEED: 1303, FOLD: 3, EPOCH: 5, train_loss: 0.008918448999200178\n",
      "SEED: 1303, FOLD: 3, EPOCH: 5, valid_loss: 0.009240983467963006\n",
      "SEED: 1303, FOLD: 3, EPOCH: 6, train_loss: 0.008907952669845976\n",
      "SEED: 1303, FOLD: 3, EPOCH: 6, valid_loss: 0.009313771915104654\n",
      "SEED: 1303, FOLD: 3, EPOCH: 7, train_loss: 0.008774188178442959\n",
      "SEED: 1303, FOLD: 3, EPOCH: 7, valid_loss: 0.00911618758820825\n",
      "SEED: 1303, FOLD: 3, EPOCH: 8, train_loss: 0.008684892268122538\n",
      "SEED: 1303, FOLD: 3, EPOCH: 8, valid_loss: 0.009154220215148397\n",
      "SEED: 1303, FOLD: 3, EPOCH: 9, train_loss: 0.008626340888440609\n",
      "SEED: 1303, FOLD: 3, EPOCH: 9, valid_loss: 0.009089382158385383\n",
      "SEED: 1303, FOLD: 3, EPOCH: 10, train_loss: 0.008535558843742247\n",
      "SEED: 1303, FOLD: 3, EPOCH: 10, valid_loss: 0.009017556698785888\n",
      "SEED: 1303, FOLD: 3, EPOCH: 11, train_loss: 0.008424812711883282\n",
      "SEED: 1303, FOLD: 3, EPOCH: 11, valid_loss: 0.008965394459664822\n",
      "SEED: 1303, FOLD: 3, EPOCH: 12, train_loss: 0.008272661948981493\n",
      "SEED: 1303, FOLD: 3, EPOCH: 12, valid_loss: 0.00892258652796348\n",
      "SEED: 1303, FOLD: 3, EPOCH: 13, train_loss: 0.008145548410011806\n",
      "SEED: 1303, FOLD: 3, EPOCH: 13, valid_loss: 0.008913318523102336\n",
      "SEED: 1303, FOLD: 3, EPOCH: 14, train_loss: 0.008051361078801363\n",
      "SEED: 1303, FOLD: 3, EPOCH: 14, valid_loss: 0.008902049623429775\n",
      "SEED: 1303, FOLD: 4, EPOCH: 0, train_loss: 0.6482737178819767\n",
      "SEED: 1303, FOLD: 4, EPOCH: 0, valid_loss: 0.21620087160004509\n",
      "SEED: 1303, FOLD: 4, EPOCH: 1, train_loss: 0.035900602832544544\n",
      "SEED: 1303, FOLD: 4, EPOCH: 1, valid_loss: 0.009182636212143633\n",
      "SEED: 1303, FOLD: 4, EPOCH: 2, train_loss: 0.009451823268571625\n",
      "SEED: 1303, FOLD: 4, EPOCH: 2, valid_loss: 0.009159831226699881\n",
      "SEED: 1303, FOLD: 4, EPOCH: 3, train_loss: 0.009357088866333166\n",
      "SEED: 1303, FOLD: 4, EPOCH: 3, valid_loss: 0.0090502490186029\n",
      "SEED: 1303, FOLD: 4, EPOCH: 4, train_loss: 0.009361557527512743\n",
      "SEED: 1303, FOLD: 4, EPOCH: 4, valid_loss: 0.008888722914788458\n",
      "SEED: 1303, FOLD: 4, EPOCH: 5, train_loss: 0.009052773316701254\n",
      "SEED: 1303, FOLD: 4, EPOCH: 5, valid_loss: 0.008772252644929621\n",
      "SEED: 1303, FOLD: 4, EPOCH: 6, train_loss: 0.009582223762096703\n",
      "SEED: 1303, FOLD: 4, EPOCH: 6, valid_loss: 0.009979438968002796\n",
      "SEED: 1303, FOLD: 4, EPOCH: 7, train_loss: 0.009242394277690977\n",
      "SEED: 1303, FOLD: 4, EPOCH: 7, valid_loss: 0.008854079991579056\n",
      "SEED: 1303, FOLD: 4, EPOCH: 8, train_loss: 0.009009033785728008\n",
      "SEED: 1303, FOLD: 4, EPOCH: 8, valid_loss: 0.00874064096974002\n",
      "SEED: 1303, FOLD: 4, EPOCH: 9, train_loss: 0.008910622825657112\n",
      "SEED: 1303, FOLD: 4, EPOCH: 9, valid_loss: 0.008683459626303779\n",
      "SEED: 1303, FOLD: 4, EPOCH: 10, train_loss: 0.008829658560832773\n",
      "SEED: 1303, FOLD: 4, EPOCH: 10, valid_loss: 0.008617627537912793\n",
      "SEED: 1303, FOLD: 4, EPOCH: 11, train_loss: 0.008721792793738237\n",
      "SEED: 1303, FOLD: 4, EPOCH: 11, valid_loss: 0.00859371531340811\n",
      "SEED: 1303, FOLD: 4, EPOCH: 12, train_loss: 0.00863343427983531\n",
      "SEED: 1303, FOLD: 4, EPOCH: 12, valid_loss: 0.00856226496398449\n",
      "SEED: 1303, FOLD: 4, EPOCH: 13, train_loss: 0.008515275427666695\n",
      "SEED: 1303, FOLD: 4, EPOCH: 13, valid_loss: 0.008533237708939446\n",
      "SEED: 1303, FOLD: 4, EPOCH: 14, train_loss: 0.00843522658544606\n",
      "SEED: 1303, FOLD: 4, EPOCH: 14, valid_loss: 0.00852994341403246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 398.201021194458\n",
      "(21948, 331)\n",
      "(3624, 331)\n"
     ]
    }
   ],
   "source": [
    "SEED = [940, 1513, 1269, 1392, 1119, 1303]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "for seed in SEED:\n",
    "\n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "    print(f\"elapsed time: {time.time() - time_start}\")\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions\n",
    "\n",
    "print(oof.shape)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:39:54.777818Z",
     "iopub.status.busy": "2020-11-26T05:39:54.776738Z",
     "iopub.status.idle": "2020-11-26T05:39:55.452574Z",
     "shell.execute_reply": "2020-11-26T05:39:55.451908Z"
    },
    "papermill": {
     "duration": 0.957526,
     "end_time": "2020-11-26T05:39:55.452699",
     "exception": false,
     "start_time": "2020-11-26T05:39:54.495173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.to_pickle(f\"{INT_DIR}/{NB}-train_nonscore_pred.pkl\")\n",
    "test.to_pickle(f\"{INT_DIR}/{NB}-test_nonscore_pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:39:56.014342Z",
     "iopub.status.busy": "2020-11-26T05:39:56.013570Z",
     "iopub.status.idle": "2020-11-26T05:39:56.019451Z",
     "shell.execute_reply": "2020-11-26T05:39:56.020058Z"
    },
    "papermill": {
     "duration": 0.289817,
     "end_time": "2020-11-26T05:39:56.020199",
     "exception": false,
     "start_time": "2020-11-26T05:39:55.730382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:39:56.622292Z",
     "iopub.status.busy": "2020-11-26T05:39:56.621021Z",
     "iopub.status.idle": "2020-11-26T05:39:58.962147Z",
     "shell.execute_reply": "2020-11-26T05:39:58.962718Z"
    },
    "papermill": {
     "duration": 2.648271,
     "end_time": "2020-11-26T05:39:58.962876",
     "exception": false,
     "start_time": "2020-11-26T05:39:56.314605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.004835599416713842\n"
     ]
    }
   ],
   "source": [
    "train[target_cols] = np.maximum(PMIN, np.minimum(PMAX, train[target_cols]))\n",
    "valid_results = train_targets_nonscored.drop(columns=target_cols).merge(\n",
    "    train[['sig_id'] + target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "y_true = train_targets_nonscored[target_cols].values\n",
    "y_true = y_true > 0.5\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "\n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.279152,
     "end_time": "2020-11-26T05:39:59.520941",
     "exception": false,
     "start_time": "2020-11-26T05:39:59.241789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "CV log_loss:  0.014761779358699672\n",
    "CV log_loss:  0.014519859174255039\n",
    "CV log_loss:  0.014525173864593479\n",
    "CV log_loss:  0.014354930596928602 # 3 umap features\n",
    "CV log_loss:  0.014353604854355429 # more umap features\n",
    "CV log_loss:  0.01436484670778641 # more hidden nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:00.092739Z",
     "iopub.status.busy": "2020-11-26T05:40:00.091533Z",
     "iopub.status.idle": "2020-11-26T05:40:00.093751Z",
     "shell.execute_reply": "2020-11-26T05:40:00.094316Z"
    },
    "papermill": {
     "duration": 0.286236,
     "end_time": "2020-11-26T05:40:00.094485",
     "exception": false,
     "start_time": "2020-11-26T05:39:59.808249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "# NFOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:00.656315Z",
     "iopub.status.busy": "2020-11-26T05:40:00.655596Z",
     "iopub.status.idle": "2020-11-26T05:40:00.660126Z",
     "shell.execute_reply": "2020-11-26T05:40:00.660675Z"
    },
    "papermill": {
     "duration": 0.287198,
     "end_time": "2020-11-26T05:40:00.660831",
     "exception": false,
     "start_time": "2020-11-26T05:40:00.373633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "# sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:01.267098Z",
     "iopub.status.busy": "2020-11-26T05:40:01.265017Z",
     "iopub.status.idle": "2020-11-26T05:40:01.267881Z",
     "shell.execute_reply": "2020-11-26T05:40:01.268448Z"
    },
    "papermill": {
     "duration": 0.308938,
     "end_time": "2020-11-26T05:40:01.268604",
     "exception": false,
     "start_time": "2020-11-26T05:40:00.959666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nonscored_target = [\n",
    "    c for c in train[train_targets_nonscored.columns] if c != \"sig_id\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:01.843910Z",
     "iopub.status.busy": "2020-11-26T05:40:01.842123Z",
     "iopub.status.idle": "2020-11-26T05:40:01.848048Z",
     "shell.execute_reply": "2020-11-26T05:40:01.848654Z"
    },
    "papermill": {
     "duration": 0.29991,
     "end_time": "2020-11-26T05:40:01.848817",
     "exception": false,
     "start_time": "2020-11-26T05:40:01.548907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc_transporter_expression_enhancer',\n",
       " 'abl_inhibitor',\n",
       " 'ace_inhibitor',\n",
       " 'acetylcholine_release_enhancer',\n",
       " 'adenosine_kinase_inhibitor',\n",
       " 'adenylyl_cyclase_inhibitor',\n",
       " 'age_inhibitor',\n",
       " 'alcohol_dehydrogenase_inhibitor',\n",
       " 'aldehyde_dehydrogenase_activator',\n",
       " 'aldose_reductase_inhibitor',\n",
       " 'ampk_inhibitor',\n",
       " 'androgen_biosynthesis_inhibitor',\n",
       " 'angiotensin_receptor_agonist',\n",
       " 'antacid',\n",
       " 'anthelmintic',\n",
       " 'antipruritic',\n",
       " 'antirheumatic_drug',\n",
       " 'antiseptic',\n",
       " 'antispasmodic',\n",
       " 'antithyroid_agent',\n",
       " 'antitussive',\n",
       " 'anxiolytic',\n",
       " 'ap_inhibitor',\n",
       " 'apoptosis_inhibitor',\n",
       " 'arf_inhibitor',\n",
       " 'aryl_hydrocarbon_receptor_agonist',\n",
       " 'aryl_hydrocarbon_receptor_antagonist',\n",
       " 'aspartic_protease_inhibitor',\n",
       " 'atherogenesis_inhibitor',\n",
       " 'atherosclerosis_formation_inhibitor',\n",
       " 'atp-sensitive_potassium_channel_agonist',\n",
       " 'atp-sensitive_potassium_channel_inhibitor',\n",
       " 'atp_channel_blocker',\n",
       " 'atp_citrase_lyase_inhibitor',\n",
       " 'autophagy_inducer',\n",
       " 'axl_kinase_inhibitor',\n",
       " 'bacterial_atpase_inhibitor',\n",
       " 'bacterial_permeability_inducer',\n",
       " 'bacterial_protein_synthesis_inhibitor',\n",
       " 'benzodiazepine_receptor_antagonist',\n",
       " 'beta_catenin_inhibitor',\n",
       " 'beta_lactamase_inhibitor',\n",
       " 'beta_secretase_inhibitor',\n",
       " 'big1_inhibitor',\n",
       " 'bile_acid',\n",
       " 'bone_resorption_inhibitor',\n",
       " 'botulin_neurotoxin_inhibitor',\n",
       " 'bradykinin_receptor_antagonist',\n",
       " 'breast_cancer_resistance_protein_inhibitor',\n",
       " 'bronchodilator',\n",
       " 'calcitonin_antagonist',\n",
       " 'calcium_channel_activator',\n",
       " 'calmodulin_inhibitor',\n",
       " 'camp_stimulant',\n",
       " 'capillary_stabilizing_agent',\n",
       " 'car_antagonist',\n",
       " 'carcinogen',\n",
       " 'carnitine_palmitoyltransferase_inhibitor',\n",
       " 'caspase_inhibitor',\n",
       " 'cathepsin_inhibitor',\n",
       " 'cc_chemokine_receptor_agonist',\n",
       " 'cdc_inhibitor',\n",
       " 'cdk_expression_enhancer',\n",
       " 'cell_cycle_inhibitor',\n",
       " 'ceramidase_inhibitor',\n",
       " 'cftr_channel_agonist',\n",
       " 'chitin_inhibitor',\n",
       " 'chloride_channel_activator',\n",
       " 'choleretic_agent',\n",
       " 'cholinergic_receptor_agonist',\n",
       " 'cholinesterase_inhibitor',\n",
       " 'clk_inhibitor',\n",
       " 'coenzyme_a_precursor',\n",
       " 'contraceptive_agent',\n",
       " 'contrast_agent',\n",
       " 'corticosteroid_antagonist',\n",
       " 'cyclin_d_inhibitor',\n",
       " 'cytidine_deaminase_inhibitor',\n",
       " 'cytokine_production_inhibitor',\n",
       " 'dehydrogenase_inhibitor',\n",
       " 'diacylglycerol_kinase_inhibitor',\n",
       " 'diacylglycerol_o_acyltransferase_inhibitor',\n",
       " 'differentiation_inducer',\n",
       " 'dihydroorotate_dehydrogenase_inhibitor',\n",
       " 'dihydropteroate_synthase_inhibitor',\n",
       " 'dihydropyrimidine_dehydrogenase_inhibitor',\n",
       " 'dna_dependent_protein_kinase_inhibitor',\n",
       " 'dna_methyltransferase_inhibitor',\n",
       " 'dna_polymerase_inhibitor',\n",
       " 'dna_synthesis_inhibitor',\n",
       " 'dopamine_release_enhancer',\n",
       " 'dot1l_inhibitor',\n",
       " 'dynamin_inhibitor',\n",
       " 'dyrk_inhibitor',\n",
       " 'endothelin_receptor_antagonist',\n",
       " 'enkephalinase_inhibitor',\n",
       " 'ephrin_inhibitor',\n",
       " 'epoxide_hydolase_inhibitor',\n",
       " 'eukaryotic_translation_initiation_factor_inhibitor',\n",
       " 'exportin_antagonist',\n",
       " 'fabi_inhibitor',\n",
       " 'farnesyl_pyrophosphate_synthase_inhibitor',\n",
       " 'fatty_acid_receptor_antagonist',\n",
       " 'fatty_acid_synthase_inhibitor',\n",
       " 'folate_receptor_ligand',\n",
       " 'fungal_ergosterol_inhibitor',\n",
       " 'fungal_lanosterol_demethylase_inhibitor',\n",
       " 'fxr_agonist',\n",
       " 'g_protein-coupled_receptor_agonist',\n",
       " 'g_protein-coupled_receptor_antagonist',\n",
       " 'g_protein_signaling_inhibitor',\n",
       " 'gaba_gated_chloride_channel_blocker',\n",
       " 'gaba_receptor_modulator',\n",
       " 'gaba_uptake_inhibitor',\n",
       " 'gap_junction_modulator',\n",
       " 'gastrin_inhibitor',\n",
       " 'gat_inhibitor',\n",
       " 'gli_antagonist',\n",
       " 'glp_receptor_agonist',\n",
       " 'glucagon_receptor_antagonist',\n",
       " 'glucocorticoid_receptor_antagonist',\n",
       " 'gluconeogenesis_inhibitor',\n",
       " 'glucose_dependent_insulinotropic_receptor_agonist',\n",
       " 'glucosidase_inhibitor',\n",
       " 'glutamate_receptor_modulator',\n",
       " 'glutathione_reductase_(nadph)_activators',\n",
       " 'glycine_receptor_antagonist',\n",
       " 'glycine_transporter_inhibitor',\n",
       " 'glycogen_phosphorylase_inhibitor',\n",
       " 'glycosylation_inhibitor',\n",
       " 'gonadotropin_receptor_antagonist',\n",
       " 'growth_factor_receptor_inhibitor',\n",
       " 'gtpase_inhibitor',\n",
       " 'guanylate_cyclase_activator',\n",
       " 'guanylyl_cyclase_activator',\n",
       " 'haemostatic_agent',\n",
       " 'hcn_channel_antagonist',\n",
       " 'hedgehog_pathway_inhibitor',\n",
       " 'heme_oxygenase_activators',\n",
       " 'hemoglobin_antagonist',\n",
       " 'hexokinase_inhibitor',\n",
       " 'hgf_receptor_inhibitor',\n",
       " 'hif_inhibitor',\n",
       " 'histamine_release_inhibitor',\n",
       " 'histone_acetyltransferase_inhibitor',\n",
       " 'histone_demethylase_inhibitor',\n",
       " 'hiv_integrase_inhibitor',\n",
       " 'hiv_protease_inhibitor',\n",
       " 'hydantoin_antiepileptic',\n",
       " 'hydroxycarboxylic_acid_receptor_agonist',\n",
       " 'icam1_antagonist',\n",
       " 'icam1_inhibitor',\n",
       " 'id1_expression_inhibitor',\n",
       " 'imidazoline_ligand',\n",
       " 'immunostimulant',\n",
       " 'indoleamine_2,3-dioxygenase_inhibitor',\n",
       " 'inosine_monophosphate_dehydrogenase_inhibitor',\n",
       " 'inositol_monophosphatase_inhibitor',\n",
       " 'interferon_inducer',\n",
       " 'interleukin_inhibitor',\n",
       " 'interleukin_receptor_agonist',\n",
       " 'ion_channel_antagonist',\n",
       " 'ip1_prostacyclin_receptor_agonist',\n",
       " 'isocitrate_dehydrogenase_inhibitor',\n",
       " 'jnk_inhibitor',\n",
       " 'kainate_receptor_antagonist',\n",
       " 'katp_activator',\n",
       " 'keap1_ligand',\n",
       " 'kinesin_inhibitor',\n",
       " 'lactamase_inhibitor',\n",
       " 'lactate_dehydrogenase_inhibitor',\n",
       " 'lanosterol_demethylase_inhibitor',\n",
       " 'leucyl-trna_synthetase_inhibitor',\n",
       " 'leukocyte_elastase_inhibitor',\n",
       " 'lim_inhibitor',\n",
       " 'lipase_clearing_factor_inhibitor',\n",
       " 'lipid_peroxidase_inhibitor',\n",
       " 'lipoprotein_lipase_activator',\n",
       " 'lrkk2_inhibitor',\n",
       " 'lymphocyte_inhibitor',\n",
       " 'lysophosphatidic_acid_receptor_antagonist',\n",
       " 'macrophage_inhibitor',\n",
       " 'macrophage_migration_inhibiting_factor_inhibitor',\n",
       " 'map_k',\n",
       " 'map_kinase_inhibitor',\n",
       " 'matrix_metalloprotease_inhibitor',\n",
       " 'mcl1_inhibitor',\n",
       " 'melanin_inhibitor',\n",
       " 'melatonin_receptor_agonist',\n",
       " 'membrane_permeability_inhibitor',\n",
       " 'mer_tyrosine_kinase_inhibitor',\n",
       " 'met_inhibitor',\n",
       " 'metalloproteinase_inhibitor',\n",
       " 'mineralocorticoid_receptor_agonist',\n",
       " 'mitochondrial_inhibitor',\n",
       " 'mitochondrial_na+_ca2+_exchanger_antagonist',\n",
       " 'monocarboxylate_transporter_inhibitor',\n",
       " 'motilin_receptor_agonist',\n",
       " 'mrp_inhibitor',\n",
       " 'mth1_inhibitor',\n",
       " 'mucus_protecting_agent',\n",
       " 'muscle_relaxant',\n",
       " 'na_k-atpase_inhibitor',\n",
       " 'nadph_inhibitor',\n",
       " 'nampt_inhibitor',\n",
       " 'neprilysin_inhibitor',\n",
       " 'neural_stem_cell_inducer',\n",
       " 'neuraminidase_inhibitor',\n",
       " 'neurokinin_receptor_antagonist',\n",
       " 'neurotensin_receptor_agonist',\n",
       " 'neurotensin_receptor_antagonist',\n",
       " 'neurotransmitter',\n",
       " 'neurotrophic_agent',\n",
       " 'nfkb_activator',\n",
       " 'niemann-pick_c1-like_1_protein_antagonist',\n",
       " 'nitric_oxide_scavenger',\n",
       " 'nociceptin_orphanin_fq_(nop)_receptor_antagonist',\n",
       " 'non-nucleoside_reverse_transcriptase_inhibitor',\n",
       " 'nootropic_agent',\n",
       " 'nop_receptor_agonist',\n",
       " 'norepinephrine_inhibitor',\n",
       " 'notch_signaling_inhibitor',\n",
       " 'nucleoside_reverse_transcriptase_inhibitor',\n",
       " 'oct_activator',\n",
       " 'omega_3_fatty_acid_stimulant',\n",
       " 'osteoclast_inhibitor',\n",
       " 'oxidosqualene_cyclase_inhibitor',\n",
       " 'oxytocin_receptor_agonist',\n",
       " 'oxytocin_receptor_antagonist',\n",
       " 'p21_activated_kinase_inhibitor',\n",
       " 'p53_activator',\n",
       " 'p53_inhibitor',\n",
       " 'paba_antagonist',\n",
       " 'pdk1_inhibitor',\n",
       " 'penicillin_binding_protein_inhibitor',\n",
       " 'peptidase_inhibitor',\n",
       " 'perk_inhibitor',\n",
       " 'phosphofructokinase_inhibitor',\n",
       " 'phospholipase_activator',\n",
       " 'pim_inhibitor',\n",
       " 'pka_inhibitor',\n",
       " 'plasminogen_activator_inhibitor',\n",
       " 'platelet_activating_factor_receptor_antagonist',\n",
       " 'platelet_aggregation_inhibitor',\n",
       " 'plk_inhibitor',\n",
       " 'porcupine_inhibitor',\n",
       " 'potassium_channel_agonist',\n",
       " 'potassium_channel_blocker',\n",
       " 'prmt_inhibitor',\n",
       " 'progestogen_hormone',\n",
       " 'prolactin_inhibitor',\n",
       " 'prostacyclin_analog',\n",
       " 'prostanoid_receptor_agonist',\n",
       " 'protease_inhibitor',\n",
       " 'protein_kinase_activator',\n",
       " 'protein_synthesis_stimulant',\n",
       " 'psychoactive_drug',\n",
       " 'purine_antagonist',\n",
       " 'purinergic_receptor_antagonist',\n",
       " 'quorum_sensing_signaling_modulator',\n",
       " 'rad51_inhibitor',\n",
       " 'receptor_tyrosine_protein_kinase_inhibitor',\n",
       " 'reducing_agent',\n",
       " 'ret_inhibitor',\n",
       " 'ret_tyrosine_kinase_inhibitor',\n",
       " 'reverse_transcriptase_inhibitor',\n",
       " 'ribosomal_protein_inhibitor',\n",
       " 'rna_synthesis_inhibitor',\n",
       " 'ror_inverse_agonist',\n",
       " 'rsv_fusion_inhibitor',\n",
       " 'sars_coronavirus_3c-like_protease_inhibitor',\n",
       " 'sedative',\n",
       " 'selective_estrogen_receptor_modulator_(serm)',\n",
       " 'selective_serotonin_reuptake_inhibitor_(ssri)',\n",
       " 'serine_protease_inhibitor',\n",
       " 'serine_threonine_kinase_inhibitor',\n",
       " 'serotonin_release_inhibitor',\n",
       " 'sirt_activator',\n",
       " 'sirt_inhibitor',\n",
       " 'smoothened_receptor_agonist',\n",
       " 'sodium_calcium_exchange_inhibitor',\n",
       " 'sodium_channel_activator',\n",
       " 'sodium_channel_blocker',\n",
       " 'somatostatin_receptor_agonist',\n",
       " 'sphingosine_1_phosphate_receptor_agonist',\n",
       " 'sphingosine_kinase_inhibitor',\n",
       " 'srebp_inhibitor',\n",
       " 'stat_inhibitor',\n",
       " 'steroid_sulfatase_inhibitor',\n",
       " 'steroidal_progestin',\n",
       " 'sterol_demethylase_inhibitor',\n",
       " 'steryl_sulfatase_inhibitor',\n",
       " 'structural_glycoprotein_antagonist',\n",
       " 'succinimide_antiepileptic',\n",
       " 't_cell_inhibitor',\n",
       " 'tankyrase_inhibitor',\n",
       " 'telomerase_inhibitor',\n",
       " 'testosterone_receptor_antagonist',\n",
       " 'thiazide_diuretic',\n",
       " 'thrombopoietin_receptor_agonist',\n",
       " 'thromboxane_receptor_antagonist',\n",
       " 'thromboxane_synthase_inhibitor',\n",
       " 'thyroid_hormone_inhibitor',\n",
       " 'thyroid_hormone_stimulant',\n",
       " 'thyrotropin_releasing_hormone_receptor_agonist',\n",
       " 'tissue_transglutaminase_inhibitor',\n",
       " 'topical_sunscreen_agent',\n",
       " 'trace_amine_associated_receptor_agonist',\n",
       " 'triacylglycerol_lipase_inhibitor',\n",
       " 'tricyclic_antidepressant',\n",
       " 'tryptophan_hydroxylase_inhibitor',\n",
       " 'tyrosinase_inhibitor',\n",
       " 'tyrosine_hydroxylase_inhibitor',\n",
       " 'tyrosine_phosphatase_inhibitor',\n",
       " 'ubiquitin-conjugating_enzyme_inhibitor',\n",
       " 'urease_inhibitor',\n",
       " 'uricase_inhibitor',\n",
       " 'uricosuric',\n",
       " 'urotensin_receptor_antagonist',\n",
       " 'vasoconstrictor',\n",
       " 'vasodilator',\n",
       " 'vasopressin_receptor_agonist',\n",
       " 'vasopressin_receptor_antagonist',\n",
       " 've-cadherin_antagonist',\n",
       " 'vesicular_monoamine_transporter_inhibitor',\n",
       " 'vitamin_k_antagonist',\n",
       " 'voltage-gated_potassium_channel_activator',\n",
       " 'voltage-gated_sodium_channel_blocker',\n",
       " 'wdr5_mll_interaction_inhibitor',\n",
       " 'xanthine_oxidase_inhibitor',\n",
       " 'xiap_inhibitor']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonscored_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:02.564050Z",
     "iopub.status.busy": "2020-11-26T05:40:02.562960Z",
     "iopub.status.idle": "2020-11-26T05:40:03.022693Z",
     "shell.execute_reply": "2020-11-26T05:40:03.023417Z"
    },
    "papermill": {
     "duration": 0.889915,
     "end_time": "2020-11-26T05:40:03.023643",
     "exception": false,
     "start_time": "2020-11-26T05:40:02.133728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle(f\"{INT_DIR}/{NB}-train_nonscore_pred.pkl\")\n",
    "test = pd.read_pickle(f\"{INT_DIR}/{NB}-test_nonscore_pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:03.707055Z",
     "iopub.status.busy": "2020-11-26T05:40:03.705517Z",
     "iopub.status.idle": "2020-11-26T05:40:04.283291Z",
     "shell.execute_reply": "2020-11-26T05:40:04.282677Z"
    },
    "papermill": {
     "duration": 0.869438,
     "end_time": "2020-11-26T05:40:04.283456",
     "exception": false,
     "start_time": "2020-11-26T05:40:03.414018",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use nonscored target in the given file as feature\n",
    "# if comment out below, use predicted nonscored target\n",
    "# train = train.drop(nonscored_target, axis=1)\n",
    "# train = train.merge(train_targets_nonscored, on=\"sig_id\")\n",
    "# train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train.merge(train_targets_scored, on='sig_id')\n",
    "# train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "# test = test[test['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "# target = train[train_targets_scored.columns]\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:04.865551Z",
     "iopub.status.busy": "2020-11-26T05:40:04.864402Z",
     "iopub.status.idle": "2020-11-26T05:40:08.872837Z",
     "shell.execute_reply": "2020-11-26T05:40:08.872145Z"
    },
    "papermill": {
     "duration": 4.307941,
     "end_time": "2020-11-26T05:40:08.872977",
     "exception": false,
     "start_time": "2020-11-26T05:40:04.565036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "for col in (nonscored_target):\n",
    "\n",
    "    vec_len = len(train[col].values)\n",
    "    vec_len_test = len(test[col].values)\n",
    "    raw_vec = train[col].values.reshape(vec_len, 1)\n",
    "    if IS_TRAIN:\n",
    "        transformer = QuantileTransformer(n_quantiles=100,\n",
    "                                          random_state=0,\n",
    "                                          output_distribution=\"normal\")\n",
    "        transformer.fit(raw_vec)\n",
    "        pd.to_pickle(transformer,\n",
    "                     f\"{MODEL_DIR}/{NB}_{col}_quantile_nonscored.pkl\")\n",
    "    else:\n",
    "        transformer = pd.read_pickle(\n",
    "            f\"{MODEL_DIR}/{NB}_{col}_quantile_nonscored.pkl\")\n",
    "\n",
    "    train[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test[col] = transformer.transform(test[col].values.reshape(\n",
    "        vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:09.653694Z",
     "iopub.status.busy": "2020-11-26T05:40:09.652673Z",
     "iopub.status.idle": "2020-11-26T05:40:09.658705Z",
     "shell.execute_reply": "2020-11-26T05:40:09.657606Z"
    },
    "papermill": {
     "duration": 0.445001,
     "end_time": "2020-11-26T05:40:09.658873",
     "exception": false,
     "start_time": "2020-11-26T05:40:09.213872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:10.591487Z",
     "iopub.status.busy": "2020-11-26T05:40:10.590370Z",
     "iopub.status.idle": "2020-11-26T05:40:10.646480Z",
     "shell.execute_reply": "2020-11-26T05:40:10.647818Z"
    },
    "papermill": {
     "duration": 0.537008,
     "end_time": "2020-11-26T05:40:10.648040",
     "exception": false,
     "start_time": "2020-11-26T05:40:10.111032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.146806</td>\n",
       "      <td>0.902075</td>\n",
       "      <td>-0.418339</td>\n",
       "      <td>-0.961202</td>\n",
       "      <td>-0.254770</td>\n",
       "      <td>-1.021300</td>\n",
       "      <td>-1.369236</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.128824</td>\n",
       "      <td>0.676862</td>\n",
       "      <td>0.274345</td>\n",
       "      <td>0.090495</td>\n",
       "      <td>1.208863</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>0.316734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.790372</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>1.428097</td>\n",
       "      <td>-0.121817</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>1.495091</td>\n",
       "      <td>0.238763</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.729866</td>\n",
       "      <td>-0.277163</td>\n",
       "      <td>-0.441200</td>\n",
       "      <td>0.766612</td>\n",
       "      <td>2.347817</td>\n",
       "      <td>-0.862761</td>\n",
       "      <td>-2.308829</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.444558</td>\n",
       "      <td>-0.481202</td>\n",
       "      <td>0.974729</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>1.468304</td>\n",
       "      <td>-0.874772</td>\n",
       "      <td>-0.372682</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.247623</td>\n",
       "      <td>-1.231184</td>\n",
       "      <td>0.221572</td>\n",
       "      <td>-0.354096</td>\n",
       "      <td>-0.332073</td>\n",
       "      <td>0.570635</td>\n",
       "      <td>-0.150125</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.217613</td>\n",
       "      <td>-0.027031</td>\n",
       "      <td>-0.237430</td>\n",
       "      <td>-0.787215</td>\n",
       "      <td>-0.677817</td>\n",
       "      <td>0.919474</td>\n",
       "      <td>0.742866</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.914666</td>\n",
       "      <td>0.581880</td>\n",
       "      <td>-0.588706</td>\n",
       "      <td>1.303439</td>\n",
       "      <td>-1.009079</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>-0.302814</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.826302</td>\n",
       "      <td>0.411235</td>\n",
       "      <td>0.433297</td>\n",
       "      <td>0.307575</td>\n",
       "      <td>1.075324</td>\n",
       "      <td>-0.024425</td>\n",
       "      <td>0.051483</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.245739</td>\n",
       "      <td>1.567230</td>\n",
       "      <td>-0.269829</td>\n",
       "      <td>1.092958</td>\n",
       "      <td>-0.515819</td>\n",
       "      <td>-2.091765</td>\n",
       "      <td>-1.627645</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1622 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  cp_time cp_dose       g-0       g-1       g-2       g-3  \\\n",
       "0      id_000644bb2       24      D1  1.146806  0.902075 -0.418339 -0.961202   \n",
       "1      id_000779bfc       72      D1  0.128824  0.676862  0.274345  0.090495   \n",
       "2      id_000a6266a       48      D1  0.790372  0.939951  1.428097 -0.121817   \n",
       "3      id_0015fd391       48      D1 -0.729866 -0.277163 -0.441200  0.766612   \n",
       "4      id_001626bd3       72      D2 -0.444558 -0.481202  0.974729  0.977467   \n",
       "...             ...      ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444       72      D1  0.247623 -1.231184  0.221572 -0.354096   \n",
       "21944  id_fffb1ceed       24      D2  0.217613 -0.027031 -0.237430 -0.787215   \n",
       "21945  id_fffb70c0c       24      D2 -1.914666  0.581880 -0.588706  1.303439   \n",
       "21946  id_fffcb9e7c       24      D1  0.826302  0.411235  0.433297  0.307575   \n",
       "21947  id_ffffdd77b       72      D1 -1.245739  1.567230 -0.269829  1.092958   \n",
       "\n",
       "            g-4       g-5       g-6  ...  \\\n",
       "0     -0.254770 -1.021300 -1.369236  ...   \n",
       "1      1.208863  0.688965  0.316734  ...   \n",
       "2     -0.002067  1.495091  0.238763  ...   \n",
       "3      2.347817 -0.862761 -2.308829  ...   \n",
       "4      1.468304 -0.874772 -0.372682  ...   \n",
       "...         ...       ...       ...  ...   \n",
       "21943 -0.332073  0.570635 -0.150125  ...   \n",
       "21944 -0.677817  0.919474  0.742866  ...   \n",
       "21945 -1.009079  0.852202 -0.302814  ...   \n",
       "21946  1.075324 -0.024425  0.051483  ...   \n",
       "21947 -0.515819 -2.091765 -1.627645  ...   \n",
       "\n",
       "       tropomyosin_receptor_kinase_inhibitor  trpv_agonist  trpv_antagonist  \\\n",
       "0                                          0             0                0   \n",
       "1                                          0             0                0   \n",
       "2                                          0             0                0   \n",
       "3                                          0             0                0   \n",
       "4                                          0             0                0   \n",
       "...                                      ...           ...              ...   \n",
       "21943                                      0             0                0   \n",
       "21944                                      0             0                0   \n",
       "21945                                      0             0                0   \n",
       "21946                                      0             0                0   \n",
       "21947                                      0             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "21943                  0                          0   \n",
       "21944                  0                          0   \n",
       "21945                  0                          0   \n",
       "21946                  0                          0   \n",
       "21947                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                      0                0          0   \n",
       "21944                                      0                0          0   \n",
       "21945                                      0                0          0   \n",
       "21946                                      0                0          0   \n",
       "21947                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                               0              0  \n",
       "1                               0              0  \n",
       "2                               0              0  \n",
       "3                               0              0  \n",
       "4                               0              0  \n",
       "...                           ...            ...  \n",
       "21943                           0              0  \n",
       "21944                           0              0  \n",
       "21945                           0              0  \n",
       "21946                           0              0  \n",
       "21947                           0              0  \n",
       "\n",
       "[21948 rows x 1622 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:11.348840Z",
     "iopub.status.busy": "2020-11-26T05:40:11.347393Z",
     "iopub.status.idle": "2020-11-26T05:40:15.029908Z",
     "shell.execute_reply": "2020-11-26T05:40:15.030560Z"
    },
    "papermill": {
     "duration": 4.014318,
     "end_time": "2020-11-26T05:40:15.030729",
     "exception": false,
     "start_time": "2020-11-26T05:40:11.016411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=False, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.146806</td>\n",
       "      <td>0.902075</td>\n",
       "      <td>-0.418339</td>\n",
       "      <td>-0.961202</td>\n",
       "      <td>-0.254770</td>\n",
       "      <td>-1.021300</td>\n",
       "      <td>-1.369236</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.128824</td>\n",
       "      <td>0.676862</td>\n",
       "      <td>0.274345</td>\n",
       "      <td>0.090495</td>\n",
       "      <td>1.208863</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>0.316734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.790372</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>1.428097</td>\n",
       "      <td>-0.121817</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>1.495091</td>\n",
       "      <td>0.238763</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.729866</td>\n",
       "      <td>-0.277163</td>\n",
       "      <td>-0.441200</td>\n",
       "      <td>0.766612</td>\n",
       "      <td>2.347817</td>\n",
       "      <td>-0.862761</td>\n",
       "      <td>-2.308829</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.444558</td>\n",
       "      <td>-0.481202</td>\n",
       "      <td>0.974729</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>1.468304</td>\n",
       "      <td>-0.874772</td>\n",
       "      <td>-0.372682</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.247623</td>\n",
       "      <td>-1.231184</td>\n",
       "      <td>0.221572</td>\n",
       "      <td>-0.354096</td>\n",
       "      <td>-0.332073</td>\n",
       "      <td>0.570635</td>\n",
       "      <td>-0.150125</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.217613</td>\n",
       "      <td>-0.027031</td>\n",
       "      <td>-0.237430</td>\n",
       "      <td>-0.787215</td>\n",
       "      <td>-0.677817</td>\n",
       "      <td>0.919474</td>\n",
       "      <td>0.742866</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.914666</td>\n",
       "      <td>0.581880</td>\n",
       "      <td>-0.588706</td>\n",
       "      <td>1.303439</td>\n",
       "      <td>-1.009079</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>-0.302814</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.826302</td>\n",
       "      <td>0.411235</td>\n",
       "      <td>0.433297</td>\n",
       "      <td>0.307575</td>\n",
       "      <td>1.075324</td>\n",
       "      <td>-0.024425</td>\n",
       "      <td>0.051483</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.245739</td>\n",
       "      <td>1.567230</td>\n",
       "      <td>-0.269829</td>\n",
       "      <td>1.092958</td>\n",
       "      <td>-0.515819</td>\n",
       "      <td>-2.091765</td>\n",
       "      <td>-1.627645</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1623 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  cp_time cp_dose       g-0       g-1       g-2       g-3  \\\n",
       "0      id_000644bb2       24      D1  1.146806  0.902075 -0.418339 -0.961202   \n",
       "1      id_000779bfc       72      D1  0.128824  0.676862  0.274345  0.090495   \n",
       "2      id_000a6266a       48      D1  0.790372  0.939951  1.428097 -0.121817   \n",
       "3      id_0015fd391       48      D1 -0.729866 -0.277163 -0.441200  0.766612   \n",
       "4      id_001626bd3       72      D2 -0.444558 -0.481202  0.974729  0.977467   \n",
       "...             ...      ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444       72      D1  0.247623 -1.231184  0.221572 -0.354096   \n",
       "21944  id_fffb1ceed       24      D2  0.217613 -0.027031 -0.237430 -0.787215   \n",
       "21945  id_fffb70c0c       24      D2 -1.914666  0.581880 -0.588706  1.303439   \n",
       "21946  id_fffcb9e7c       24      D1  0.826302  0.411235  0.433297  0.307575   \n",
       "21947  id_ffffdd77b       72      D1 -1.245739  1.567230 -0.269829  1.092958   \n",
       "\n",
       "            g-4       g-5       g-6  ...  trpv_agonist  trpv_antagonist  \\\n",
       "0     -0.254770 -1.021300 -1.369236  ...             0                0   \n",
       "1      1.208863  0.688965  0.316734  ...             0                0   \n",
       "2     -0.002067  1.495091  0.238763  ...             0                0   \n",
       "3      2.347817 -0.862761 -2.308829  ...             0                0   \n",
       "4      1.468304 -0.874772 -0.372682  ...             0                0   \n",
       "...         ...       ...       ...  ...           ...              ...   \n",
       "21943 -0.332073  0.570635 -0.150125  ...             0                0   \n",
       "21944 -0.677817  0.919474  0.742866  ...             0                0   \n",
       "21945 -1.009079  0.852202 -0.302814  ...             0                0   \n",
       "21946  1.075324 -0.024425  0.051483  ...             0                0   \n",
       "21947 -0.515819 -2.091765 -1.627645  ...             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "21943                  0                          0   \n",
       "21944                  0                          0   \n",
       "21945                  0                          0   \n",
       "21946                  0                          0   \n",
       "21947                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                      0                0          0   \n",
       "21944                                      0                0          0   \n",
       "21945                                      0                0          0   \n",
       "21946                                      0                0          0   \n",
       "21947                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  kfold  \n",
       "0                               0              0      4  \n",
       "1                               0              0      4  \n",
       "2                               0              0      4  \n",
       "3                               0              0      4  \n",
       "4                               0              0      3  \n",
       "...                           ...            ...    ...  \n",
       "21943                           0              0      4  \n",
       "21944                           0              0      0  \n",
       "21945                           0              0      1  \n",
       "21946                           0              0      1  \n",
       "21947                           0              0      4  \n",
       "\n",
       "[21948 rows x 1623 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=NFOLDS)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:15.656087Z",
     "iopub.status.busy": "2020-11-26T05:40:15.655094Z",
     "iopub.status.idle": "2020-11-26T05:40:15.658947Z",
     "shell.execute_reply": "2020-11-26T05:40:15.656745Z"
    },
    "papermill": {
     "duration": 0.297372,
     "end_time": "2020-11-26T05:40:15.659108",
     "exception": false,
     "start_time": "2020-11-26T05:40:15.361736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1622)\n",
      "(21948, 1623)\n",
      "(3624, 1416)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:16.246436Z",
     "iopub.status.busy": "2020-11-26T05:40:16.245313Z",
     "iopub.status.idle": "2020-11-26T05:40:16.248611Z",
     "shell.execute_reply": "2020-11-26T05:40:16.248040Z"
    },
    "papermill": {
     "duration": 0.304774,
     "end_time": "2020-11-26T05:40:16.248739",
     "exception": false,
     "start_time": "2020-11-26T05:40:15.943965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "\n",
    "    data = pd.get_dummies(data, columns=['cp_time', 'cp_dose'])\n",
    "    #     data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "    #     data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "\n",
    "    # --------------------- Normalize ---------------------\n",
    "    #     for col in GENES:\n",
    "    #         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "\n",
    "    #     for col in CELLS:\n",
    "    #         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "\n",
    "    #--------------------- Removing Skewness ---------------------\n",
    "    #     for col in GENES + CELLS:\n",
    "    #         if(abs(data[col].skew()) > 0.75):\n",
    "\n",
    "    #             if(data[col].skew() < 0): # neg-skewness\n",
    "    #                 data[col] = data[col].max() - data[col] + 1\n",
    "    #                 data[col] = np.sqrt(data[col])\n",
    "\n",
    "    #             else:\n",
    "    #                 data[col] = np.sqrt(data[col])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:16.867521Z",
     "iopub.status.busy": "2020-11-26T05:40:16.865976Z",
     "iopub.status.idle": "2020-11-26T05:40:17.070140Z",
     "shell.execute_reply": "2020-11-26T05:40:17.070740Z"
    },
    "papermill": {
     "duration": 0.52829,
     "end_time": "2020-11-26T05:40:17.070889",
     "exception": false,
     "start_time": "2020-11-26T05:40:16.542599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1418"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:17.675003Z",
     "iopub.status.busy": "2020-11-26T05:40:17.672841Z",
     "iopub.status.idle": "2020-11-26T05:40:17.675807Z",
     "shell.execute_reply": "2020-11-26T05:40:17.676377Z"
    },
    "papermill": {
     "duration": 0.296016,
     "end_time": "2020-11-26T05:40:17.676520",
     "exception": false,
     "start_time": "2020-11-26T05:40:17.380504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=2048\n",
    "# hidden_size=4096\n",
    "# hidden_size=9192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:18.279799Z",
     "iopub.status.busy": "2020-11-26T05:40:18.277743Z",
     "iopub.status.idle": "2020-11-26T05:40:18.280589Z",
     "shell.execute_reply": "2020-11-26T05:40:18.281147Z"
    },
    "papermill": {
     "duration": 0.31986,
     "end_time": "2020-11-26T05:40:18.281297",
     "exception": false,
     "start_time": "2020-11-26T05:40:17.961437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "\n",
    "    seed_everything(seed)\n",
    "\n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "\n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "\n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    x_train, y_train = train_df[feature_cols].values, train_df[\n",
    "        target_cols].values\n",
    "    x_valid, y_valid = valid_df[feature_cols].values, valid_df[\n",
    "        target_cols].values\n",
    "\n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=False)\n",
    "\n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=5e-3,\n",
    "                                 weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer,\n",
    "                                              pct_start=0.2,\n",
    "                                              div_factor=1e3,\n",
    "                                              max_lr=1e-2,\n",
    "                                              epochs=EPOCHS,\n",
    "                                              steps_per_epoch=len(trainloader))\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "\n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        train_loss = train_fn(model, optimizer, scheduler, loss_fn,\n",
    "                              trainloader, DEVICE)\n",
    "        print(\n",
    "            f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\"\n",
    "        )\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(\n",
    "            f\"SEED: {seed} ,FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\"\n",
    "        )\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "\n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(),\n",
    "                       f\"{MODEL_DIR}/{NB}-scored1-SEED{seed}-FOLD{fold}_.pth\")\n",
    "\n",
    "        elif (EARLY_STOP == True):\n",
    "\n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "\n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             shuffle=False)\n",
    "\n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(\n",
    "        torch.load(f\"{MODEL_DIR}/{NB}-scored1-SEED{seed}-FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "\n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:18.862848Z",
     "iopub.status.busy": "2020-11-26T05:40:18.860747Z",
     "iopub.status.idle": "2020-11-26T05:40:18.863656Z",
     "shell.execute_reply": "2020-11-26T05:40:18.864217Z"
    },
    "papermill": {
     "duration": 0.296551,
     "end_time": "2020-11-26T05:40:18.864383",
     "exception": false,
     "start_time": "2020-11-26T05:40:18.567832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "\n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "\n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T05:40:19.480852Z",
     "iopub.status.busy": "2020-11-26T05:40:19.479059Z",
     "iopub.status.idle": "2020-11-26T06:01:11.744701Z",
     "shell.execute_reply": "2020-11-26T06:01:11.743449Z"
    },
    "papermill": {
     "duration": 1252.594071,
     "end_time": "2020-11-26T06:01:11.744849",
     "exception": false,
     "start_time": "2020-11-26T05:40:19.150778",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 940, FOLD: 0, EPOCH: 0, train_loss: 0.71265501215838\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6155504816108279\n",
      "SEED: 940, FOLD: 0, EPOCH: 1, train_loss: 0.20263613539113515\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 1, valid_loss: 0.022887404180235334\n",
      "SEED: 940, FOLD: 0, EPOCH: 2, train_loss: 0.02104678291125574\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01929207446260585\n",
      "SEED: 940, FOLD: 0, EPOCH: 3, train_loss: 0.018855544657486935\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 3, valid_loss: 0.018203541739947267\n",
      "SEED: 940, FOLD: 0, EPOCH: 4, train_loss: 0.018072179640116898\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017530292169087462\n",
      "SEED: 940, FOLD: 0, EPOCH: 5, train_loss: 0.017151300349961155\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017212128473652735\n",
      "SEED: 940, FOLD: 0, EPOCH: 6, train_loss: 0.016607041254747604\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 6, valid_loss: 0.016719647941903934\n",
      "SEED: 940, FOLD: 0, EPOCH: 7, train_loss: 0.01708855508300273\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 7, valid_loss: 0.020239912594358127\n",
      "SEED: 940, FOLD: 0, EPOCH: 8, train_loss: 0.01702877734720275\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 8, valid_loss: 0.016678442454172507\n",
      "SEED: 940, FOLD: 0, EPOCH: 9, train_loss: 0.01645396239515664\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 9, valid_loss: 0.016538797981209226\n",
      "SEED: 940, FOLD: 0, EPOCH: 10, train_loss: 0.016237351409011128\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 10, valid_loss: 0.016393325084613428\n",
      "SEED: 940, FOLD: 0, EPOCH: 11, train_loss: 0.016163539897272552\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01636683666664693\n",
      "SEED: 940, FOLD: 0, EPOCH: 12, train_loss: 0.01602419263318829\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016250079032033682\n",
      "SEED: 940, FOLD: 0, EPOCH: 13, train_loss: 0.015854331705233326\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01630710443067882\n",
      "SEED: 940, FOLD: 0, EPOCH: 14, train_loss: 0.0156652109724456\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016056437304036483\n",
      "SEED: 940, FOLD: 0, EPOCH: 15, train_loss: 0.015470956465688305\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016150065128588013\n",
      "SEED: 940, FOLD: 0, EPOCH: 16, train_loss: 0.015207724902184977\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 16, valid_loss: 0.015914228020442858\n",
      "SEED: 940, FOLD: 0, EPOCH: 17, train_loss: 0.014846513385250084\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01580326807581716\n",
      "SEED: 940, FOLD: 0, EPOCH: 18, train_loss: 0.014482232620534689\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 18, valid_loss: 0.015809619281854894\n",
      "SEED: 940, FOLD: 0, EPOCH: 19, train_loss: 0.014015220348601755\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01573655205882258\n",
      "SEED: 940, FOLD: 0, EPOCH: 20, train_loss: 0.01339948884602906\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01566744114582737\n",
      "SEED: 940, FOLD: 0, EPOCH: 21, train_loss: 0.012727971931082615\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01566126202750537\n",
      "SEED: 940, FOLD: 0, EPOCH: 22, train_loss: 0.012051325669323189\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015652955406241946\n",
      "SEED: 940, FOLD: 0, EPOCH: 23, train_loss: 0.01155363339120927\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01563801606082254\n",
      "SEED: 940, FOLD: 0, EPOCH: 24, train_loss: 0.011338594288605711\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01563766308956676\n",
      "SEED: 940, FOLD: 1, EPOCH: 0, train_loss: 0.7126933223959329\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6002775761816237\n",
      "SEED: 940, FOLD: 1, EPOCH: 1, train_loss: 0.20177243895612765\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 1, valid_loss: 0.024045464893182118\n",
      "SEED: 940, FOLD: 1, EPOCH: 2, train_loss: 0.021249449744388676\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 2, valid_loss: 0.019518345387445554\n",
      "SEED: 940, FOLD: 1, EPOCH: 3, train_loss: 0.018983309953540996\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018365708490212757\n",
      "SEED: 940, FOLD: 1, EPOCH: 4, train_loss: 0.018039566559204155\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01768577926688724\n",
      "SEED: 940, FOLD: 1, EPOCH: 5, train_loss: 0.018005642014137214\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 5, valid_loss: 0.01727720329331027\n",
      "SEED: 940, FOLD: 1, EPOCH: 6, train_loss: 0.01688756351021753\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01692822886010011\n",
      "SEED: 940, FOLD: 1, EPOCH: 7, train_loss: 0.016606429470298084\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 7, valid_loss: 0.016618473041388724\n",
      "SEED: 940, FOLD: 1, EPOCH: 8, train_loss: 0.016374267718714218\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 8, valid_loss: 0.016587977815005515\n",
      "SEED: 940, FOLD: 1, EPOCH: 9, train_loss: 0.016334384436840595\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 9, valid_loss: 0.016529619176354673\n",
      "SEED: 940, FOLD: 1, EPOCH: 10, train_loss: 0.01621666906968407\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016431086489723787\n",
      "SEED: 940, FOLD: 1, EPOCH: 11, train_loss: 0.016112116448905155\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016408919563723937\n",
      "SEED: 940, FOLD: 1, EPOCH: 12, train_loss: 0.016027675752622494\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016353976654095784\n",
      "SEED: 940, FOLD: 1, EPOCH: 13, train_loss: 0.01590840847811837\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016368102696206834\n",
      "SEED: 940, FOLD: 1, EPOCH: 14, train_loss: 0.015751995429720566\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016359509382810857\n",
      "SEED: 940, FOLD: 1, EPOCH: 15, train_loss: 0.015519753948825857\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 15, valid_loss: 0.0161225031543937\n",
      "SEED: 940, FOLD: 1, EPOCH: 16, train_loss: 0.015266395200961742\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016043892337216273\n",
      "SEED: 940, FOLD: 1, EPOCH: 17, train_loss: 0.014927794319995935\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 17, valid_loss: 0.015899196008427277\n",
      "SEED: 940, FOLD: 1, EPOCH: 18, train_loss: 0.01450449240434429\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 18, valid_loss: 0.015800223375360172\n",
      "SEED: 940, FOLD: 1, EPOCH: 19, train_loss: 0.013970274586176527\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01569241104233596\n",
      "SEED: 940, FOLD: 1, EPOCH: 20, train_loss: 0.013354159729636234\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 20, valid_loss: 0.015654400715397462\n",
      "SEED: 940, FOLD: 1, EPOCH: 21, train_loss: 0.012696098347288975\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015543747952000963\n",
      "SEED: 940, FOLD: 1, EPOCH: 22, train_loss: 0.012067260936010574\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015592704682300488\n",
      "SEED: 940, FOLD: 1, EPOCH: 23, train_loss: 0.011592833635707697\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015590670311616527\n",
      "SEED: 940, FOLD: 1, EPOCH: 24, train_loss: 0.011349941266403683\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015579817299213674\n",
      "SEED: 940, FOLD: 2, EPOCH: 0, train_loss: 0.7130858690842338\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 0, valid_loss: 0.5972333881590102\n",
      "SEED: 940, FOLD: 2, EPOCH: 1, train_loss: 0.20286135154141896\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 1, valid_loss: 0.023352125763065286\n",
      "SEED: 940, FOLD: 2, EPOCH: 2, train_loss: 0.02107025126832119\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 2, valid_loss: 0.019276850442919467\n",
      "SEED: 940, FOLD: 2, EPOCH: 3, train_loss: 0.018873046516724255\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 3, valid_loss: 0.018176271838860378\n",
      "SEED: 940, FOLD: 2, EPOCH: 4, train_loss: 0.017855415903571724\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017509383615106344\n",
      "SEED: 940, FOLD: 2, EPOCH: 5, train_loss: 0.017014348353056805\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01737687312480476\n",
      "SEED: 940, FOLD: 2, EPOCH: 6, train_loss: 0.016513916542348656\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 6, valid_loss: 0.016929575345582433\n",
      "SEED: 940, FOLD: 2, EPOCH: 7, train_loss: 0.016347372270040753\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 7, valid_loss: 0.016967760502464242\n",
      "SEED: 940, FOLD: 2, EPOCH: 8, train_loss: 0.016274590666095417\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01672411761764023\n",
      "SEED: 940, FOLD: 2, EPOCH: 9, train_loss: 0.016135088519017765\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016608131376819477\n",
      "SEED: 940, FOLD: 2, EPOCH: 10, train_loss: 0.01599603193555621\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 10, valid_loss: 0.016719098358104627\n",
      "SEED: 940, FOLD: 2, EPOCH: 11, train_loss: 0.015859717476195183\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01658101949012942\n",
      "SEED: 940, FOLD: 2, EPOCH: 12, train_loss: 0.015811590194378212\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016460229642689228\n",
      "SEED: 940, FOLD: 2, EPOCH: 13, train_loss: 0.015744401884359726\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016311591853284173\n",
      "SEED: 940, FOLD: 2, EPOCH: 14, train_loss: 0.015446436564451542\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016362449050777488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 940, FOLD: 2, EPOCH: 15, train_loss: 0.015264661807188953\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016178909223526716\n",
      "SEED: 940, FOLD: 2, EPOCH: 16, train_loss: 0.01497469174311213\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01617078736631407\n",
      "SEED: 940, FOLD: 2, EPOCH: 17, train_loss: 0.014639085253187712\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016073988905797403\n",
      "SEED: 940, FOLD: 2, EPOCH: 18, train_loss: 0.014194936586031015\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016157698558850422\n",
      "SEED: 940, FOLD: 2, EPOCH: 19, train_loss: 0.013755107163519098\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016103939722395606\n",
      "SEED: 940, FOLD: 2, EPOCH: 20, train_loss: 0.013032844155163004\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016028448577142425\n",
      "SEED: 940, FOLD: 2, EPOCH: 21, train_loss: 0.012259715101749136\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015977731284995873\n",
      "SEED: 940, FOLD: 2, EPOCH: 22, train_loss: 0.01159796012106581\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 22, valid_loss: 0.015978428793864116\n",
      "SEED: 940, FOLD: 2, EPOCH: 23, train_loss: 0.011104176968228126\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01598756341263652\n",
      "SEED: 940, FOLD: 2, EPOCH: 24, train_loss: 0.010834377825908039\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016036184090707038\n",
      "SEED: 940, FOLD: 3, EPOCH: 0, train_loss: 0.7128365117570629\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 0, valid_loss: 0.620438794294993\n",
      "SEED: 940, FOLD: 3, EPOCH: 1, train_loss: 0.20293045945573543\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 1, valid_loss: 0.02398901494840781\n",
      "SEED: 940, FOLD: 3, EPOCH: 2, train_loss: 0.021055178095897038\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 2, valid_loss: 0.01941794167376227\n",
      "SEED: 940, FOLD: 3, EPOCH: 3, train_loss: 0.018818722875869793\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018326793538613453\n",
      "SEED: 940, FOLD: 3, EPOCH: 4, train_loss: 0.01796081694571868\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017772495643132262\n",
      "SEED: 940, FOLD: 3, EPOCH: 5, train_loss: 0.01712627479455609\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 5, valid_loss: 0.01730512186057038\n",
      "SEED: 940, FOLD: 3, EPOCH: 6, train_loss: 0.016578915056543075\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01711114899565776\n",
      "SEED: 940, FOLD: 3, EPOCH: 7, train_loss: 0.016701928771816303\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01748771422232191\n",
      "SEED: 940, FOLD: 3, EPOCH: 8, train_loss: 0.016523468834550484\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 8, valid_loss: 0.016870717983692884\n",
      "SEED: 940, FOLD: 3, EPOCH: 9, train_loss: 0.016209052916130295\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017077661636802886\n",
      "SEED: 940, FOLD: 3, EPOCH: 10, train_loss: 0.016189822859630203\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01696542019231452\n",
      "SEED: 940, FOLD: 3, EPOCH: 11, train_loss: 0.016017144235471886\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 11, valid_loss: 0.0167540627428227\n",
      "SEED: 940, FOLD: 3, EPOCH: 12, train_loss: 0.015882333268182003\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016700980356997915\n",
      "SEED: 940, FOLD: 3, EPOCH: 13, train_loss: 0.01580306654121133\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 13, valid_loss: 0.0165773989736206\n",
      "SEED: 940, FOLD: 3, EPOCH: 14, train_loss: 0.015649133942265442\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016443040118449263\n",
      "SEED: 940, FOLD: 3, EPOCH: 15, train_loss: 0.015364886288517628\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01638297291679515\n",
      "SEED: 940, FOLD: 3, EPOCH: 16, train_loss: 0.015150096510415491\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01634192590912183\n",
      "SEED: 940, FOLD: 3, EPOCH: 17, train_loss: 0.014848642172696798\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01614323046265377\n",
      "SEED: 940, FOLD: 3, EPOCH: 18, train_loss: 0.014371059457029121\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016005794207255047\n",
      "SEED: 940, FOLD: 3, EPOCH: 19, train_loss: 0.013859539495214172\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 19, valid_loss: 0.015969603063745633\n",
      "SEED: 940, FOLD: 3, EPOCH: 20, train_loss: 0.013214539817493895\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 20, valid_loss: 0.015921079605403874\n",
      "SEED: 940, FOLD: 3, EPOCH: 21, train_loss: 0.012523511856578398\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01586124026733968\n",
      "SEED: 940, FOLD: 3, EPOCH: 22, train_loss: 0.011840644211548826\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 22, valid_loss: 0.015878062540044386\n",
      "SEED: 940, FOLD: 3, EPOCH: 23, train_loss: 0.011339001883955105\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 23, valid_loss: 0.015882737572408386\n",
      "SEED: 940, FOLD: 3, EPOCH: 24, train_loss: 0.011116409876748272\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01588785420689318\n",
      "SEED: 940, FOLD: 4, EPOCH: 0, train_loss: 0.7132121946500696\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6038292149702708\n",
      "SEED: 940, FOLD: 4, EPOCH: 1, train_loss: 0.20417317035405533\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 1, valid_loss: 0.027265557708839577\n",
      "SEED: 940, FOLD: 4, EPOCH: 2, train_loss: 0.02118213855378006\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 2, valid_loss: 0.019421028904616833\n",
      "SEED: 940, FOLD: 4, EPOCH: 3, train_loss: 0.018906504968586174\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01831834939204984\n",
      "SEED: 940, FOLD: 4, EPOCH: 4, train_loss: 0.017864853548614876\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017553458507690165\n",
      "SEED: 940, FOLD: 4, EPOCH: 5, train_loss: 0.017070826588441498\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017178857699036598\n",
      "SEED: 940, FOLD: 4, EPOCH: 6, train_loss: 0.01666573020697072\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 6, valid_loss: 0.0167708627672659\n",
      "SEED: 940, FOLD: 4, EPOCH: 7, train_loss: 0.016339293249167393\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 7, valid_loss: 0.016922239265922043\n",
      "SEED: 940, FOLD: 4, EPOCH: 8, train_loss: 0.016313312372759632\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 8, valid_loss: 0.016741860192269087\n",
      "SEED: 940, FOLD: 4, EPOCH: 9, train_loss: 0.01620938549277143\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01655969675630331\n",
      "SEED: 940, FOLD: 4, EPOCH: 10, train_loss: 0.016141440921827503\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017250106669962406\n",
      "SEED: 940, FOLD: 4, EPOCH: 11, train_loss: 0.016217674304177795\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016406949919958908\n",
      "SEED: 940, FOLD: 4, EPOCH: 12, train_loss: 0.015904195795672527\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016353625648965437\n",
      "SEED: 940, FOLD: 4, EPOCH: 13, train_loss: 0.01575214429286079\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01632029501100381\n",
      "SEED: 940, FOLD: 4, EPOCH: 14, train_loss: 0.0156190636554274\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01615291130211618\n",
      "SEED: 940, FOLD: 4, EPOCH: 15, train_loss: 0.015393814638904903\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016239019472979836\n",
      "SEED: 940, FOLD: 4, EPOCH: 16, train_loss: 0.015131332871058712\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01599984672955341\n",
      "SEED: 940, FOLD: 4, EPOCH: 17, train_loss: 0.014713389029645401\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 17, valid_loss: 0.015824513044208288\n",
      "SEED: 940, FOLD: 4, EPOCH: 18, train_loss: 0.0143505052352945\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01583391148597002\n",
      "SEED: 940, FOLD: 4, EPOCH: 19, train_loss: 0.013809998276764933\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 19, valid_loss: 0.015774160157889128\n",
      "SEED: 940, FOLD: 4, EPOCH: 20, train_loss: 0.0132631945113341\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 20, valid_loss: 0.015729645525829658\n",
      "SEED: 940, FOLD: 4, EPOCH: 21, train_loss: 0.012576150424454523\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01574154130907522\n",
      "SEED: 940, FOLD: 4, EPOCH: 22, train_loss: 0.01193046617065219\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015700172839893237\n",
      "SEED: 940, FOLD: 4, EPOCH: 23, train_loss: 0.011415652228870254\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01568642258644104\n",
      "SEED: 940, FOLD: 4, EPOCH: 24, train_loss: 0.011182533455607683\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015674743956575792\n",
      "elapsed time: 114.16221237182617\n",
      "SEED: 1513, FOLD: 0, EPOCH: 0, train_loss: 0.7125256035638892\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 0, valid_loss: 0.611270073387358\n",
      "SEED: 1513, FOLD: 0, EPOCH: 1, train_loss: 0.2042414350570112\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 1, valid_loss: 0.02243460590640704\n",
      "SEED: 1513, FOLD: 0, EPOCH: 2, train_loss: 0.0209273430046396\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 2, valid_loss: 0.019267250628521044\n",
      "SEED: 1513, FOLD: 0, EPOCH: 3, train_loss: 0.01871171725940877\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 3, valid_loss: 0.018174981491433248\n",
      "SEED: 1513, FOLD: 0, EPOCH: 4, train_loss: 0.01820164549069992\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017632549162954092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1513, FOLD: 0, EPOCH: 5, train_loss: 0.017186988091123276\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017066122498363256\n",
      "SEED: 1513, FOLD: 0, EPOCH: 6, train_loss: 0.016723733233368916\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01708546741348174\n",
      "SEED: 1513, FOLD: 0, EPOCH: 7, train_loss: 0.016940113319003063\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 7, valid_loss: 0.016805684245708916\n",
      "SEED: 1513, FOLD: 0, EPOCH: 8, train_loss: 0.016447000596942245\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01663975536616312\n",
      "SEED: 1513, FOLD: 0, EPOCH: 9, train_loss: 0.016341927366844124\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 9, valid_loss: 0.016825660442312557\n",
      "SEED: 1513, FOLD: 0, EPOCH: 10, train_loss: 0.01624331605769154\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01653326680469844\n",
      "SEED: 1513, FOLD: 0, EPOCH: 11, train_loss: 0.016118605729138504\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01657687360420823\n",
      "SEED: 1513, FOLD: 0, EPOCH: 12, train_loss: 0.01604625099487063\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016443211792243853\n",
      "SEED: 1513, FOLD: 0, EPOCH: 13, train_loss: 0.015962722063388512\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016374839107609458\n",
      "SEED: 1513, FOLD: 0, EPOCH: 14, train_loss: 0.01569284497341816\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016193443391886022\n",
      "SEED: 1513, FOLD: 0, EPOCH: 15, train_loss: 0.015462263298315414\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016280298742155235\n",
      "SEED: 1513, FOLD: 0, EPOCH: 16, train_loss: 0.015228128803057083\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016125684293607872\n",
      "SEED: 1513, FOLD: 0, EPOCH: 17, train_loss: 0.014929813805265703\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 17, valid_loss: 0.0159423323865566\n",
      "SEED: 1513, FOLD: 0, EPOCH: 18, train_loss: 0.014474505221174248\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 18, valid_loss: 0.01585020347394877\n",
      "SEED: 1513, FOLD: 0, EPOCH: 19, train_loss: 0.013932671384426994\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 19, valid_loss: 0.015781377752621967\n",
      "SEED: 1513, FOLD: 0, EPOCH: 20, train_loss: 0.01334095627501391\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01574245871355136\n",
      "SEED: 1513, FOLD: 0, EPOCH: 21, train_loss: 0.012719365930103737\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015746325720101595\n",
      "SEED: 1513, FOLD: 0, EPOCH: 22, train_loss: 0.01201962312494499\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015714442098720208\n",
      "SEED: 1513, FOLD: 0, EPOCH: 23, train_loss: 0.01155120815973783\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015698200195199914\n",
      "SEED: 1513, FOLD: 0, EPOCH: 24, train_loss: 0.011308426253389622\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015700583139227495\n",
      "SEED: 1513, FOLD: 1, EPOCH: 0, train_loss: 0.7127244766207709\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6138766076829698\n",
      "SEED: 1513, FOLD: 1, EPOCH: 1, train_loss: 0.20474086904331393\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 1, valid_loss: 0.024399578364359006\n",
      "SEED: 1513, FOLD: 1, EPOCH: 2, train_loss: 0.02095642634599969\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 2, valid_loss: 0.019379299754897755\n",
      "SEED: 1513, FOLD: 1, EPOCH: 3, train_loss: 0.018868057637650898\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 3, valid_loss: 0.01842360022581286\n",
      "SEED: 1513, FOLD: 1, EPOCH: 4, train_loss: 0.017964987624166668\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017602491192519665\n",
      "SEED: 1513, FOLD: 1, EPOCH: 5, train_loss: 0.017217947723532932\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017122483398351405\n",
      "SEED: 1513, FOLD: 1, EPOCH: 6, train_loss: 0.01660232610352661\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 6, valid_loss: 0.016984850375188723\n",
      "SEED: 1513, FOLD: 1, EPOCH: 7, train_loss: 0.01826332192328097\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01719951919383473\n",
      "SEED: 1513, FOLD: 1, EPOCH: 8, train_loss: 0.016824352919407513\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01673589346723424\n",
      "SEED: 1513, FOLD: 1, EPOCH: 9, train_loss: 0.016495406573665314\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 9, valid_loss: 0.016608627720011607\n",
      "SEED: 1513, FOLD: 1, EPOCH: 10, train_loss: 0.01637684867001962\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016489868776665792\n",
      "SEED: 1513, FOLD: 1, EPOCH: 11, train_loss: 0.01623160135594831\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01636387086990807\n",
      "SEED: 1513, FOLD: 1, EPOCH: 12, train_loss: 0.01602455497165953\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01632271945062611\n",
      "SEED: 1513, FOLD: 1, EPOCH: 13, train_loss: 0.015965925084184044\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016339365082482498\n",
      "SEED: 1513, FOLD: 1, EPOCH: 14, train_loss: 0.015803382961430412\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016157326857662864\n",
      "SEED: 1513, FOLD: 1, EPOCH: 15, train_loss: 0.01553890986395055\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01610859969837798\n",
      "SEED: 1513, FOLD: 1, EPOCH: 16, train_loss: 0.01522795299904934\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 16, valid_loss: 0.015982977787239686\n",
      "SEED: 1513, FOLD: 1, EPOCH: 17, train_loss: 0.014952448520647444\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01595983224817448\n",
      "SEED: 1513, FOLD: 1, EPOCH: 18, train_loss: 0.014524624885424324\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 18, valid_loss: 0.015852960913131636\n",
      "SEED: 1513, FOLD: 1, EPOCH: 19, train_loss: 0.014030413148735744\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 19, valid_loss: 0.015743114985525608\n",
      "SEED: 1513, FOLD: 1, EPOCH: 20, train_loss: 0.013420868530005648\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 20, valid_loss: 0.015762768530597288\n",
      "SEED: 1513, FOLD: 1, EPOCH: 21, train_loss: 0.012764035454154879\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01567510324012902\n",
      "SEED: 1513, FOLD: 1, EPOCH: 22, train_loss: 0.012081286572999712\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015616146174983846\n",
      "SEED: 1513, FOLD: 1, EPOCH: 23, train_loss: 0.011596944938967194\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01563116219929523\n",
      "SEED: 1513, FOLD: 1, EPOCH: 24, train_loss: 0.011385709330763506\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01564936324333151\n",
      "SEED: 1513, FOLD: 2, EPOCH: 0, train_loss: 0.7123361661814261\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6127283109558953\n",
      "SEED: 1513, FOLD: 2, EPOCH: 1, train_loss: 0.20217722419487394\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 1, valid_loss: 0.02355430916779571\n",
      "SEED: 1513, FOLD: 2, EPOCH: 2, train_loss: 0.021074456608165867\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 2, valid_loss: 0.019635901268985536\n",
      "SEED: 1513, FOLD: 2, EPOCH: 3, train_loss: 0.018836141199521397\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01825351645756099\n",
      "SEED: 1513, FOLD: 2, EPOCH: 4, train_loss: 0.017840927466750145\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01833139065032204\n",
      "SEED: 1513, FOLD: 2, EPOCH: 5, train_loss: 0.017666889300596886\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01721226889640093\n",
      "SEED: 1513, FOLD: 2, EPOCH: 6, train_loss: 0.016648644136021965\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 6, valid_loss: 0.016917958493447967\n",
      "SEED: 1513, FOLD: 2, EPOCH: 7, train_loss: 0.01633440704503353\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 7, valid_loss: 0.016982834475735824\n",
      "SEED: 1513, FOLD: 2, EPOCH: 8, train_loss: 0.01624189766690783\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016651317270265684\n",
      "SEED: 1513, FOLD: 2, EPOCH: 9, train_loss: 0.016254452691561935\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016642692033201456\n",
      "SEED: 1513, FOLD: 2, EPOCH: 10, train_loss: 0.016105529042365757\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 10, valid_loss: 0.0168920388031337\n",
      "SEED: 1513, FOLD: 2, EPOCH: 11, train_loss: 0.016026838574612488\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01644652709364891\n",
      "SEED: 1513, FOLD: 2, EPOCH: 12, train_loss: 0.015866260908112145\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016471485348625317\n",
      "SEED: 1513, FOLD: 2, EPOCH: 13, train_loss: 0.015806937981666862\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016547359060496092\n",
      "SEED: 1513, FOLD: 2, EPOCH: 14, train_loss: 0.015565916072523249\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016570492906288967\n",
      "SEED: 1513, FOLD: 2, EPOCH: 15, train_loss: 0.015370630794137285\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016284429623434942\n",
      "SEED: 1513, FOLD: 2, EPOCH: 16, train_loss: 0.015075829905876215\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016137015488412645\n",
      "SEED: 1513, FOLD: 2, EPOCH: 17, train_loss: 0.014662362986068794\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01611918733558721\n",
      "SEED: 1513, FOLD: 2, EPOCH: 18, train_loss: 0.014279004820770975\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01619711083670457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1513, FOLD: 2, EPOCH: 19, train_loss: 0.013735001326363155\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 19, valid_loss: 0.015980667693333492\n",
      "SEED: 1513, FOLD: 2, EPOCH: 20, train_loss: 0.013080957791079645\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01598525404309233\n",
      "SEED: 1513, FOLD: 2, EPOCH: 21, train_loss: 0.012425638708299484\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01596826133835647\n",
      "SEED: 1513, FOLD: 2, EPOCH: 22, train_loss: 0.011775551120872084\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 22, valid_loss: 0.015992806137849886\n",
      "SEED: 1513, FOLD: 2, EPOCH: 23, train_loss: 0.01123383699281924\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015959526412189007\n",
      "SEED: 1513, FOLD: 2, EPOCH: 24, train_loss: 0.011031053150477617\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 24, valid_loss: 0.015964934809340373\n",
      "SEED: 1513, FOLD: 3, EPOCH: 0, train_loss: 0.7129119487776272\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6056828167703416\n",
      "SEED: 1513, FOLD: 3, EPOCH: 1, train_loss: 0.20440754729012647\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 1, valid_loss: 0.022859208803209994\n",
      "SEED: 1513, FOLD: 3, EPOCH: 2, train_loss: 0.021101635759291443\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 2, valid_loss: 0.019380080099734995\n",
      "SEED: 1513, FOLD: 3, EPOCH: 3, train_loss: 0.018661569453020027\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018288259497947164\n",
      "SEED: 1513, FOLD: 3, EPOCH: 4, train_loss: 0.01810190293506004\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01781590148392651\n",
      "SEED: 1513, FOLD: 3, EPOCH: 5, train_loss: 0.017112430063602718\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017245410631100338\n",
      "SEED: 1513, FOLD: 3, EPOCH: 6, train_loss: 0.016894840918805287\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 6, valid_loss: 0.016998025123029947\n",
      "SEED: 1513, FOLD: 3, EPOCH: 7, train_loss: 0.01640342112522626\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01708558051743441\n",
      "SEED: 1513, FOLD: 3, EPOCH: 8, train_loss: 0.01623911329585573\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 8, valid_loss: 0.016912532090726826\n",
      "SEED: 1513, FOLD: 3, EPOCH: 9, train_loss: 0.016210814398052036\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 9, valid_loss: 0.016772053721878264\n",
      "SEED: 1513, FOLD: 3, EPOCH: 10, train_loss: 0.016099022795864636\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016892731758869357\n",
      "SEED: 1513, FOLD: 3, EPOCH: 11, train_loss: 0.016032210834648297\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016638306952599023\n",
      "SEED: 1513, FOLD: 3, EPOCH: 12, train_loss: 0.015880622901022434\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016497462677458923\n",
      "SEED: 1513, FOLD: 3, EPOCH: 13, train_loss: 0.01575942024372626\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016521806880417798\n",
      "SEED: 1513, FOLD: 3, EPOCH: 14, train_loss: 0.01561768284148496\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016392362200551562\n",
      "SEED: 1513, FOLD: 3, EPOCH: 15, train_loss: 0.015355439829653587\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016268853046413925\n",
      "SEED: 1513, FOLD: 3, EPOCH: 16, train_loss: 0.015084113979685133\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01618852662957377\n",
      "SEED: 1513, FOLD: 3, EPOCH: 17, train_loss: 0.014680129610865877\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016093607008871105\n",
      "SEED: 1513, FOLD: 3, EPOCH: 18, train_loss: 0.014313768878903078\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016027944421188697\n",
      "SEED: 1513, FOLD: 3, EPOCH: 19, train_loss: 0.01381282581259375\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 19, valid_loss: 0.015982419459356204\n",
      "SEED: 1513, FOLD: 3, EPOCH: 20, train_loss: 0.01311505515722261\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 20, valid_loss: 0.01597848834676875\n",
      "SEED: 1513, FOLD: 3, EPOCH: 21, train_loss: 0.012402710207886454\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01587350055989292\n",
      "SEED: 1513, FOLD: 3, EPOCH: 22, train_loss: 0.011804052264146183\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 22, valid_loss: 0.0158994205089079\n",
      "SEED: 1513, FOLD: 3, EPOCH: 23, train_loss: 0.011257207722983498\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01591339045100742\n",
      "SEED: 1513, FOLD: 3, EPOCH: 24, train_loss: 0.011063730992052866\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 24, valid_loss: 0.015924263849026628\n",
      "SEED: 1513, FOLD: 4, EPOCH: 0, train_loss: 0.712735192499299\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6121813853581747\n",
      "SEED: 1513, FOLD: 4, EPOCH: 1, train_loss: 0.2050696255342252\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 1, valid_loss: 0.022882299187282722\n",
      "SEED: 1513, FOLD: 4, EPOCH: 2, train_loss: 0.021002304591778397\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 2, valid_loss: 0.019624648926158745\n",
      "SEED: 1513, FOLD: 4, EPOCH: 3, train_loss: 0.018947974225317223\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 3, valid_loss: 0.018338435019056003\n",
      "SEED: 1513, FOLD: 4, EPOCH: 4, train_loss: 0.01781436539106611\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017435276466939185\n",
      "SEED: 1513, FOLD: 4, EPOCH: 5, train_loss: 0.017707963514587154\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017113476888173156\n",
      "SEED: 1513, FOLD: 4, EPOCH: 6, train_loss: 0.016692382229519062\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 6, valid_loss: 0.016907816752791405\n",
      "SEED: 1513, FOLD: 4, EPOCH: 7, train_loss: 0.016533800562762695\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017699349568121962\n",
      "SEED: 1513, FOLD: 4, EPOCH: 8, train_loss: 0.016616470355918442\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 8, valid_loss: 0.016676299532668457\n",
      "SEED: 1513, FOLD: 4, EPOCH: 9, train_loss: 0.016303617412737316\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01661244138247437\n",
      "SEED: 1513, FOLD: 4, EPOCH: 10, train_loss: 0.016158312289179234\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 10, valid_loss: 0.016665724313093558\n",
      "SEED: 1513, FOLD: 4, EPOCH: 11, train_loss: 0.01616143942743108\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016329007481949195\n",
      "SEED: 1513, FOLD: 4, EPOCH: 12, train_loss: 0.01600305676676225\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016569973331772618\n",
      "SEED: 1513, FOLD: 4, EPOCH: 13, train_loss: 0.015897779806476574\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01645635301247239\n",
      "SEED: 1513, FOLD: 4, EPOCH: 14, train_loss: 0.015697854962469875\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016174690590964422\n",
      "SEED: 1513, FOLD: 4, EPOCH: 15, train_loss: 0.01545928330903036\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01614782607389821\n",
      "SEED: 1513, FOLD: 4, EPOCH: 16, train_loss: 0.015230044817039068\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016061389456606574\n",
      "SEED: 1513, FOLD: 4, EPOCH: 17, train_loss: 0.014842935905292414\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01602031828628646\n",
      "SEED: 1513, FOLD: 4, EPOCH: 18, train_loss: 0.014425891559517038\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01579940298365222\n",
      "SEED: 1513, FOLD: 4, EPOCH: 19, train_loss: 0.013945949196383573\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 19, valid_loss: 0.0157460853871372\n",
      "SEED: 1513, FOLD: 4, EPOCH: 20, train_loss: 0.0132200058846586\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 20, valid_loss: 0.015619610332780413\n",
      "SEED: 1513, FOLD: 4, EPOCH: 21, train_loss: 0.01256648402499116\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015651487486643925\n",
      "SEED: 1513, FOLD: 4, EPOCH: 22, train_loss: 0.011903952874675177\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015635916963219643\n",
      "SEED: 1513, FOLD: 4, EPOCH: 23, train_loss: 0.011396155719631824\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 23, valid_loss: 0.015608327101088233\n",
      "SEED: 1513, FOLD: 4, EPOCH: 24, train_loss: 0.011193287788309914\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01560640645523866\n",
      "elapsed time: 225.44274020195007\n",
      "SEED: 1269, FOLD: 0, EPOCH: 0, train_loss: 0.7124892335007156\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 0, valid_loss: 0.621717267566257\n",
      "SEED: 1269, FOLD: 0, EPOCH: 1, train_loss: 0.20280979986747968\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 1, valid_loss: 0.02329875063151121\n",
      "SEED: 1269, FOLD: 0, EPOCH: 2, train_loss: 0.021161444269228672\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 2, valid_loss: 0.019525807092173234\n",
      "SEED: 1269, FOLD: 0, EPOCH: 3, train_loss: 0.018864855008280796\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 3, valid_loss: 0.018276206890328064\n",
      "SEED: 1269, FOLD: 0, EPOCH: 4, train_loss: 0.018088525863013405\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01777124648085899\n",
      "SEED: 1269, FOLD: 0, EPOCH: 5, train_loss: 0.01710744432943023\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 5, valid_loss: 0.01706557058625751\n",
      "SEED: 1269, FOLD: 0, EPOCH: 6, train_loss: 0.016936804626838886\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 6, valid_loss: 0.02274199202656746\n",
      "SEED: 1269, FOLD: 0, EPOCH: 7, train_loss: 0.017057683386340523\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01689597452059388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1269, FOLD: 0, EPOCH: 8, train_loss: 0.016437698924994987\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 8, valid_loss: 0.016766903611520927\n",
      "SEED: 1269, FOLD: 0, EPOCH: 9, train_loss: 0.016349687969878964\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 9, valid_loss: 0.016404570183820195\n",
      "SEED: 1269, FOLD: 0, EPOCH: 10, train_loss: 0.01615612114361231\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 10, valid_loss: 0.016572738635457225\n",
      "SEED: 1269, FOLD: 0, EPOCH: 11, train_loss: 0.016069984373946983\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 11, valid_loss: 0.016550880753331713\n",
      "SEED: 1269, FOLD: 0, EPOCH: 12, train_loss: 0.016043862651871597\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01642914457867543\n",
      "SEED: 1269, FOLD: 0, EPOCH: 13, train_loss: 0.015859826332956985\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016258138749334548\n",
      "SEED: 1269, FOLD: 0, EPOCH: 14, train_loss: 0.015687429008708485\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016251411599417526\n",
      "SEED: 1269, FOLD: 0, EPOCH: 15, train_loss: 0.015430981279823227\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016107213993867237\n",
      "SEED: 1269, FOLD: 0, EPOCH: 16, train_loss: 0.015225122763734797\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01592972067495187\n",
      "SEED: 1269, FOLD: 0, EPOCH: 17, train_loss: 0.014843067788667437\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 17, valid_loss: 0.015786569513794448\n",
      "SEED: 1269, FOLD: 0, EPOCH: 18, train_loss: 0.014413756439867228\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 18, valid_loss: 0.0158566085414754\n",
      "SEED: 1269, FOLD: 0, EPOCH: 19, train_loss: 0.01393912953958995\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 19, valid_loss: 0.015772186478392944\n",
      "SEED: 1269, FOLD: 0, EPOCH: 20, train_loss: 0.013324910653350145\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01571806939318776\n",
      "SEED: 1269, FOLD: 0, EPOCH: 21, train_loss: 0.01263034670357255\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015667262849294476\n",
      "SEED: 1269, FOLD: 0, EPOCH: 22, train_loss: 0.012010687381784985\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015685852254844375\n",
      "SEED: 1269, FOLD: 0, EPOCH: 23, train_loss: 0.011503092877134897\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015680755799015362\n",
      "SEED: 1269, FOLD: 0, EPOCH: 24, train_loss: 0.01129545926021925\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01566550585751732\n",
      "SEED: 1269, FOLD: 1, EPOCH: 0, train_loss: 0.7124803670938464\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 0, valid_loss: 0.5975327988465627\n",
      "SEED: 1269, FOLD: 1, EPOCH: 1, train_loss: 0.20408384645006794\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 1, valid_loss: 0.02329945729838477\n",
      "SEED: 1269, FOLD: 1, EPOCH: 2, train_loss: 0.021049750104978466\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 2, valid_loss: 0.01965318599508868\n",
      "SEED: 1269, FOLD: 1, EPOCH: 3, train_loss: 0.01901101002442664\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018259668308827613\n",
      "SEED: 1269, FOLD: 1, EPOCH: 4, train_loss: 0.017958418506643047\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017447886678079765\n",
      "SEED: 1269, FOLD: 1, EPOCH: 5, train_loss: 0.017335673659176067\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 5, valid_loss: 0.01740281977173355\n",
      "SEED: 1269, FOLD: 1, EPOCH: 6, train_loss: 0.016827445706703525\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 6, valid_loss: 0.016757876612246037\n",
      "SEED: 1269, FOLD: 1, EPOCH: 7, train_loss: 0.016422363119604794\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 7, valid_loss: 0.016862561615804832\n",
      "SEED: 1269, FOLD: 1, EPOCH: 8, train_loss: 0.016491103040027447\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 8, valid_loss: 0.016729956078860495\n",
      "SEED: 1269, FOLD: 1, EPOCH: 9, train_loss: 0.01639761974144241\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01652011378771729\n",
      "SEED: 1269, FOLD: 1, EPOCH: 10, train_loss: 0.01623853370277346\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01662484235647652\n",
      "SEED: 1269, FOLD: 1, EPOCH: 11, train_loss: 0.016058952183179234\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016442877654400136\n",
      "SEED: 1269, FOLD: 1, EPOCH: 12, train_loss: 0.01598952656638795\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01676452046053277\n",
      "SEED: 1269, FOLD: 1, EPOCH: 13, train_loss: 0.015851348476565403\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01630908354289002\n",
      "SEED: 1269, FOLD: 1, EPOCH: 14, train_loss: 0.015615851712831553\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016021600148330133\n",
      "SEED: 1269, FOLD: 1, EPOCH: 15, train_loss: 0.015399035943699057\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016048247305055458\n",
      "SEED: 1269, FOLD: 1, EPOCH: 16, train_loss: 0.015151770137574362\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 16, valid_loss: 0.015953630881590977\n",
      "SEED: 1269, FOLD: 1, EPOCH: 17, train_loss: 0.014795561874474304\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01585870386204786\n",
      "SEED: 1269, FOLD: 1, EPOCH: 18, train_loss: 0.014438568641418133\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 18, valid_loss: 0.015845745129303798\n",
      "SEED: 1269, FOLD: 1, EPOCH: 19, train_loss: 0.01392648444659468\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 19, valid_loss: 0.015835739051302273\n",
      "SEED: 1269, FOLD: 1, EPOCH: 20, train_loss: 0.013291520538969316\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 20, valid_loss: 0.015775651360551517\n",
      "SEED: 1269, FOLD: 1, EPOCH: 21, train_loss: 0.012563656921080057\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015692205323527258\n",
      "SEED: 1269, FOLD: 1, EPOCH: 22, train_loss: 0.011946726887338404\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015664938785549667\n",
      "SEED: 1269, FOLD: 1, EPOCH: 23, train_loss: 0.011488354602909607\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015685397976388533\n",
      "SEED: 1269, FOLD: 1, EPOCH: 24, train_loss: 0.011228404156323792\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01568345052914487\n",
      "SEED: 1269, FOLD: 2, EPOCH: 0, train_loss: 0.7126303246055824\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6054472128550211\n",
      "SEED: 1269, FOLD: 2, EPOCH: 1, train_loss: 0.20336459118171016\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 1, valid_loss: 0.023762700458367664\n",
      "SEED: 1269, FOLD: 2, EPOCH: 2, train_loss: 0.02098666409543459\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 2, valid_loss: 0.019344458046058815\n",
      "SEED: 1269, FOLD: 2, EPOCH: 3, train_loss: 0.01891957944178063\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01836193208065298\n",
      "SEED: 1269, FOLD: 2, EPOCH: 4, train_loss: 0.018068996244582577\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01753476422487034\n",
      "SEED: 1269, FOLD: 2, EPOCH: 5, train_loss: 0.01715208140566297\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017074021510779858\n",
      "SEED: 1269, FOLD: 2, EPOCH: 6, train_loss: 0.016576596495249996\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01700903045841389\n",
      "SEED: 1269, FOLD: 2, EPOCH: 7, train_loss: 0.016416923385923324\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 7, valid_loss: 0.016902188097851142\n",
      "SEED: 1269, FOLD: 2, EPOCH: 8, train_loss: 0.01631612105268067\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016715057763374515\n",
      "SEED: 1269, FOLD: 2, EPOCH: 9, train_loss: 0.01619953075018914\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016997124223659437\n",
      "SEED: 1269, FOLD: 2, EPOCH: 10, train_loss: 0.016055048200423302\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01698062651687198\n",
      "SEED: 1269, FOLD: 2, EPOCH: 11, train_loss: 0.016013285334127537\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016614411129719682\n",
      "SEED: 1269, FOLD: 2, EPOCH: 12, train_loss: 0.015942169204894184\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016539781561328307\n",
      "SEED: 1269, FOLD: 2, EPOCH: 13, train_loss: 0.0156439863604264\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016489133187052276\n",
      "SEED: 1269, FOLD: 2, EPOCH: 14, train_loss: 0.015535445397962694\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01631803401849336\n",
      "SEED: 1269, FOLD: 2, EPOCH: 15, train_loss: 0.015310126221806242\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016182683563480776\n",
      "SEED: 1269, FOLD: 2, EPOCH: 16, train_loss: 0.015046787245765976\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016350155903233424\n",
      "SEED: 1269, FOLD: 2, EPOCH: 17, train_loss: 0.014676678358860638\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016174879390746355\n",
      "SEED: 1269, FOLD: 2, EPOCH: 18, train_loss: 0.014260740289329618\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01616620375878281\n",
      "SEED: 1269, FOLD: 2, EPOCH: 19, train_loss: 0.013695556413976179\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016009097091025777\n",
      "SEED: 1269, FOLD: 2, EPOCH: 20, train_loss: 0.013054786196005518\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01600854041882687\n",
      "SEED: 1269, FOLD: 2, EPOCH: 21, train_loss: 0.012351573444902897\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015988887649857335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1269, FOLD: 2, EPOCH: 22, train_loss: 0.01170420006889364\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016002678622802097\n",
      "SEED: 1269, FOLD: 2, EPOCH: 23, train_loss: 0.011177998589540737\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01598661175618569\n",
      "SEED: 1269, FOLD: 2, EPOCH: 24, train_loss: 0.011005040946538034\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016010826350086264\n",
      "SEED: 1269, FOLD: 3, EPOCH: 0, train_loss: 0.7127395151317983\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6009805036915673\n",
      "SEED: 1269, FOLD: 3, EPOCH: 1, train_loss: 0.20380426646358724\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 1, valid_loss: 0.023143276882668335\n",
      "SEED: 1269, FOLD: 3, EPOCH: 2, train_loss: 0.02086722475571045\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 2, valid_loss: 0.019640291937523417\n",
      "SEED: 1269, FOLD: 3, EPOCH: 3, train_loss: 0.018817759429415066\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018420808741615877\n",
      "SEED: 1269, FOLD: 3, EPOCH: 4, train_loss: 0.017880389318410038\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017657981668081548\n",
      "SEED: 1269, FOLD: 3, EPOCH: 5, train_loss: 0.01713562608305095\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 5, valid_loss: 0.020714845404856734\n",
      "SEED: 1269, FOLD: 3, EPOCH: 6, train_loss: 0.0169528828177979\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01710507066713439\n",
      "SEED: 1269, FOLD: 3, EPOCH: 7, train_loss: 0.016392196177680424\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017088270228770044\n",
      "SEED: 1269, FOLD: 3, EPOCH: 8, train_loss: 0.016245003573704456\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 8, valid_loss: 0.016751399729400873\n",
      "SEED: 1269, FOLD: 3, EPOCH: 9, train_loss: 0.016136653842809406\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01673613478326135\n",
      "SEED: 1269, FOLD: 3, EPOCH: 10, train_loss: 0.016062627856930096\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016576929121381707\n",
      "SEED: 1269, FOLD: 3, EPOCH: 11, train_loss: 0.01600668071836665\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016594528272334073\n",
      "SEED: 1269, FOLD: 3, EPOCH: 12, train_loss: 0.01586962371146765\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 12, valid_loss: 0.0164648138711022\n",
      "SEED: 1269, FOLD: 3, EPOCH: 13, train_loss: 0.015805763044003128\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016521102127929527\n",
      "SEED: 1269, FOLD: 3, EPOCH: 14, train_loss: 0.015600668279913025\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01648424157044954\n",
      "SEED: 1269, FOLD: 3, EPOCH: 15, train_loss: 0.015310777148798756\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016255694441497326\n",
      "SEED: 1269, FOLD: 3, EPOCH: 16, train_loss: 0.01507908786120622\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01624271697882149\n",
      "SEED: 1269, FOLD: 3, EPOCH: 17, train_loss: 0.014725133884644163\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016198302308718365\n",
      "SEED: 1269, FOLD: 3, EPOCH: 18, train_loss: 0.014277623831361963\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 18, valid_loss: 0.015935945893741317\n",
      "SEED: 1269, FOLD: 3, EPOCH: 19, train_loss: 0.013778310876501642\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 19, valid_loss: 0.015986112205104694\n",
      "SEED: 1269, FOLD: 3, EPOCH: 20, train_loss: 0.013160937506219616\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 20, valid_loss: 0.015860127388603158\n",
      "SEED: 1269, FOLD: 3, EPOCH: 21, train_loss: 0.012480499020413212\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01584061359365781\n",
      "SEED: 1269, FOLD: 3, EPOCH: 22, train_loss: 0.011784159821336683\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 22, valid_loss: 0.015820332440651126\n",
      "SEED: 1269, FOLD: 3, EPOCH: 23, train_loss: 0.0112474264604026\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01579578427804841\n",
      "SEED: 1269, FOLD: 3, EPOCH: 24, train_loss: 0.011056828987447248\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 24, valid_loss: 0.015804650055037603\n",
      "SEED: 1269, FOLD: 4, EPOCH: 0, train_loss: 0.7131275828333868\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6114987267388238\n",
      "SEED: 1269, FOLD: 4, EPOCH: 1, train_loss: 0.20600753631172836\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 1, valid_loss: 0.02402984702752696\n",
      "SEED: 1269, FOLD: 4, EPOCH: 2, train_loss: 0.021121781562333523\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 2, valid_loss: 0.01935681824882825\n",
      "SEED: 1269, FOLD: 4, EPOCH: 3, train_loss: 0.01894389829881813\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01817026837832398\n",
      "SEED: 1269, FOLD: 4, EPOCH: 4, train_loss: 0.018021904728442863\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 4, valid_loss: 0.01746281101885769\n",
      "SEED: 1269, FOLD: 4, EPOCH: 5, train_loss: 0.017234893988116062\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017024266637033887\n",
      "SEED: 1269, FOLD: 4, EPOCH: 6, train_loss: 0.016789556534933872\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 6, valid_loss: 0.016846075809250276\n",
      "SEED: 1269, FOLD: 4, EPOCH: 7, train_loss: 0.016466074150757515\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01679693700538741\n",
      "SEED: 1269, FOLD: 4, EPOCH: 8, train_loss: 0.016365111886483173\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 8, valid_loss: 0.016809147886104055\n",
      "SEED: 1269, FOLD: 4, EPOCH: 9, train_loss: 0.01627677441507146\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 9, valid_loss: 0.016952320467680693\n",
      "SEED: 1269, FOLD: 4, EPOCH: 10, train_loss: 0.016230173516964565\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01669053127989173\n",
      "SEED: 1269, FOLD: 4, EPOCH: 11, train_loss: 0.016041111336022183\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016390374085555475\n",
      "SEED: 1269, FOLD: 4, EPOCH: 12, train_loss: 0.015894053085450676\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016453346547981102\n",
      "SEED: 1269, FOLD: 4, EPOCH: 13, train_loss: 0.01575093895898781\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016216288062019482\n",
      "SEED: 1269, FOLD: 4, EPOCH: 14, train_loss: 0.01563332070583019\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016279675118211243\n",
      "SEED: 1269, FOLD: 4, EPOCH: 15, train_loss: 0.015405232950613119\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016103951519148216\n",
      "SEED: 1269, FOLD: 4, EPOCH: 16, train_loss: 0.01506396782570991\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01608367905848556\n",
      "SEED: 1269, FOLD: 4, EPOCH: 17, train_loss: 0.014700244774744995\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016000934669540987\n",
      "SEED: 1269, FOLD: 4, EPOCH: 18, train_loss: 0.014231187844837921\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 18, valid_loss: 0.015856264262563653\n",
      "SEED: 1269, FOLD: 4, EPOCH: 19, train_loss: 0.013751469957439796\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01585633105908831\n",
      "SEED: 1269, FOLD: 4, EPOCH: 20, train_loss: 0.013112743398633556\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01582034496176574\n",
      "SEED: 1269, FOLD: 4, EPOCH: 21, train_loss: 0.012397976713659971\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 21, valid_loss: 0.0156753763763441\n",
      "SEED: 1269, FOLD: 4, EPOCH: 22, train_loss: 0.011743514717597029\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015706691839214828\n",
      "SEED: 1269, FOLD: 4, EPOCH: 23, train_loss: 0.011257278436012026\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01570728302208914\n",
      "SEED: 1269, FOLD: 4, EPOCH: 24, train_loss: 0.011014193552883638\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015703771573801834\n",
      "elapsed time: 335.98916935920715\n",
      "SEED: 1392, FOLD: 0, EPOCH: 0, train_loss: 0.7137704448423524\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6289675268861983\n",
      "SEED: 1392, FOLD: 0, EPOCH: 1, train_loss: 0.20254121229484462\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 1, valid_loss: 0.023429701932602458\n",
      "SEED: 1392, FOLD: 0, EPOCH: 2, train_loss: 0.021010839096877888\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01931417728256848\n",
      "SEED: 1392, FOLD: 0, EPOCH: 3, train_loss: 0.01885458640754223\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 3, valid_loss: 0.01826999057084322\n",
      "SEED: 1392, FOLD: 0, EPOCH: 4, train_loss: 0.017847829673817192\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01840966370784574\n",
      "SEED: 1392, FOLD: 0, EPOCH: 5, train_loss: 0.017242645696345447\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017000302568905883\n",
      "SEED: 1392, FOLD: 0, EPOCH: 6, train_loss: 0.01665076783493809\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 6, valid_loss: 0.016997605976131227\n",
      "SEED: 1392, FOLD: 0, EPOCH: 7, train_loss: 0.01648323820984882\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01672189310193062\n",
      "SEED: 1392, FOLD: 0, EPOCH: 8, train_loss: 0.016309811504206795\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01663302940626939\n",
      "SEED: 1392, FOLD: 0, EPOCH: 9, train_loss: 0.016292007059614727\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 9, valid_loss: 0.016699089461730585\n",
      "SEED: 1392, FOLD: 0, EPOCH: 10, train_loss: 0.01612998588361602\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 10, valid_loss: 0.016626156814810302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1392, FOLD: 0, EPOCH: 11, train_loss: 0.016097641684978767\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01650571460939116\n",
      "SEED: 1392, FOLD: 0, EPOCH: 12, train_loss: 0.015965741748611133\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01637556916102767\n",
      "SEED: 1392, FOLD: 0, EPOCH: 13, train_loss: 0.0157690169694631\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016336217367400725\n",
      "SEED: 1392, FOLD: 0, EPOCH: 14, train_loss: 0.015673524970053764\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 14, valid_loss: 0.01615924688263072\n",
      "SEED: 1392, FOLD: 0, EPOCH: 15, train_loss: 0.015420452381173769\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01605805480438802\n",
      "SEED: 1392, FOLD: 0, EPOCH: 16, train_loss: 0.015164129031093224\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 16, valid_loss: 0.015953205784575805\n",
      "SEED: 1392, FOLD: 0, EPOCH: 17, train_loss: 0.01474861672445052\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 17, valid_loss: 0.015852466432584658\n",
      "SEED: 1392, FOLD: 0, EPOCH: 18, train_loss: 0.014353182180312233\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 18, valid_loss: 0.015733534780641396\n",
      "SEED: 1392, FOLD: 0, EPOCH: 19, train_loss: 0.013848622801943102\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 19, valid_loss: 0.015778315098335344\n",
      "SEED: 1392, FOLD: 0, EPOCH: 20, train_loss: 0.013212041699907917\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 20, valid_loss: 0.015649244603183534\n",
      "SEED: 1392, FOLD: 0, EPOCH: 21, train_loss: 0.012538529379104359\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015652228974633746\n",
      "SEED: 1392, FOLD: 0, EPOCH: 22, train_loss: 0.011903636413963808\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015696369318498507\n",
      "SEED: 1392, FOLD: 0, EPOCH: 23, train_loss: 0.01142115176965793\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01567482456771864\n",
      "SEED: 1392, FOLD: 0, EPOCH: 24, train_loss: 0.011220719543812067\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015673260670155287\n",
      "SEED: 1392, FOLD: 1, EPOCH: 0, train_loss: 0.714285571506058\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6005683872434828\n",
      "SEED: 1392, FOLD: 1, EPOCH: 1, train_loss: 0.20398136222924013\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 1, valid_loss: 0.0230257295899921\n",
      "SEED: 1392, FOLD: 1, EPOCH: 2, train_loss: 0.021004360358136288\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 2, valid_loss: 0.019618733889526792\n",
      "SEED: 1392, FOLD: 1, EPOCH: 3, train_loss: 0.019022785073173218\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018363553513255384\n",
      "SEED: 1392, FOLD: 1, EPOCH: 4, train_loss: 0.01789198807724144\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017944575804803107\n",
      "SEED: 1392, FOLD: 1, EPOCH: 5, train_loss: 0.017477857178428036\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 5, valid_loss: 0.01718880867378579\n",
      "SEED: 1392, FOLD: 1, EPOCH: 6, train_loss: 0.017104505426317886\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017030849845872983\n",
      "SEED: 1392, FOLD: 1, EPOCH: 7, train_loss: 0.016487632567683857\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 7, valid_loss: 0.016687620845105913\n",
      "SEED: 1392, FOLD: 1, EPOCH: 8, train_loss: 0.01638277298838332\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 8, valid_loss: 0.016470478537182014\n",
      "SEED: 1392, FOLD: 1, EPOCH: 9, train_loss: 0.016349118351396442\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01669109592007266\n",
      "SEED: 1392, FOLD: 1, EPOCH: 10, train_loss: 0.0161966807546391\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016524942488306098\n",
      "SEED: 1392, FOLD: 1, EPOCH: 11, train_loss: 0.016075097726307053\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 11, valid_loss: 0.0164595123173462\n",
      "SEED: 1392, FOLD: 1, EPOCH: 12, train_loss: 0.015985730994978676\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01645080465823412\n",
      "SEED: 1392, FOLD: 1, EPOCH: 13, train_loss: 0.015923449432180412\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016275231519507036\n",
      "SEED: 1392, FOLD: 1, EPOCH: 14, train_loss: 0.015674800517550415\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016050296576900616\n",
      "SEED: 1392, FOLD: 1, EPOCH: 15, train_loss: 0.01537427715147319\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016014252582357988\n",
      "SEED: 1392, FOLD: 1, EPOCH: 16, train_loss: 0.015142127588067366\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 16, valid_loss: 0.01604474460085233\n",
      "SEED: 1392, FOLD: 1, EPOCH: 17, train_loss: 0.014866267560400825\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 17, valid_loss: 0.015934302057656977\n",
      "SEED: 1392, FOLD: 1, EPOCH: 18, train_loss: 0.014429058326219303\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 18, valid_loss: 0.015863866907440953\n",
      "SEED: 1392, FOLD: 1, EPOCH: 19, train_loss: 0.013858054670086805\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01571531319576833\n",
      "SEED: 1392, FOLD: 1, EPOCH: 20, train_loss: 0.013327964999969456\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 20, valid_loss: 0.015621997829940584\n",
      "SEED: 1392, FOLD: 1, EPOCH: 21, train_loss: 0.012652404700824316\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015576392205225097\n",
      "SEED: 1392, FOLD: 1, EPOCH: 22, train_loss: 0.012020931552177753\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015567937451932166\n",
      "SEED: 1392, FOLD: 1, EPOCH: 23, train_loss: 0.011496741959042307\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015579723132153353\n",
      "SEED: 1392, FOLD: 1, EPOCH: 24, train_loss: 0.011334297787128151\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015586078373922242\n",
      "SEED: 1392, FOLD: 2, EPOCH: 0, train_loss: 0.7142101396685061\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6020324296421475\n",
      "SEED: 1392, FOLD: 2, EPOCH: 1, train_loss: 0.20437453760077123\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 1, valid_loss: 0.02324928415732251\n",
      "SEED: 1392, FOLD: 2, EPOCH: 2, train_loss: 0.020981704195340473\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 2, valid_loss: 0.019460579380393028\n",
      "SEED: 1392, FOLD: 2, EPOCH: 3, train_loss: 0.01886689843798893\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 3, valid_loss: 0.018377556672526732\n",
      "SEED: 1392, FOLD: 2, EPOCH: 4, train_loss: 0.01796713136676429\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01769807722626461\n",
      "SEED: 1392, FOLD: 2, EPOCH: 5, train_loss: 0.01710167679719735\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01702540310927563\n",
      "SEED: 1392, FOLD: 2, EPOCH: 6, train_loss: 0.01864222385853097\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01743125868961215\n",
      "SEED: 1392, FOLD: 2, EPOCH: 7, train_loss: 0.016957148828584213\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017087162368827395\n",
      "SEED: 1392, FOLD: 2, EPOCH: 8, train_loss: 0.016625292356247486\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01696878309465117\n",
      "SEED: 1392, FOLD: 2, EPOCH: 9, train_loss: 0.01633273819596439\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016765694340897933\n",
      "SEED: 1392, FOLD: 2, EPOCH: 10, train_loss: 0.016172267199642418\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01650988284705414\n",
      "SEED: 1392, FOLD: 2, EPOCH: 11, train_loss: 0.016082705943372803\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016589470259431336\n",
      "SEED: 1392, FOLD: 2, EPOCH: 12, train_loss: 0.015977163313199646\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016425269345442455\n",
      "SEED: 1392, FOLD: 2, EPOCH: 13, train_loss: 0.01573722879739775\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016388140049659543\n",
      "SEED: 1392, FOLD: 2, EPOCH: 14, train_loss: 0.01551176569815995\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01639767363667488\n",
      "SEED: 1392, FOLD: 2, EPOCH: 15, train_loss: 0.015347380083108294\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016292478889226913\n",
      "SEED: 1392, FOLD: 2, EPOCH: 16, train_loss: 0.015016098007343817\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016338704567816522\n",
      "SEED: 1392, FOLD: 2, EPOCH: 17, train_loss: 0.014741324455193851\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01608012228583296\n",
      "SEED: 1392, FOLD: 2, EPOCH: 18, train_loss: 0.014301483262924181\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016128733133276302\n",
      "SEED: 1392, FOLD: 2, EPOCH: 19, train_loss: 0.013724737949129463\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01609014155757096\n",
      "SEED: 1392, FOLD: 2, EPOCH: 20, train_loss: 0.013050630594185297\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 20, valid_loss: 0.015986072986076277\n",
      "SEED: 1392, FOLD: 2, EPOCH: 21, train_loss: 0.012310454109008762\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01601674681943324\n",
      "SEED: 1392, FOLD: 2, EPOCH: 22, train_loss: 0.011616939422337042\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016019642766979005\n",
      "SEED: 1392, FOLD: 2, EPOCH: 23, train_loss: 0.011091083787597609\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01601634831685159\n",
      "SEED: 1392, FOLD: 2, EPOCH: 24, train_loss: 0.010823167550067106\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016013804202278454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1392, FOLD: 3, EPOCH: 0, train_loss: 0.7142266631126404\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6155180831750234\n",
      "SEED: 1392, FOLD: 3, EPOCH: 1, train_loss: 0.20392211054222306\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 1, valid_loss: 0.023242825435267553\n",
      "SEED: 1392, FOLD: 3, EPOCH: 2, train_loss: 0.02114195657381113\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 2, valid_loss: 0.019583909668856196\n",
      "SEED: 1392, FOLD: 3, EPOCH: 3, train_loss: 0.018881930389266083\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 3, valid_loss: 0.01837532724150353\n",
      "SEED: 1392, FOLD: 3, EPOCH: 4, train_loss: 0.017970061145614887\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01772538246586919\n",
      "SEED: 1392, FOLD: 3, EPOCH: 5, train_loss: 0.017067205012384533\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017374441648523014\n",
      "SEED: 1392, FOLD: 3, EPOCH: 6, train_loss: 0.016558105679417866\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01751897142579158\n",
      "SEED: 1392, FOLD: 3, EPOCH: 7, train_loss: 0.016435607835866402\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 7, valid_loss: 0.016942743056764204\n",
      "SEED: 1392, FOLD: 3, EPOCH: 8, train_loss: 0.016290843027873314\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 8, valid_loss: 0.016796792081246775\n",
      "SEED: 1392, FOLD: 3, EPOCH: 9, train_loss: 0.01611772116165662\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01691180058858461\n",
      "SEED: 1392, FOLD: 3, EPOCH: 10, train_loss: 0.01611430254643378\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016881071858935885\n",
      "SEED: 1392, FOLD: 3, EPOCH: 11, train_loss: 0.016003358204835567\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016706797087358102\n",
      "SEED: 1392, FOLD: 3, EPOCH: 12, train_loss: 0.015823988122460636\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016597015576230154\n",
      "SEED: 1392, FOLD: 3, EPOCH: 13, train_loss: 0.015696033524970215\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016459047018239897\n",
      "SEED: 1392, FOLD: 3, EPOCH: 14, train_loss: 0.015550411171347334\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016455238012390003\n",
      "SEED: 1392, FOLD: 3, EPOCH: 15, train_loss: 0.015315670074652071\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016138371028419998\n",
      "SEED: 1392, FOLD: 3, EPOCH: 16, train_loss: 0.01501535602669785\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01618102715454168\n",
      "SEED: 1392, FOLD: 3, EPOCH: 17, train_loss: 0.014671460968320784\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01608224032032821\n",
      "SEED: 1392, FOLD: 3, EPOCH: 18, train_loss: 0.014254308157209038\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 18, valid_loss: 0.015992515720427036\n",
      "SEED: 1392, FOLD: 3, EPOCH: 19, train_loss: 0.013700730896190456\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 19, valid_loss: 0.015846229520522885\n",
      "SEED: 1392, FOLD: 3, EPOCH: 20, train_loss: 0.013095034421354101\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 20, valid_loss: 0.015808927671362955\n",
      "SEED: 1392, FOLD: 3, EPOCH: 21, train_loss: 0.012425898979215519\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 21, valid_loss: 0.015817742536051407\n",
      "SEED: 1392, FOLD: 3, EPOCH: 22, train_loss: 0.01172854122368322\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 22, valid_loss: 0.015749069085965555\n",
      "SEED: 1392, FOLD: 3, EPOCH: 23, train_loss: 0.01127845908690622\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 23, valid_loss: 0.015730202870650425\n",
      "SEED: 1392, FOLD: 3, EPOCH: 24, train_loss: 0.011043566940487295\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 24, valid_loss: 0.015725721812082663\n",
      "SEED: 1392, FOLD: 4, EPOCH: 0, train_loss: 0.7136909236078677\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 0, valid_loss: 0.5968363715542687\n",
      "SEED: 1392, FOLD: 4, EPOCH: 1, train_loss: 0.20236698027862154\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 1, valid_loss: 0.023057259619235992\n",
      "SEED: 1392, FOLD: 4, EPOCH: 2, train_loss: 0.020845322073369785\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 2, valid_loss: 0.01928314111298985\n",
      "SEED: 1392, FOLD: 4, EPOCH: 3, train_loss: 0.018661919900256653\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 3, valid_loss: 0.018029511181844607\n",
      "SEED: 1392, FOLD: 4, EPOCH: 4, train_loss: 0.01812945549254832\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017590757666362658\n",
      "SEED: 1392, FOLD: 4, EPOCH: 5, train_loss: 0.017633413288580334\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017215347848832607\n",
      "SEED: 1392, FOLD: 4, EPOCH: 6, train_loss: 0.017607445261724617\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01709320680755708\n",
      "SEED: 1392, FOLD: 4, EPOCH: 7, train_loss: 0.016711842363187367\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01682241949149304\n",
      "SEED: 1392, FOLD: 4, EPOCH: 8, train_loss: 0.016375538299157135\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 8, valid_loss: 0.016676707814137142\n",
      "SEED: 1392, FOLD: 4, EPOCH: 9, train_loss: 0.016268107270740944\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 9, valid_loss: 0.016543308635138802\n",
      "SEED: 1392, FOLD: 4, EPOCH: 10, train_loss: 0.016200869033734005\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 10, valid_loss: 0.016461944207549095\n",
      "SEED: 1392, FOLD: 4, EPOCH: 11, train_loss: 0.016087783608531605\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016315410379320383\n",
      "SEED: 1392, FOLD: 4, EPOCH: 12, train_loss: 0.016030184398202793\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016347229480743408\n",
      "SEED: 1392, FOLD: 4, EPOCH: 13, train_loss: 0.015798992126424244\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016343751456588507\n",
      "SEED: 1392, FOLD: 4, EPOCH: 14, train_loss: 0.015623728218285934\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016279265388018556\n",
      "SEED: 1392, FOLD: 4, EPOCH: 15, train_loss: 0.015446181773491528\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016123516329874594\n",
      "SEED: 1392, FOLD: 4, EPOCH: 16, train_loss: 0.015161041116368944\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016230372349835105\n",
      "SEED: 1392, FOLD: 4, EPOCH: 17, train_loss: 0.01475697039100139\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01584922041123112\n",
      "SEED: 1392, FOLD: 4, EPOCH: 18, train_loss: 0.014418847022065218\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 18, valid_loss: 0.015864633075479005\n",
      "SEED: 1392, FOLD: 4, EPOCH: 19, train_loss: 0.013852955139093641\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 19, valid_loss: 0.015756345457500882\n",
      "SEED: 1392, FOLD: 4, EPOCH: 20, train_loss: 0.013299726408676825\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 20, valid_loss: 0.015708915216641292\n",
      "SEED: 1392, FOLD: 4, EPOCH: 21, train_loss: 0.012581503977054272\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015658919233828783\n",
      "SEED: 1392, FOLD: 4, EPOCH: 22, train_loss: 0.01186320018293201\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015651972343524296\n",
      "SEED: 1392, FOLD: 4, EPOCH: 23, train_loss: 0.01140338364664627\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 23, valid_loss: 0.015657494827691052\n",
      "SEED: 1392, FOLD: 4, EPOCH: 24, train_loss: 0.011161225969376772\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015653953059679933\n",
      "elapsed time: 446.59997272491455\n",
      "SEED: 1119, FOLD: 0, EPOCH: 0, train_loss: 0.7131713481916897\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6223820282353295\n",
      "SEED: 1119, FOLD: 0, EPOCH: 1, train_loss: 0.20295502034866292\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 1, valid_loss: 0.02304282712025775\n",
      "SEED: 1119, FOLD: 0, EPOCH: 2, train_loss: 0.020821810686501904\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01913329679518938\n",
      "SEED: 1119, FOLD: 0, EPOCH: 3, train_loss: 0.018727823309060455\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 3, valid_loss: 0.01830815151333809\n",
      "SEED: 1119, FOLD: 0, EPOCH: 4, train_loss: 0.018249310337115025\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017769078620605998\n",
      "SEED: 1119, FOLD: 0, EPOCH: 5, train_loss: 0.017143351997694244\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017426860932674672\n",
      "SEED: 1119, FOLD: 0, EPOCH: 6, train_loss: 0.016939149022210335\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01705030972758929\n",
      "SEED: 1119, FOLD: 0, EPOCH: 7, train_loss: 0.01657263663313959\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 7, valid_loss: 0.016707806382328272\n",
      "SEED: 1119, FOLD: 0, EPOCH: 8, train_loss: 0.016342995391375778\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01675075271891223\n",
      "SEED: 1119, FOLD: 0, EPOCH: 9, train_loss: 0.016235025599598885\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 9, valid_loss: 0.016489544417709112\n",
      "SEED: 1119, FOLD: 0, EPOCH: 10, train_loss: 0.01612703942194365\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01649472267470426\n",
      "SEED: 1119, FOLD: 0, EPOCH: 11, train_loss: 0.01608332754045293\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01656448163299097\n",
      "SEED: 1119, FOLD: 0, EPOCH: 12, train_loss: 0.0159636823784398\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016408641563935414\n",
      "SEED: 1119, FOLD: 0, EPOCH: 13, train_loss: 0.01579011540751958\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016277951498826344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1119, FOLD: 0, EPOCH: 14, train_loss: 0.015613302264524542\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016190104445235595\n",
      "SEED: 1119, FOLD: 0, EPOCH: 15, train_loss: 0.015402941127726133\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016127841857572395\n",
      "SEED: 1119, FOLD: 0, EPOCH: 16, train_loss: 0.015165757144922796\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016036606238534052\n",
      "SEED: 1119, FOLD: 0, EPOCH: 17, train_loss: 0.014885168536093788\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 17, valid_loss: 0.015852090023044083\n",
      "SEED: 1119, FOLD: 0, EPOCH: 18, train_loss: 0.014356870717112568\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 18, valid_loss: 0.015828294834742945\n",
      "SEED: 1119, FOLD: 0, EPOCH: 19, train_loss: 0.013911717044918434\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01584018777228064\n",
      "SEED: 1119, FOLD: 0, EPOCH: 20, train_loss: 0.013312242533741653\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 20, valid_loss: 0.015705842783467636\n",
      "SEED: 1119, FOLD: 0, EPOCH: 21, train_loss: 0.012599494200253832\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01566016761999991\n",
      "SEED: 1119, FOLD: 0, EPOCH: 22, train_loss: 0.011928188331101252\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015710841605646744\n",
      "SEED: 1119, FOLD: 0, EPOCH: 23, train_loss: 0.011472289153523203\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015707033841560285\n",
      "SEED: 1119, FOLD: 0, EPOCH: 24, train_loss: 0.011224697249523108\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01569725459234582\n",
      "SEED: 1119, FOLD: 1, EPOCH: 0, train_loss: 0.7134365197541057\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6121502584881253\n",
      "SEED: 1119, FOLD: 1, EPOCH: 1, train_loss: 0.2051021049366049\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 1, valid_loss: 0.022754237780140504\n",
      "SEED: 1119, FOLD: 1, EPOCH: 2, train_loss: 0.02151377998508405\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 2, valid_loss: 0.019673257859216794\n",
      "SEED: 1119, FOLD: 1, EPOCH: 3, train_loss: 0.018888635344911312\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018379323908852205\n",
      "SEED: 1119, FOLD: 1, EPOCH: 4, train_loss: 0.018565082058742428\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 4, valid_loss: 0.02006546614898576\n",
      "SEED: 1119, FOLD: 1, EPOCH: 5, train_loss: 0.017645883130962433\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017234274186193943\n",
      "SEED: 1119, FOLD: 1, EPOCH: 6, train_loss: 0.016757791510958603\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 6, valid_loss: 0.016823256388306618\n",
      "SEED: 1119, FOLD: 1, EPOCH: 7, train_loss: 0.01664414785910344\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 7, valid_loss: 0.016731309704482555\n",
      "SEED: 1119, FOLD: 1, EPOCH: 8, train_loss: 0.0167409787359445\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01671977827532424\n",
      "SEED: 1119, FOLD: 1, EPOCH: 9, train_loss: 0.016400105670850346\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 9, valid_loss: 0.016576430035962\n",
      "SEED: 1119, FOLD: 1, EPOCH: 10, train_loss: 0.01626425907285749\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016521788202226162\n",
      "SEED: 1119, FOLD: 1, EPOCH: 11, train_loss: 0.01616862682166739\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016444206496493682\n",
      "SEED: 1119, FOLD: 1, EPOCH: 12, train_loss: 0.0160494157369586\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016562943036357563\n",
      "SEED: 1119, FOLD: 1, EPOCH: 13, train_loss: 0.015949068456024364\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016339639046539862\n",
      "SEED: 1119, FOLD: 1, EPOCH: 14, train_loss: 0.015765157541719036\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016297399790750608\n",
      "SEED: 1119, FOLD: 1, EPOCH: 15, train_loss: 0.015494536689442137\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016295087058097124\n",
      "SEED: 1119, FOLD: 1, EPOCH: 16, train_loss: 0.015295407329888447\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016027068408826988\n",
      "SEED: 1119, FOLD: 1, EPOCH: 17, train_loss: 0.014983186673750912\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 17, valid_loss: 0.015930810011923313\n",
      "SEED: 1119, FOLD: 1, EPOCH: 18, train_loss: 0.014490870151506819\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 18, valid_loss: 0.015718005494111113\n",
      "SEED: 1119, FOLD: 1, EPOCH: 19, train_loss: 0.014024378016483093\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 19, valid_loss: 0.015748471383833222\n",
      "SEED: 1119, FOLD: 1, EPOCH: 20, train_loss: 0.013450368442505167\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 20, valid_loss: 0.01565185096114874\n",
      "SEED: 1119, FOLD: 1, EPOCH: 21, train_loss: 0.012750840907835442\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015661001826326054\n",
      "SEED: 1119, FOLD: 1, EPOCH: 22, train_loss: 0.012089474450634874\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 22, valid_loss: 0.0156181661101679\n",
      "SEED: 1119, FOLD: 1, EPOCH: 23, train_loss: 0.011618709650592527\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015635555196139548\n",
      "SEED: 1119, FOLD: 1, EPOCH: 24, train_loss: 0.01134522815329441\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015644890256226063\n",
      "SEED: 1119, FOLD: 2, EPOCH: 0, train_loss: 0.7135947519454403\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6042047407892015\n",
      "SEED: 1119, FOLD: 2, EPOCH: 1, train_loss: 0.2052453080651121\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 1, valid_loss: 0.02288401561478774\n",
      "SEED: 1119, FOLD: 2, EPOCH: 2, train_loss: 0.020974959611244823\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 2, valid_loss: 0.01976708457287815\n",
      "SEED: 1119, FOLD: 2, EPOCH: 3, train_loss: 0.01882615936515124\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 3, valid_loss: 0.018169108364317153\n",
      "SEED: 1119, FOLD: 2, EPOCH: 4, train_loss: 0.017941979218976223\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017653110385355022\n",
      "SEED: 1119, FOLD: 2, EPOCH: 5, train_loss: 0.017931227882703144\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01738651262389289\n",
      "SEED: 1119, FOLD: 2, EPOCH: 6, train_loss: 0.016722983640173206\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01701062053648962\n",
      "SEED: 1119, FOLD: 2, EPOCH: 7, train_loss: 0.01641691509850215\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 7, valid_loss: 0.016765406407001946\n",
      "SEED: 1119, FOLD: 2, EPOCH: 8, train_loss: 0.01637044130568055\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016830914239916537\n",
      "SEED: 1119, FOLD: 2, EPOCH: 9, train_loss: 0.01628726275394792\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016795487608760595\n",
      "SEED: 1119, FOLD: 2, EPOCH: 10, train_loss: 0.016100614817570084\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 10, valid_loss: 0.016800327692180872\n",
      "SEED: 1119, FOLD: 2, EPOCH: 11, train_loss: 0.016025299678786076\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016799963338093624\n",
      "SEED: 1119, FOLD: 2, EPOCH: 12, train_loss: 0.015951781830601933\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01658456094769968\n",
      "SEED: 1119, FOLD: 2, EPOCH: 13, train_loss: 0.01572064419641443\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016391528045965567\n",
      "SEED: 1119, FOLD: 2, EPOCH: 14, train_loss: 0.01560209453969762\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016423199532760516\n",
      "SEED: 1119, FOLD: 2, EPOCH: 15, train_loss: 0.01532745577286983\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01625168002727959\n",
      "SEED: 1119, FOLD: 2, EPOCH: 16, train_loss: 0.015085892144428648\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016267266900589068\n",
      "SEED: 1119, FOLD: 2, EPOCH: 17, train_loss: 0.014703361304017944\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01606661681499746\n",
      "SEED: 1119, FOLD: 2, EPOCH: 18, train_loss: 0.01433603820539471\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016055181777725618\n",
      "SEED: 1119, FOLD: 2, EPOCH: 19, train_loss: 0.013806715594145699\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016022704179502197\n",
      "SEED: 1119, FOLD: 2, EPOCH: 20, train_loss: 0.013117348950734173\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 20, valid_loss: 0.015950913023617532\n",
      "SEED: 1119, FOLD: 2, EPOCH: 21, train_loss: 0.01245407409210136\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015990039695882134\n",
      "SEED: 1119, FOLD: 2, EPOCH: 22, train_loss: 0.011807019552350908\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 22, valid_loss: 0.015991260763257742\n",
      "SEED: 1119, FOLD: 2, EPOCH: 23, train_loss: 0.011334025894926079\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015965398504502244\n",
      "SEED: 1119, FOLD: 2, EPOCH: 24, train_loss: 0.011087727409018122\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01598839420411322\n",
      "SEED: 1119, FOLD: 3, EPOCH: 0, train_loss: 0.7128843017246412\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6210899021890428\n",
      "SEED: 1119, FOLD: 3, EPOCH: 1, train_loss: 0.2020373281793318\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 1, valid_loss: 0.02368354041957193\n",
      "SEED: 1119, FOLD: 3, EPOCH: 2, train_loss: 0.02092782815621383\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 2, valid_loss: 0.019689565627939172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1119, FOLD: 3, EPOCH: 3, train_loss: 0.01885689827411071\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 3, valid_loss: 0.01854017335507605\n",
      "SEED: 1119, FOLD: 3, EPOCH: 4, train_loss: 0.01771986385996359\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01831452227714989\n",
      "SEED: 1119, FOLD: 3, EPOCH: 5, train_loss: 0.017591862750334152\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017233004379603598\n",
      "SEED: 1119, FOLD: 3, EPOCH: 6, train_loss: 0.01659698880183092\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017232329895099003\n",
      "SEED: 1119, FOLD: 3, EPOCH: 7, train_loss: 0.01637173562810041\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 7, valid_loss: 0.016950516185412805\n",
      "SEED: 1119, FOLD: 3, EPOCH: 8, train_loss: 0.01631733463348254\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01719138626423147\n",
      "SEED: 1119, FOLD: 3, EPOCH: 9, train_loss: 0.016300996212099773\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 9, valid_loss: 0.016709826110551756\n",
      "SEED: 1119, FOLD: 3, EPOCH: 10, train_loss: 0.016129332324624924\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016806385945528746\n",
      "SEED: 1119, FOLD: 3, EPOCH: 11, train_loss: 0.01599326446328474\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016600276653965313\n",
      "SEED: 1119, FOLD: 3, EPOCH: 12, train_loss: 0.01590260191132193\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016692783476577863\n",
      "SEED: 1119, FOLD: 3, EPOCH: 13, train_loss: 0.015828996032908344\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016668986891292863\n",
      "SEED: 1119, FOLD: 3, EPOCH: 14, train_loss: 0.01558073634362739\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016392313823517825\n",
      "SEED: 1119, FOLD: 3, EPOCH: 15, train_loss: 0.015393751686897831\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01632178911111421\n",
      "SEED: 1119, FOLD: 3, EPOCH: 16, train_loss: 0.015095392093602299\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016216046797732513\n",
      "SEED: 1119, FOLD: 3, EPOCH: 17, train_loss: 0.014759466510967932\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01612029928300116\n",
      "SEED: 1119, FOLD: 3, EPOCH: 18, train_loss: 0.014288443667085274\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016020965296775103\n",
      "SEED: 1119, FOLD: 3, EPOCH: 19, train_loss: 0.013793370241056318\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 19, valid_loss: 0.015982916423430044\n",
      "SEED: 1119, FOLD: 3, EPOCH: 20, train_loss: 0.013163800081373125\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 20, valid_loss: 0.01591559923771355\n",
      "SEED: 1119, FOLD: 3, EPOCH: 21, train_loss: 0.012493647257055061\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 21, valid_loss: 0.015920004703932338\n",
      "SEED: 1119, FOLD: 3, EPOCH: 22, train_loss: 0.011782541817081148\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 22, valid_loss: 0.015875156399690442\n",
      "SEED: 1119, FOLD: 3, EPOCH: 23, train_loss: 0.011294049210846424\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 23, valid_loss: 0.015883628382451005\n",
      "SEED: 1119, FOLD: 3, EPOCH: 24, train_loss: 0.011078884757623293\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 24, valid_loss: 0.015871192742553022\n",
      "SEED: 1119, FOLD: 4, EPOCH: 0, train_loss: 0.7131150753601737\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6079584790600671\n",
      "SEED: 1119, FOLD: 4, EPOCH: 1, train_loss: 0.20492400984833206\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 1, valid_loss: 0.023220837426682312\n",
      "SEED: 1119, FOLD: 4, EPOCH: 2, train_loss: 0.020878668631548466\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 2, valid_loss: 0.019275360119839508\n",
      "SEED: 1119, FOLD: 4, EPOCH: 3, train_loss: 0.01891720923932566\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 3, valid_loss: 0.018403013857702415\n",
      "SEED: 1119, FOLD: 4, EPOCH: 4, train_loss: 0.017843721110535705\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 4, valid_loss: 0.01771746493048138\n",
      "SEED: 1119, FOLD: 4, EPOCH: 5, train_loss: 0.017161778390299583\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017042873634232417\n",
      "SEED: 1119, FOLD: 4, EPOCH: 6, train_loss: 0.01730505703691987\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017731674946844578\n",
      "SEED: 1119, FOLD: 4, EPOCH: 7, train_loss: 0.016982804376470005\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 7, valid_loss: 0.016947369349913463\n",
      "SEED: 1119, FOLD: 4, EPOCH: 8, train_loss: 0.016511561807946884\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 8, valid_loss: 0.016717145322925515\n",
      "SEED: 1119, FOLD: 4, EPOCH: 9, train_loss: 0.01637869833064252\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01653628744598892\n",
      "SEED: 1119, FOLD: 4, EPOCH: 10, train_loss: 0.016212255626484966\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 10, valid_loss: 0.016645843939234812\n",
      "SEED: 1119, FOLD: 4, EPOCH: 11, train_loss: 0.016082317419890045\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016496203581078187\n",
      "SEED: 1119, FOLD: 4, EPOCH: 12, train_loss: 0.016031332880906437\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 12, valid_loss: 0.0164548644485573\n",
      "SEED: 1119, FOLD: 4, EPOCH: 13, train_loss: 0.015897700914006302\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016145204814771812\n",
      "SEED: 1119, FOLD: 4, EPOCH: 14, train_loss: 0.015664235337812832\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01626287643901176\n",
      "SEED: 1119, FOLD: 4, EPOCH: 15, train_loss: 0.015492898614510246\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016195997647527192\n",
      "SEED: 1119, FOLD: 4, EPOCH: 16, train_loss: 0.015244932129871155\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01606947695836425\n",
      "SEED: 1119, FOLD: 4, EPOCH: 17, train_loss: 0.0148907160602402\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 17, valid_loss: 0.015964891916761797\n",
      "SEED: 1119, FOLD: 4, EPOCH: 18, train_loss: 0.014537197605207346\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01583193615078926\n",
      "SEED: 1119, FOLD: 4, EPOCH: 19, train_loss: 0.01400269570665947\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 19, valid_loss: 0.015679386392649677\n",
      "SEED: 1119, FOLD: 4, EPOCH: 20, train_loss: 0.013348794056345587\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 20, valid_loss: 0.015718310967915587\n",
      "SEED: 1119, FOLD: 4, EPOCH: 21, train_loss: 0.012673056900393272\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015757746425353818\n",
      "SEED: 1119, FOLD: 4, EPOCH: 22, train_loss: 0.012034687348573969\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015622098930180073\n",
      "SEED: 1119, FOLD: 4, EPOCH: 23, train_loss: 0.01154558649421602\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 23, valid_loss: 0.015646500719918147\n",
      "SEED: 1119, FOLD: 4, EPOCH: 24, train_loss: 0.011287588936587175\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015642580421020586\n",
      "elapsed time: 558.103374004364\n",
      "SEED: 1303, FOLD: 0, EPOCH: 0, train_loss: 0.7133692451145338\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6097444030973647\n",
      "SEED: 1303, FOLD: 0, EPOCH: 1, train_loss: 0.20369396893226582\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 1, valid_loss: 0.022811979779766664\n",
      "SEED: 1303, FOLD: 0, EPOCH: 2, train_loss: 0.020847100805005302\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01923868003197842\n",
      "SEED: 1303, FOLD: 0, EPOCH: 3, train_loss: 0.018794134475182796\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 3, valid_loss: 0.01807514660888248\n",
      "SEED: 1303, FOLD: 0, EPOCH: 4, train_loss: 0.01791246772568295\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01765203268991576\n",
      "SEED: 1303, FOLD: 0, EPOCH: 5, train_loss: 0.018147743118090042\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017186229531135824\n",
      "SEED: 1303, FOLD: 0, EPOCH: 6, train_loss: 0.017006688845762306\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01674834902708729\n",
      "SEED: 1303, FOLD: 0, EPOCH: 7, train_loss: 0.016491843468469124\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01658252828444044\n",
      "SEED: 1303, FOLD: 0, EPOCH: 8, train_loss: 0.01646329995676659\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 8, valid_loss: 0.016699568316754367\n",
      "SEED: 1303, FOLD: 0, EPOCH: 9, train_loss: 0.01629294005587049\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 9, valid_loss: 0.016556264470434852\n",
      "SEED: 1303, FOLD: 0, EPOCH: 10, train_loss: 0.016141682552794617\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01664406702750259\n",
      "SEED: 1303, FOLD: 0, EPOCH: 11, train_loss: 0.016055147554995357\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 11, valid_loss: 0.016337897059404187\n",
      "SEED: 1303, FOLD: 0, EPOCH: 12, train_loss: 0.01590714521328176\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016382738223506346\n",
      "SEED: 1303, FOLD: 0, EPOCH: 13, train_loss: 0.015857907417027847\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01619330167563425\n",
      "SEED: 1303, FOLD: 0, EPOCH: 14, train_loss: 0.0156186922331867\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 14, valid_loss: 0.01618988610183199\n",
      "SEED: 1303, FOLD: 0, EPOCH: 15, train_loss: 0.015394484840225483\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016116395799650088\n",
      "SEED: 1303, FOLD: 0, EPOCH: 16, train_loss: 0.01511196469537158\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016040680464357138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1303, FOLD: 0, EPOCH: 17, train_loss: 0.014749038505597391\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01602541644954019\n",
      "SEED: 1303, FOLD: 0, EPOCH: 18, train_loss: 0.014413308878631695\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 18, valid_loss: 0.015861721398929756\n",
      "SEED: 1303, FOLD: 0, EPOCH: 19, train_loss: 0.013858832094980322\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 19, valid_loss: 0.015698907586435478\n",
      "SEED: 1303, FOLD: 0, EPOCH: 20, train_loss: 0.013188735419965309\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 20, valid_loss: 0.015748933888971806\n",
      "SEED: 1303, FOLD: 0, EPOCH: 21, train_loss: 0.012488213543226753\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015759551690684423\n",
      "SEED: 1303, FOLD: 0, EPOCH: 22, train_loss: 0.011798783961305584\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015700462325993512\n",
      "SEED: 1303, FOLD: 0, EPOCH: 23, train_loss: 0.011298596710506557\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015690927755915456\n",
      "SEED: 1303, FOLD: 0, EPOCH: 24, train_loss: 0.01108844459488772\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015722797924859658\n",
      "SEED: 1303, FOLD: 1, EPOCH: 0, train_loss: 0.7131104529767797\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6226678093274435\n",
      "SEED: 1303, FOLD: 1, EPOCH: 1, train_loss: 0.20477228625205116\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 1, valid_loss: 0.024250554334786203\n",
      "SEED: 1303, FOLD: 1, EPOCH: 2, train_loss: 0.021034168781361717\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 2, valid_loss: 0.019549384713172913\n",
      "SEED: 1303, FOLD: 1, EPOCH: 3, train_loss: 0.018998481630199196\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 3, valid_loss: 0.01837172607580821\n",
      "SEED: 1303, FOLD: 1, EPOCH: 4, train_loss: 0.01814202961606392\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01788760649247302\n",
      "SEED: 1303, FOLD: 1, EPOCH: 5, train_loss: 0.01736225062252387\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017782008378869958\n",
      "SEED: 1303, FOLD: 1, EPOCH: 6, train_loss: 0.016767472987049732\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01752278757178121\n",
      "SEED: 1303, FOLD: 1, EPOCH: 7, train_loss: 0.016579409453855908\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01663151818017165\n",
      "SEED: 1303, FOLD: 1, EPOCH: 8, train_loss: 0.016404551048965557\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01666971927301751\n",
      "SEED: 1303, FOLD: 1, EPOCH: 9, train_loss: 0.016426436198146446\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 9, valid_loss: 0.016459839832451608\n",
      "SEED: 1303, FOLD: 1, EPOCH: 10, train_loss: 0.016197425731714222\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016844987869262695\n",
      "SEED: 1303, FOLD: 1, EPOCH: 11, train_loss: 0.01618226575732663\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016547721707158618\n",
      "SEED: 1303, FOLD: 1, EPOCH: 12, train_loss: 0.015960774249464706\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01627678367205792\n",
      "SEED: 1303, FOLD: 1, EPOCH: 13, train_loss: 0.015822288809695106\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016483307919568486\n",
      "SEED: 1303, FOLD: 1, EPOCH: 14, train_loss: 0.01568210803890142\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 14, valid_loss: 0.01622626216461261\n",
      "SEED: 1303, FOLD: 1, EPOCH: 15, train_loss: 0.015455680777845175\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01616153410739369\n",
      "SEED: 1303, FOLD: 1, EPOCH: 16, train_loss: 0.01513898641248976\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 16, valid_loss: 0.0159254532514347\n",
      "SEED: 1303, FOLD: 1, EPOCH: 17, train_loss: 0.014880713399337686\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 17, valid_loss: 0.015933104066385165\n",
      "SEED: 1303, FOLD: 1, EPOCH: 18, train_loss: 0.014332459402689035\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 18, valid_loss: 0.015824565715673897\n",
      "SEED: 1303, FOLD: 1, EPOCH: 19, train_loss: 0.013826716772240141\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 19, valid_loss: 0.015660470506797235\n",
      "SEED: 1303, FOLD: 1, EPOCH: 20, train_loss: 0.013191782842403736\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 20, valid_loss: 0.01569010726072722\n",
      "SEED: 1303, FOLD: 1, EPOCH: 21, train_loss: 0.012475039674967959\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015659345572607383\n",
      "SEED: 1303, FOLD: 1, EPOCH: 22, train_loss: 0.011826836639016436\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015668704640120268\n",
      "SEED: 1303, FOLD: 1, EPOCH: 23, train_loss: 0.011326120491477026\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01563119251901905\n",
      "SEED: 1303, FOLD: 1, EPOCH: 24, train_loss: 0.011100351365040178\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01565509418853455\n",
      "SEED: 1303, FOLD: 2, EPOCH: 0, train_loss: 0.7133111919181935\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 0, valid_loss: 0.5893972151809268\n",
      "SEED: 1303, FOLD: 2, EPOCH: 1, train_loss: 0.20431268744278644\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 1, valid_loss: 0.023310450009173818\n",
      "SEED: 1303, FOLD: 2, EPOCH: 2, train_loss: 0.021024732944974\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 2, valid_loss: 0.019427066358427208\n",
      "SEED: 1303, FOLD: 2, EPOCH: 3, train_loss: 0.018880495504624603\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 3, valid_loss: 0.018227684828970168\n",
      "SEED: 1303, FOLD: 2, EPOCH: 4, train_loss: 0.018119856985150905\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017509369748748012\n",
      "SEED: 1303, FOLD: 2, EPOCH: 5, train_loss: 0.016994051297829636\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 5, valid_loss: 0.016972123334805172\n",
      "SEED: 1303, FOLD: 2, EPOCH: 6, train_loss: 0.016667192207946293\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01681872834968898\n",
      "SEED: 1303, FOLD: 2, EPOCH: 7, train_loss: 0.017612157929418743\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017193773864871927\n",
      "SEED: 1303, FOLD: 2, EPOCH: 8, train_loss: 0.016748452694087788\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016893278134779796\n",
      "SEED: 1303, FOLD: 2, EPOCH: 9, train_loss: 0.016391470312964226\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01690245119647847\n",
      "SEED: 1303, FOLD: 2, EPOCH: 10, train_loss: 0.016176105922330982\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 10, valid_loss: 0.016680801959915295\n",
      "SEED: 1303, FOLD: 2, EPOCH: 11, train_loss: 0.016042017863820427\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016490130840490263\n",
      "SEED: 1303, FOLD: 2, EPOCH: 12, train_loss: 0.015970617397755817\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01655524932882852\n",
      "SEED: 1303, FOLD: 2, EPOCH: 13, train_loss: 0.015807929448783398\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016479223138756223\n",
      "SEED: 1303, FOLD: 2, EPOCH: 14, train_loss: 0.015605377019855423\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016373026236477826\n",
      "SEED: 1303, FOLD: 2, EPOCH: 15, train_loss: 0.015362825150183146\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016390620730817318\n",
      "SEED: 1303, FOLD: 2, EPOCH: 16, train_loss: 0.015142201027576473\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016280931575844686\n",
      "SEED: 1303, FOLD: 2, EPOCH: 17, train_loss: 0.01473794646723115\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016142171238445573\n",
      "SEED: 1303, FOLD: 2, EPOCH: 18, train_loss: 0.014350139023061249\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016078106748561066\n",
      "SEED: 1303, FOLD: 2, EPOCH: 19, train_loss: 0.013726820480888304\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01602824016784628\n",
      "SEED: 1303, FOLD: 2, EPOCH: 20, train_loss: 0.013048093361051186\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016031066266198952\n",
      "SEED: 1303, FOLD: 2, EPOCH: 21, train_loss: 0.012361729747035366\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01600219092021386\n",
      "SEED: 1303, FOLD: 2, EPOCH: 22, train_loss: 0.011662023384933886\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01600744187210997\n",
      "SEED: 1303, FOLD: 2, EPOCH: 23, train_loss: 0.011121035769473816\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 23, valid_loss: 0.016026306586960953\n",
      "SEED: 1303, FOLD: 2, EPOCH: 24, train_loss: 0.010885701879211094\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016011197947793536\n",
      "SEED: 1303, FOLD: 3, EPOCH: 0, train_loss: 0.7128707593765812\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6094360185994042\n",
      "SEED: 1303, FOLD: 3, EPOCH: 1, train_loss: 0.2024413147482319\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 1, valid_loss: 0.023192329849633906\n",
      "SEED: 1303, FOLD: 3, EPOCH: 2, train_loss: 0.020905515314012333\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 2, valid_loss: 0.01947057516210609\n",
      "SEED: 1303, FOLD: 3, EPOCH: 3, train_loss: 0.01883012123837851\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018405222127007112\n",
      "SEED: 1303, FOLD: 3, EPOCH: 4, train_loss: 0.01781061623731385\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017696797019905515\n",
      "SEED: 1303, FOLD: 3, EPOCH: 5, train_loss: 0.01721741776049569\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 5, valid_loss: 0.018089039199468162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1303, FOLD: 3, EPOCH: 6, train_loss: 0.0172701900338997\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017572164845963318\n",
      "SEED: 1303, FOLD: 3, EPOCH: 7, train_loss: 0.016599498054795506\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 7, valid_loss: 0.016837053880509403\n",
      "SEED: 1303, FOLD: 3, EPOCH: 8, train_loss: 0.016424978745804317\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 8, valid_loss: 0.016884021357529692\n",
      "SEED: 1303, FOLD: 3, EPOCH: 9, train_loss: 0.01617468695115784\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 9, valid_loss: 0.016603480507102277\n",
      "SEED: 1303, FOLD: 3, EPOCH: 10, train_loss: 0.016151860545294872\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016580511298444536\n",
      "SEED: 1303, FOLD: 3, EPOCH: 11, train_loss: 0.01606974820943846\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016582716773781512\n",
      "SEED: 1303, FOLD: 3, EPOCH: 12, train_loss: 0.015904985219780086\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016717028390202258\n",
      "SEED: 1303, FOLD: 3, EPOCH: 13, train_loss: 0.015768158762459305\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016498571520464286\n",
      "SEED: 1303, FOLD: 3, EPOCH: 14, train_loss: 0.015649674271327862\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016619713718278542\n",
      "SEED: 1303, FOLD: 3, EPOCH: 15, train_loss: 0.015424589181075926\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01619957351229257\n",
      "SEED: 1303, FOLD: 3, EPOCH: 16, train_loss: 0.015161622626086077\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016142071483449802\n",
      "SEED: 1303, FOLD: 3, EPOCH: 17, train_loss: 0.014837777673982191\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01606387422523565\n",
      "SEED: 1303, FOLD: 3, EPOCH: 18, train_loss: 0.014399605776196804\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 18, valid_loss: 0.01594687858596444\n",
      "SEED: 1303, FOLD: 3, EPOCH: 19, train_loss: 0.013853831203195496\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01593622798100114\n",
      "SEED: 1303, FOLD: 3, EPOCH: 20, train_loss: 0.01328253918799801\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 20, valid_loss: 0.015872172131720517\n",
      "SEED: 1303, FOLD: 3, EPOCH: 21, train_loss: 0.012615461590821329\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 21, valid_loss: 0.015875145172079403\n",
      "SEED: 1303, FOLD: 3, EPOCH: 22, train_loss: 0.011960283920600794\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 22, valid_loss: 0.015863317271901503\n",
      "SEED: 1303, FOLD: 3, EPOCH: 23, train_loss: 0.011468843921371128\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01585629525490933\n",
      "SEED: 1303, FOLD: 3, EPOCH: 24, train_loss: 0.011210905522971914\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01587239544217785\n",
      "SEED: 1303, FOLD: 4, EPOCH: 0, train_loss: 0.7133642823799796\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6260668668482039\n",
      "SEED: 1303, FOLD: 4, EPOCH: 1, train_loss: 0.20316607094761255\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 1, valid_loss: 0.02317684402482377\n",
      "SEED: 1303, FOLD: 4, EPOCH: 2, train_loss: 0.02087713359598664\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 2, valid_loss: 0.019602031033072207\n",
      "SEED: 1303, FOLD: 4, EPOCH: 3, train_loss: 0.018810285201323204\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 3, valid_loss: 0.018549351228608027\n",
      "SEED: 1303, FOLD: 4, EPOCH: 4, train_loss: 0.018155534603241562\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017415054763356846\n",
      "SEED: 1303, FOLD: 4, EPOCH: 5, train_loss: 0.0179512709028263\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017229208464009896\n",
      "SEED: 1303, FOLD: 4, EPOCH: 6, train_loss: 0.016803181122826492\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01692937593907118\n",
      "SEED: 1303, FOLD: 4, EPOCH: 7, train_loss: 0.016541275236269703\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 7, valid_loss: 0.016722342672033444\n",
      "SEED: 1303, FOLD: 4, EPOCH: 8, train_loss: 0.016418134793639183\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 8, valid_loss: 0.016678726559297904\n",
      "SEED: 1303, FOLD: 4, EPOCH: 9, train_loss: 0.016336720531293446\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 9, valid_loss: 0.016517521606551275\n",
      "SEED: 1303, FOLD: 4, EPOCH: 10, train_loss: 0.01623005943669789\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 10, valid_loss: 0.016577371810045507\n",
      "SEED: 1303, FOLD: 4, EPOCH: 11, train_loss: 0.016083789975854797\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01649654780824979\n",
      "SEED: 1303, FOLD: 4, EPOCH: 12, train_loss: 0.016016175498025143\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016494860406965017\n",
      "SEED: 1303, FOLD: 4, EPOCH: 13, train_loss: 0.015742457809223644\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 13, valid_loss: 0.0165469813057118\n",
      "SEED: 1303, FOLD: 4, EPOCH: 14, train_loss: 0.015730140838718067\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01625904223571221\n",
      "SEED: 1303, FOLD: 4, EPOCH: 15, train_loss: 0.015498756174592005\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01613418250862095\n",
      "SEED: 1303, FOLD: 4, EPOCH: 16, train_loss: 0.015132663569048695\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01607469552093082\n",
      "SEED: 1303, FOLD: 4, EPOCH: 17, train_loss: 0.014820505082067371\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016041140848149855\n",
      "SEED: 1303, FOLD: 4, EPOCH: 18, train_loss: 0.014409921887884106\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 18, valid_loss: 0.015937772217310138\n",
      "SEED: 1303, FOLD: 4, EPOCH: 19, train_loss: 0.013804302915282871\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 19, valid_loss: 0.015861705773406558\n",
      "SEED: 1303, FOLD: 4, EPOCH: 20, train_loss: 0.013243369866108549\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01577404948572318\n",
      "SEED: 1303, FOLD: 4, EPOCH: 21, train_loss: 0.01252154529472624\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015751776544170246\n",
      "SEED: 1303, FOLD: 4, EPOCH: 22, train_loss: 0.011786376018131125\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015688798079888027\n",
      "SEED: 1303, FOLD: 4, EPOCH: 23, train_loss: 0.011298387702824413\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01571088320472174\n",
      "SEED: 1303, FOLD: 4, EPOCH: 24, train_loss: 0.011044238694012165\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015688118369628985\n",
      "elapsed time: 669.271769285202\n"
     ]
    }
   ],
   "source": [
    "SEED = [940, 1513, 1269, 1392, 1119, 1303]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "for seed in SEED:\n",
    "\n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "    print(f\"elapsed time: {time.time() - time_start}\")\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:13.616982Z",
     "iopub.status.busy": "2020-11-26T06:01:13.615723Z",
     "iopub.status.idle": "2020-11-26T06:01:14.398511Z",
     "shell.execute_reply": "2020-11-26T06:01:14.400153Z"
    },
    "papermill": {
     "duration": 1.997645,
     "end_time": "2020-11-26T06:01:14.400404",
     "exception": false,
     "start_time": "2020-11-26T06:01:12.402759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.to_pickle(f\"{INT_DIR}/{NB}-train-score-pred.pkl\")\n",
    "test.to_pickle(f\"{INT_DIR}/{NB}-test-score-pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:16.325441Z",
     "iopub.status.busy": "2020-11-26T06:01:16.323178Z",
     "iopub.status.idle": "2020-11-26T06:01:16.328165Z",
     "shell.execute_reply": "2020-11-26T06:01:16.327557Z"
    },
    "papermill": {
     "duration": 0.859033,
     "end_time": "2020-11-26T06:01:16.328276",
     "exception": false,
     "start_time": "2020-11-26T06:01:15.469243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:17.712118Z",
     "iopub.status.busy": "2020-11-26T06:01:17.710514Z",
     "iopub.status.idle": "2020-11-26T06:01:19.176359Z",
     "shell.execute_reply": "2020-11-26T06:01:19.177266Z"
    },
    "papermill": {
     "duration": 2.153899,
     "end_time": "2020-11-26T06:01:19.177502",
     "exception": false,
     "start_time": "2020-11-26T06:01:17.023603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.014299388238043196\n"
     ]
    }
   ],
   "source": [
    "train[target_cols] = np.maximum(PMIN, np.minimum(PMAX, train[target_cols]))\n",
    "\n",
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(\n",
    "    train[['sig_id'] + target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_true = y_true > 0.5\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "\n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.627064,
     "end_time": "2020-11-26T06:01:20.507437",
     "exception": false,
     "start_time": "2020-11-26T06:01:19.880373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- CV log_loss:  0.014761779358699672\n",
    "- CV log_loss:  0.014519859174255039\n",
    "- CV log_loss:  0.014525173864593479\n",
    "- CV log_loss:  0.014354930596928602 # 3 umap features\n",
    "- CV log_loss:  0.014353604854355429 # more umap features\n",
    "- CV log_loss:  0.01436484670778641 # more hidden nodes\n",
    "- CV log_loss:  0.014344688083211073\n",
    "  - using predicted unscored targets as feature \n",
    "- CV log_loss:  0.013368097791623873\n",
    "  - using given unscored targets as feature\n",
    "  - bad in public lb\n",
    "- CV log_loss:  0.01434373547175235\n",
    "  - rankgauss predicted unscored targets\n",
    "- CV log_loss:  0.014346100008158216\n",
    "  - unscored targets pca/umap\n",
    "- CV log_loss:  0.014328486629791769\n",
    "  - NFOLDS=10, Epoch=20\n",
    "- CV log_loss:  0.014299741080816082\n",
    "  - NFOLDS=10, Epoch=20, 25\n",
    "- CV log_loss:  0.014311301224480969\n",
    "  - NFOLDS=10, Epoch=25\n",
    "- CV log_loss:  0.01429269446076626\n",
    "  - NFOLDS=10, Epoch=15, 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:21.755147Z",
     "iopub.status.busy": "2020-11-26T06:01:21.754200Z",
     "iopub.status.idle": "2020-11-26T06:01:21.759141Z",
     "shell.execute_reply": "2020-11-26T06:01:21.758497Z"
    },
    "papermill": {
     "duration": 0.631618,
     "end_time": "2020-11-26T06:01:21.759258",
     "exception": false,
     "start_time": "2020-11-26T06:01:21.127640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train = pd.read_pickle(f\"../interim/23-train-score-pred.pkl\")\n",
    "# test = pd.read_pickle(f\"../interim/23-test-score-pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:23.016410Z",
     "iopub.status.busy": "2020-11-26T06:01:23.015094Z",
     "iopub.status.idle": "2020-11-26T06:01:23.478577Z",
     "shell.execute_reply": "2020-11-26T06:01:23.477851Z"
    },
    "papermill": {
     "duration": 1.093868,
     "end_time": "2020-11-26T06:01:23.478713",
     "exception": false,
     "start_time": "2020-11-26T06:01:22.384845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle(f\"{INT_DIR}/{NB}-train-score-pred.pkl\")\n",
    "test = pd.read_pickle(f\"{INT_DIR}/{NB}-test-score-pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:24.747114Z",
     "iopub.status.busy": "2020-11-26T06:01:24.746295Z",
     "iopub.status.idle": "2020-11-26T06:01:24.751826Z",
     "shell.execute_reply": "2020-11-26T06:01:24.751204Z"
    },
    "papermill": {
     "duration": 0.649495,
     "end_time": "2020-11-26T06:01:24.751946",
     "exception": false,
     "start_time": "2020-11-26T06:01:24.102451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "# NFOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:26.284371Z",
     "iopub.status.busy": "2020-11-26T06:01:26.282269Z",
     "iopub.status.idle": "2020-11-26T06:01:27.208820Z",
     "shell.execute_reply": "2020-11-26T06:01:27.208112Z"
    },
    "papermill": {
     "duration": 1.719857,
     "end_time": "2020-11-26T06:01:27.208942",
     "exception": false,
     "start_time": "2020-11-26T06:01:25.489085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PMIN = 0.0005\n",
    "PMAX = 0.9995\n",
    "for c in train_targets_scored.columns:\n",
    "    if c != \"sig_id\":\n",
    "        train_targets_scored[c] = np.maximum(\n",
    "            PMIN, np.minimum(PMAX, train_targets_scored[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:28.464915Z",
     "iopub.status.busy": "2020-11-26T06:01:28.463868Z",
     "iopub.status.idle": "2020-11-26T06:01:28.468971Z",
     "shell.execute_reply": "2020-11-26T06:01:28.469665Z"
    },
    "papermill": {
     "duration": 0.638334,
     "end_time": "2020-11-26T06:01:28.469825",
     "exception": false,
     "start_time": "2020-11-26T06:01:27.831491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sig_id', '5-alpha_reductase_inhibitor', '11-beta-hsd1_inhibitor',\n",
       "       'acat_inhibitor', 'acetylcholine_receptor_agonist',\n",
       "       'acetylcholine_receptor_antagonist', 'acetylcholinesterase_inhibitor',\n",
       "       'adenosine_receptor_agonist', 'adenosine_receptor_antagonist',\n",
       "       'adenylyl_cyclase_activator',\n",
       "       ...\n",
       "       'tropomyosin_receptor_kinase_inhibitor', 'trpv_agonist',\n",
       "       'trpv_antagonist', 'tubulin_inhibitor', 'tyrosine_kinase_inhibitor',\n",
       "       'ubiquitin_specific_protease_inhibitor', 'vegfr_inhibitor', 'vitamin_b',\n",
       "       'vitamin_d_receptor_agonist', 'wnt_inhibitor'],\n",
       "      dtype='object', length=207)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_scored.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:29.738230Z",
     "iopub.status.busy": "2020-11-26T06:01:29.736762Z",
     "iopub.status.idle": "2020-11-26T06:01:30.082169Z",
     "shell.execute_reply": "2020-11-26T06:01:30.081567Z"
    },
    "papermill": {
     "duration": 0.989108,
     "end_time": "2020-11-26T06:01:30.082296",
     "exception": false,
     "start_time": "2020-11-26T06:01:29.093188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train_targets_scored.columns]\n",
    "train.columns = [\n",
    "    c + \"_pred\" if (c != 'sig_id' and c in train_targets_scored.columns) else c\n",
    "    for c in train.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:31.345699Z",
     "iopub.status.busy": "2020-11-26T06:01:31.343862Z",
     "iopub.status.idle": "2020-11-26T06:01:31.346544Z",
     "shell.execute_reply": "2020-11-26T06:01:31.347129Z"
    },
    "papermill": {
     "duration": 0.635984,
     "end_time": "2020-11-26T06:01:31.347288",
     "exception": false,
     "start_time": "2020-11-26T06:01:30.711304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = test[train_targets_scored.columns]\n",
    "test.columns = [\n",
    "    c + \"_pred\" if (c != 'sig_id' and c in train_targets_scored.columns) else c\n",
    "    for c in test.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:32.598000Z",
     "iopub.status.busy": "2020-11-26T06:01:32.596935Z",
     "iopub.status.idle": "2020-11-26T06:01:32.639776Z",
     "shell.execute_reply": "2020-11-26T06:01:32.640437Z"
    },
    "papermill": {
     "duration": 0.673501,
     "end_time": "2020-11-26T06:01:32.640612",
     "exception": false,
     "start_time": "2020-11-26T06:01:31.967111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor_pred</th>\n",
       "      <th>11-beta-hsd1_inhibitor_pred</th>\n",
       "      <th>acat_inhibitor_pred</th>\n",
       "      <th>acetylcholine_receptor_agonist_pred</th>\n",
       "      <th>acetylcholine_receptor_antagonist_pred</th>\n",
       "      <th>acetylcholinesterase_inhibitor_pred</th>\n",
       "      <th>adenosine_receptor_agonist_pred</th>\n",
       "      <th>adenosine_receptor_antagonist_pred</th>\n",
       "      <th>adenylyl_cyclase_activator_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor_pred</th>\n",
       "      <th>trpv_agonist_pred</th>\n",
       "      <th>trpv_antagonist_pred</th>\n",
       "      <th>tubulin_inhibitor_pred</th>\n",
       "      <th>tyrosine_kinase_inhibitor_pred</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor_pred</th>\n",
       "      <th>vegfr_inhibitor_pred</th>\n",
       "      <th>vitamin_b_pred</th>\n",
       "      <th>vitamin_d_receptor_agonist_pred</th>\n",
       "      <th>wnt_inhibitor_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.009744</td>\n",
       "      <td>0.038131</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.002069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.013645</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.002312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.009119</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.009765</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.037448</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.001654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.007561</td>\n",
       "      <td>0.009475</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.029406</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.007727</td>\n",
       "      <td>0.010248</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.004712</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.001318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>0.004956</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.006845</td>\n",
       "      <td>0.029195</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.005247</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.011255</td>\n",
       "      <td>0.034413</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>0.011916</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.007309</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.005852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.004916</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor_pred  \\\n",
       "0      id_000644bb2                          0.000822   \n",
       "1      id_000779bfc                          0.000524   \n",
       "2      id_000a6266a                          0.001740   \n",
       "3      id_0015fd391                          0.000375   \n",
       "4      id_001626bd3                          0.000418   \n",
       "...             ...                               ...   \n",
       "21943  id_fff8c2444                          0.004956   \n",
       "21944  id_fffb1ceed                          0.001999   \n",
       "21945  id_fffb70c0c                          0.001252   \n",
       "21946  id_fffcb9e7c                          0.000310   \n",
       "21947  id_ffffdd77b                          0.000349   \n",
       "\n",
       "       11-beta-hsd1_inhibitor_pred  acat_inhibitor_pred  \\\n",
       "0                         0.000502             0.001046   \n",
       "1                         0.000529             0.001235   \n",
       "2                         0.002226             0.001088   \n",
       "3                         0.000629             0.001531   \n",
       "4                         0.000743             0.003778   \n",
       "...                            ...                  ...   \n",
       "21943                     0.003686             0.000441   \n",
       "21944                     0.001331             0.000962   \n",
       "21945                     0.001061             0.002338   \n",
       "21946                     0.000305             0.000328   \n",
       "21947                     0.000293             0.000486   \n",
       "\n",
       "       acetylcholine_receptor_agonist_pred  \\\n",
       "0                                 0.009744   \n",
       "1                                 0.013645   \n",
       "2                                 0.004657   \n",
       "3                                 0.007561   \n",
       "4                                 0.007727   \n",
       "...                                    ...   \n",
       "21943                             0.006845   \n",
       "21944                             0.011255   \n",
       "21945                             0.002183   \n",
       "21946                             0.001899   \n",
       "21947                             0.001837   \n",
       "\n",
       "       acetylcholine_receptor_antagonist_pred  \\\n",
       "0                                    0.038131   \n",
       "1                                    0.014442   \n",
       "2                                    0.009119   \n",
       "3                                    0.009475   \n",
       "4                                    0.010248   \n",
       "...                                       ...   \n",
       "21943                                0.029195   \n",
       "21944                                0.034413   \n",
       "21945                                0.002365   \n",
       "21946                                0.002964   \n",
       "21947                                0.004916   \n",
       "\n",
       "       acetylcholinesterase_inhibitor_pred  adenosine_receptor_agonist_pred  \\\n",
       "0                                 0.004170                         0.003465   \n",
       "1                                 0.004031                         0.002750   \n",
       "2                                 0.002140                         0.001818   \n",
       "3                                 0.001604                         0.002851   \n",
       "4                                 0.001827                         0.004712   \n",
       "...                                    ...                              ...   \n",
       "21943                             0.003761                         0.001185   \n",
       "21944                             0.003121                         0.001882   \n",
       "21945                             0.003345                         0.001769   \n",
       "21946                             0.000758                         0.000700   \n",
       "21947                             0.000926                         0.000497   \n",
       "\n",
       "       adenosine_receptor_antagonist_pred  adenylyl_cyclase_activator_pred  \\\n",
       "0                                0.004213                         0.000307   \n",
       "1                                0.004612                         0.000311   \n",
       "2                                0.006204                         0.000739   \n",
       "3                                0.002150                         0.000341   \n",
       "4                                0.002950                         0.000644   \n",
       "...                                   ...                              ...   \n",
       "21943                            0.002988                         0.000214   \n",
       "21944                            0.004319                         0.000238   \n",
       "21945                            0.011916                         0.001696   \n",
       "21946                            0.000942                         0.000094   \n",
       "21947                            0.001484                         0.000095   \n",
       "\n",
       "       ...  tropomyosin_receptor_kinase_inhibitor_pred  trpv_agonist_pred  \\\n",
       "0      ...                                    0.000406           0.000411   \n",
       "1      ...                                    0.000555           0.001166   \n",
       "2      ...                                    0.000405           0.001578   \n",
       "3      ...                                    0.000595           0.002003   \n",
       "4      ...                                    0.001129           0.001830   \n",
       "...    ...                                         ...                ...   \n",
       "21943  ...                                    0.000358           0.000281   \n",
       "21944  ...                                    0.000474           0.000345   \n",
       "21945  ...                                    0.000433           0.001225   \n",
       "21946  ...                                    0.000126           0.000249   \n",
       "21947  ...                                    0.000206           0.000702   \n",
       "\n",
       "       trpv_antagonist_pred  tubulin_inhibitor_pred  \\\n",
       "0                  0.002389                0.001663   \n",
       "1                  0.001491                0.003492   \n",
       "2                  0.003114                0.004492   \n",
       "3                  0.001855                0.029406   \n",
       "4                  0.002106                0.002657   \n",
       "...                     ...                     ...   \n",
       "21943              0.005247                0.000353   \n",
       "21944              0.002403                0.001051   \n",
       "21945              0.003078                0.000465   \n",
       "21946              0.000611                0.001738   \n",
       "21947              0.000600                0.008830   \n",
       "\n",
       "       tyrosine_kinase_inhibitor_pred  \\\n",
       "0                            0.000883   \n",
       "1                            0.001437   \n",
       "2                            0.009765   \n",
       "3                            0.002980   \n",
       "4                            0.001869   \n",
       "...                               ...   \n",
       "21943                        0.000502   \n",
       "21944                        0.001516   \n",
       "21945                        0.007309   \n",
       "21946                        0.001826   \n",
       "21947                        0.001591   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor_pred  vegfr_inhibitor_pred  \\\n",
       "0                                        0.000406              0.000745   \n",
       "1                                        0.000278              0.001146   \n",
       "2                                        0.000638              0.037448   \n",
       "3                                        0.000783              0.001937   \n",
       "4                                        0.000676              0.002021   \n",
       "...                                           ...                   ...   \n",
       "21943                                    0.000746              0.001878   \n",
       "21944                                    0.000380              0.000909   \n",
       "21945                                    0.000332              0.002859   \n",
       "21946                                    0.000154              0.001165   \n",
       "21947                                    0.000498              0.001657   \n",
       "\n",
       "       vitamin_b_pred  vitamin_d_receptor_agonist_pred  wnt_inhibitor_pred  \n",
       "0            0.001785                         0.000324            0.002069  \n",
       "1            0.002702                         0.001103            0.002312  \n",
       "2            0.003954                         0.000287            0.001654  \n",
       "3            0.001951                         0.000278            0.000580  \n",
       "4            0.002728                         0.000578            0.001318  \n",
       "...               ...                              ...                 ...  \n",
       "21943        0.000714                         0.000579            0.000455  \n",
       "21944        0.001232                         0.000498            0.000967  \n",
       "21945        0.001278                         0.002171            0.005852  \n",
       "21946        0.000361                         0.000110            0.000428  \n",
       "21947        0.000843                         0.000252            0.000265  \n",
       "\n",
       "[21948 rows x 207 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:33.889150Z",
     "iopub.status.busy": "2020-11-26T06:01:33.887547Z",
     "iopub.status.idle": "2020-11-26T06:01:34.053938Z",
     "shell.execute_reply": "2020-11-26T06:01:34.053307Z"
    },
    "papermill": {
     "duration": 0.793132,
     "end_time": "2020-11-26T06:01:34.054077",
     "exception": false,
     "start_time": "2020-11-26T06:01:33.260945",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use nonscored target in the given file as feature\n",
    "# if comment out below, use predicted nonscored target\n",
    "# train = train.drop(nonscored_target, axis=1)\n",
    "# train = train.merge(train_targets_nonscored, on=\"sig_id\")\n",
    "# train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train.merge(train_targets_scored, on='sig_id')\n",
    "# train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "# test = test[test['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "# target = train[train_targets_scored.columns]\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:35.362823Z",
     "iopub.status.busy": "2020-11-26T06:01:35.360442Z",
     "iopub.status.idle": "2020-11-26T06:01:35.363705Z",
     "shell.execute_reply": "2020-11-26T06:01:35.364270Z"
    },
    "papermill": {
     "duration": 0.647934,
     "end_time": "2020-11-26T06:01:35.364469",
     "exception": false,
     "start_time": "2020-11-26T06:01:34.716535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train[\"cp_time\"] = train_features[train_features[\"cp_type\"]==\"trt_cp\"].reset_index(drop=True)[\"cp_time\"]\n",
    "# train[\"cp_dose\"] = train_features[train_features[\"cp_type\"]==\"trt_cp\"].reset_index(drop=True)[\"cp_dose\"]\n",
    "# test[\"cp_time\"] = test_features[test_features[\"cp_type\"]==\"trt_cp\"].reset_index(drop=True)[\"cp_time\"]\n",
    "# test[\"cp_dose\"] = test_features[test_features[\"cp_type\"]==\"trt_cp\"].reset_index(drop=True)[\"cp_dose\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:36.967386Z",
     "iopub.status.busy": "2020-11-26T06:01:36.965915Z",
     "iopub.status.idle": "2020-11-26T06:01:39.447702Z",
     "shell.execute_reply": "2020-11-26T06:01:39.446487Z"
    },
    "papermill": {
     "duration": 3.437977,
     "end_time": "2020-11-26T06:01:39.447830",
     "exception": false,
     "start_time": "2020-11-26T06:01:36.009853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "scored_target_pred = [\n",
    "    c + \"_pred\" for c in train_targets_scored.columns if c != 'sig_id'\n",
    "]\n",
    "\n",
    "for col in (scored_target_pred):\n",
    "\n",
    "    #     transformer = QuantileTransformer(n_quantiles=100, random_state=0, output_distribution=\"normal\")\n",
    "    vec_len = len(train[col].values)\n",
    "    vec_len_test = len(test[col].values)\n",
    "    raw_vec = train[col].values.reshape(vec_len, 1)\n",
    "    #     transformer.fit(raw_vec)\n",
    "    if IS_TRAIN:\n",
    "        transformer = QuantileTransformer(n_quantiles=100,\n",
    "                                          random_state=0,\n",
    "                                          output_distribution=\"normal\")\n",
    "        transformer.fit(raw_vec)\n",
    "        pd.to_pickle(transformer,\n",
    "                     f\"{MODEL_DIR}/{NB}_{col}_quantile_scored.pkl\")\n",
    "    else:\n",
    "        transformer = pd.read_pickle(\n",
    "            f\"{MODEL_DIR}/{NB}_{col}_quantile_scored.pkl\")\n",
    "\n",
    "    train[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test[col] = transformer.transform(test[col].values.reshape(\n",
    "        vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:40.709446Z",
     "iopub.status.busy": "2020-11-26T06:01:40.708681Z",
     "iopub.status.idle": "2020-11-26T06:01:40.713494Z",
     "shell.execute_reply": "2020-11-26T06:01:40.712838Z"
    },
    "papermill": {
     "duration": 0.630182,
     "end_time": "2020-11-26T06:01:40.713614",
     "exception": false,
     "start_time": "2020-11-26T06:01:40.083432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train = train.drop('cp_type', axis=1)\n",
    "# test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:41.982506Z",
     "iopub.status.busy": "2020-11-26T06:01:41.981605Z",
     "iopub.status.idle": "2020-11-26T06:01:41.985915Z",
     "shell.execute_reply": "2020-11-26T06:01:41.985342Z"
    },
    "papermill": {
     "duration": 0.647589,
     "end_time": "2020-11-26T06:01:41.986035",
     "exception": false,
     "start_time": "2020-11-26T06:01:41.338446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:43.243692Z",
     "iopub.status.busy": "2020-11-26T06:01:43.242592Z",
     "iopub.status.idle": "2020-11-26T06:01:43.285461Z",
     "shell.execute_reply": "2020-11-26T06:01:43.286108Z"
    },
    "papermill": {
     "duration": 0.676294,
     "end_time": "2020-11-26T06:01:43.286273",
     "exception": false,
     "start_time": "2020-11-26T06:01:42.609979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor_pred</th>\n",
       "      <th>11-beta-hsd1_inhibitor_pred</th>\n",
       "      <th>acat_inhibitor_pred</th>\n",
       "      <th>acetylcholine_receptor_agonist_pred</th>\n",
       "      <th>acetylcholine_receptor_antagonist_pred</th>\n",
       "      <th>acetylcholinesterase_inhibitor_pred</th>\n",
       "      <th>adenosine_receptor_agonist_pred</th>\n",
       "      <th>adenosine_receptor_antagonist_pred</th>\n",
       "      <th>adenylyl_cyclase_activator_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0.537081</td>\n",
       "      <td>-0.400535</td>\n",
       "      <td>-0.069270</td>\n",
       "      <td>0.345114</td>\n",
       "      <td>1.591405</td>\n",
       "      <td>0.361417</td>\n",
       "      <td>0.807020</td>\n",
       "      <td>0.308358</td>\n",
       "      <td>0.345785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>-0.076446</td>\n",
       "      <td>-0.331551</td>\n",
       "      <td>0.224693</td>\n",
       "      <td>0.775918</td>\n",
       "      <td>0.020212</td>\n",
       "      <td>0.309040</td>\n",
       "      <td>0.505060</td>\n",
       "      <td>0.435642</td>\n",
       "      <td>0.369333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>1.409396</td>\n",
       "      <td>1.474718</td>\n",
       "      <td>-0.002142</td>\n",
       "      <td>-0.416476</td>\n",
       "      <td>-0.406838</td>\n",
       "      <td>-0.447629</td>\n",
       "      <td>-0.016101</td>\n",
       "      <td>0.831803</td>\n",
       "      <td>1.543713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>-0.522910</td>\n",
       "      <td>-0.088334</td>\n",
       "      <td>0.611943</td>\n",
       "      <td>0.060545</td>\n",
       "      <td>-0.376046</td>\n",
       "      <td>-0.659599</td>\n",
       "      <td>0.554086</td>\n",
       "      <td>-0.560342</td>\n",
       "      <td>0.512390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>-0.377659</td>\n",
       "      <td>0.155786</td>\n",
       "      <td>2.087313</td>\n",
       "      <td>0.082745</td>\n",
       "      <td>-0.315074</td>\n",
       "      <td>-0.575166</td>\n",
       "      <td>1.202246</td>\n",
       "      <td>-0.181915</td>\n",
       "      <td>1.386576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>2.322966</td>\n",
       "      <td>1.996291</td>\n",
       "      <td>-1.447835</td>\n",
       "      <td>-0.042943</td>\n",
       "      <td>1.089451</td>\n",
       "      <td>0.211433</td>\n",
       "      <td>-0.493232</td>\n",
       "      <td>-0.165787</td>\n",
       "      <td>-0.272616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>1.556072</td>\n",
       "      <td>0.897324</td>\n",
       "      <td>-0.217874</td>\n",
       "      <td>0.526463</td>\n",
       "      <td>1.401514</td>\n",
       "      <td>-0.038725</td>\n",
       "      <td>0.026458</td>\n",
       "      <td>0.341287</td>\n",
       "      <td>-0.091528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>1.039404</td>\n",
       "      <td>0.625719</td>\n",
       "      <td>1.334725</td>\n",
       "      <td>-0.984314</td>\n",
       "      <td>-1.353316</td>\n",
       "      <td>0.046913</td>\n",
       "      <td>-0.049031</td>\n",
       "      <td>1.628580</td>\n",
       "      <td>2.185396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>-0.747835</td>\n",
       "      <td>-0.966265</td>\n",
       "      <td>-1.901506</td>\n",
       "      <td>-1.095612</td>\n",
       "      <td>-1.131262</td>\n",
       "      <td>-1.116467</td>\n",
       "      <td>-0.970621</td>\n",
       "      <td>-1.177981</td>\n",
       "      <td>-1.356659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>-0.612563</td>\n",
       "      <td>-1.004499</td>\n",
       "      <td>-1.301197</td>\n",
       "      <td>-1.125517</td>\n",
       "      <td>-0.773039</td>\n",
       "      <td>-0.978121</td>\n",
       "      <td>-1.323702</td>\n",
       "      <td>-0.887014</td>\n",
       "      <td>-1.353705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 413 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor_pred  \\\n",
       "0      id_000644bb2                          0.537081   \n",
       "1      id_000779bfc                         -0.076446   \n",
       "2      id_000a6266a                          1.409396   \n",
       "3      id_0015fd391                         -0.522910   \n",
       "4      id_001626bd3                         -0.377659   \n",
       "...             ...                               ...   \n",
       "21943  id_fff8c2444                          2.322966   \n",
       "21944  id_fffb1ceed                          1.556072   \n",
       "21945  id_fffb70c0c                          1.039404   \n",
       "21946  id_fffcb9e7c                         -0.747835   \n",
       "21947  id_ffffdd77b                         -0.612563   \n",
       "\n",
       "       11-beta-hsd1_inhibitor_pred  acat_inhibitor_pred  \\\n",
       "0                        -0.400535            -0.069270   \n",
       "1                        -0.331551             0.224693   \n",
       "2                         1.474718            -0.002142   \n",
       "3                        -0.088334             0.611943   \n",
       "4                         0.155786             2.087313   \n",
       "...                            ...                  ...   \n",
       "21943                     1.996291            -1.447835   \n",
       "21944                     0.897324            -0.217874   \n",
       "21945                     0.625719             1.334725   \n",
       "21946                    -0.966265            -1.901506   \n",
       "21947                    -1.004499            -1.301197   \n",
       "\n",
       "       acetylcholine_receptor_agonist_pred  \\\n",
       "0                                 0.345114   \n",
       "1                                 0.775918   \n",
       "2                                -0.416476   \n",
       "3                                 0.060545   \n",
       "4                                 0.082745   \n",
       "...                                    ...   \n",
       "21943                            -0.042943   \n",
       "21944                             0.526463   \n",
       "21945                            -0.984314   \n",
       "21946                            -1.095612   \n",
       "21947                            -1.125517   \n",
       "\n",
       "       acetylcholine_receptor_antagonist_pred  \\\n",
       "0                                    1.591405   \n",
       "1                                    0.020212   \n",
       "2                                   -0.406838   \n",
       "3                                   -0.376046   \n",
       "4                                   -0.315074   \n",
       "...                                       ...   \n",
       "21943                                1.089451   \n",
       "21944                                1.401514   \n",
       "21945                               -1.353316   \n",
       "21946                               -1.131262   \n",
       "21947                               -0.773039   \n",
       "\n",
       "       acetylcholinesterase_inhibitor_pred  adenosine_receptor_agonist_pred  \\\n",
       "0                                 0.361417                         0.807020   \n",
       "1                                 0.309040                         0.505060   \n",
       "2                                -0.447629                        -0.016101   \n",
       "3                                -0.659599                         0.554086   \n",
       "4                                -0.575166                         1.202246   \n",
       "...                                    ...                              ...   \n",
       "21943                             0.211433                        -0.493232   \n",
       "21944                            -0.038725                         0.026458   \n",
       "21945                             0.046913                        -0.049031   \n",
       "21946                            -1.116467                        -0.970621   \n",
       "21947                            -0.978121                        -1.323702   \n",
       "\n",
       "       adenosine_receptor_antagonist_pred  adenylyl_cyclase_activator_pred  \\\n",
       "0                                0.308358                         0.345785   \n",
       "1                                0.435642                         0.369333   \n",
       "2                                0.831803                         1.543713   \n",
       "3                               -0.560342                         0.512390   \n",
       "4                               -0.181915                         1.386576   \n",
       "...                                   ...                              ...   \n",
       "21943                           -0.165787                        -0.272616   \n",
       "21944                            0.341287                        -0.091528   \n",
       "21945                            1.628580                         2.185396   \n",
       "21946                           -1.177981                        -1.356659   \n",
       "21947                           -0.887014                        -1.353705   \n",
       "\n",
       "       ...  tropomyosin_receptor_kinase_inhibitor  trpv_agonist  \\\n",
       "0      ...                                 0.0005        0.0005   \n",
       "1      ...                                 0.0005        0.0005   \n",
       "2      ...                                 0.0005        0.0005   \n",
       "3      ...                                 0.0005        0.0005   \n",
       "4      ...                                 0.0005        0.0005   \n",
       "...    ...                                    ...           ...   \n",
       "21943  ...                                 0.0005        0.0005   \n",
       "21944  ...                                 0.0005        0.0005   \n",
       "21945  ...                                 0.0005        0.0005   \n",
       "21946  ...                                 0.0005        0.0005   \n",
       "21947  ...                                 0.0005        0.0005   \n",
       "\n",
       "       trpv_antagonist  tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0               0.0005             0.0005                     0.0005   \n",
       "1               0.0005             0.0005                     0.0005   \n",
       "2               0.0005             0.0005                     0.0005   \n",
       "3               0.0005             0.0005                     0.0005   \n",
       "4               0.0005             0.0005                     0.0005   \n",
       "...                ...                ...                        ...   \n",
       "21943           0.0005             0.0005                     0.0005   \n",
       "21944           0.0005             0.0005                     0.0005   \n",
       "21945           0.0005             0.0005                     0.0005   \n",
       "21946           0.0005             0.0005                     0.0005   \n",
       "21947           0.0005             0.0005                     0.0005   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                     0.0005           0.0005     0.0005   \n",
       "1                                     0.0005           0.0005     0.0005   \n",
       "2                                     0.0005           0.0005     0.0005   \n",
       "3                                     0.0005           0.0005     0.0005   \n",
       "4                                     0.0005           0.0005     0.0005   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                 0.0005           0.0005     0.0005   \n",
       "21944                                 0.0005           0.0005     0.0005   \n",
       "21945                                 0.0005           0.0005     0.0005   \n",
       "21946                                 0.0005           0.0005     0.0005   \n",
       "21947                                 0.0005           0.0005     0.0005   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                          0.0005         0.0005  \n",
       "1                          0.0005         0.0005  \n",
       "2                          0.0005         0.0005  \n",
       "3                          0.0005         0.0005  \n",
       "4                          0.0005         0.0005  \n",
       "...                           ...            ...  \n",
       "21943                      0.0005         0.0005  \n",
       "21944                      0.0005         0.0005  \n",
       "21945                      0.0005         0.0005  \n",
       "21946                      0.0005         0.0005  \n",
       "21947                      0.0005         0.0005  \n",
       "\n",
       "[21948 rows x 413 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:44.641760Z",
     "iopub.status.busy": "2020-11-26T06:01:44.640258Z",
     "iopub.status.idle": "2020-11-26T06:01:46.859865Z",
     "shell.execute_reply": "2020-11-26T06:01:46.861281Z"
    },
    "papermill": {
     "duration": 2.856402,
     "end_time": "2020-11-26T06:01:46.861540",
     "exception": false,
     "start_time": "2020-11-26T06:01:44.005138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=False, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor_pred</th>\n",
       "      <th>11-beta-hsd1_inhibitor_pred</th>\n",
       "      <th>acat_inhibitor_pred</th>\n",
       "      <th>acetylcholine_receptor_agonist_pred</th>\n",
       "      <th>acetylcholine_receptor_antagonist_pred</th>\n",
       "      <th>acetylcholinesterase_inhibitor_pred</th>\n",
       "      <th>adenosine_receptor_agonist_pred</th>\n",
       "      <th>adenosine_receptor_antagonist_pred</th>\n",
       "      <th>adenylyl_cyclase_activator_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0.537081</td>\n",
       "      <td>-0.400535</td>\n",
       "      <td>-0.069270</td>\n",
       "      <td>0.345114</td>\n",
       "      <td>1.591405</td>\n",
       "      <td>0.361417</td>\n",
       "      <td>0.807020</td>\n",
       "      <td>0.308358</td>\n",
       "      <td>0.345785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>-0.076446</td>\n",
       "      <td>-0.331551</td>\n",
       "      <td>0.224693</td>\n",
       "      <td>0.775918</td>\n",
       "      <td>0.020212</td>\n",
       "      <td>0.309040</td>\n",
       "      <td>0.505060</td>\n",
       "      <td>0.435642</td>\n",
       "      <td>0.369333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>1.409396</td>\n",
       "      <td>1.474718</td>\n",
       "      <td>-0.002142</td>\n",
       "      <td>-0.416476</td>\n",
       "      <td>-0.406838</td>\n",
       "      <td>-0.447629</td>\n",
       "      <td>-0.016101</td>\n",
       "      <td>0.831803</td>\n",
       "      <td>1.543713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>-0.522910</td>\n",
       "      <td>-0.088334</td>\n",
       "      <td>0.611943</td>\n",
       "      <td>0.060545</td>\n",
       "      <td>-0.376046</td>\n",
       "      <td>-0.659599</td>\n",
       "      <td>0.554086</td>\n",
       "      <td>-0.560342</td>\n",
       "      <td>0.512390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>-0.377659</td>\n",
       "      <td>0.155786</td>\n",
       "      <td>2.087313</td>\n",
       "      <td>0.082745</td>\n",
       "      <td>-0.315074</td>\n",
       "      <td>-0.575166</td>\n",
       "      <td>1.202246</td>\n",
       "      <td>-0.181915</td>\n",
       "      <td>1.386576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>2.322966</td>\n",
       "      <td>1.996291</td>\n",
       "      <td>-1.447835</td>\n",
       "      <td>-0.042943</td>\n",
       "      <td>1.089451</td>\n",
       "      <td>0.211433</td>\n",
       "      <td>-0.493232</td>\n",
       "      <td>-0.165787</td>\n",
       "      <td>-0.272616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>1.556072</td>\n",
       "      <td>0.897324</td>\n",
       "      <td>-0.217874</td>\n",
       "      <td>0.526463</td>\n",
       "      <td>1.401514</td>\n",
       "      <td>-0.038725</td>\n",
       "      <td>0.026458</td>\n",
       "      <td>0.341287</td>\n",
       "      <td>-0.091528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>1.039404</td>\n",
       "      <td>0.625719</td>\n",
       "      <td>1.334725</td>\n",
       "      <td>-0.984314</td>\n",
       "      <td>-1.353316</td>\n",
       "      <td>0.046913</td>\n",
       "      <td>-0.049031</td>\n",
       "      <td>1.628580</td>\n",
       "      <td>2.185396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>-0.747835</td>\n",
       "      <td>-0.966265</td>\n",
       "      <td>-1.901506</td>\n",
       "      <td>-1.095612</td>\n",
       "      <td>-1.131262</td>\n",
       "      <td>-1.116467</td>\n",
       "      <td>-0.970621</td>\n",
       "      <td>-1.177981</td>\n",
       "      <td>-1.356659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>-0.612563</td>\n",
       "      <td>-1.004499</td>\n",
       "      <td>-1.301197</td>\n",
       "      <td>-1.125517</td>\n",
       "      <td>-0.773039</td>\n",
       "      <td>-0.978121</td>\n",
       "      <td>-1.323702</td>\n",
       "      <td>-0.887014</td>\n",
       "      <td>-1.353705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 414 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor_pred  \\\n",
       "0      id_000644bb2                          0.537081   \n",
       "1      id_000779bfc                         -0.076446   \n",
       "2      id_000a6266a                          1.409396   \n",
       "3      id_0015fd391                         -0.522910   \n",
       "4      id_001626bd3                         -0.377659   \n",
       "...             ...                               ...   \n",
       "21943  id_fff8c2444                          2.322966   \n",
       "21944  id_fffb1ceed                          1.556072   \n",
       "21945  id_fffb70c0c                          1.039404   \n",
       "21946  id_fffcb9e7c                         -0.747835   \n",
       "21947  id_ffffdd77b                         -0.612563   \n",
       "\n",
       "       11-beta-hsd1_inhibitor_pred  acat_inhibitor_pred  \\\n",
       "0                        -0.400535            -0.069270   \n",
       "1                        -0.331551             0.224693   \n",
       "2                         1.474718            -0.002142   \n",
       "3                        -0.088334             0.611943   \n",
       "4                         0.155786             2.087313   \n",
       "...                            ...                  ...   \n",
       "21943                     1.996291            -1.447835   \n",
       "21944                     0.897324            -0.217874   \n",
       "21945                     0.625719             1.334725   \n",
       "21946                    -0.966265            -1.901506   \n",
       "21947                    -1.004499            -1.301197   \n",
       "\n",
       "       acetylcholine_receptor_agonist_pred  \\\n",
       "0                                 0.345114   \n",
       "1                                 0.775918   \n",
       "2                                -0.416476   \n",
       "3                                 0.060545   \n",
       "4                                 0.082745   \n",
       "...                                    ...   \n",
       "21943                            -0.042943   \n",
       "21944                             0.526463   \n",
       "21945                            -0.984314   \n",
       "21946                            -1.095612   \n",
       "21947                            -1.125517   \n",
       "\n",
       "       acetylcholine_receptor_antagonist_pred  \\\n",
       "0                                    1.591405   \n",
       "1                                    0.020212   \n",
       "2                                   -0.406838   \n",
       "3                                   -0.376046   \n",
       "4                                   -0.315074   \n",
       "...                                       ...   \n",
       "21943                                1.089451   \n",
       "21944                                1.401514   \n",
       "21945                               -1.353316   \n",
       "21946                               -1.131262   \n",
       "21947                               -0.773039   \n",
       "\n",
       "       acetylcholinesterase_inhibitor_pred  adenosine_receptor_agonist_pred  \\\n",
       "0                                 0.361417                         0.807020   \n",
       "1                                 0.309040                         0.505060   \n",
       "2                                -0.447629                        -0.016101   \n",
       "3                                -0.659599                         0.554086   \n",
       "4                                -0.575166                         1.202246   \n",
       "...                                    ...                              ...   \n",
       "21943                             0.211433                        -0.493232   \n",
       "21944                            -0.038725                         0.026458   \n",
       "21945                             0.046913                        -0.049031   \n",
       "21946                            -1.116467                        -0.970621   \n",
       "21947                            -0.978121                        -1.323702   \n",
       "\n",
       "       adenosine_receptor_antagonist_pred  adenylyl_cyclase_activator_pred  \\\n",
       "0                                0.308358                         0.345785   \n",
       "1                                0.435642                         0.369333   \n",
       "2                                0.831803                         1.543713   \n",
       "3                               -0.560342                         0.512390   \n",
       "4                               -0.181915                         1.386576   \n",
       "...                                   ...                              ...   \n",
       "21943                           -0.165787                        -0.272616   \n",
       "21944                            0.341287                        -0.091528   \n",
       "21945                            1.628580                         2.185396   \n",
       "21946                           -1.177981                        -1.356659   \n",
       "21947                           -0.887014                        -1.353705   \n",
       "\n",
       "       ...  trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      ...        0.0005           0.0005             0.0005   \n",
       "1      ...        0.0005           0.0005             0.0005   \n",
       "2      ...        0.0005           0.0005             0.0005   \n",
       "3      ...        0.0005           0.0005             0.0005   \n",
       "4      ...        0.0005           0.0005             0.0005   \n",
       "...    ...           ...              ...                ...   \n",
       "21943  ...        0.0005           0.0005             0.0005   \n",
       "21944  ...        0.0005           0.0005             0.0005   \n",
       "21945  ...        0.0005           0.0005             0.0005   \n",
       "21946  ...        0.0005           0.0005             0.0005   \n",
       "21947  ...        0.0005           0.0005             0.0005   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                         0.0005                                 0.0005   \n",
       "1                         0.0005                                 0.0005   \n",
       "2                         0.0005                                 0.0005   \n",
       "3                         0.0005                                 0.0005   \n",
       "4                         0.0005                                 0.0005   \n",
       "...                          ...                                    ...   \n",
       "21943                     0.0005                                 0.0005   \n",
       "21944                     0.0005                                 0.0005   \n",
       "21945                     0.0005                                 0.0005   \n",
       "21946                     0.0005                                 0.0005   \n",
       "21947                     0.0005                                 0.0005   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0               0.0005     0.0005                      0.0005         0.0005   \n",
       "1               0.0005     0.0005                      0.0005         0.0005   \n",
       "2               0.0005     0.0005                      0.0005         0.0005   \n",
       "3               0.0005     0.0005                      0.0005         0.0005   \n",
       "4               0.0005     0.0005                      0.0005         0.0005   \n",
       "...                ...        ...                         ...            ...   \n",
       "21943           0.0005     0.0005                      0.0005         0.0005   \n",
       "21944           0.0005     0.0005                      0.0005         0.0005   \n",
       "21945           0.0005     0.0005                      0.0005         0.0005   \n",
       "21946           0.0005     0.0005                      0.0005         0.0005   \n",
       "21947           0.0005     0.0005                      0.0005         0.0005   \n",
       "\n",
       "       kfold  \n",
       "0          2  \n",
       "1          4  \n",
       "2          0  \n",
       "3          3  \n",
       "4          1  \n",
       "...      ...  \n",
       "21943      4  \n",
       "21944      0  \n",
       "21945      4  \n",
       "21946      3  \n",
       "21947      1  \n",
       "\n",
       "[21948 rows x 414 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=NFOLDS)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:49.033106Z",
     "iopub.status.busy": "2020-11-26T06:01:49.030412Z",
     "iopub.status.idle": "2020-11-26T06:01:49.036620Z",
     "shell.execute_reply": "2020-11-26T06:01:49.035704Z"
    },
    "papermill": {
     "duration": 0.722189,
     "end_time": "2020-11-26T06:01:49.036794",
     "exception": false,
     "start_time": "2020-11-26T06:01:48.314605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 413)\n",
      "(21948, 414)\n",
      "(3624, 207)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:50.875719Z",
     "iopub.status.busy": "2020-11-26T06:01:50.874667Z",
     "iopub.status.idle": "2020-11-26T06:01:50.917423Z",
     "shell.execute_reply": "2020-11-26T06:01:50.918032Z"
    },
    "papermill": {
     "duration": 0.67909,
     "end_time": "2020-11-26T06:01:50.918187",
     "exception": false,
     "start_time": "2020-11-26T06:01:50.239097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor_pred</th>\n",
       "      <th>11-beta-hsd1_inhibitor_pred</th>\n",
       "      <th>acat_inhibitor_pred</th>\n",
       "      <th>acetylcholine_receptor_agonist_pred</th>\n",
       "      <th>acetylcholine_receptor_antagonist_pred</th>\n",
       "      <th>acetylcholinesterase_inhibitor_pred</th>\n",
       "      <th>adenosine_receptor_agonist_pred</th>\n",
       "      <th>adenosine_receptor_antagonist_pred</th>\n",
       "      <th>adenylyl_cyclase_activator_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0.537081</td>\n",
       "      <td>-0.400535</td>\n",
       "      <td>-0.069270</td>\n",
       "      <td>0.345114</td>\n",
       "      <td>1.591405</td>\n",
       "      <td>0.361417</td>\n",
       "      <td>0.807020</td>\n",
       "      <td>0.308358</td>\n",
       "      <td>0.345785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>-0.076446</td>\n",
       "      <td>-0.331551</td>\n",
       "      <td>0.224693</td>\n",
       "      <td>0.775918</td>\n",
       "      <td>0.020212</td>\n",
       "      <td>0.309040</td>\n",
       "      <td>0.505060</td>\n",
       "      <td>0.435642</td>\n",
       "      <td>0.369333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>1.409396</td>\n",
       "      <td>1.474718</td>\n",
       "      <td>-0.002142</td>\n",
       "      <td>-0.416476</td>\n",
       "      <td>-0.406838</td>\n",
       "      <td>-0.447629</td>\n",
       "      <td>-0.016101</td>\n",
       "      <td>0.831803</td>\n",
       "      <td>1.543713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>-0.522910</td>\n",
       "      <td>-0.088334</td>\n",
       "      <td>0.611943</td>\n",
       "      <td>0.060545</td>\n",
       "      <td>-0.376046</td>\n",
       "      <td>-0.659599</td>\n",
       "      <td>0.554086</td>\n",
       "      <td>-0.560342</td>\n",
       "      <td>0.512390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>-0.377659</td>\n",
       "      <td>0.155786</td>\n",
       "      <td>2.087313</td>\n",
       "      <td>0.082745</td>\n",
       "      <td>-0.315074</td>\n",
       "      <td>-0.575166</td>\n",
       "      <td>1.202246</td>\n",
       "      <td>-0.181915</td>\n",
       "      <td>1.386576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>2.322966</td>\n",
       "      <td>1.996291</td>\n",
       "      <td>-1.447835</td>\n",
       "      <td>-0.042943</td>\n",
       "      <td>1.089451</td>\n",
       "      <td>0.211433</td>\n",
       "      <td>-0.493232</td>\n",
       "      <td>-0.165787</td>\n",
       "      <td>-0.272616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>1.556072</td>\n",
       "      <td>0.897324</td>\n",
       "      <td>-0.217874</td>\n",
       "      <td>0.526463</td>\n",
       "      <td>1.401514</td>\n",
       "      <td>-0.038725</td>\n",
       "      <td>0.026458</td>\n",
       "      <td>0.341287</td>\n",
       "      <td>-0.091528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>1.039404</td>\n",
       "      <td>0.625719</td>\n",
       "      <td>1.334725</td>\n",
       "      <td>-0.984314</td>\n",
       "      <td>-1.353316</td>\n",
       "      <td>0.046913</td>\n",
       "      <td>-0.049031</td>\n",
       "      <td>1.628580</td>\n",
       "      <td>2.185396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>-0.747835</td>\n",
       "      <td>-0.966265</td>\n",
       "      <td>-1.901506</td>\n",
       "      <td>-1.095612</td>\n",
       "      <td>-1.131262</td>\n",
       "      <td>-1.116467</td>\n",
       "      <td>-0.970621</td>\n",
       "      <td>-1.177981</td>\n",
       "      <td>-1.356659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>-0.612563</td>\n",
       "      <td>-1.004499</td>\n",
       "      <td>-1.301197</td>\n",
       "      <td>-1.125517</td>\n",
       "      <td>-0.773039</td>\n",
       "      <td>-0.978121</td>\n",
       "      <td>-1.323702</td>\n",
       "      <td>-0.887014</td>\n",
       "      <td>-1.353705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 414 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor_pred  \\\n",
       "0      id_000644bb2                          0.537081   \n",
       "1      id_000779bfc                         -0.076446   \n",
       "2      id_000a6266a                          1.409396   \n",
       "3      id_0015fd391                         -0.522910   \n",
       "4      id_001626bd3                         -0.377659   \n",
       "...             ...                               ...   \n",
       "21943  id_fff8c2444                          2.322966   \n",
       "21944  id_fffb1ceed                          1.556072   \n",
       "21945  id_fffb70c0c                          1.039404   \n",
       "21946  id_fffcb9e7c                         -0.747835   \n",
       "21947  id_ffffdd77b                         -0.612563   \n",
       "\n",
       "       11-beta-hsd1_inhibitor_pred  acat_inhibitor_pred  \\\n",
       "0                        -0.400535            -0.069270   \n",
       "1                        -0.331551             0.224693   \n",
       "2                         1.474718            -0.002142   \n",
       "3                        -0.088334             0.611943   \n",
       "4                         0.155786             2.087313   \n",
       "...                            ...                  ...   \n",
       "21943                     1.996291            -1.447835   \n",
       "21944                     0.897324            -0.217874   \n",
       "21945                     0.625719             1.334725   \n",
       "21946                    -0.966265            -1.901506   \n",
       "21947                    -1.004499            -1.301197   \n",
       "\n",
       "       acetylcholine_receptor_agonist_pred  \\\n",
       "0                                 0.345114   \n",
       "1                                 0.775918   \n",
       "2                                -0.416476   \n",
       "3                                 0.060545   \n",
       "4                                 0.082745   \n",
       "...                                    ...   \n",
       "21943                            -0.042943   \n",
       "21944                             0.526463   \n",
       "21945                            -0.984314   \n",
       "21946                            -1.095612   \n",
       "21947                            -1.125517   \n",
       "\n",
       "       acetylcholine_receptor_antagonist_pred  \\\n",
       "0                                    1.591405   \n",
       "1                                    0.020212   \n",
       "2                                   -0.406838   \n",
       "3                                   -0.376046   \n",
       "4                                   -0.315074   \n",
       "...                                       ...   \n",
       "21943                                1.089451   \n",
       "21944                                1.401514   \n",
       "21945                               -1.353316   \n",
       "21946                               -1.131262   \n",
       "21947                               -0.773039   \n",
       "\n",
       "       acetylcholinesterase_inhibitor_pred  adenosine_receptor_agonist_pred  \\\n",
       "0                                 0.361417                         0.807020   \n",
       "1                                 0.309040                         0.505060   \n",
       "2                                -0.447629                        -0.016101   \n",
       "3                                -0.659599                         0.554086   \n",
       "4                                -0.575166                         1.202246   \n",
       "...                                    ...                              ...   \n",
       "21943                             0.211433                        -0.493232   \n",
       "21944                            -0.038725                         0.026458   \n",
       "21945                             0.046913                        -0.049031   \n",
       "21946                            -1.116467                        -0.970621   \n",
       "21947                            -0.978121                        -1.323702   \n",
       "\n",
       "       adenosine_receptor_antagonist_pred  adenylyl_cyclase_activator_pred  \\\n",
       "0                                0.308358                         0.345785   \n",
       "1                                0.435642                         0.369333   \n",
       "2                                0.831803                         1.543713   \n",
       "3                               -0.560342                         0.512390   \n",
       "4                               -0.181915                         1.386576   \n",
       "...                                   ...                              ...   \n",
       "21943                           -0.165787                        -0.272616   \n",
       "21944                            0.341287                        -0.091528   \n",
       "21945                            1.628580                         2.185396   \n",
       "21946                           -1.177981                        -1.356659   \n",
       "21947                           -0.887014                        -1.353705   \n",
       "\n",
       "       ...  trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      ...        0.0005           0.0005             0.0005   \n",
       "1      ...        0.0005           0.0005             0.0005   \n",
       "2      ...        0.0005           0.0005             0.0005   \n",
       "3      ...        0.0005           0.0005             0.0005   \n",
       "4      ...        0.0005           0.0005             0.0005   \n",
       "...    ...           ...              ...                ...   \n",
       "21943  ...        0.0005           0.0005             0.0005   \n",
       "21944  ...        0.0005           0.0005             0.0005   \n",
       "21945  ...        0.0005           0.0005             0.0005   \n",
       "21946  ...        0.0005           0.0005             0.0005   \n",
       "21947  ...        0.0005           0.0005             0.0005   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                         0.0005                                 0.0005   \n",
       "1                         0.0005                                 0.0005   \n",
       "2                         0.0005                                 0.0005   \n",
       "3                         0.0005                                 0.0005   \n",
       "4                         0.0005                                 0.0005   \n",
       "...                          ...                                    ...   \n",
       "21943                     0.0005                                 0.0005   \n",
       "21944                     0.0005                                 0.0005   \n",
       "21945                     0.0005                                 0.0005   \n",
       "21946                     0.0005                                 0.0005   \n",
       "21947                     0.0005                                 0.0005   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0               0.0005     0.0005                      0.0005         0.0005   \n",
       "1               0.0005     0.0005                      0.0005         0.0005   \n",
       "2               0.0005     0.0005                      0.0005         0.0005   \n",
       "3               0.0005     0.0005                      0.0005         0.0005   \n",
       "4               0.0005     0.0005                      0.0005         0.0005   \n",
       "...                ...        ...                         ...            ...   \n",
       "21943           0.0005     0.0005                      0.0005         0.0005   \n",
       "21944           0.0005     0.0005                      0.0005         0.0005   \n",
       "21945           0.0005     0.0005                      0.0005         0.0005   \n",
       "21946           0.0005     0.0005                      0.0005         0.0005   \n",
       "21947           0.0005     0.0005                      0.0005         0.0005   \n",
       "\n",
       "       kfold  \n",
       "0          2  \n",
       "1          4  \n",
       "2          0  \n",
       "3          3  \n",
       "4          1  \n",
       "...      ...  \n",
       "21943      4  \n",
       "21944      0  \n",
       "21945      4  \n",
       "21946      3  \n",
       "21947      1  \n",
       "\n",
       "[21948 rows x 414 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:52.210363Z",
     "iopub.status.busy": "2020-11-26T06:01:52.209471Z",
     "iopub.status.idle": "2020-11-26T06:01:52.213450Z",
     "shell.execute_reply": "2020-11-26T06:01:52.212801Z"
    },
    "papermill": {
     "duration": 0.639638,
     "end_time": "2020-11-26T06:01:52.213592",
     "exception": false,
     "start_time": "2020-11-26T06:01:51.573954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "\n",
    "    #     data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    #     data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2, 0:0, 1:1, 2:2})\n",
    "    #     data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1, 0:0, 1:1})\n",
    "\n",
    "    # --------------------- Normalize ---------------------\n",
    "    #     for col in GENES:\n",
    "    #         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "\n",
    "    #     for col in CELLS:\n",
    "    #         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "\n",
    "    #--------------------- Removing Skewness ---------------------\n",
    "    #     for col in GENES + CELLS:\n",
    "    #         if(abs(data[col].skew()) > 0.75):\n",
    "\n",
    "    #             if(data[col].skew() < 0): # neg-skewness\n",
    "    #                 data[col] = data[col].max() - data[col] + 1\n",
    "    #                 data[col] = np.sqrt(data[col])\n",
    "\n",
    "    #             else:\n",
    "    #                 data[col] = np.sqrt(data[col])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:53.483713Z",
     "iopub.status.busy": "2020-11-26T06:01:53.482223Z",
     "iopub.status.idle": "2020-11-26T06:01:53.486554Z",
     "shell.execute_reply": "2020-11-26T06:01:53.487086Z"
    },
    "papermill": {
     "duration": 0.642814,
     "end_time": "2020-11-26T06:01:53.487235",
     "exception": false,
     "start_time": "2020-11-26T06:01:52.844421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in folds.columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:54.758540Z",
     "iopub.status.busy": "2020-11-26T06:01:54.757291Z",
     "iopub.status.idle": "2020-11-26T06:01:54.761658Z",
     "shell.execute_reply": "2020-11-26T06:01:54.762212Z"
    },
    "papermill": {
     "duration": 0.644469,
     "end_time": "2020-11-26T06:01:54.762394",
     "exception": false,
     "start_time": "2020-11-26T06:01:54.117925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5-alpha_reductase_inhibitor_pred',\n",
       " '11-beta-hsd1_inhibitor_pred',\n",
       " 'acat_inhibitor_pred',\n",
       " 'acetylcholine_receptor_agonist_pred',\n",
       " 'acetylcholine_receptor_antagonist_pred',\n",
       " 'acetylcholinesterase_inhibitor_pred',\n",
       " 'adenosine_receptor_agonist_pred',\n",
       " 'adenosine_receptor_antagonist_pred',\n",
       " 'adenylyl_cyclase_activator_pred',\n",
       " 'adrenergic_receptor_agonist_pred',\n",
       " 'adrenergic_receptor_antagonist_pred',\n",
       " 'akt_inhibitor_pred',\n",
       " 'aldehyde_dehydrogenase_inhibitor_pred',\n",
       " 'alk_inhibitor_pred',\n",
       " 'ampk_activator_pred',\n",
       " 'analgesic_pred',\n",
       " 'androgen_receptor_agonist_pred',\n",
       " 'androgen_receptor_antagonist_pred',\n",
       " 'anesthetic_-_local_pred',\n",
       " 'angiogenesis_inhibitor_pred',\n",
       " 'angiotensin_receptor_antagonist_pred',\n",
       " 'anti-inflammatory_pred',\n",
       " 'antiarrhythmic_pred',\n",
       " 'antibiotic_pred',\n",
       " 'anticonvulsant_pred',\n",
       " 'antifungal_pred',\n",
       " 'antihistamine_pred',\n",
       " 'antimalarial_pred',\n",
       " 'antioxidant_pred',\n",
       " 'antiprotozoal_pred',\n",
       " 'antiviral_pred',\n",
       " 'apoptosis_stimulant_pred',\n",
       " 'aromatase_inhibitor_pred',\n",
       " 'atm_kinase_inhibitor_pred',\n",
       " 'atp-sensitive_potassium_channel_antagonist_pred',\n",
       " 'atp_synthase_inhibitor_pred',\n",
       " 'atpase_inhibitor_pred',\n",
       " 'atr_kinase_inhibitor_pred',\n",
       " 'aurora_kinase_inhibitor_pred',\n",
       " 'autotaxin_inhibitor_pred',\n",
       " 'bacterial_30s_ribosomal_subunit_inhibitor_pred',\n",
       " 'bacterial_50s_ribosomal_subunit_inhibitor_pred',\n",
       " 'bacterial_antifolate_pred',\n",
       " 'bacterial_cell_wall_synthesis_inhibitor_pred',\n",
       " 'bacterial_dna_gyrase_inhibitor_pred',\n",
       " 'bacterial_dna_inhibitor_pred',\n",
       " 'bacterial_membrane_integrity_inhibitor_pred',\n",
       " 'bcl_inhibitor_pred',\n",
       " 'bcr-abl_inhibitor_pred',\n",
       " 'benzodiazepine_receptor_agonist_pred',\n",
       " 'beta_amyloid_inhibitor_pred',\n",
       " 'bromodomain_inhibitor_pred',\n",
       " 'btk_inhibitor_pred',\n",
       " 'calcineurin_inhibitor_pred',\n",
       " 'calcium_channel_blocker_pred',\n",
       " 'cannabinoid_receptor_agonist_pred',\n",
       " 'cannabinoid_receptor_antagonist_pred',\n",
       " 'carbonic_anhydrase_inhibitor_pred',\n",
       " 'casein_kinase_inhibitor_pred',\n",
       " 'caspase_activator_pred',\n",
       " 'catechol_o_methyltransferase_inhibitor_pred',\n",
       " 'cc_chemokine_receptor_antagonist_pred',\n",
       " 'cck_receptor_antagonist_pred',\n",
       " 'cdk_inhibitor_pred',\n",
       " 'chelating_agent_pred',\n",
       " 'chk_inhibitor_pred',\n",
       " 'chloride_channel_blocker_pred',\n",
       " 'cholesterol_inhibitor_pred',\n",
       " 'cholinergic_receptor_antagonist_pred',\n",
       " 'coagulation_factor_inhibitor_pred',\n",
       " 'corticosteroid_agonist_pred',\n",
       " 'cyclooxygenase_inhibitor_pred',\n",
       " 'cytochrome_p450_inhibitor_pred',\n",
       " 'dihydrofolate_reductase_inhibitor_pred',\n",
       " 'dipeptidyl_peptidase_inhibitor_pred',\n",
       " 'diuretic_pred',\n",
       " 'dna_alkylating_agent_pred',\n",
       " 'dna_inhibitor_pred',\n",
       " 'dopamine_receptor_agonist_pred',\n",
       " 'dopamine_receptor_antagonist_pred',\n",
       " 'egfr_inhibitor_pred',\n",
       " 'elastase_inhibitor_pred',\n",
       " 'erbb2_inhibitor_pred',\n",
       " 'estrogen_receptor_agonist_pred',\n",
       " 'estrogen_receptor_antagonist_pred',\n",
       " 'faah_inhibitor_pred',\n",
       " 'farnesyltransferase_inhibitor_pred',\n",
       " 'fatty_acid_receptor_agonist_pred',\n",
       " 'fgfr_inhibitor_pred',\n",
       " 'flt3_inhibitor_pred',\n",
       " 'focal_adhesion_kinase_inhibitor_pred',\n",
       " 'free_radical_scavenger_pred',\n",
       " 'fungal_squalene_epoxidase_inhibitor_pred',\n",
       " 'gaba_receptor_agonist_pred',\n",
       " 'gaba_receptor_antagonist_pred',\n",
       " 'gamma_secretase_inhibitor_pred',\n",
       " 'glucocorticoid_receptor_agonist_pred',\n",
       " 'glutamate_inhibitor_pred',\n",
       " 'glutamate_receptor_agonist_pred',\n",
       " 'glutamate_receptor_antagonist_pred',\n",
       " 'gonadotropin_receptor_agonist_pred',\n",
       " 'gsk_inhibitor_pred',\n",
       " 'hcv_inhibitor_pred',\n",
       " 'hdac_inhibitor_pred',\n",
       " 'histamine_receptor_agonist_pred',\n",
       " 'histamine_receptor_antagonist_pred',\n",
       " 'histone_lysine_demethylase_inhibitor_pred',\n",
       " 'histone_lysine_methyltransferase_inhibitor_pred',\n",
       " 'hiv_inhibitor_pred',\n",
       " 'hmgcr_inhibitor_pred',\n",
       " 'hsp_inhibitor_pred',\n",
       " 'igf-1_inhibitor_pred',\n",
       " 'ikk_inhibitor_pred',\n",
       " 'imidazoline_receptor_agonist_pred',\n",
       " 'immunosuppressant_pred',\n",
       " 'insulin_secretagogue_pred',\n",
       " 'insulin_sensitizer_pred',\n",
       " 'integrin_inhibitor_pred',\n",
       " 'jak_inhibitor_pred',\n",
       " 'kit_inhibitor_pred',\n",
       " 'laxative_pred',\n",
       " 'leukotriene_inhibitor_pred',\n",
       " 'leukotriene_receptor_antagonist_pred',\n",
       " 'lipase_inhibitor_pred',\n",
       " 'lipoxygenase_inhibitor_pred',\n",
       " 'lxr_agonist_pred',\n",
       " 'mdm_inhibitor_pred',\n",
       " 'mek_inhibitor_pred',\n",
       " 'membrane_integrity_inhibitor_pred',\n",
       " 'mineralocorticoid_receptor_antagonist_pred',\n",
       " 'monoacylglycerol_lipase_inhibitor_pred',\n",
       " 'monoamine_oxidase_inhibitor_pred',\n",
       " 'monopolar_spindle_1_kinase_inhibitor_pred',\n",
       " 'mtor_inhibitor_pred',\n",
       " 'mucolytic_agent_pred',\n",
       " 'neuropeptide_receptor_antagonist_pred',\n",
       " 'nfkb_inhibitor_pred',\n",
       " 'nicotinic_receptor_agonist_pred',\n",
       " 'nitric_oxide_donor_pred',\n",
       " 'nitric_oxide_production_inhibitor_pred',\n",
       " 'nitric_oxide_synthase_inhibitor_pred',\n",
       " 'norepinephrine_reuptake_inhibitor_pred',\n",
       " 'nrf2_activator_pred',\n",
       " 'opioid_receptor_agonist_pred',\n",
       " 'opioid_receptor_antagonist_pred',\n",
       " 'orexin_receptor_antagonist_pred',\n",
       " 'p38_mapk_inhibitor_pred',\n",
       " 'p-glycoprotein_inhibitor_pred',\n",
       " 'parp_inhibitor_pred',\n",
       " 'pdgfr_inhibitor_pred',\n",
       " 'pdk_inhibitor_pred',\n",
       " 'phosphodiesterase_inhibitor_pred',\n",
       " 'phospholipase_inhibitor_pred',\n",
       " 'pi3k_inhibitor_pred',\n",
       " 'pkc_inhibitor_pred',\n",
       " 'potassium_channel_activator_pred',\n",
       " 'potassium_channel_antagonist_pred',\n",
       " 'ppar_receptor_agonist_pred',\n",
       " 'ppar_receptor_antagonist_pred',\n",
       " 'progesterone_receptor_agonist_pred',\n",
       " 'progesterone_receptor_antagonist_pred',\n",
       " 'prostaglandin_inhibitor_pred',\n",
       " 'prostanoid_receptor_antagonist_pred',\n",
       " 'proteasome_inhibitor_pred',\n",
       " 'protein_kinase_inhibitor_pred',\n",
       " 'protein_phosphatase_inhibitor_pred',\n",
       " 'protein_synthesis_inhibitor_pred',\n",
       " 'protein_tyrosine_kinase_inhibitor_pred',\n",
       " 'radiopaque_medium_pred',\n",
       " 'raf_inhibitor_pred',\n",
       " 'ras_gtpase_inhibitor_pred',\n",
       " 'retinoid_receptor_agonist_pred',\n",
       " 'retinoid_receptor_antagonist_pred',\n",
       " 'rho_associated_kinase_inhibitor_pred',\n",
       " 'ribonucleoside_reductase_inhibitor_pred',\n",
       " 'rna_polymerase_inhibitor_pred',\n",
       " 'serotonin_receptor_agonist_pred',\n",
       " 'serotonin_receptor_antagonist_pred',\n",
       " 'serotonin_reuptake_inhibitor_pred',\n",
       " 'sigma_receptor_agonist_pred',\n",
       " 'sigma_receptor_antagonist_pred',\n",
       " 'smoothened_receptor_antagonist_pred',\n",
       " 'sodium_channel_inhibitor_pred',\n",
       " 'sphingosine_receptor_agonist_pred',\n",
       " 'src_inhibitor_pred',\n",
       " 'steroid_pred',\n",
       " 'syk_inhibitor_pred',\n",
       " 'tachykinin_antagonist_pred',\n",
       " 'tgf-beta_receptor_inhibitor_pred',\n",
       " 'thrombin_inhibitor_pred',\n",
       " 'thymidylate_synthase_inhibitor_pred',\n",
       " 'tlr_agonist_pred',\n",
       " 'tlr_antagonist_pred',\n",
       " 'tnf_inhibitor_pred',\n",
       " 'topoisomerase_inhibitor_pred',\n",
       " 'transient_receptor_potential_channel_antagonist_pred',\n",
       " 'tropomyosin_receptor_kinase_inhibitor_pred',\n",
       " 'trpv_agonist_pred',\n",
       " 'trpv_antagonist_pred',\n",
       " 'tubulin_inhibitor_pred',\n",
       " 'tyrosine_kinase_inhibitor_pred',\n",
       " 'ubiquitin_specific_protease_inhibitor_pred',\n",
       " 'vegfr_inhibitor_pred',\n",
       " 'vitamin_b_pred',\n",
       " 'vitamin_d_receptor_agonist_pred',\n",
       " 'wnt_inhibitor_pred']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:56.048844Z",
     "iopub.status.busy": "2020-11-26T06:01:56.047773Z",
     "iopub.status.idle": "2020-11-26T06:01:56.091882Z",
     "shell.execute_reply": "2020-11-26T06:01:56.092691Z"
    },
    "papermill": {
     "duration": 0.683242,
     "end_time": "2020-11-26T06:01:56.092871",
     "exception": false,
     "start_time": "2020-11-26T06:01:55.409629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor_pred</th>\n",
       "      <th>11-beta-hsd1_inhibitor_pred</th>\n",
       "      <th>acat_inhibitor_pred</th>\n",
       "      <th>acetylcholine_receptor_agonist_pred</th>\n",
       "      <th>acetylcholine_receptor_antagonist_pred</th>\n",
       "      <th>acetylcholinesterase_inhibitor_pred</th>\n",
       "      <th>adenosine_receptor_agonist_pred</th>\n",
       "      <th>adenosine_receptor_antagonist_pred</th>\n",
       "      <th>adenylyl_cyclase_activator_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0.537081</td>\n",
       "      <td>-0.400535</td>\n",
       "      <td>-0.069270</td>\n",
       "      <td>0.345114</td>\n",
       "      <td>1.591405</td>\n",
       "      <td>0.361417</td>\n",
       "      <td>0.807020</td>\n",
       "      <td>0.308358</td>\n",
       "      <td>0.345785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>-0.076446</td>\n",
       "      <td>-0.331551</td>\n",
       "      <td>0.224693</td>\n",
       "      <td>0.775918</td>\n",
       "      <td>0.020212</td>\n",
       "      <td>0.309040</td>\n",
       "      <td>0.505060</td>\n",
       "      <td>0.435642</td>\n",
       "      <td>0.369333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>1.409396</td>\n",
       "      <td>1.474718</td>\n",
       "      <td>-0.002142</td>\n",
       "      <td>-0.416476</td>\n",
       "      <td>-0.406838</td>\n",
       "      <td>-0.447629</td>\n",
       "      <td>-0.016101</td>\n",
       "      <td>0.831803</td>\n",
       "      <td>1.543713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>-0.522910</td>\n",
       "      <td>-0.088334</td>\n",
       "      <td>0.611943</td>\n",
       "      <td>0.060545</td>\n",
       "      <td>-0.376046</td>\n",
       "      <td>-0.659599</td>\n",
       "      <td>0.554086</td>\n",
       "      <td>-0.560342</td>\n",
       "      <td>0.512390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>-0.377659</td>\n",
       "      <td>0.155786</td>\n",
       "      <td>2.087313</td>\n",
       "      <td>0.082745</td>\n",
       "      <td>-0.315074</td>\n",
       "      <td>-0.575166</td>\n",
       "      <td>1.202246</td>\n",
       "      <td>-0.181915</td>\n",
       "      <td>1.386576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>2.322966</td>\n",
       "      <td>1.996291</td>\n",
       "      <td>-1.447835</td>\n",
       "      <td>-0.042943</td>\n",
       "      <td>1.089451</td>\n",
       "      <td>0.211433</td>\n",
       "      <td>-0.493232</td>\n",
       "      <td>-0.165787</td>\n",
       "      <td>-0.272616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>1.556072</td>\n",
       "      <td>0.897324</td>\n",
       "      <td>-0.217874</td>\n",
       "      <td>0.526463</td>\n",
       "      <td>1.401514</td>\n",
       "      <td>-0.038725</td>\n",
       "      <td>0.026458</td>\n",
       "      <td>0.341287</td>\n",
       "      <td>-0.091528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>1.039404</td>\n",
       "      <td>0.625719</td>\n",
       "      <td>1.334725</td>\n",
       "      <td>-0.984314</td>\n",
       "      <td>-1.353316</td>\n",
       "      <td>0.046913</td>\n",
       "      <td>-0.049031</td>\n",
       "      <td>1.628580</td>\n",
       "      <td>2.185396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>-0.747835</td>\n",
       "      <td>-0.966265</td>\n",
       "      <td>-1.901506</td>\n",
       "      <td>-1.095612</td>\n",
       "      <td>-1.131262</td>\n",
       "      <td>-1.116467</td>\n",
       "      <td>-0.970621</td>\n",
       "      <td>-1.177981</td>\n",
       "      <td>-1.356659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>-0.612563</td>\n",
       "      <td>-1.004499</td>\n",
       "      <td>-1.301197</td>\n",
       "      <td>-1.125517</td>\n",
       "      <td>-0.773039</td>\n",
       "      <td>-0.978121</td>\n",
       "      <td>-1.323702</td>\n",
       "      <td>-0.887014</td>\n",
       "      <td>-1.353705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 414 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor_pred  \\\n",
       "0      id_000644bb2                          0.537081   \n",
       "1      id_000779bfc                         -0.076446   \n",
       "2      id_000a6266a                          1.409396   \n",
       "3      id_0015fd391                         -0.522910   \n",
       "4      id_001626bd3                         -0.377659   \n",
       "...             ...                               ...   \n",
       "21943  id_fff8c2444                          2.322966   \n",
       "21944  id_fffb1ceed                          1.556072   \n",
       "21945  id_fffb70c0c                          1.039404   \n",
       "21946  id_fffcb9e7c                         -0.747835   \n",
       "21947  id_ffffdd77b                         -0.612563   \n",
       "\n",
       "       11-beta-hsd1_inhibitor_pred  acat_inhibitor_pred  \\\n",
       "0                        -0.400535            -0.069270   \n",
       "1                        -0.331551             0.224693   \n",
       "2                         1.474718            -0.002142   \n",
       "3                        -0.088334             0.611943   \n",
       "4                         0.155786             2.087313   \n",
       "...                            ...                  ...   \n",
       "21943                     1.996291            -1.447835   \n",
       "21944                     0.897324            -0.217874   \n",
       "21945                     0.625719             1.334725   \n",
       "21946                    -0.966265            -1.901506   \n",
       "21947                    -1.004499            -1.301197   \n",
       "\n",
       "       acetylcholine_receptor_agonist_pred  \\\n",
       "0                                 0.345114   \n",
       "1                                 0.775918   \n",
       "2                                -0.416476   \n",
       "3                                 0.060545   \n",
       "4                                 0.082745   \n",
       "...                                    ...   \n",
       "21943                            -0.042943   \n",
       "21944                             0.526463   \n",
       "21945                            -0.984314   \n",
       "21946                            -1.095612   \n",
       "21947                            -1.125517   \n",
       "\n",
       "       acetylcholine_receptor_antagonist_pred  \\\n",
       "0                                    1.591405   \n",
       "1                                    0.020212   \n",
       "2                                   -0.406838   \n",
       "3                                   -0.376046   \n",
       "4                                   -0.315074   \n",
       "...                                       ...   \n",
       "21943                                1.089451   \n",
       "21944                                1.401514   \n",
       "21945                               -1.353316   \n",
       "21946                               -1.131262   \n",
       "21947                               -0.773039   \n",
       "\n",
       "       acetylcholinesterase_inhibitor_pred  adenosine_receptor_agonist_pred  \\\n",
       "0                                 0.361417                         0.807020   \n",
       "1                                 0.309040                         0.505060   \n",
       "2                                -0.447629                        -0.016101   \n",
       "3                                -0.659599                         0.554086   \n",
       "4                                -0.575166                         1.202246   \n",
       "...                                    ...                              ...   \n",
       "21943                             0.211433                        -0.493232   \n",
       "21944                            -0.038725                         0.026458   \n",
       "21945                             0.046913                        -0.049031   \n",
       "21946                            -1.116467                        -0.970621   \n",
       "21947                            -0.978121                        -1.323702   \n",
       "\n",
       "       adenosine_receptor_antagonist_pred  adenylyl_cyclase_activator_pred  \\\n",
       "0                                0.308358                         0.345785   \n",
       "1                                0.435642                         0.369333   \n",
       "2                                0.831803                         1.543713   \n",
       "3                               -0.560342                         0.512390   \n",
       "4                               -0.181915                         1.386576   \n",
       "...                                   ...                              ...   \n",
       "21943                           -0.165787                        -0.272616   \n",
       "21944                            0.341287                        -0.091528   \n",
       "21945                            1.628580                         2.185396   \n",
       "21946                           -1.177981                        -1.356659   \n",
       "21947                           -0.887014                        -1.353705   \n",
       "\n",
       "       ...  trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      ...        0.0005           0.0005             0.0005   \n",
       "1      ...        0.0005           0.0005             0.0005   \n",
       "2      ...        0.0005           0.0005             0.0005   \n",
       "3      ...        0.0005           0.0005             0.0005   \n",
       "4      ...        0.0005           0.0005             0.0005   \n",
       "...    ...           ...              ...                ...   \n",
       "21943  ...        0.0005           0.0005             0.0005   \n",
       "21944  ...        0.0005           0.0005             0.0005   \n",
       "21945  ...        0.0005           0.0005             0.0005   \n",
       "21946  ...        0.0005           0.0005             0.0005   \n",
       "21947  ...        0.0005           0.0005             0.0005   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                         0.0005                                 0.0005   \n",
       "1                         0.0005                                 0.0005   \n",
       "2                         0.0005                                 0.0005   \n",
       "3                         0.0005                                 0.0005   \n",
       "4                         0.0005                                 0.0005   \n",
       "...                          ...                                    ...   \n",
       "21943                     0.0005                                 0.0005   \n",
       "21944                     0.0005                                 0.0005   \n",
       "21945                     0.0005                                 0.0005   \n",
       "21946                     0.0005                                 0.0005   \n",
       "21947                     0.0005                                 0.0005   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0               0.0005     0.0005                      0.0005         0.0005   \n",
       "1               0.0005     0.0005                      0.0005         0.0005   \n",
       "2               0.0005     0.0005                      0.0005         0.0005   \n",
       "3               0.0005     0.0005                      0.0005         0.0005   \n",
       "4               0.0005     0.0005                      0.0005         0.0005   \n",
       "...                ...        ...                         ...            ...   \n",
       "21943           0.0005     0.0005                      0.0005         0.0005   \n",
       "21944           0.0005     0.0005                      0.0005         0.0005   \n",
       "21945           0.0005     0.0005                      0.0005         0.0005   \n",
       "21946           0.0005     0.0005                      0.0005         0.0005   \n",
       "21947           0.0005     0.0005                      0.0005         0.0005   \n",
       "\n",
       "       kfold  \n",
       "0          2  \n",
       "1          4  \n",
       "2          0  \n",
       "3          3  \n",
       "4          1  \n",
       "...      ...  \n",
       "21943      4  \n",
       "21944      0  \n",
       "21945      4  \n",
       "21946      3  \n",
       "21947      1  \n",
       "\n",
       "[21948 rows x 414 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:57.384708Z",
     "iopub.status.busy": "2020-11-26T06:01:57.382570Z",
     "iopub.status.idle": "2020-11-26T06:01:57.385478Z",
     "shell.execute_reply": "2020-11-26T06:01:57.386058Z"
    },
    "papermill": {
     "duration": 0.643554,
     "end_time": "2020-11-26T06:01:57.386201",
     "exception": false,
     "start_time": "2020-11-26T06:01:56.742647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "num_features = len(feature_cols)\n",
    "num_targets = len(target_cols)\n",
    "hidden_size = 1024\n",
    "# hidden_size=4096\n",
    "# hidden_size=9192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:01:58.909061Z",
     "iopub.status.busy": "2020-11-26T06:01:58.907747Z",
     "iopub.status.idle": "2020-11-26T06:01:58.951308Z",
     "shell.execute_reply": "2020-11-26T06:01:58.952159Z"
    },
    "papermill": {
     "duration": 0.937579,
     "end_time": "2020-11-26T06:01:58.952408",
     "exception": false,
     "start_time": "2020-11-26T06:01:58.014829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "\n",
    "    seed_everything(seed)\n",
    "\n",
    "    train = (folds)\n",
    "    test_ = (test)\n",
    "\n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "\n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    x_train, y_train = train_df[feature_cols].values, train_df[\n",
    "        target_cols].values\n",
    "    x_valid, y_valid = valid_df[feature_cols].values, valid_df[\n",
    "        target_cols].values\n",
    "\n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=False)\n",
    "\n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=5e-3,\n",
    "                                 weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer,\n",
    "                                              pct_start=0.2,\n",
    "                                              div_factor=1e3,\n",
    "                                              max_lr=1e-2,\n",
    "                                              epochs=EPOCHS,\n",
    "                                              steps_per_epoch=len(trainloader))\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "\n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        train_loss = train_fn(model, optimizer, scheduler, loss_fn,\n",
    "                              trainloader, DEVICE)\n",
    "        print(\n",
    "            f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\"\n",
    "        )\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(\n",
    "            f\"SEED: {seed} ,FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\"\n",
    "        )\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "\n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(),\n",
    "                       f\"{MODEL_DIR}/{NB}-scored2-SEED{seed}-FOLD{fold}_.pth\")\n",
    "\n",
    "        elif (EARLY_STOP == True):\n",
    "\n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "\n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             shuffle=False)\n",
    "\n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    model.load_state_dict(\n",
    "        torch.load(f\"{MODEL_DIR}/{NB}-scored2-SEED{seed}-FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    #   if not IS_TRAIN:\n",
    "    # valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "    # oof[val_idx] = valid_preds\n",
    "\n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "\n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:02:00.240084Z",
     "iopub.status.busy": "2020-11-26T06:02:00.239158Z",
     "iopub.status.idle": "2020-11-26T06:02:00.243802Z",
     "shell.execute_reply": "2020-11-26T06:02:00.243153Z"
    },
    "papermill": {
     "duration": 0.647174,
     "end_time": "2020-11-26T06:02:00.243920",
     "exception": false,
     "start_time": "2020-11-26T06:01:59.596746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "\n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "\n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:02:01.520384Z",
     "iopub.status.busy": "2020-11-26T06:02:01.518623Z",
     "iopub.status.idle": "2020-11-26T06:15:08.199092Z",
     "shell.execute_reply": "2020-11-26T06:15:08.198426Z"
    },
    "papermill": {
     "duration": 787.323857,
     "end_time": "2020-11-26T06:15:08.199235",
     "exception": false,
     "start_time": "2020-11-26T06:02:00.875378",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 940, FOLD: 0, EPOCH: 0, train_loss: 0.718145609765813\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6396683785650465\n",
      "SEED: 940, FOLD: 0, EPOCH: 1, train_loss: 0.2655495387920435\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 1, valid_loss: 0.03087172212286128\n",
      "SEED: 940, FOLD: 0, EPOCH: 2, train_loss: 0.024781704434882038\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 2, valid_loss: 0.021605933499005105\n",
      "SEED: 940, FOLD: 0, EPOCH: 3, train_loss: 0.021165007455409435\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 3, valid_loss: 0.02030052699976497\n",
      "SEED: 940, FOLD: 0, EPOCH: 4, train_loss: 0.020388307022875633\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 4, valid_loss: 0.019968161669870216\n",
      "SEED: 940, FOLD: 0, EPOCH: 5, train_loss: 0.019876298670103584\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 5, valid_loss: 0.019536862874196634\n",
      "SEED: 940, FOLD: 0, EPOCH: 6, train_loss: 0.01959703001531138\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 6, valid_loss: 0.019616645864314504\n",
      "SEED: 940, FOLD: 0, EPOCH: 7, train_loss: 0.01935468875951525\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 7, valid_loss: 0.019411795255210664\n",
      "SEED: 940, FOLD: 0, EPOCH: 8, train_loss: 0.01927460535712864\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01937516602791018\n",
      "SEED: 940, FOLD: 0, EPOCH: 9, train_loss: 0.019204800327618916\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 9, valid_loss: 0.019288686518039968\n",
      "SEED: 940, FOLD: 0, EPOCH: 10, train_loss: 0.01917990359167258\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 10, valid_loss: 0.019256188741160765\n",
      "SEED: 940, FOLD: 0, EPOCH: 11, train_loss: 0.01918251180778379\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 11, valid_loss: 0.019245999865233898\n",
      "SEED: 940, FOLD: 0, EPOCH: 12, train_loss: 0.019126847413355026\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 12, valid_loss: 0.019191170525219705\n",
      "SEED: 940, FOLD: 0, EPOCH: 13, train_loss: 0.019120842488347622\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 13, valid_loss: 0.019394871778786182\n",
      "SEED: 940, FOLD: 0, EPOCH: 14, train_loss: 0.019058151548539383\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 14, valid_loss: 0.0192421968612406\n",
      "SEED: 940, FOLD: 0, EPOCH: 15, train_loss: 0.018960366970387058\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01909844142695268\n",
      "SEED: 940, FOLD: 0, EPOCH: 16, train_loss: 0.018809953758466072\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 16, valid_loss: 0.019135215112732515\n",
      "SEED: 940, FOLD: 0, EPOCH: 17, train_loss: 0.018710277056780415\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 17, valid_loss: 0.018979778823753197\n",
      "SEED: 940, FOLD: 0, EPOCH: 18, train_loss: 0.018553363672201183\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 18, valid_loss: 0.01893427585148149\n",
      "SEED: 940, FOLD: 0, EPOCH: 19, train_loss: 0.01838509428004424\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 19, valid_loss: 0.018901831987831328\n",
      "SEED: 940, FOLD: 0, EPOCH: 20, train_loss: 0.018206751756909965\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 20, valid_loss: 0.018870009419818718\n",
      "SEED: 940, FOLD: 0, EPOCH: 21, train_loss: 0.018020760564916374\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 21, valid_loss: 0.018748684579299554\n",
      "SEED: 940, FOLD: 0, EPOCH: 22, train_loss: 0.017867121521545494\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 22, valid_loss: 0.018748823139402602\n",
      "SEED: 940, FOLD: 0, EPOCH: 23, train_loss: 0.01771902025717756\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 23, valid_loss: 0.018745092985530693\n",
      "SEED: 940, FOLD: 0, EPOCH: 24, train_loss: 0.01768696291939072\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 24, valid_loss: 0.018745384282535978\n",
      "SEED: 940, FOLD: 1, EPOCH: 0, train_loss: 0.7182386526163074\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6358938382731544\n",
      "SEED: 940, FOLD: 1, EPOCH: 1, train_loss: 0.2654742869831946\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 1, valid_loss: 0.03059239685535431\n",
      "SEED: 940, FOLD: 1, EPOCH: 2, train_loss: 0.024728135084328445\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 2, valid_loss: 0.02172072438730134\n",
      "SEED: 940, FOLD: 1, EPOCH: 3, train_loss: 0.021192421893710674\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 3, valid_loss: 0.020248173736035824\n",
      "SEED: 940, FOLD: 1, EPOCH: 4, train_loss: 0.020383388181959373\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 4, valid_loss: 0.019990292895171378\n",
      "SEED: 940, FOLD: 1, EPOCH: 5, train_loss: 0.01997733882803848\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 5, valid_loss: 0.019680639832384057\n",
      "SEED: 940, FOLD: 1, EPOCH: 6, train_loss: 0.01953734176746313\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01947648957785633\n",
      "SEED: 940, FOLD: 1, EPOCH: 7, train_loss: 0.01938384331330873\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01939900488489204\n",
      "SEED: 940, FOLD: 1, EPOCH: 8, train_loss: 0.019250701761979988\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 8, valid_loss: 0.019470507589479286\n",
      "SEED: 940, FOLD: 1, EPOCH: 9, train_loss: 0.019270741124299988\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 9, valid_loss: 0.019359675443006888\n",
      "SEED: 940, FOLD: 1, EPOCH: 10, train_loss: 0.019204565688319828\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 10, valid_loss: 0.019371985664798155\n",
      "SEED: 940, FOLD: 1, EPOCH: 11, train_loss: 0.019192927260545715\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 11, valid_loss: 0.019250719187160332\n",
      "SEED: 940, FOLD: 1, EPOCH: 12, train_loss: 0.019146334433901138\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 12, valid_loss: 0.019320317233602207\n",
      "SEED: 940, FOLD: 1, EPOCH: 13, train_loss: 0.019096896862206253\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01921240726692809\n",
      "SEED: 940, FOLD: 1, EPOCH: 14, train_loss: 0.01910667815178201\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 14, valid_loss: 0.019412955165737204\n",
      "SEED: 940, FOLD: 1, EPOCH: 15, train_loss: 0.018989380638020626\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 15, valid_loss: 0.019099249607986875\n",
      "SEED: 940, FOLD: 1, EPOCH: 16, train_loss: 0.018883841139250908\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 16, valid_loss: 0.019027764598528545\n",
      "SEED: 940, FOLD: 1, EPOCH: 17, train_loss: 0.018717137124875317\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 17, valid_loss: 0.018975974577996466\n",
      "SEED: 940, FOLD: 1, EPOCH: 18, train_loss: 0.018591861227068348\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01891534413314528\n",
      "SEED: 940, FOLD: 1, EPOCH: 19, train_loss: 0.01843474864743758\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01885300947146283\n",
      "SEED: 940, FOLD: 1, EPOCH: 20, train_loss: 0.018224448883447094\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 20, valid_loss: 0.018819919787347317\n",
      "SEED: 940, FOLD: 1, EPOCH: 21, train_loss: 0.018052547873146294\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 21, valid_loss: 0.018758164925707713\n",
      "SEED: 940, FOLD: 1, EPOCH: 22, train_loss: 0.0179148496169111\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 22, valid_loss: 0.01870405746416913\n",
      "SEED: 940, FOLD: 1, EPOCH: 23, train_loss: 0.017761790099135345\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 23, valid_loss: 0.018697923877173\n",
      "SEED: 940, FOLD: 1, EPOCH: 24, train_loss: 0.017749752417422722\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 24, valid_loss: 0.018696038362880547\n",
      "SEED: 940, FOLD: 2, EPOCH: 0, train_loss: 0.7182748844658119\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6400210791163974\n",
      "SEED: 940, FOLD: 2, EPOCH: 1, train_loss: 0.2638305046096228\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 1, valid_loss: 0.030616799265974097\n",
      "SEED: 940, FOLD: 2, EPOCH: 2, train_loss: 0.02467291737380235\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 2, valid_loss: 0.021521927064491644\n",
      "SEED: 940, FOLD: 2, EPOCH: 3, train_loss: 0.021192232470797455\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 3, valid_loss: 0.02042709156456921\n",
      "SEED: 940, FOLD: 2, EPOCH: 4, train_loss: 0.02040692464704963\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 4, valid_loss: 0.019776976046462853\n",
      "SEED: 940, FOLD: 2, EPOCH: 5, train_loss: 0.01985738979841488\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01965225487947464\n",
      "SEED: 940, FOLD: 2, EPOCH: 6, train_loss: 0.019588900784003563\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 6, valid_loss: 0.019431954870621364\n",
      "SEED: 940, FOLD: 2, EPOCH: 7, train_loss: 0.019450944294964058\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01945665530446503\n",
      "SEED: 940, FOLD: 2, EPOCH: 8, train_loss: 0.019336425388852756\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 8, valid_loss: 0.019434251201649506\n",
      "SEED: 940, FOLD: 2, EPOCH: 9, train_loss: 0.01924928129259227\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 9, valid_loss: 0.019285302919646103\n",
      "SEED: 940, FOLD: 2, EPOCH: 10, train_loss: 0.019242103737981422\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 10, valid_loss: 0.019260204811063077\n",
      "SEED: 940, FOLD: 2, EPOCH: 11, train_loss: 0.01922842058474603\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 11, valid_loss: 0.019236627862685256\n",
      "SEED: 940, FOLD: 2, EPOCH: 12, train_loss: 0.0192083350342253\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 12, valid_loss: 0.019179365183744166\n",
      "SEED: 940, FOLD: 2, EPOCH: 13, train_loss: 0.019152965774570686\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 13, valid_loss: 0.019187719871600468\n",
      "SEED: 940, FOLD: 2, EPOCH: 14, train_loss: 0.01905404498287733\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 14, valid_loss: 0.019123344268235896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 940, FOLD: 2, EPOCH: 15, train_loss: 0.01908902856318847\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 15, valid_loss: 0.0190724174802502\n",
      "SEED: 940, FOLD: 2, EPOCH: 16, train_loss: 0.018878019482329273\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 16, valid_loss: 0.019048736948106024\n",
      "SEED: 940, FOLD: 2, EPOCH: 17, train_loss: 0.01876743286308171\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 17, valid_loss: 0.019006037360264197\n",
      "SEED: 940, FOLD: 2, EPOCH: 18, train_loss: 0.01860826667668163\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 18, valid_loss: 0.018901370155314606\n",
      "SEED: 940, FOLD: 2, EPOCH: 19, train_loss: 0.018438921755422718\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 19, valid_loss: 0.018788124434649944\n",
      "SEED: 940, FOLD: 2, EPOCH: 20, train_loss: 0.01829090136764706\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 20, valid_loss: 0.0187627664870686\n",
      "SEED: 940, FOLD: 2, EPOCH: 21, train_loss: 0.018112322072619976\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01869153914352258\n",
      "SEED: 940, FOLD: 2, EPOCH: 22, train_loss: 0.017946369811028675\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01866833886338605\n",
      "SEED: 940, FOLD: 2, EPOCH: 23, train_loss: 0.017811176056663196\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01865069857901997\n",
      "SEED: 940, FOLD: 2, EPOCH: 24, train_loss: 0.017775629120676414\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 24, valid_loss: 0.018644740701549582\n",
      "SEED: 940, FOLD: 3, EPOCH: 0, train_loss: 0.7181011447008105\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6337773899237314\n",
      "SEED: 940, FOLD: 3, EPOCH: 1, train_loss: 0.26357416004158446\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 1, valid_loss: 0.031657995449172124\n",
      "SEED: 940, FOLD: 3, EPOCH: 2, train_loss: 0.024745920888971592\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 2, valid_loss: 0.021416690924929246\n",
      "SEED: 940, FOLD: 3, EPOCH: 3, train_loss: 0.0211388214720764\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 3, valid_loss: 0.02037276617354817\n",
      "SEED: 940, FOLD: 3, EPOCH: 4, train_loss: 0.02040854668703632\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 4, valid_loss: 0.019830181780788634\n",
      "SEED: 940, FOLD: 3, EPOCH: 5, train_loss: 0.01991833562868229\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 5, valid_loss: 0.019456967297527526\n",
      "SEED: 940, FOLD: 3, EPOCH: 6, train_loss: 0.019578231768547626\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 6, valid_loss: 0.019343138568931155\n",
      "SEED: 940, FOLD: 3, EPOCH: 7, train_loss: 0.01935691648311373\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 7, valid_loss: 0.0193951189931896\n",
      "SEED: 940, FOLD: 3, EPOCH: 8, train_loss: 0.019279107721387478\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 8, valid_loss: 0.019375211973157194\n",
      "SEED: 940, FOLD: 3, EPOCH: 9, train_loss: 0.01922150444833265\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 9, valid_loss: 0.019165962727533445\n",
      "SEED: 940, FOLD: 3, EPOCH: 10, train_loss: 0.019204748389513596\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01943751186546352\n",
      "SEED: 940, FOLD: 3, EPOCH: 11, train_loss: 0.019155750429068787\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 11, valid_loss: 0.019188388871649902\n",
      "SEED: 940, FOLD: 3, EPOCH: 12, train_loss: 0.019178358891951866\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 12, valid_loss: 0.019231201770404976\n",
      "SEED: 940, FOLD: 3, EPOCH: 13, train_loss: 0.01911770457914774\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 13, valid_loss: 0.019135370436641905\n",
      "SEED: 940, FOLD: 3, EPOCH: 14, train_loss: 0.019077001004547314\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01917736677245961\n",
      "SEED: 940, FOLD: 3, EPOCH: 15, train_loss: 0.018935060209554176\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 15, valid_loss: 0.019018131722178724\n",
      "SEED: 940, FOLD: 3, EPOCH: 16, train_loss: 0.01881195094598376\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 16, valid_loss: 0.019005679835875828\n",
      "SEED: 940, FOLD: 3, EPOCH: 17, train_loss: 0.01872408635698367\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 17, valid_loss: 0.018898750551872782\n",
      "SEED: 940, FOLD: 3, EPOCH: 18, train_loss: 0.01857467675986497\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 18, valid_loss: 0.018839073160456285\n",
      "SEED: 940, FOLD: 3, EPOCH: 19, train_loss: 0.01841639919017536\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01880213918371333\n",
      "SEED: 940, FOLD: 3, EPOCH: 20, train_loss: 0.01820077541945637\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 20, valid_loss: 0.018737523402604792\n",
      "SEED: 940, FOLD: 3, EPOCH: 21, train_loss: 0.01801820558266363\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01866928767412901\n",
      "SEED: 940, FOLD: 3, EPOCH: 22, train_loss: 0.01784608383541522\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 22, valid_loss: 0.018646020649207964\n",
      "SEED: 940, FOLD: 3, EPOCH: 23, train_loss: 0.01774159316783366\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 23, valid_loss: 0.018633108793033495\n",
      "SEED: 940, FOLD: 3, EPOCH: 24, train_loss: 0.01766087931405375\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 24, valid_loss: 0.018628878001537588\n",
      "SEED: 940, FOLD: 4, EPOCH: 0, train_loss: 0.7179315729417662\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 0, valid_loss: 0.638819608423445\n",
      "SEED: 940, FOLD: 4, EPOCH: 1, train_loss: 0.2631941066002068\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 1, valid_loss: 0.031380508612427443\n",
      "SEED: 940, FOLD: 4, EPOCH: 2, train_loss: 0.024788663682082424\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 2, valid_loss: 0.02193339427726136\n",
      "SEED: 940, FOLD: 4, EPOCH: 3, train_loss: 0.021123587545277416\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 3, valid_loss: 0.020540406306584675\n",
      "SEED: 940, FOLD: 4, EPOCH: 4, train_loss: 0.020377715455665104\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 4, valid_loss: 0.02037744379291932\n",
      "SEED: 940, FOLD: 4, EPOCH: 5, train_loss: 0.019971938236899998\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 5, valid_loss: 0.019854563288390636\n",
      "SEED: 940, FOLD: 4, EPOCH: 6, train_loss: 0.019541754049883373\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 6, valid_loss: 0.019670327607956197\n",
      "SEED: 940, FOLD: 4, EPOCH: 7, train_loss: 0.01931666785284229\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 7, valid_loss: 0.019474784119261637\n",
      "SEED: 940, FOLD: 4, EPOCH: 8, train_loss: 0.01921765854501206\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 8, valid_loss: 0.019513579706350963\n",
      "SEED: 940, FOLD: 4, EPOCH: 9, train_loss: 0.0192898057833098\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 9, valid_loss: 0.019388305437233713\n",
      "SEED: 940, FOLD: 4, EPOCH: 10, train_loss: 0.019238612655064335\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01948166431652175\n",
      "SEED: 940, FOLD: 4, EPOCH: 11, train_loss: 0.019168302578770596\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 11, valid_loss: 0.019376018808947668\n",
      "SEED: 940, FOLD: 4, EPOCH: 12, train_loss: 0.019173847673379856\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 12, valid_loss: 0.019501838108731642\n",
      "SEED: 940, FOLD: 4, EPOCH: 13, train_loss: 0.019067117215498634\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01939187840455108\n",
      "SEED: 940, FOLD: 4, EPOCH: 14, train_loss: 0.019084771582181904\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 14, valid_loss: 0.019334173036946192\n",
      "SEED: 940, FOLD: 4, EPOCH: 15, train_loss: 0.01895341495780841\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01926093165659242\n",
      "SEED: 940, FOLD: 4, EPOCH: 16, train_loss: 0.01889060259513233\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01922602682477898\n",
      "SEED: 940, FOLD: 4, EPOCH: 17, train_loss: 0.018750898594009704\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 17, valid_loss: 0.019135382026433945\n",
      "SEED: 940, FOLD: 4, EPOCH: 18, train_loss: 0.01860710087677707\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01903903515388568\n",
      "SEED: 940, FOLD: 4, EPOCH: 19, train_loss: 0.018445413559675217\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 19, valid_loss: 0.019010470662679937\n",
      "SEED: 940, FOLD: 4, EPOCH: 20, train_loss: 0.018234865550977596\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 20, valid_loss: 0.018878140279816255\n",
      "SEED: 940, FOLD: 4, EPOCH: 21, train_loss: 0.01806040850562462\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01882245008730226\n",
      "SEED: 940, FOLD: 4, EPOCH: 22, train_loss: 0.017934829806504043\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 22, valid_loss: 0.018768124592800934\n",
      "SEED: 940, FOLD: 4, EPOCH: 23, train_loss: 0.017774660653178242\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01876802338908116\n",
      "SEED: 940, FOLD: 4, EPOCH: 24, train_loss: 0.017718237136369167\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01876594177964661\n",
      "elapsed time: 66.55211448669434\n",
      "SEED: 1513, FOLD: 0, EPOCH: 0, train_loss: 0.7172919045323911\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 0, valid_loss: 0.636640555328793\n",
      "SEED: 1513, FOLD: 0, EPOCH: 1, train_loss: 0.2602822799505531\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 1, valid_loss: 0.03031674896677335\n",
      "SEED: 1513, FOLD: 0, EPOCH: 2, train_loss: 0.024898758590005447\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 2, valid_loss: 0.02190098435514503\n",
      "SEED: 1513, FOLD: 0, EPOCH: 3, train_loss: 0.021176533125664875\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 3, valid_loss: 0.02026789014538129\n",
      "SEED: 1513, FOLD: 0, EPOCH: 4, train_loss: 0.020605886786960174\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 4, valid_loss: 0.02014588492198123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1513, FOLD: 0, EPOCH: 5, train_loss: 0.01993294108820998\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 5, valid_loss: 0.019761933634678524\n",
      "SEED: 1513, FOLD: 0, EPOCH: 6, train_loss: 0.01957793136977631\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01940046726829476\n",
      "SEED: 1513, FOLD: 0, EPOCH: 7, train_loss: 0.019405940493595772\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 7, valid_loss: 0.019453050568699837\n",
      "SEED: 1513, FOLD: 0, EPOCH: 8, train_loss: 0.019299754144056984\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01950250855750508\n",
      "SEED: 1513, FOLD: 0, EPOCH: 9, train_loss: 0.019296473108124042\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 9, valid_loss: 0.019363499246537685\n",
      "SEED: 1513, FOLD: 0, EPOCH: 10, train_loss: 0.019168155834726665\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 10, valid_loss: 0.019305344257089827\n",
      "SEED: 1513, FOLD: 0, EPOCH: 11, train_loss: 0.01915799424160218\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 11, valid_loss: 0.019280485084487334\n",
      "SEED: 1513, FOLD: 0, EPOCH: 12, train_loss: 0.01922717774151892\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01925334127412902\n",
      "SEED: 1513, FOLD: 0, EPOCH: 13, train_loss: 0.019133598449221557\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01931516184575028\n",
      "SEED: 1513, FOLD: 0, EPOCH: 14, train_loss: 0.019087749735816666\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 14, valid_loss: 0.019101655421157677\n",
      "SEED: 1513, FOLD: 0, EPOCH: 15, train_loss: 0.018976388931058456\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 15, valid_loss: 0.019103265988330047\n",
      "SEED: 1513, FOLD: 0, EPOCH: 16, train_loss: 0.01882969847191935\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01900022414823373\n",
      "SEED: 1513, FOLD: 0, EPOCH: 17, train_loss: 0.018710602101856384\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 17, valid_loss: 0.018973049190309312\n",
      "SEED: 1513, FOLD: 0, EPOCH: 18, train_loss: 0.01859768380181513\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 18, valid_loss: 0.018990227952599525\n",
      "SEED: 1513, FOLD: 0, EPOCH: 19, train_loss: 0.018433090002424476\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01889697213967641\n",
      "SEED: 1513, FOLD: 0, EPOCH: 20, train_loss: 0.018247481381547623\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 20, valid_loss: 0.018813736115892727\n",
      "SEED: 1513, FOLD: 0, EPOCH: 21, train_loss: 0.018050182934688484\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 21, valid_loss: 0.018816954352789454\n",
      "SEED: 1513, FOLD: 0, EPOCH: 22, train_loss: 0.017904840598719707\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01876471336517069\n",
      "SEED: 1513, FOLD: 0, EPOCH: 23, train_loss: 0.01776097758092742\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 23, valid_loss: 0.018758391444053914\n",
      "SEED: 1513, FOLD: 0, EPOCH: 24, train_loss: 0.01773772734230843\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 24, valid_loss: 0.018755021194616955\n",
      "SEED: 1513, FOLD: 1, EPOCH: 0, train_loss: 0.718174814314082\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6325905852847629\n",
      "SEED: 1513, FOLD: 1, EPOCH: 1, train_loss: 0.2633083300206108\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 1, valid_loss: 0.030288051399919722\n",
      "SEED: 1513, FOLD: 1, EPOCH: 2, train_loss: 0.024794090377247852\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 2, valid_loss: 0.021735854136447113\n",
      "SEED: 1513, FOLD: 1, EPOCH: 3, train_loss: 0.02123851779902327\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 3, valid_loss: 0.020343569728235405\n",
      "SEED: 1513, FOLD: 1, EPOCH: 4, train_loss: 0.020492200429240864\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 4, valid_loss: 0.019829612225294113\n",
      "SEED: 1513, FOLD: 1, EPOCH: 5, train_loss: 0.019954525366209556\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 5, valid_loss: 0.019604724521438282\n",
      "SEED: 1513, FOLD: 1, EPOCH: 6, train_loss: 0.01958868377234625\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 6, valid_loss: 0.019555291678342555\n",
      "SEED: 1513, FOLD: 1, EPOCH: 7, train_loss: 0.01936297977100248\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 7, valid_loss: 0.019347916460699506\n",
      "SEED: 1513, FOLD: 1, EPOCH: 8, train_loss: 0.019314387057354485\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01936504089583953\n",
      "SEED: 1513, FOLD: 1, EPOCH: 9, train_loss: 0.019242923652780228\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 9, valid_loss: 0.019312729955547385\n",
      "SEED: 1513, FOLD: 1, EPOCH: 10, train_loss: 0.019238358633457752\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01932496453324954\n",
      "SEED: 1513, FOLD: 1, EPOCH: 11, train_loss: 0.019166515195283337\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01932861583514346\n",
      "SEED: 1513, FOLD: 1, EPOCH: 12, train_loss: 0.019168446596333946\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 12, valid_loss: 0.019247623574402597\n",
      "SEED: 1513, FOLD: 1, EPOCH: 13, train_loss: 0.019134508148915527\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 13, valid_loss: 0.019209161918196414\n",
      "SEED: 1513, FOLD: 1, EPOCH: 14, train_loss: 0.01903516556257787\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 14, valid_loss: 0.01936438534822729\n",
      "SEED: 1513, FOLD: 1, EPOCH: 15, train_loss: 0.019018015432832897\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 15, valid_loss: 0.019182469902767077\n",
      "SEED: 1513, FOLD: 1, EPOCH: 16, train_loss: 0.01891434162963128\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 16, valid_loss: 0.019089005784028105\n",
      "SEED: 1513, FOLD: 1, EPOCH: 17, train_loss: 0.018724005021478817\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01904560315112273\n",
      "SEED: 1513, FOLD: 1, EPOCH: 18, train_loss: 0.018565487548492958\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01893442455265257\n",
      "SEED: 1513, FOLD: 1, EPOCH: 19, train_loss: 0.018442733591233475\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 19, valid_loss: 0.018861392719878092\n",
      "SEED: 1513, FOLD: 1, EPOCH: 20, train_loss: 0.01826913816773373\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 20, valid_loss: 0.01885772744814555\n",
      "SEED: 1513, FOLD: 1, EPOCH: 21, train_loss: 0.01807224739720856\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 21, valid_loss: 0.018816034723487165\n",
      "SEED: 1513, FOLD: 1, EPOCH: 22, train_loss: 0.017940330359598865\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 22, valid_loss: 0.018752697648273572\n",
      "SEED: 1513, FOLD: 1, EPOCH: 23, train_loss: 0.01779866782759411\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 23, valid_loss: 0.018748876328269642\n",
      "SEED: 1513, FOLD: 1, EPOCH: 24, train_loss: 0.017768002938533176\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 24, valid_loss: 0.018744610353476472\n",
      "SEED: 1513, FOLD: 2, EPOCH: 0, train_loss: 0.7176371018091837\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 0, valid_loss: 0.636731763680776\n",
      "SEED: 1513, FOLD: 2, EPOCH: 1, train_loss: 0.26211555056489894\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 1, valid_loss: 0.030528595567577414\n",
      "SEED: 1513, FOLD: 2, EPOCH: 2, train_loss: 0.024769726735742195\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 2, valid_loss: 0.021663575019273493\n",
      "SEED: 1513, FOLD: 2, EPOCH: 3, train_loss: 0.02116884485535\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 3, valid_loss: 0.020225557705594435\n",
      "SEED: 1513, FOLD: 2, EPOCH: 4, train_loss: 0.020460016539563305\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 4, valid_loss: 0.020058733514613576\n",
      "SEED: 1513, FOLD: 2, EPOCH: 5, train_loss: 0.019962312437701916\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01998652383271191\n",
      "SEED: 1513, FOLD: 2, EPOCH: 6, train_loss: 0.019640916715497555\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01941219727612204\n",
      "SEED: 1513, FOLD: 2, EPOCH: 7, train_loss: 0.019399027812524117\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 7, valid_loss: 0.019351712634993926\n",
      "SEED: 1513, FOLD: 2, EPOCH: 8, train_loss: 0.019327673251214234\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 8, valid_loss: 0.0194130577147007\n",
      "SEED: 1513, FOLD: 2, EPOCH: 9, train_loss: 0.019295240900870682\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 9, valid_loss: 0.019288501081367333\n",
      "SEED: 1513, FOLD: 2, EPOCH: 10, train_loss: 0.019225681065649227\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 10, valid_loss: 0.019411261296934552\n",
      "SEED: 1513, FOLD: 2, EPOCH: 11, train_loss: 0.019233572742213375\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 11, valid_loss: 0.0192878365309702\n",
      "SEED: 1513, FOLD: 2, EPOCH: 12, train_loss: 0.019251206295861713\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01931657124724653\n",
      "SEED: 1513, FOLD: 2, EPOCH: 13, train_loss: 0.019160522930863975\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 13, valid_loss: 0.019233564742737345\n",
      "SEED: 1513, FOLD: 2, EPOCH: 14, train_loss: 0.01911322472859984\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 14, valid_loss: 0.019174137566652562\n",
      "SEED: 1513, FOLD: 2, EPOCH: 15, train_loss: 0.019034179008525352\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 15, valid_loss: 0.019079899104932945\n",
      "SEED: 1513, FOLD: 2, EPOCH: 16, train_loss: 0.018900919246716774\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 16, valid_loss: 0.019099552494784195\n",
      "SEED: 1513, FOLD: 2, EPOCH: 17, train_loss: 0.01880641046749509\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 17, valid_loss: 0.019011924353738625\n",
      "SEED: 1513, FOLD: 2, EPOCH: 18, train_loss: 0.018668203277216442\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 18, valid_loss: 0.018879675409860082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1513, FOLD: 2, EPOCH: 19, train_loss: 0.018485438429575035\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01881455464495553\n",
      "SEED: 1513, FOLD: 2, EPOCH: 20, train_loss: 0.018311332047417545\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01876267169912656\n",
      "SEED: 1513, FOLD: 2, EPOCH: 21, train_loss: 0.018134920898339024\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 21, valid_loss: 0.018702793038553663\n",
      "SEED: 1513, FOLD: 2, EPOCH: 22, train_loss: 0.017979617433055588\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01868340962876876\n",
      "SEED: 1513, FOLD: 2, EPOCH: 23, train_loss: 0.01786795636450035\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01865694599433078\n",
      "SEED: 1513, FOLD: 2, EPOCH: 24, train_loss: 0.017796520413695904\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01865293075227075\n",
      "SEED: 1513, FOLD: 3, EPOCH: 0, train_loss: 0.7181667210399241\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 0, valid_loss: 0.632506572537952\n",
      "SEED: 1513, FOLD: 3, EPOCH: 1, train_loss: 0.2637901277537795\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 1, valid_loss: 0.03011868190434244\n",
      "SEED: 1513, FOLD: 3, EPOCH: 2, train_loss: 0.024673072189308594\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 2, valid_loss: 0.021353011433449056\n",
      "SEED: 1513, FOLD: 3, EPOCH: 3, train_loss: 0.02117072134886099\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 3, valid_loss: 0.020111862673527665\n",
      "SEED: 1513, FOLD: 3, EPOCH: 4, train_loss: 0.02036963100882544\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 4, valid_loss: 0.019908171974950366\n",
      "SEED: 1513, FOLD: 3, EPOCH: 5, train_loss: 0.019935862039742264\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 5, valid_loss: 0.019578082693947688\n",
      "SEED: 1513, FOLD: 3, EPOCH: 6, train_loss: 0.01955491633734841\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 6, valid_loss: 0.019428965428637132\n",
      "SEED: 1513, FOLD: 3, EPOCH: 7, train_loss: 0.019375930310807365\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 7, valid_loss: 0.019378582015633583\n",
      "SEED: 1513, FOLD: 3, EPOCH: 8, train_loss: 0.0193467457657275\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01949277716792292\n",
      "SEED: 1513, FOLD: 3, EPOCH: 9, train_loss: 0.01924339287738869\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 9, valid_loss: 0.019262012508180406\n",
      "SEED: 1513, FOLD: 3, EPOCH: 10, train_loss: 0.019185316735419674\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01929477643635538\n",
      "SEED: 1513, FOLD: 3, EPOCH: 11, train_loss: 0.01917451760475186\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01925255378915204\n",
      "SEED: 1513, FOLD: 3, EPOCH: 12, train_loss: 0.01917998900340087\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01920215826895502\n",
      "SEED: 1513, FOLD: 3, EPOCH: 13, train_loss: 0.01910550314663113\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 13, valid_loss: 0.019060792504913278\n",
      "SEED: 1513, FOLD: 3, EPOCH: 14, train_loss: 0.018990081694463024\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 14, valid_loss: 0.019133818853232596\n",
      "SEED: 1513, FOLD: 3, EPOCH: 15, train_loss: 0.01897477763502494\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 15, valid_loss: 0.019001007080078125\n",
      "SEED: 1513, FOLD: 3, EPOCH: 16, train_loss: 0.01884469433107238\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 16, valid_loss: 0.018968924983508058\n",
      "SEED: 1513, FOLD: 3, EPOCH: 17, train_loss: 0.01873351377097593\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 17, valid_loss: 0.018834805116057396\n",
      "SEED: 1513, FOLD: 3, EPOCH: 18, train_loss: 0.018594991766672203\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 18, valid_loss: 0.01880663250469499\n",
      "SEED: 1513, FOLD: 3, EPOCH: 19, train_loss: 0.01839741635257783\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 19, valid_loss: 0.018758034747507837\n",
      "SEED: 1513, FOLD: 3, EPOCH: 20, train_loss: 0.01824709292555201\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 20, valid_loss: 0.01870411613749133\n",
      "SEED: 1513, FOLD: 3, EPOCH: 21, train_loss: 0.01805484554041987\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 21, valid_loss: 0.018612131890323427\n",
      "SEED: 1513, FOLD: 3, EPOCH: 22, train_loss: 0.0179045717569365\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 22, valid_loss: 0.018624995835125446\n",
      "SEED: 1513, FOLD: 3, EPOCH: 23, train_loss: 0.01776947388830392\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01860429724264476\n",
      "SEED: 1513, FOLD: 3, EPOCH: 24, train_loss: 0.017745305446610935\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01860487207563387\n",
      "SEED: 1513, FOLD: 4, EPOCH: 0, train_loss: 0.7181982251181118\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6374981469578214\n",
      "SEED: 1513, FOLD: 4, EPOCH: 1, train_loss: 0.26346643798161246\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 1, valid_loss: 0.03087544606791602\n",
      "SEED: 1513, FOLD: 4, EPOCH: 2, train_loss: 0.024839941763143608\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 2, valid_loss: 0.022105105117791228\n",
      "SEED: 1513, FOLD: 4, EPOCH: 3, train_loss: 0.021264703593392303\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 3, valid_loss: 0.020596081908378337\n",
      "SEED: 1513, FOLD: 4, EPOCH: 4, train_loss: 0.02040348420648471\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 4, valid_loss: 0.02044762060460117\n",
      "SEED: 1513, FOLD: 4, EPOCH: 5, train_loss: 0.01998387123255626\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 5, valid_loss: 0.019848117087450292\n",
      "SEED: 1513, FOLD: 4, EPOCH: 6, train_loss: 0.019591389493881794\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01958530665271812\n",
      "SEED: 1513, FOLD: 4, EPOCH: 7, train_loss: 0.01940566614486169\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 7, valid_loss: 0.019637293078833155\n",
      "SEED: 1513, FOLD: 4, EPOCH: 8, train_loss: 0.019335050837717194\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 8, valid_loss: 0.019435436878767278\n",
      "SEED: 1513, FOLD: 4, EPOCH: 9, train_loss: 0.019279942213409187\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01948461288379298\n",
      "SEED: 1513, FOLD: 4, EPOCH: 10, train_loss: 0.019221260954720387\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01945558252433936\n",
      "SEED: 1513, FOLD: 4, EPOCH: 11, train_loss: 0.019191165873105976\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 11, valid_loss: 0.019381780073874526\n",
      "SEED: 1513, FOLD: 4, EPOCH: 12, train_loss: 0.01918667981374091\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 12, valid_loss: 0.019333983461062115\n",
      "SEED: 1513, FOLD: 4, EPOCH: 13, train_loss: 0.019122391561235207\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01933006662875414\n",
      "SEED: 1513, FOLD: 4, EPOCH: 14, train_loss: 0.019028888799358105\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 14, valid_loss: 0.019285864817599457\n",
      "SEED: 1513, FOLD: 4, EPOCH: 15, train_loss: 0.01897927389844604\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 15, valid_loss: 0.019251154632204108\n",
      "SEED: 1513, FOLD: 4, EPOCH: 16, train_loss: 0.018922028550203297\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 16, valid_loss: 0.019167159994443256\n",
      "SEED: 1513, FOLD: 4, EPOCH: 17, train_loss: 0.018795440486375836\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01915782741788361\n",
      "SEED: 1513, FOLD: 4, EPOCH: 18, train_loss: 0.01864605148633321\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01900004440297683\n",
      "SEED: 1513, FOLD: 4, EPOCH: 19, train_loss: 0.018421961912426395\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 19, valid_loss: 0.018923122435808182\n",
      "SEED: 1513, FOLD: 4, EPOCH: 20, train_loss: 0.018263298451252605\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 20, valid_loss: 0.018866230319771502\n",
      "SEED: 1513, FOLD: 4, EPOCH: 21, train_loss: 0.018070823661443115\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01879781184511052\n",
      "SEED: 1513, FOLD: 4, EPOCH: 22, train_loss: 0.01792983618983324\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01876747618532843\n",
      "SEED: 1513, FOLD: 4, EPOCH: 23, train_loss: 0.017795055537768032\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01876921175668637\n",
      "SEED: 1513, FOLD: 4, EPOCH: 24, train_loss: 0.01774024555756562\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01876247374133931\n",
      "elapsed time: 133.47284722328186\n",
      "SEED: 1269, FOLD: 0, EPOCH: 0, train_loss: 0.7208291266275488\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6342989504337311\n",
      "SEED: 1269, FOLD: 0, EPOCH: 1, train_loss: 0.26280165193737415\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 1, valid_loss: 0.03023422271427181\n",
      "SEED: 1269, FOLD: 0, EPOCH: 2, train_loss: 0.02489910066883633\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 2, valid_loss: 0.021634563596712217\n",
      "SEED: 1269, FOLD: 0, EPOCH: 3, train_loss: 0.02120429177539072\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 3, valid_loss: 0.020480361560152635\n",
      "SEED: 1269, FOLD: 0, EPOCH: 4, train_loss: 0.020485519418034\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 4, valid_loss: 0.019955548043880198\n",
      "SEED: 1269, FOLD: 0, EPOCH: 5, train_loss: 0.019979499415427013\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 5, valid_loss: 0.019591200061970286\n",
      "SEED: 1269, FOLD: 0, EPOCH: 6, train_loss: 0.01959181385303753\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 6, valid_loss: 0.019571988739901118\n",
      "SEED: 1269, FOLD: 0, EPOCH: 7, train_loss: 0.01950488968387894\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 7, valid_loss: 0.019450429930455156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1269, FOLD: 0, EPOCH: 8, train_loss: 0.01929672677879748\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 8, valid_loss: 0.019351669897635777\n",
      "SEED: 1269, FOLD: 0, EPOCH: 9, train_loss: 0.019194220584155857\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01921900806741582\n",
      "SEED: 1269, FOLD: 0, EPOCH: 10, train_loss: 0.019187275671224663\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01942023283077611\n",
      "SEED: 1269, FOLD: 0, EPOCH: 11, train_loss: 0.019160444213860275\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 11, valid_loss: 0.019336542735497158\n",
      "SEED: 1269, FOLD: 0, EPOCH: 12, train_loss: 0.019149161389340526\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 12, valid_loss: 0.019354186434712674\n",
      "SEED: 1269, FOLD: 0, EPOCH: 13, train_loss: 0.019106623433206394\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01918785274028778\n",
      "SEED: 1269, FOLD: 0, EPOCH: 14, train_loss: 0.019026904191443886\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 14, valid_loss: 0.019259562198486593\n",
      "SEED: 1269, FOLD: 0, EPOCH: 15, train_loss: 0.018917792868139088\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 15, valid_loss: 0.019117911346256733\n",
      "SEED: 1269, FOLD: 0, EPOCH: 16, train_loss: 0.018821687883009083\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01914776333918174\n",
      "SEED: 1269, FOLD: 0, EPOCH: 17, train_loss: 0.018720756622328274\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01903862226754427\n",
      "SEED: 1269, FOLD: 0, EPOCH: 18, train_loss: 0.01858039929167084\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 18, valid_loss: 0.018964149471786287\n",
      "SEED: 1269, FOLD: 0, EPOCH: 19, train_loss: 0.01840274861973265\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 19, valid_loss: 0.018865307482580345\n",
      "SEED: 1269, FOLD: 0, EPOCH: 20, train_loss: 0.01820514162165531\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 20, valid_loss: 0.018855718585352104\n",
      "SEED: 1269, FOLD: 0, EPOCH: 21, train_loss: 0.01804572033385436\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01876762757698695\n",
      "SEED: 1269, FOLD: 0, EPOCH: 22, train_loss: 0.017907668849912243\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 22, valid_loss: 0.018727530414859455\n",
      "SEED: 1269, FOLD: 0, EPOCH: 23, train_loss: 0.017775659840823948\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 23, valid_loss: 0.0187086985549993\n",
      "SEED: 1269, FOLD: 0, EPOCH: 24, train_loss: 0.01771657741156177\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 24, valid_loss: 0.018701516091823578\n",
      "SEED: 1269, FOLD: 1, EPOCH: 0, train_loss: 0.7208621329155521\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6358273890283372\n",
      "SEED: 1269, FOLD: 1, EPOCH: 1, train_loss: 0.26302934724135674\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 1, valid_loss: 0.030633190439807043\n",
      "SEED: 1269, FOLD: 1, EPOCH: 2, train_loss: 0.02480157291975574\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 2, valid_loss: 0.021672120524777308\n",
      "SEED: 1269, FOLD: 1, EPOCH: 3, train_loss: 0.02120594510241695\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 3, valid_loss: 0.02040984947234392\n",
      "SEED: 1269, FOLD: 1, EPOCH: 4, train_loss: 0.02044134670733542\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 4, valid_loss: 0.019907620425025623\n",
      "SEED: 1269, FOLD: 1, EPOCH: 5, train_loss: 0.01991838570414246\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 5, valid_loss: 0.019678635315762624\n",
      "SEED: 1269, FOLD: 1, EPOCH: 6, train_loss: 0.019527845975497494\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 6, valid_loss: 0.019419629954629473\n",
      "SEED: 1269, FOLD: 1, EPOCH: 7, train_loss: 0.019381985527233803\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 7, valid_loss: 0.019329932518303394\n",
      "SEED: 1269, FOLD: 1, EPOCH: 8, train_loss: 0.019313544925788174\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 8, valid_loss: 0.019302436668011878\n",
      "SEED: 1269, FOLD: 1, EPOCH: 9, train_loss: 0.019246005763610203\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01939016891022523\n",
      "SEED: 1269, FOLD: 1, EPOCH: 10, train_loss: 0.019224024229291557\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01949777950843175\n",
      "SEED: 1269, FOLD: 1, EPOCH: 11, train_loss: 0.019176817161665447\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 11, valid_loss: 0.019266857041252985\n",
      "SEED: 1269, FOLD: 1, EPOCH: 12, train_loss: 0.019153374395724655\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 12, valid_loss: 0.019189241238766246\n",
      "SEED: 1269, FOLD: 1, EPOCH: 13, train_loss: 0.019102773156718933\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01920391608857446\n",
      "SEED: 1269, FOLD: 1, EPOCH: 14, train_loss: 0.019041907258223797\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 14, valid_loss: 0.019226679371462926\n",
      "SEED: 1269, FOLD: 1, EPOCH: 15, train_loss: 0.018990543306521748\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 15, valid_loss: 0.019166950446863968\n",
      "SEED: 1269, FOLD: 1, EPOCH: 16, train_loss: 0.018841928491989773\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 16, valid_loss: 0.019033297585944336\n",
      "SEED: 1269, FOLD: 1, EPOCH: 17, train_loss: 0.0187367402503024\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 17, valid_loss: 0.019020939866701763\n",
      "SEED: 1269, FOLD: 1, EPOCH: 18, train_loss: 0.018570903472710346\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 18, valid_loss: 0.018918983534806304\n",
      "SEED: 1269, FOLD: 1, EPOCH: 19, train_loss: 0.018408506919724354\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 19, valid_loss: 0.018912154353327222\n",
      "SEED: 1269, FOLD: 1, EPOCH: 20, train_loss: 0.0182430661836828\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 20, valid_loss: 0.018788536286188498\n",
      "SEED: 1269, FOLD: 1, EPOCH: 21, train_loss: 0.018044588304516197\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01874965543134345\n",
      "SEED: 1269, FOLD: 1, EPOCH: 22, train_loss: 0.01789718461425408\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 22, valid_loss: 0.018698360667460494\n",
      "SEED: 1269, FOLD: 1, EPOCH: 23, train_loss: 0.017779190579186314\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 23, valid_loss: 0.018679895541734166\n",
      "SEED: 1269, FOLD: 1, EPOCH: 24, train_loss: 0.01771208762690641\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01868709735572338\n",
      "SEED: 1269, FOLD: 2, EPOCH: 0, train_loss: 0.720829054929208\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6366043620639377\n",
      "SEED: 1269, FOLD: 2, EPOCH: 1, train_loss: 0.2625872221221958\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 1, valid_loss: 0.030921294974784058\n",
      "SEED: 1269, FOLD: 2, EPOCH: 2, train_loss: 0.02505416047853836\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 2, valid_loss: 0.021751278183526464\n",
      "SEED: 1269, FOLD: 2, EPOCH: 3, train_loss: 0.021243676867174065\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 3, valid_loss: 0.020352359136773482\n",
      "SEED: 1269, FOLD: 2, EPOCH: 4, train_loss: 0.020544782010973362\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 4, valid_loss: 0.020662904613547854\n",
      "SEED: 1269, FOLD: 2, EPOCH: 5, train_loss: 0.02003075482080812\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01994059058941073\n",
      "SEED: 1269, FOLD: 2, EPOCH: 6, train_loss: 0.019692182162965553\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01974240266200569\n",
      "SEED: 1269, FOLD: 2, EPOCH: 7, train_loss: 0.0194855532946362\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 7, valid_loss: 0.019647342566814687\n",
      "SEED: 1269, FOLD: 2, EPOCH: 8, train_loss: 0.019329146171609562\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 8, valid_loss: 0.019601650018658903\n",
      "SEED: 1269, FOLD: 2, EPOCH: 9, train_loss: 0.019285722352240398\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 9, valid_loss: 0.019359206987751856\n",
      "SEED: 1269, FOLD: 2, EPOCH: 10, train_loss: 0.01923798955976963\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 10, valid_loss: 0.019285532231960032\n",
      "SEED: 1269, FOLD: 2, EPOCH: 11, train_loss: 0.019164746276278427\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 11, valid_loss: 0.019408821852670774\n",
      "SEED: 1269, FOLD: 2, EPOCH: 12, train_loss: 0.019209900924908943\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 12, valid_loss: 0.019205661283599004\n",
      "SEED: 1269, FOLD: 2, EPOCH: 13, train_loss: 0.019182151561413986\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 13, valid_loss: 0.019217347001863852\n",
      "SEED: 1269, FOLD: 2, EPOCH: 14, train_loss: 0.01908148147597693\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 14, valid_loss: 0.019254832321570978\n",
      "SEED: 1269, FOLD: 2, EPOCH: 15, train_loss: 0.018969808664658794\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01906335126194689\n",
      "SEED: 1269, FOLD: 2, EPOCH: 16, train_loss: 0.018873045139986534\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 16, valid_loss: 0.018960433184272714\n",
      "SEED: 1269, FOLD: 2, EPOCH: 17, train_loss: 0.018754468744863636\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 17, valid_loss: 0.018998192623257637\n",
      "SEED: 1269, FOLD: 2, EPOCH: 18, train_loss: 0.018590748256099396\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 18, valid_loss: 0.018902268985079393\n",
      "SEED: 1269, FOLD: 2, EPOCH: 19, train_loss: 0.01844993114903353\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 19, valid_loss: 0.018856707442965772\n",
      "SEED: 1269, FOLD: 2, EPOCH: 20, train_loss: 0.018286331435260567\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 20, valid_loss: 0.018731748478280172\n",
      "SEED: 1269, FOLD: 2, EPOCH: 21, train_loss: 0.01805879062284594\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 21, valid_loss: 0.018698842885593574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1269, FOLD: 2, EPOCH: 22, train_loss: 0.01793018566525501\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 22, valid_loss: 0.018672290878991287\n",
      "SEED: 1269, FOLD: 2, EPOCH: 23, train_loss: 0.017796212132426277\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 23, valid_loss: 0.018651734727124374\n",
      "SEED: 1269, FOLD: 2, EPOCH: 24, train_loss: 0.017732760558525722\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 24, valid_loss: 0.018659216351807117\n",
      "SEED: 1269, FOLD: 3, EPOCH: 0, train_loss: 0.7206153126730435\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6407128638691373\n",
      "SEED: 1269, FOLD: 3, EPOCH: 1, train_loss: 0.26238041964993963\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 1, valid_loss: 0.031742003849811025\n",
      "SEED: 1269, FOLD: 3, EPOCH: 2, train_loss: 0.025002557163437206\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 2, valid_loss: 0.021740789835651714\n",
      "SEED: 1269, FOLD: 3, EPOCH: 3, train_loss: 0.02125154103597869\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 3, valid_loss: 0.02020814859618743\n",
      "SEED: 1269, FOLD: 3, EPOCH: 4, train_loss: 0.02042561950351017\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 4, valid_loss: 0.019932758166558213\n",
      "SEED: 1269, FOLD: 3, EPOCH: 5, train_loss: 0.019894326078718987\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 5, valid_loss: 0.019515578945477802\n",
      "SEED: 1269, FOLD: 3, EPOCH: 6, train_loss: 0.019572403308921967\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01936050711406602\n",
      "SEED: 1269, FOLD: 3, EPOCH: 7, train_loss: 0.019403497378031414\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 7, valid_loss: 0.019350281813078456\n",
      "SEED: 1269, FOLD: 3, EPOCH: 8, train_loss: 0.01931566353617371\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 8, valid_loss: 0.019302753835088678\n",
      "SEED: 1269, FOLD: 3, EPOCH: 9, train_loss: 0.01927212369290815\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 9, valid_loss: 0.019264639251761966\n",
      "SEED: 1269, FOLD: 3, EPOCH: 10, train_loss: 0.01921112973081029\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 10, valid_loss: 0.019196061831381585\n",
      "SEED: 1269, FOLD: 3, EPOCH: 11, train_loss: 0.019200798313038937\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 11, valid_loss: 0.019174963235855103\n",
      "SEED: 1269, FOLD: 3, EPOCH: 12, train_loss: 0.01914888677065787\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 12, valid_loss: 0.019090927878601685\n",
      "SEED: 1269, FOLD: 3, EPOCH: 13, train_loss: 0.019114968650366947\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 13, valid_loss: 0.019150389772322442\n",
      "SEED: 1269, FOLD: 3, EPOCH: 14, train_loss: 0.01904615236149318\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 14, valid_loss: 0.019085347548955016\n",
      "SEED: 1269, FOLD: 3, EPOCH: 15, train_loss: 0.01895361277612223\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01904487402902709\n",
      "SEED: 1269, FOLD: 3, EPOCH: 16, train_loss: 0.018843102633305218\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 16, valid_loss: 0.018953950351311102\n",
      "SEED: 1269, FOLD: 3, EPOCH: 17, train_loss: 0.01874965375316316\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 17, valid_loss: 0.018910599458548758\n",
      "SEED: 1269, FOLD: 3, EPOCH: 18, train_loss: 0.018557146758488987\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 18, valid_loss: 0.01885895658698347\n",
      "SEED: 1269, FOLD: 3, EPOCH: 19, train_loss: 0.018409858795179836\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 19, valid_loss: 0.018780447646147676\n",
      "SEED: 1269, FOLD: 3, EPOCH: 20, train_loss: 0.018216269846627678\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 20, valid_loss: 0.018752318599985704\n",
      "SEED: 1269, FOLD: 3, EPOCH: 21, train_loss: 0.018055979594372322\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 21, valid_loss: 0.018668207960824173\n",
      "SEED: 1269, FOLD: 3, EPOCH: 22, train_loss: 0.017900471751024757\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 22, valid_loss: 0.018640110165708594\n",
      "SEED: 1269, FOLD: 3, EPOCH: 23, train_loss: 0.017763748036130615\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 23, valid_loss: 0.018628037224213283\n",
      "SEED: 1269, FOLD: 3, EPOCH: 24, train_loss: 0.01769316620260909\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 24, valid_loss: 0.018627672507945035\n",
      "SEED: 1269, FOLD: 4, EPOCH: 0, train_loss: 0.7208252315935881\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6318506134880914\n",
      "SEED: 1269, FOLD: 4, EPOCH: 1, train_loss: 0.26286125210100325\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 1, valid_loss: 0.031638554090427026\n",
      "SEED: 1269, FOLD: 4, EPOCH: 2, train_loss: 0.024867092569669087\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 2, valid_loss: 0.02213487256732252\n",
      "SEED: 1269, FOLD: 4, EPOCH: 3, train_loss: 0.021178791650395462\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 3, valid_loss: 0.020415604528453615\n",
      "SEED: 1269, FOLD: 4, EPOCH: 4, train_loss: 0.020397389091659283\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 4, valid_loss: 0.019900757508973282\n",
      "SEED: 1269, FOLD: 4, EPOCH: 5, train_loss: 0.019869526632238125\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01998024754640129\n",
      "SEED: 1269, FOLD: 4, EPOCH: 6, train_loss: 0.01955586248009965\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 6, valid_loss: 0.019478516032298405\n",
      "SEED: 1269, FOLD: 4, EPOCH: 7, train_loss: 0.01937851965751337\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01950588035914633\n",
      "SEED: 1269, FOLD: 4, EPOCH: 8, train_loss: 0.019256438844013905\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 8, valid_loss: 0.01960152584231562\n",
      "SEED: 1269, FOLD: 4, EPOCH: 9, train_loss: 0.019234717837062435\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01954981984777583\n",
      "SEED: 1269, FOLD: 4, EPOCH: 10, train_loss: 0.019189623009035553\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 10, valid_loss: 0.019444939369956653\n",
      "SEED: 1269, FOLD: 4, EPOCH: 11, train_loss: 0.019134906296064888\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01939510605815384\n",
      "SEED: 1269, FOLD: 4, EPOCH: 12, train_loss: 0.019125315347227497\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 12, valid_loss: 0.019400361511442397\n",
      "SEED: 1269, FOLD: 4, EPOCH: 13, train_loss: 0.01910610470002976\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01945895018676917\n",
      "SEED: 1269, FOLD: 4, EPOCH: 14, train_loss: 0.019052832589849182\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 14, valid_loss: 0.0191945293918252\n",
      "SEED: 1269, FOLD: 4, EPOCH: 15, train_loss: 0.018894331367767376\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 15, valid_loss: 0.019217823321620624\n",
      "SEED: 1269, FOLD: 4, EPOCH: 16, train_loss: 0.018860215294188347\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 16, valid_loss: 0.019152545784082677\n",
      "SEED: 1269, FOLD: 4, EPOCH: 17, train_loss: 0.01870966956451319\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 17, valid_loss: 0.019082022623883352\n",
      "SEED: 1269, FOLD: 4, EPOCH: 18, train_loss: 0.018579280516807583\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 18, valid_loss: 0.019026865458322897\n",
      "SEED: 1269, FOLD: 4, EPOCH: 19, train_loss: 0.01837180338907933\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 19, valid_loss: 0.018938455523716077\n",
      "SEED: 1269, FOLD: 4, EPOCH: 20, train_loss: 0.01820442223570485\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 20, valid_loss: 0.018886236059996817\n",
      "SEED: 1269, FOLD: 4, EPOCH: 21, train_loss: 0.018044436107511105\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 21, valid_loss: 0.018786642803914018\n",
      "SEED: 1269, FOLD: 4, EPOCH: 22, train_loss: 0.017864131463178688\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 22, valid_loss: 0.018768392503261566\n",
      "SEED: 1269, FOLD: 4, EPOCH: 23, train_loss: 0.0177496372303669\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01875909697264433\n",
      "SEED: 1269, FOLD: 4, EPOCH: 24, train_loss: 0.017691540153886097\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 24, valid_loss: 0.018745325609213777\n",
      "elapsed time: 199.5500955581665\n",
      "SEED: 1392, FOLD: 0, EPOCH: 0, train_loss: 0.7196257624073304\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6471514337592654\n",
      "SEED: 1392, FOLD: 0, EPOCH: 1, train_loss: 0.263082814929278\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 1, valid_loss: 0.031225503629280463\n",
      "SEED: 1392, FOLD: 0, EPOCH: 2, train_loss: 0.024970133910360542\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 2, valid_loss: 0.022033158068855602\n",
      "SEED: 1392, FOLD: 0, EPOCH: 3, train_loss: 0.021243967358832775\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 3, valid_loss: 0.020273234281275008\n",
      "SEED: 1392, FOLD: 0, EPOCH: 4, train_loss: 0.02045449968157471\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01976711530652311\n",
      "SEED: 1392, FOLD: 0, EPOCH: 5, train_loss: 0.01990057004318721\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 5, valid_loss: 0.019513521136509046\n",
      "SEED: 1392, FOLD: 0, EPOCH: 6, train_loss: 0.019608607299733852\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01949924220227533\n",
      "SEED: 1392, FOLD: 0, EPOCH: 7, train_loss: 0.01941463739975639\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 7, valid_loss: 0.019303472712635994\n",
      "SEED: 1392, FOLD: 0, EPOCH: 8, train_loss: 0.019277136124994442\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 8, valid_loss: 0.019445534588562116\n",
      "SEED: 1392, FOLD: 0, EPOCH: 9, train_loss: 0.01923484598164973\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 9, valid_loss: 0.019396188254985545\n",
      "SEED: 1392, FOLD: 0, EPOCH: 10, train_loss: 0.019219668663066368\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 10, valid_loss: 0.019348234869539738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1392, FOLD: 0, EPOCH: 11, train_loss: 0.019185428143195484\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 11, valid_loss: 0.019425188708636496\n",
      "SEED: 1392, FOLD: 0, EPOCH: 12, train_loss: 0.019117515507167664\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01923563289973471\n",
      "SEED: 1392, FOLD: 0, EPOCH: 13, train_loss: 0.01909494359532128\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01919711950338549\n",
      "SEED: 1392, FOLD: 0, EPOCH: 14, train_loss: 0.01905156944648943\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 14, valid_loss: 0.019208221489356622\n",
      "SEED: 1392, FOLD: 0, EPOCH: 15, train_loss: 0.01895094090613766\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 15, valid_loss: 0.019241492057012186\n",
      "SEED: 1392, FOLD: 0, EPOCH: 16, train_loss: 0.018854141208356705\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 16, valid_loss: 0.019056764638258353\n",
      "SEED: 1392, FOLD: 0, EPOCH: 17, train_loss: 0.018690567787574684\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 17, valid_loss: 0.019033711300128035\n",
      "SEED: 1392, FOLD: 0, EPOCH: 18, train_loss: 0.018593294977925827\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 18, valid_loss: 0.018950670543644164\n",
      "SEED: 1392, FOLD: 0, EPOCH: 19, train_loss: 0.01839995565081852\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 19, valid_loss: 0.018906858439246815\n",
      "SEED: 1392, FOLD: 0, EPOCH: 20, train_loss: 0.018212029521448025\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 20, valid_loss: 0.018797277472913265\n",
      "SEED: 1392, FOLD: 0, EPOCH: 21, train_loss: 0.018024996058016583\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 21, valid_loss: 0.018767113383445475\n",
      "SEED: 1392, FOLD: 0, EPOCH: 22, train_loss: 0.017890804069305676\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 22, valid_loss: 0.018742345687415864\n",
      "SEED: 1392, FOLD: 0, EPOCH: 23, train_loss: 0.017747143566932366\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01873726946198278\n",
      "SEED: 1392, FOLD: 0, EPOCH: 24, train_loss: 0.017703572018206982\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01873467903998163\n",
      "SEED: 1392, FOLD: 1, EPOCH: 0, train_loss: 0.7197133760521377\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6413597928153144\n",
      "SEED: 1392, FOLD: 1, EPOCH: 1, train_loss: 0.2629677835797918\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 1, valid_loss: 0.02962894541107946\n",
      "SEED: 1392, FOLD: 1, EPOCH: 2, train_loss: 0.024888333824017773\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 2, valid_loss: 0.021751157732473478\n",
      "SEED: 1392, FOLD: 1, EPOCH: 3, train_loss: 0.021241934700072674\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 3, valid_loss: 0.020604762248694897\n",
      "SEED: 1392, FOLD: 1, EPOCH: 4, train_loss: 0.020476431626340618\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01981645201643308\n",
      "SEED: 1392, FOLD: 1, EPOCH: 5, train_loss: 0.02004637566489586\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 5, valid_loss: 0.0195978589148985\n",
      "SEED: 1392, FOLD: 1, EPOCH: 6, train_loss: 0.01961820119101068\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 6, valid_loss: 0.019591869372460578\n",
      "SEED: 1392, FOLD: 1, EPOCH: 7, train_loss: 0.019421211700292602\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 7, valid_loss: 0.019435498863458633\n",
      "SEED: 1392, FOLD: 1, EPOCH: 8, train_loss: 0.019310845035141792\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 8, valid_loss: 0.019379150432844956\n",
      "SEED: 1392, FOLD: 1, EPOCH: 9, train_loss: 0.01926769000356612\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 9, valid_loss: 0.019356163425578013\n",
      "SEED: 1392, FOLD: 1, EPOCH: 10, train_loss: 0.019212914252842682\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01927761474831237\n",
      "SEED: 1392, FOLD: 1, EPOCH: 11, train_loss: 0.01923378583961639\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01944572271572219\n",
      "SEED: 1392, FOLD: 1, EPOCH: 12, train_loss: 0.019150206225289814\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 12, valid_loss: 0.019305450841784477\n",
      "SEED: 1392, FOLD: 1, EPOCH: 13, train_loss: 0.01913732233578744\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 13, valid_loss: 0.019222856913175847\n",
      "SEED: 1392, FOLD: 1, EPOCH: 14, train_loss: 0.019081282658853393\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 14, valid_loss: 0.019194427670703992\n",
      "SEED: 1392, FOLD: 1, EPOCH: 15, train_loss: 0.01893871534021868\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 15, valid_loss: 0.019146085716784\n",
      "SEED: 1392, FOLD: 1, EPOCH: 16, train_loss: 0.01883804792727249\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 16, valid_loss: 0.01904210603485505\n",
      "SEED: 1392, FOLD: 1, EPOCH: 17, train_loss: 0.018725690013472584\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01900776620540354\n",
      "SEED: 1392, FOLD: 1, EPOCH: 18, train_loss: 0.018599198132321453\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01890444445113341\n",
      "SEED: 1392, FOLD: 1, EPOCH: 19, train_loss: 0.018413604655559513\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 19, valid_loss: 0.018835156742069457\n",
      "SEED: 1392, FOLD: 1, EPOCH: 20, train_loss: 0.018237619890251022\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 20, valid_loss: 0.018815113748941157\n",
      "SEED: 1392, FOLD: 1, EPOCH: 21, train_loss: 0.018058617504826492\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01874234713613987\n",
      "SEED: 1392, FOLD: 1, EPOCH: 22, train_loss: 0.017881563635192055\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 22, valid_loss: 0.018733929739230208\n",
      "SEED: 1392, FOLD: 1, EPOCH: 23, train_loss: 0.017768678079912628\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 23, valid_loss: 0.018711963151064184\n",
      "SEED: 1392, FOLD: 1, EPOCH: 24, train_loss: 0.017745027426576267\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 24, valid_loss: 0.018721733035312757\n",
      "SEED: 1392, FOLD: 2, EPOCH: 0, train_loss: 0.7197692662045576\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6471370160579681\n",
      "SEED: 1392, FOLD: 2, EPOCH: 1, train_loss: 0.2640421061736086\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 1, valid_loss: 0.030742857191297743\n",
      "SEED: 1392, FOLD: 2, EPOCH: 2, train_loss: 0.025145631850413654\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 2, valid_loss: 0.02194389048963785\n",
      "SEED: 1392, FOLD: 2, EPOCH: 3, train_loss: 0.02132617690317009\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 3, valid_loss: 0.02034463422993819\n",
      "SEED: 1392, FOLD: 2, EPOCH: 4, train_loss: 0.020547554814729137\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01994551159441471\n",
      "SEED: 1392, FOLD: 2, EPOCH: 5, train_loss: 0.01999522386577682\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01961080926573939\n",
      "SEED: 1392, FOLD: 2, EPOCH: 6, train_loss: 0.01965918526917264\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 6, valid_loss: 0.019576665220989123\n",
      "SEED: 1392, FOLD: 2, EPOCH: 7, train_loss: 0.019441852238083233\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 7, valid_loss: 0.019468804717891745\n",
      "SEED: 1392, FOLD: 2, EPOCH: 8, train_loss: 0.019358453894222992\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 8, valid_loss: 0.019311197929912143\n",
      "SEED: 1392, FOLD: 2, EPOCH: 9, train_loss: 0.01932772662004699\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 9, valid_loss: 0.019439798055423632\n",
      "SEED: 1392, FOLD: 2, EPOCH: 10, train_loss: 0.019249175337777622\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01947392150759697\n",
      "SEED: 1392, FOLD: 2, EPOCH: 11, train_loss: 0.01923375838584658\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01925012810776631\n",
      "SEED: 1392, FOLD: 2, EPOCH: 12, train_loss: 0.019209415260432423\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01928168690452973\n",
      "SEED: 1392, FOLD: 2, EPOCH: 13, train_loss: 0.019158322553055874\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01924526443084081\n",
      "SEED: 1392, FOLD: 2, EPOCH: 14, train_loss: 0.01908884097592554\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01920716981920931\n",
      "SEED: 1392, FOLD: 2, EPOCH: 15, train_loss: 0.019008619089921314\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01910962164402008\n",
      "SEED: 1392, FOLD: 2, EPOCH: 16, train_loss: 0.01892086277729359\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 16, valid_loss: 0.018962546458674803\n",
      "SEED: 1392, FOLD: 2, EPOCH: 17, train_loss: 0.018768756393937096\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 17, valid_loss: 0.018975567693511646\n",
      "SEED: 1392, FOLD: 2, EPOCH: 18, train_loss: 0.018670492522094562\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 18, valid_loss: 0.018911780789494514\n",
      "SEED: 1392, FOLD: 2, EPOCH: 19, train_loss: 0.018514076787708462\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 19, valid_loss: 0.018849428018762007\n",
      "SEED: 1392, FOLD: 2, EPOCH: 20, train_loss: 0.01831516510118609\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01876506271461646\n",
      "SEED: 1392, FOLD: 2, EPOCH: 21, train_loss: 0.01812917887624623\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 21, valid_loss: 0.018713155450920265\n",
      "SEED: 1392, FOLD: 2, EPOCH: 22, train_loss: 0.01797837302412676\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 22, valid_loss: 0.018670474489529926\n",
      "SEED: 1392, FOLD: 2, EPOCH: 23, train_loss: 0.017867666736677074\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01865887279725737\n",
      "SEED: 1392, FOLD: 2, EPOCH: 24, train_loss: 0.017810670119048893\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 24, valid_loss: 0.018656602129340172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1392, FOLD: 3, EPOCH: 0, train_loss: 0.7197182023006937\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6392995350890689\n",
      "SEED: 1392, FOLD: 3, EPOCH: 1, train_loss: 0.26422847135235433\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 1, valid_loss: 0.030144351120624278\n",
      "SEED: 1392, FOLD: 3, EPOCH: 2, train_loss: 0.024936743566523426\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 2, valid_loss: 0.02185430729554759\n",
      "SEED: 1392, FOLD: 3, EPOCH: 3, train_loss: 0.02127879485487938\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 3, valid_loss: 0.020196364778611395\n",
      "SEED: 1392, FOLD: 3, EPOCH: 4, train_loss: 0.020526168948930244\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 4, valid_loss: 0.019783337083127763\n",
      "SEED: 1392, FOLD: 3, EPOCH: 5, train_loss: 0.019968282296389774\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 5, valid_loss: 0.019704107609060075\n",
      "SEED: 1392, FOLD: 3, EPOCH: 6, train_loss: 0.019691256320346958\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01934542755285899\n",
      "SEED: 1392, FOLD: 3, EPOCH: 7, train_loss: 0.01938487211431282\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01934140134188864\n",
      "SEED: 1392, FOLD: 3, EPOCH: 8, train_loss: 0.019325365460869194\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 8, valid_loss: 0.019417492983241875\n",
      "SEED: 1392, FOLD: 3, EPOCH: 9, train_loss: 0.01930508476452551\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01929900184687641\n",
      "SEED: 1392, FOLD: 3, EPOCH: 10, train_loss: 0.019244097686116245\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 10, valid_loss: 0.019272853413389787\n",
      "SEED: 1392, FOLD: 3, EPOCH: 11, train_loss: 0.01922321330378021\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 11, valid_loss: 0.019236731342971325\n",
      "SEED: 1392, FOLD: 3, EPOCH: 12, train_loss: 0.019121614703233692\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 12, valid_loss: 0.019233246540857687\n",
      "SEED: 1392, FOLD: 3, EPOCH: 13, train_loss: 0.019095345521750656\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01905873552378681\n",
      "SEED: 1392, FOLD: 3, EPOCH: 14, train_loss: 0.019044266527761585\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 14, valid_loss: 0.019106142222881317\n",
      "SEED: 1392, FOLD: 3, EPOCH: 15, train_loss: 0.01901111090420813\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 15, valid_loss: 0.019018112474845514\n",
      "SEED: 1392, FOLD: 3, EPOCH: 16, train_loss: 0.01884809184981429\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01893795933574438\n",
      "SEED: 1392, FOLD: 3, EPOCH: 17, train_loss: 0.018716768186161484\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 17, valid_loss: 0.018907040564550295\n",
      "SEED: 1392, FOLD: 3, EPOCH: 18, train_loss: 0.018594298214800117\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 18, valid_loss: 0.018864933504826494\n",
      "SEED: 1392, FOLD: 3, EPOCH: 19, train_loss: 0.018405777631678444\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01879161109940873\n",
      "SEED: 1392, FOLD: 3, EPOCH: 20, train_loss: 0.018261251971125603\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 20, valid_loss: 0.01869449122912354\n",
      "SEED: 1392, FOLD: 3, EPOCH: 21, train_loss: 0.018059385886442833\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 21, valid_loss: 0.018632931531303458\n",
      "SEED: 1392, FOLD: 3, EPOCH: 22, train_loss: 0.017891833018781483\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01862388973434766\n",
      "SEED: 1392, FOLD: 3, EPOCH: 23, train_loss: 0.01777396499570729\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 23, valid_loss: 0.018609433227943048\n",
      "SEED: 1392, FOLD: 3, EPOCH: 24, train_loss: 0.017694745239788208\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 24, valid_loss: 0.018607034347951412\n",
      "SEED: 1392, FOLD: 4, EPOCH: 0, train_loss: 0.719588475814764\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6429340806272295\n",
      "SEED: 1392, FOLD: 4, EPOCH: 1, train_loss: 0.2633068834202013\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 1, valid_loss: 0.031012582282225292\n",
      "SEED: 1392, FOLD: 4, EPOCH: 2, train_loss: 0.025018019844656406\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 2, valid_loss: 0.022281626963780984\n",
      "SEED: 1392, FOLD: 4, EPOCH: 3, train_loss: 0.021301791179871212\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 3, valid_loss: 0.02094991670714484\n",
      "SEED: 1392, FOLD: 4, EPOCH: 4, train_loss: 0.020521551289636154\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 4, valid_loss: 0.02026461313168208\n",
      "SEED: 1392, FOLD: 4, EPOCH: 5, train_loss: 0.019950760123522385\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 5, valid_loss: 0.019746345053944323\n",
      "SEED: 1392, FOLD: 4, EPOCH: 6, train_loss: 0.019637457324542862\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 6, valid_loss: 0.019717207902835474\n",
      "SEED: 1392, FOLD: 4, EPOCH: 7, train_loss: 0.019455946280040604\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01952915235112111\n",
      "SEED: 1392, FOLD: 4, EPOCH: 8, train_loss: 0.019295271836977074\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 8, valid_loss: 0.019564336062305503\n",
      "SEED: 1392, FOLD: 4, EPOCH: 9, train_loss: 0.019269620972699013\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 9, valid_loss: 0.020192148370875254\n",
      "SEED: 1392, FOLD: 4, EPOCH: 10, train_loss: 0.019237520254176597\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01939267013221979\n",
      "SEED: 1392, FOLD: 4, EPOCH: 11, train_loss: 0.01920762965860574\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01939447731193569\n",
      "SEED: 1392, FOLD: 4, EPOCH: 12, train_loss: 0.01909420018394788\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 12, valid_loss: 0.019379957165155146\n",
      "SEED: 1392, FOLD: 4, EPOCH: 13, train_loss: 0.01910307047807652\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 13, valid_loss: 0.019294561818242073\n",
      "SEED: 1392, FOLD: 4, EPOCH: 14, train_loss: 0.01900020735743253\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01926823788219028\n",
      "SEED: 1392, FOLD: 4, EPOCH: 15, train_loss: 0.018943066236333572\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 15, valid_loss: 0.019220961671736505\n",
      "SEED: 1392, FOLD: 4, EPOCH: 16, train_loss: 0.018841792464904163\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 16, valid_loss: 0.019263420874873798\n",
      "SEED: 1392, FOLD: 4, EPOCH: 17, train_loss: 0.018705410045990044\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01908847513712115\n",
      "SEED: 1392, FOLD: 4, EPOCH: 18, train_loss: 0.018600229470842125\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 18, valid_loss: 0.019023746045099363\n",
      "SEED: 1392, FOLD: 4, EPOCH: 19, train_loss: 0.018385613526123157\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01888754591345787\n",
      "SEED: 1392, FOLD: 4, EPOCH: 20, train_loss: 0.01818279633163542\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 20, valid_loss: 0.018847093503508303\n",
      "SEED: 1392, FOLD: 4, EPOCH: 21, train_loss: 0.018042141220707825\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 21, valid_loss: 0.018785194907751348\n",
      "SEED: 1392, FOLD: 4, EPOCH: 22, train_loss: 0.01787262623184833\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 22, valid_loss: 0.018726382094124954\n",
      "SEED: 1392, FOLD: 4, EPOCH: 23, train_loss: 0.017745062681859818\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 23, valid_loss: 0.018716494345830545\n",
      "SEED: 1392, FOLD: 4, EPOCH: 24, train_loss: 0.01769093982875347\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01871485056148635\n",
      "elapsed time: 265.96126341819763\n",
      "SEED: 1119, FOLD: 0, EPOCH: 0, train_loss: 0.7190721510113149\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6420382029480405\n",
      "SEED: 1119, FOLD: 0, EPOCH: 1, train_loss: 0.26566824581528053\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 1, valid_loss: 0.030330374836921692\n",
      "SEED: 1119, FOLD: 0, EPOCH: 2, train_loss: 0.02477595407137836\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 2, valid_loss: 0.021669882349669933\n",
      "SEED: 1119, FOLD: 0, EPOCH: 3, train_loss: 0.02112472753809846\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 3, valid_loss: 0.02031106222420931\n",
      "SEED: 1119, FOLD: 0, EPOCH: 4, train_loss: 0.02044778576363688\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 4, valid_loss: 0.019889046334558062\n",
      "SEED: 1119, FOLD: 0, EPOCH: 5, train_loss: 0.019914042690525883\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 5, valid_loss: 0.019685950130224228\n",
      "SEED: 1119, FOLD: 0, EPOCH: 6, train_loss: 0.01954535967197971\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 6, valid_loss: 0.019555623332659405\n",
      "SEED: 1119, FOLD: 0, EPOCH: 7, train_loss: 0.01940875036129053\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01951265593783723\n",
      "SEED: 1119, FOLD: 0, EPOCH: 8, train_loss: 0.019254992891480957\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 8, valid_loss: 0.019468595273792744\n",
      "SEED: 1119, FOLD: 0, EPOCH: 9, train_loss: 0.019287371063146038\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01940656950076421\n",
      "SEED: 1119, FOLD: 0, EPOCH: 10, train_loss: 0.01920305081791636\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 10, valid_loss: 0.019359332612819143\n",
      "SEED: 1119, FOLD: 0, EPOCH: 11, train_loss: 0.019187081524211426\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01921390586843093\n",
      "SEED: 1119, FOLD: 0, EPOCH: 12, train_loss: 0.019171050925185715\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 12, valid_loss: 0.019258862361311913\n",
      "SEED: 1119, FOLD: 0, EPOCH: 13, train_loss: 0.019094943757290424\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01919564397798644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1119, FOLD: 0, EPOCH: 14, train_loss: 0.01902765907563161\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 14, valid_loss: 0.019311419791645475\n",
      "SEED: 1119, FOLD: 0, EPOCH: 15, train_loss: 0.018961713203917378\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 15, valid_loss: 0.019139828470846016\n",
      "SEED: 1119, FOLD: 0, EPOCH: 16, train_loss: 0.018824595337112743\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 16, valid_loss: 0.019017116373611823\n",
      "SEED: 1119, FOLD: 0, EPOCH: 17, train_loss: 0.01871909660057745\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 17, valid_loss: 0.018945430715878803\n",
      "SEED: 1119, FOLD: 0, EPOCH: 18, train_loss: 0.018545195946226948\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 18, valid_loss: 0.018942948948178027\n",
      "SEED: 1119, FOLD: 0, EPOCH: 19, train_loss: 0.018417938787868057\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 19, valid_loss: 0.018867167230281565\n",
      "SEED: 1119, FOLD: 0, EPOCH: 20, train_loss: 0.018219036684520004\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 20, valid_loss: 0.018851352027720876\n",
      "SEED: 1119, FOLD: 0, EPOCH: 21, train_loss: 0.018017235981381458\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 21, valid_loss: 0.018752690197692976\n",
      "SEED: 1119, FOLD: 0, EPOCH: 22, train_loss: 0.01786718112619027\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 22, valid_loss: 0.018729402373234432\n",
      "SEED: 1119, FOLD: 0, EPOCH: 23, train_loss: 0.017743263852553093\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01871593917409579\n",
      "SEED: 1119, FOLD: 0, EPOCH: 24, train_loss: 0.01770569919945969\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 24, valid_loss: 0.018721695471968915\n",
      "SEED: 1119, FOLD: 1, EPOCH: 0, train_loss: 0.7188707529634669\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 0, valid_loss: 0.6298102703359392\n",
      "SEED: 1119, FOLD: 1, EPOCH: 1, train_loss: 0.2636388289755669\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 1, valid_loss: 0.03082852220783631\n",
      "SEED: 1119, FOLD: 1, EPOCH: 2, train_loss: 0.024821743774025337\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 2, valid_loss: 0.02179157951225837\n",
      "SEED: 1119, FOLD: 1, EPOCH: 3, train_loss: 0.021178333196735035\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 3, valid_loss: 0.02038724347949028\n",
      "SEED: 1119, FOLD: 1, EPOCH: 4, train_loss: 0.020412441720997078\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01998069054550595\n",
      "SEED: 1119, FOLD: 1, EPOCH: 5, train_loss: 0.019942922247708706\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 5, valid_loss: 0.01957282465365198\n",
      "SEED: 1119, FOLD: 1, EPOCH: 6, train_loss: 0.019648511448632115\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 6, valid_loss: 0.019427216404842004\n",
      "SEED: 1119, FOLD: 1, EPOCH: 7, train_loss: 0.01937987528525401\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01933883647951815\n",
      "SEED: 1119, FOLD: 1, EPOCH: 8, train_loss: 0.019257680715426155\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01930750399414036\n",
      "SEED: 1119, FOLD: 1, EPOCH: 9, train_loss: 0.019197212640142094\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01940960343927145\n",
      "SEED: 1119, FOLD: 1, EPOCH: 10, train_loss: 0.019221591155814087\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01929445844143629\n",
      "SEED: 1119, FOLD: 1, EPOCH: 11, train_loss: 0.019176211828986805\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 11, valid_loss: 0.019295804099076323\n",
      "SEED: 1119, FOLD: 1, EPOCH: 12, train_loss: 0.019135068670131157\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 12, valid_loss: 0.019254964362416003\n",
      "SEED: 1119, FOLD: 1, EPOCH: 13, train_loss: 0.019064582884311676\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01918501282731692\n",
      "SEED: 1119, FOLD: 1, EPOCH: 14, train_loss: 0.019047946223746174\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 14, valid_loss: 0.019187805760237906\n",
      "SEED: 1119, FOLD: 1, EPOCH: 15, train_loss: 0.01895367022117843\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 15, valid_loss: 0.019165871768361993\n",
      "SEED: 1119, FOLD: 1, EPOCH: 16, train_loss: 0.01887109117123528\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 16, valid_loss: 0.019086101092398167\n",
      "SEED: 1119, FOLD: 1, EPOCH: 17, train_loss: 0.018703535496108772\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 17, valid_loss: 0.019013906104697123\n",
      "SEED: 1119, FOLD: 1, EPOCH: 18, train_loss: 0.018554129867234093\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01892891153693199\n",
      "SEED: 1119, FOLD: 1, EPOCH: 19, train_loss: 0.01844338565200999\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 19, valid_loss: 0.018841174638105765\n",
      "SEED: 1119, FOLD: 1, EPOCH: 20, train_loss: 0.018218565570271534\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 20, valid_loss: 0.018802955850130983\n",
      "SEED: 1119, FOLD: 1, EPOCH: 21, train_loss: 0.01805397525321746\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 21, valid_loss: 0.018754300971825916\n",
      "SEED: 1119, FOLD: 1, EPOCH: 22, train_loss: 0.01789864247151907\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 22, valid_loss: 0.01868845522403717\n",
      "SEED: 1119, FOLD: 1, EPOCH: 23, train_loss: 0.017775805613053017\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 23, valid_loss: 0.0186885478388932\n",
      "SEED: 1119, FOLD: 1, EPOCH: 24, train_loss: 0.017713390425711437\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 24, valid_loss: 0.018692451322244272\n",
      "SEED: 1119, FOLD: 2, EPOCH: 0, train_loss: 0.7191375934559366\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6334641608926985\n",
      "SEED: 1119, FOLD: 2, EPOCH: 1, train_loss: 0.2638952226742454\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 1, valid_loss: 0.030208381203313667\n",
      "SEED: 1119, FOLD: 2, EPOCH: 2, train_loss: 0.024799319200109745\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 2, valid_loss: 0.02147043827507231\n",
      "SEED: 1119, FOLD: 2, EPOCH: 3, train_loss: 0.02112291369965111\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 3, valid_loss: 0.02024584139386813\n",
      "SEED: 1119, FOLD: 2, EPOCH: 4, train_loss: 0.02047509756749091\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 4, valid_loss: 0.020025952926112547\n",
      "SEED: 1119, FOLD: 2, EPOCH: 5, train_loss: 0.019932583676300186\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 5, valid_loss: 0.019486301061179902\n",
      "SEED: 1119, FOLD: 2, EPOCH: 6, train_loss: 0.019549534966548283\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01951028189311425\n",
      "SEED: 1119, FOLD: 2, EPOCH: 7, train_loss: 0.01943567562578381\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 7, valid_loss: 0.019590794212288327\n",
      "SEED: 1119, FOLD: 2, EPOCH: 8, train_loss: 0.01937087220342263\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 8, valid_loss: 0.019252667720947\n",
      "SEED: 1119, FOLD: 2, EPOCH: 9, train_loss: 0.019270978787023087\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01935238836126195\n",
      "SEED: 1119, FOLD: 2, EPOCH: 10, train_loss: 0.019240158947481625\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 10, valid_loss: 0.019152274251812033\n",
      "SEED: 1119, FOLD: 2, EPOCH: 11, train_loss: 0.01917507059440233\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01932421616382069\n",
      "SEED: 1119, FOLD: 2, EPOCH: 12, train_loss: 0.019169703206938248\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01926586249222358\n",
      "SEED: 1119, FOLD: 2, EPOCH: 13, train_loss: 0.019161717048373775\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01918963073856301\n",
      "SEED: 1119, FOLD: 2, EPOCH: 14, train_loss: 0.019050546503369358\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 14, valid_loss: 0.019171571876439784\n",
      "SEED: 1119, FOLD: 2, EPOCH: 15, train_loss: 0.01897996402197126\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 15, valid_loss: 0.019104619303511247\n",
      "SEED: 1119, FOLD: 2, EPOCH: 16, train_loss: 0.01889392523014027\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01904642902728584\n",
      "SEED: 1119, FOLD: 2, EPOCH: 17, train_loss: 0.018740450315501377\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01891277606288592\n",
      "SEED: 1119, FOLD: 2, EPOCH: 18, train_loss: 0.018608923326583877\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01897834696703487\n",
      "SEED: 1119, FOLD: 2, EPOCH: 19, train_loss: 0.01843513802125834\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 19, valid_loss: 0.018797095244129498\n",
      "SEED: 1119, FOLD: 2, EPOCH: 20, train_loss: 0.01824676113176173\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01877070849554406\n",
      "SEED: 1119, FOLD: 2, EPOCH: 21, train_loss: 0.018093915440250134\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 21, valid_loss: 0.018679696031742625\n",
      "SEED: 1119, FOLD: 2, EPOCH: 22, train_loss: 0.017925955085218815\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 22, valid_loss: 0.018665696183840435\n",
      "SEED: 1119, FOLD: 2, EPOCH: 23, train_loss: 0.017812706449109574\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 23, valid_loss: 0.018648699650333986\n",
      "SEED: 1119, FOLD: 2, EPOCH: 24, train_loss: 0.017774219476226448\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 24, valid_loss: 0.018657808088594012\n",
      "SEED: 1119, FOLD: 3, EPOCH: 0, train_loss: 0.7191605395165043\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6404105259312524\n",
      "SEED: 1119, FOLD: 3, EPOCH: 1, train_loss: 0.26567059582558233\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 1, valid_loss: 0.029020655589799087\n",
      "SEED: 1119, FOLD: 3, EPOCH: 2, train_loss: 0.024906293448546658\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 2, valid_loss: 0.021569643894003496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1119, FOLD: 3, EPOCH: 3, train_loss: 0.021170932205690853\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 3, valid_loss: 0.020263576569656532\n",
      "SEED: 1119, FOLD: 3, EPOCH: 4, train_loss: 0.020481691655257473\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 4, valid_loss: 0.019788341803683177\n",
      "SEED: 1119, FOLD: 3, EPOCH: 5, train_loss: 0.019911673189937206\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 5, valid_loss: 0.019516131323244836\n",
      "SEED: 1119, FOLD: 3, EPOCH: 6, train_loss: 0.019570102834183235\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 6, valid_loss: 0.019379828435679276\n",
      "SEED: 1119, FOLD: 3, EPOCH: 7, train_loss: 0.01937524053821529\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01932408691694339\n",
      "SEED: 1119, FOLD: 3, EPOCH: 8, train_loss: 0.01928944831741029\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 8, valid_loss: 0.019319431338873174\n",
      "SEED: 1119, FOLD: 3, EPOCH: 9, train_loss: 0.019225612984619278\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 9, valid_loss: 0.0192488305684593\n",
      "SEED: 1119, FOLD: 3, EPOCH: 10, train_loss: 0.01921041463704213\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 10, valid_loss: 0.019311859375900693\n",
      "SEED: 1119, FOLD: 3, EPOCH: 11, train_loss: 0.019177784603359043\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 11, valid_loss: 0.019203050165540643\n",
      "SEED: 1119, FOLD: 3, EPOCH: 12, train_loss: 0.01911881822498812\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 12, valid_loss: 0.019260235751668613\n",
      "SEED: 1119, FOLD: 3, EPOCH: 13, train_loss: 0.019058097828773483\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01914841764503055\n",
      "SEED: 1119, FOLD: 3, EPOCH: 14, train_loss: 0.01903932301354581\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 14, valid_loss: 0.019116326028274164\n",
      "SEED: 1119, FOLD: 3, EPOCH: 15, train_loss: 0.01895404823016429\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 15, valid_loss: 0.019036109041836526\n",
      "SEED: 1119, FOLD: 3, EPOCH: 16, train_loss: 0.018846410367151966\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 16, valid_loss: 0.018891414110031392\n",
      "SEED: 1119, FOLD: 3, EPOCH: 17, train_loss: 0.01872695213102776\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 17, valid_loss: 0.018894142885175016\n",
      "SEED: 1119, FOLD: 3, EPOCH: 18, train_loss: 0.018581185543882675\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 18, valid_loss: 0.01885477091289229\n",
      "SEED: 1119, FOLD: 3, EPOCH: 19, train_loss: 0.018376293416688408\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 19, valid_loss: 0.018784722727206018\n",
      "SEED: 1119, FOLD: 3, EPOCH: 20, train_loss: 0.018210166093447933\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 20, valid_loss: 0.018711796547803614\n",
      "SEED: 1119, FOLD: 3, EPOCH: 21, train_loss: 0.01804724951153216\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01865223826219638\n",
      "SEED: 1119, FOLD: 3, EPOCH: 22, train_loss: 0.01786628225143405\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 22, valid_loss: 0.018638195676936045\n",
      "SEED: 1119, FOLD: 3, EPOCH: 23, train_loss: 0.01774629652230204\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 23, valid_loss: 0.018621007084018655\n",
      "SEED: 1119, FOLD: 3, EPOCH: 24, train_loss: 0.017671978344088016\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 24, valid_loss: 0.018626553730832204\n",
      "SEED: 1119, FOLD: 4, EPOCH: 0, train_loss: 0.719220108744027\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6469806399610307\n",
      "SEED: 1119, FOLD: 4, EPOCH: 1, train_loss: 0.26637861445762107\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 1, valid_loss: 0.03200687033434709\n",
      "SEED: 1119, FOLD: 4, EPOCH: 2, train_loss: 0.024814633004691288\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 2, valid_loss: 0.021783142040173214\n",
      "SEED: 1119, FOLD: 4, EPOCH: 3, train_loss: 0.02118129747501318\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 3, valid_loss: 0.020835136373837788\n",
      "SEED: 1119, FOLD: 4, EPOCH: 4, train_loss: 0.02038719135242096\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 4, valid_loss: 0.02001240270005332\n",
      "SEED: 1119, FOLD: 4, EPOCH: 5, train_loss: 0.019920468060434727\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 5, valid_loss: 0.019860564938022032\n",
      "SEED: 1119, FOLD: 4, EPOCH: 6, train_loss: 0.019586460286940353\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 6, valid_loss: 0.019750373541480966\n",
      "SEED: 1119, FOLD: 4, EPOCH: 7, train_loss: 0.019419605128359104\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 7, valid_loss: 0.019571889295346208\n",
      "SEED: 1119, FOLD: 4, EPOCH: 8, train_loss: 0.019268159174184868\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 8, valid_loss: 0.019530301706658468\n",
      "SEED: 1119, FOLD: 4, EPOCH: 9, train_loss: 0.01924845244249572\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 9, valid_loss: 0.020065523477064237\n",
      "SEED: 1119, FOLD: 4, EPOCH: 10, train_loss: 0.019265748452449192\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 10, valid_loss: 0.019546419382095337\n",
      "SEED: 1119, FOLD: 4, EPOCH: 11, train_loss: 0.01921754967475283\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01955731896062692\n",
      "SEED: 1119, FOLD: 4, EPOCH: 12, train_loss: 0.01915352051888687\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 12, valid_loss: 0.019486427617569763\n",
      "SEED: 1119, FOLD: 4, EPOCH: 13, train_loss: 0.019080728724382927\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 13, valid_loss: 0.019281959989004664\n",
      "SEED: 1119, FOLD: 4, EPOCH: 14, train_loss: 0.019012495146497436\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 14, valid_loss: 0.019231643838187058\n",
      "SEED: 1119, FOLD: 4, EPOCH: 15, train_loss: 0.01888624489631342\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01922368299629953\n",
      "SEED: 1119, FOLD: 4, EPOCH: 16, train_loss: 0.018849502897996834\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01917038154270914\n",
      "SEED: 1119, FOLD: 4, EPOCH: 17, train_loss: 0.0187089575211639\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 17, valid_loss: 0.019097137885789078\n",
      "SEED: 1119, FOLD: 4, EPOCH: 18, train_loss: 0.018591353561783184\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 18, valid_loss: 0.018973093686832324\n",
      "SEED: 1119, FOLD: 4, EPOCH: 19, train_loss: 0.01845318945529668\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 19, valid_loss: 0.018887773259646363\n",
      "SEED: 1119, FOLD: 4, EPOCH: 20, train_loss: 0.018230065865361172\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 20, valid_loss: 0.018854971664647262\n",
      "SEED: 1119, FOLD: 4, EPOCH: 21, train_loss: 0.018078037497142086\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 21, valid_loss: 0.0187954514597853\n",
      "SEED: 1119, FOLD: 4, EPOCH: 22, train_loss: 0.017881345786694168\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01876421459019184\n",
      "SEED: 1119, FOLD: 4, EPOCH: 23, train_loss: 0.01775604840098084\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 23, valid_loss: 0.018749769156177837\n",
      "SEED: 1119, FOLD: 4, EPOCH: 24, train_loss: 0.017694306870301563\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 24, valid_loss: 0.018748729800184567\n",
      "elapsed time: 332.27605390548706\n",
      "SEED: 1303, FOLD: 0, EPOCH: 0, train_loss: 0.7197814575140027\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 0, valid_loss: 0.6380338271458944\n",
      "SEED: 1303, FOLD: 0, EPOCH: 1, train_loss: 0.26217050013550813\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 1, valid_loss: 0.0313067300659087\n",
      "SEED: 1303, FOLD: 0, EPOCH: 2, train_loss: 0.024827731071390968\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 2, valid_loss: 0.021730488476653893\n",
      "SEED: 1303, FOLD: 0, EPOCH: 3, train_loss: 0.021186316547834354\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 3, valid_loss: 0.02050130772921774\n",
      "SEED: 1303, FOLD: 0, EPOCH: 4, train_loss: 0.02048007714683595\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 4, valid_loss: 0.020081342094474368\n",
      "SEED: 1303, FOLD: 0, EPOCH: 5, train_loss: 0.019906984750127445\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 5, valid_loss: 0.019730071330236063\n",
      "SEED: 1303, FOLD: 0, EPOCH: 6, train_loss: 0.019579362313168636\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 6, valid_loss: 0.019574487685329385\n",
      "SEED: 1303, FOLD: 0, EPOCH: 7, train_loss: 0.01941110941486946\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01938353944569826\n",
      "SEED: 1303, FOLD: 0, EPOCH: 8, train_loss: 0.019262021272510723\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01945840298301644\n",
      "SEED: 1303, FOLD: 0, EPOCH: 9, train_loss: 0.0192111372353806\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01943828206923273\n",
      "SEED: 1303, FOLD: 0, EPOCH: 10, train_loss: 0.01921595600636109\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 10, valid_loss: 0.019258643293546304\n",
      "SEED: 1303, FOLD: 0, EPOCH: 11, train_loss: 0.019147149327656498\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01941331196576357\n",
      "SEED: 1303, FOLD: 0, EPOCH: 12, train_loss: 0.019157474860548973\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01936895741770665\n",
      "SEED: 1303, FOLD: 0, EPOCH: 13, train_loss: 0.019086877720943397\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01919668633490801\n",
      "SEED: 1303, FOLD: 0, EPOCH: 14, train_loss: 0.018994073370012684\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 14, valid_loss: 0.01915748758862416\n",
      "SEED: 1303, FOLD: 0, EPOCH: 15, train_loss: 0.018914259430290997\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 15, valid_loss: 0.019154926865465112\n",
      "SEED: 1303, FOLD: 0, EPOCH: 16, train_loss: 0.01880993648175744\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01901611520184411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1303, FOLD: 0, EPOCH: 17, train_loss: 0.01867948928712935\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01907795812520716\n",
      "SEED: 1303, FOLD: 0, EPOCH: 18, train_loss: 0.01857534445066383\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 18, valid_loss: 0.018924188075794116\n",
      "SEED: 1303, FOLD: 0, EPOCH: 19, train_loss: 0.018386608610550564\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 19, valid_loss: 0.018868224798805185\n",
      "SEED: 1303, FOLD: 0, EPOCH: 20, train_loss: 0.018225621702014538\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01879824625535144\n",
      "SEED: 1303, FOLD: 0, EPOCH: 21, train_loss: 0.0180242663330358\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 21, valid_loss: 0.018807893618941307\n",
      "SEED: 1303, FOLD: 0, EPOCH: 22, train_loss: 0.017854232314056244\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 22, valid_loss: 0.018752904298404854\n",
      "SEED: 1303, FOLD: 0, EPOCH: 23, train_loss: 0.01773616261240365\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 23, valid_loss: 0.018739088541931577\n",
      "SEED: 1303, FOLD: 0, EPOCH: 24, train_loss: 0.017676962593543358\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01873873360455036\n",
      "SEED: 1303, FOLD: 1, EPOCH: 0, train_loss: 0.7200239810390748\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 0, valid_loss: 0.649022079176373\n",
      "SEED: 1303, FOLD: 1, EPOCH: 1, train_loss: 0.2620432327730932\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 1, valid_loss: 0.030635368906789355\n",
      "SEED: 1303, FOLD: 1, EPOCH: 2, train_loss: 0.02515638114857501\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 2, valid_loss: 0.02195055637922552\n",
      "SEED: 1303, FOLD: 1, EPOCH: 3, train_loss: 0.021283129581074783\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 3, valid_loss: 0.02014692986590995\n",
      "SEED: 1303, FOLD: 1, EPOCH: 4, train_loss: 0.020437822744682217\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 4, valid_loss: 0.02001415193080902\n",
      "SEED: 1303, FOLD: 1, EPOCH: 5, train_loss: 0.019971483859463013\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 5, valid_loss: 0.019620760137008295\n",
      "SEED: 1303, FOLD: 1, EPOCH: 6, train_loss: 0.019567878835875054\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01946999380985896\n",
      "SEED: 1303, FOLD: 1, EPOCH: 7, train_loss: 0.019394783897028454\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 7, valid_loss: 0.019439075866507158\n",
      "SEED: 1303, FOLD: 1, EPOCH: 8, train_loss: 0.019309198564809303\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01942228391352627\n",
      "SEED: 1303, FOLD: 1, EPOCH: 9, train_loss: 0.01922993855955808\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01932385905335347\n",
      "SEED: 1303, FOLD: 1, EPOCH: 10, train_loss: 0.019208602418286213\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 10, valid_loss: 0.019372214045789506\n",
      "SEED: 1303, FOLD: 1, EPOCH: 11, train_loss: 0.019168373602239983\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 11, valid_loss: 0.019262985843751166\n",
      "SEED: 1303, FOLD: 1, EPOCH: 12, train_loss: 0.01913203558196192\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01939002341694302\n",
      "SEED: 1303, FOLD: 1, EPOCH: 13, train_loss: 0.019111296809885815\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01922303086353673\n",
      "SEED: 1303, FOLD: 1, EPOCH: 14, train_loss: 0.019035833793273872\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 14, valid_loss: 0.01924249478098419\n",
      "SEED: 1303, FOLD: 1, EPOCH: 15, train_loss: 0.018948265526821648\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 15, valid_loss: 0.019157458200222917\n",
      "SEED: 1303, FOLD: 1, EPOCH: 16, train_loss: 0.018859958249157753\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 16, valid_loss: 0.019082548510697152\n",
      "SEED: 1303, FOLD: 1, EPOCH: 17, train_loss: 0.0187158791375333\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 17, valid_loss: 0.019061518626080617\n",
      "SEED: 1303, FOLD: 1, EPOCH: 18, train_loss: 0.018526788423026817\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 18, valid_loss: 0.018958449363708496\n",
      "SEED: 1303, FOLD: 1, EPOCH: 19, train_loss: 0.018407461219939632\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 19, valid_loss: 0.018900980345076986\n",
      "SEED: 1303, FOLD: 1, EPOCH: 20, train_loss: 0.018212976501039837\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 20, valid_loss: 0.018802918183306854\n",
      "SEED: 1303, FOLD: 1, EPOCH: 21, train_loss: 0.01805622956675032\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 21, valid_loss: 0.018770137077404395\n",
      "SEED: 1303, FOLD: 1, EPOCH: 22, train_loss: 0.017867703098749767\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 22, valid_loss: 0.018707675031489797\n",
      "SEED: 1303, FOLD: 1, EPOCH: 23, train_loss: 0.017758282198422196\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 23, valid_loss: 0.018728993315663602\n",
      "SEED: 1303, FOLD: 1, EPOCH: 24, train_loss: 0.017691205917061237\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 24, valid_loss: 0.018728122529056337\n",
      "SEED: 1303, FOLD: 2, EPOCH: 0, train_loss: 0.7202280638874441\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 0, valid_loss: 0.6430025961663988\n",
      "SEED: 1303, FOLD: 2, EPOCH: 1, train_loss: 0.263443933772868\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 1, valid_loss: 0.030651297523743577\n",
      "SEED: 1303, FOLD: 2, EPOCH: 2, train_loss: 0.024852433606334354\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 2, valid_loss: 0.02165187843557861\n",
      "SEED: 1303, FOLD: 2, EPOCH: 3, train_loss: 0.021171876836730087\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 3, valid_loss: 0.020480567382441625\n",
      "SEED: 1303, FOLD: 2, EPOCH: 4, train_loss: 0.02054492359899956\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 4, valid_loss: 0.020245965673691697\n",
      "SEED: 1303, FOLD: 2, EPOCH: 5, train_loss: 0.01999062734345595\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 5, valid_loss: 0.019936891065703496\n",
      "SEED: 1303, FOLD: 2, EPOCH: 6, train_loss: 0.019597738225390945\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01941328588873148\n",
      "SEED: 1303, FOLD: 2, EPOCH: 7, train_loss: 0.019429556350561157\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 7, valid_loss: 0.019465445747805968\n",
      "SEED: 1303, FOLD: 2, EPOCH: 8, train_loss: 0.01935533269483974\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 8, valid_loss: 0.019500360099805727\n",
      "SEED: 1303, FOLD: 2, EPOCH: 9, train_loss: 0.019267841606684353\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 9, valid_loss: 0.019361903787487082\n",
      "SEED: 1303, FOLD: 2, EPOCH: 10, train_loss: 0.019224917732071186\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01946710381242964\n",
      "SEED: 1303, FOLD: 2, EPOCH: 11, train_loss: 0.01923054821141388\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01932738980071412\n",
      "SEED: 1303, FOLD: 2, EPOCH: 12, train_loss: 0.019196678546891697\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01923738420009613\n",
      "SEED: 1303, FOLD: 2, EPOCH: 13, train_loss: 0.01911302377888258\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01922755471120278\n",
      "SEED: 1303, FOLD: 2, EPOCH: 14, train_loss: 0.019065683761584587\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 14, valid_loss: 0.019059846902059183\n",
      "SEED: 1303, FOLD: 2, EPOCH: 15, train_loss: 0.01895192430179188\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 15, valid_loss: 0.019085793962909117\n",
      "SEED: 1303, FOLD: 2, EPOCH: 16, train_loss: 0.018890750283996265\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 16, valid_loss: 0.019040518233345613\n",
      "SEED: 1303, FOLD: 2, EPOCH: 17, train_loss: 0.018755440262780674\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 17, valid_loss: 0.018875770995186433\n",
      "SEED: 1303, FOLD: 2, EPOCH: 18, train_loss: 0.018589542908728985\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01887685815907187\n",
      "SEED: 1303, FOLD: 2, EPOCH: 19, train_loss: 0.018453426983045494\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 19, valid_loss: 0.018796917982399464\n",
      "SEED: 1303, FOLD: 2, EPOCH: 20, train_loss: 0.01823589931903542\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 20, valid_loss: 0.018750104328824416\n",
      "SEED: 1303, FOLD: 2, EPOCH: 21, train_loss: 0.018080112699797188\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 21, valid_loss: 0.018692686429454222\n",
      "SEED: 1303, FOLD: 2, EPOCH: 22, train_loss: 0.01793679227863533\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01866196220119794\n",
      "SEED: 1303, FOLD: 2, EPOCH: 23, train_loss: 0.017790653837331825\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01865134998742077\n",
      "SEED: 1303, FOLD: 2, EPOCH: 24, train_loss: 0.01772480622689793\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 24, valid_loss: 0.018646859253446262\n",
      "SEED: 1303, FOLD: 3, EPOCH: 0, train_loss: 0.7200180248937745\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 0, valid_loss: 0.6435247792137994\n",
      "SEED: 1303, FOLD: 3, EPOCH: 1, train_loss: 0.2620602488193823\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 1, valid_loss: 0.03022270670367612\n",
      "SEED: 1303, FOLD: 3, EPOCH: 2, train_loss: 0.02493533160051574\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 2, valid_loss: 0.02159583123607768\n",
      "SEED: 1303, FOLD: 3, EPOCH: 3, train_loss: 0.021235763027832127\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 3, valid_loss: 0.020179603041874036\n",
      "SEED: 1303, FOLD: 3, EPOCH: 4, train_loss: 0.020433820676112522\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01985404681828287\n",
      "SEED: 1303, FOLD: 3, EPOCH: 5, train_loss: 0.019941509336881016\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 5, valid_loss: 0.019488114967114396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1303, FOLD: 3, EPOCH: 6, train_loss: 0.01956681461761827\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 6, valid_loss: 0.019432169799175527\n",
      "SEED: 1303, FOLD: 3, EPOCH: 7, train_loss: 0.019343144786746605\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 7, valid_loss: 0.019358665371934574\n",
      "SEED: 1303, FOLD: 3, EPOCH: 8, train_loss: 0.01927231543737909\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01926756908910142\n",
      "SEED: 1303, FOLD: 3, EPOCH: 9, train_loss: 0.019238362466727478\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01920522666639752\n",
      "SEED: 1303, FOLD: 3, EPOCH: 10, train_loss: 0.01921104075576084\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 10, valid_loss: 0.019247974476052657\n",
      "SEED: 1303, FOLD: 3, EPOCH: 11, train_loss: 0.019205585446046745\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 11, valid_loss: 0.019313448419173557\n",
      "SEED: 1303, FOLD: 3, EPOCH: 12, train_loss: 0.01914144963349985\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 12, valid_loss: 0.019254831079807546\n",
      "SEED: 1303, FOLD: 3, EPOCH: 13, train_loss: 0.019129766826180443\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 13, valid_loss: 0.019173608161509037\n",
      "SEED: 1303, FOLD: 3, EPOCH: 14, train_loss: 0.019049432695559834\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 14, valid_loss: 0.019062737934291363\n",
      "SEED: 1303, FOLD: 3, EPOCH: 15, train_loss: 0.018948869860690574\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 15, valid_loss: 0.019001394510269165\n",
      "SEED: 1303, FOLD: 3, EPOCH: 16, train_loss: 0.01887419166556303\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 16, valid_loss: 0.018953165867262416\n",
      "SEED: 1303, FOLD: 3, EPOCH: 17, train_loss: 0.01871715982755025\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01890389962742726\n",
      "SEED: 1303, FOLD: 3, EPOCH: 18, train_loss: 0.018550715044788692\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 18, valid_loss: 0.018812884369658098\n",
      "SEED: 1303, FOLD: 3, EPOCH: 19, train_loss: 0.01837510707369749\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 19, valid_loss: 0.018771856195396848\n",
      "SEED: 1303, FOLD: 3, EPOCH: 20, train_loss: 0.018207605253311172\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 20, valid_loss: 0.018676865587217942\n",
      "SEED: 1303, FOLD: 3, EPOCH: 21, train_loss: 0.018030203123023544\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 21, valid_loss: 0.018634635023772717\n",
      "SEED: 1303, FOLD: 3, EPOCH: 22, train_loss: 0.01785244557844556\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01862096796847052\n",
      "SEED: 1303, FOLD: 3, EPOCH: 23, train_loss: 0.017752883199980293\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01860446808859706\n",
      "SEED: 1303, FOLD: 3, EPOCH: 24, train_loss: 0.017712629575660263\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 24, valid_loss: 0.018599099945276976\n",
      "SEED: 1303, FOLD: 4, EPOCH: 0, train_loss: 0.7204085985819498\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 0, valid_loss: 0.6456192798084683\n",
      "SEED: 1303, FOLD: 4, EPOCH: 1, train_loss: 0.2629708557565143\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 1, valid_loss: 0.031415382917556495\n",
      "SEED: 1303, FOLD: 4, EPOCH: 2, train_loss: 0.024921892129856606\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 2, valid_loss: 0.02204443183210161\n",
      "SEED: 1303, FOLD: 4, EPOCH: 3, train_loss: 0.02117612447751605\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 3, valid_loss: 0.02078935555699799\n",
      "SEED: 1303, FOLD: 4, EPOCH: 4, train_loss: 0.020449823929347855\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 4, valid_loss: 0.020118736765450902\n",
      "SEED: 1303, FOLD: 4, EPOCH: 5, train_loss: 0.019924845546483994\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01995568349957466\n",
      "SEED: 1303, FOLD: 4, EPOCH: 6, train_loss: 0.01959369925485141\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 6, valid_loss: 0.019620754652553134\n",
      "SEED: 1303, FOLD: 4, EPOCH: 7, train_loss: 0.01938668198451616\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 7, valid_loss: 0.019588737645083003\n",
      "SEED: 1303, FOLD: 4, EPOCH: 8, train_loss: 0.01928433789399223\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 8, valid_loss: 0.019444129947159026\n",
      "SEED: 1303, FOLD: 4, EPOCH: 9, train_loss: 0.019201187011988266\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01959421599490775\n",
      "SEED: 1303, FOLD: 4, EPOCH: 10, train_loss: 0.01918927963445152\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 10, valid_loss: 0.019450353665484324\n",
      "SEED: 1303, FOLD: 4, EPOCH: 11, train_loss: 0.019145885914348175\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 11, valid_loss: 0.019383919632269278\n",
      "SEED: 1303, FOLD: 4, EPOCH: 12, train_loss: 0.01913734498447266\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 12, valid_loss: 0.019326873848007783\n",
      "SEED: 1303, FOLD: 4, EPOCH: 13, train_loss: 0.019072646869049557\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01938536877019538\n",
      "SEED: 1303, FOLD: 4, EPOCH: 14, train_loss: 0.019004120261988777\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 14, valid_loss: 0.019350753579702642\n",
      "SEED: 1303, FOLD: 4, EPOCH: 15, train_loss: 0.018977024120049202\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 15, valid_loss: 0.019252955810063414\n",
      "SEED: 1303, FOLD: 4, EPOCH: 16, train_loss: 0.01882424359412297\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01916978580670224\n",
      "SEED: 1303, FOLD: 4, EPOCH: 17, train_loss: 0.018698317687148632\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 17, valid_loss: 0.019069635412759252\n",
      "SEED: 1303, FOLD: 4, EPOCH: 18, train_loss: 0.018558599945643673\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 18, valid_loss: 0.019008686766028404\n",
      "SEED: 1303, FOLD: 4, EPOCH: 19, train_loss: 0.018376165353085682\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 19, valid_loss: 0.018942996445629332\n",
      "SEED: 1303, FOLD: 4, EPOCH: 20, train_loss: 0.0182000492847916\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01883979245192475\n",
      "SEED: 1303, FOLD: 4, EPOCH: 21, train_loss: 0.018019035188616184\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 21, valid_loss: 0.018769359009133443\n",
      "SEED: 1303, FOLD: 4, EPOCH: 22, train_loss: 0.017844743081840916\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 22, valid_loss: 0.018765293061733246\n",
      "SEED: 1303, FOLD: 4, EPOCH: 23, train_loss: 0.01775782873881036\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 23, valid_loss: 0.018751074766947165\n",
      "SEED: 1303, FOLD: 4, EPOCH: 24, train_loss: 0.017676340335089226\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 24, valid_loss: 0.018742603146367602\n",
      "elapsed time: 397.9851655960083\n"
     ]
    }
   ],
   "source": [
    "SEED = [940, 1513, 1269, 1392, 1119, 1303]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "for seed in SEED:\n",
    "\n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "    print(f\"elapsed time: {time.time() - time_start}\")\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:15:10.434067Z",
     "iopub.status.busy": "2020-11-26T06:15:10.432856Z",
     "iopub.status.idle": "2020-11-26T06:15:11.048605Z",
     "shell.execute_reply": "2020-11-26T06:15:11.036104Z"
    },
    "papermill": {
     "duration": 1.896525,
     "end_time": "2020-11-26T06:15:11.048797",
     "exception": false,
     "start_time": "2020-11-26T06:15:09.152272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.to_pickle(f\"{INT_DIR}/{NB}-train-score-stack-pred.pkl\")\n",
    "test.to_pickle(f\"{INT_DIR}/{NB}-test-score-stack-pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:15:13.639130Z",
     "iopub.status.busy": "2020-11-26T06:15:13.637906Z",
     "iopub.status.idle": "2020-11-26T06:15:14.901819Z",
     "shell.execute_reply": "2020-11-26T06:15:14.900887Z"
    },
    "papermill": {
     "duration": 2.257493,
     "end_time": "2020-11-26T06:15:14.901943",
     "exception": false,
     "start_time": "2020-11-26T06:15:12.644450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.014318743530085496\n"
     ]
    }
   ],
   "source": [
    "train[target_cols] = np.maximum(PMIN, np.minimum(PMAX, train[target_cols]))\n",
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(\n",
    "    train[['sig_id'] + target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_true = y_true > 0.5\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "y_pred = np.minimum(SMAX, np.maximum(SMIN, y_pred))\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "\n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:15:17.085148Z",
     "iopub.status.busy": "2020-11-26T06:15:17.083691Z",
     "iopub.status.idle": "2020-11-26T06:15:19.335222Z",
     "shell.execute_reply": "2020-11-26T06:15:19.334277Z"
    },
    "papermill": {
     "duration": 3.451146,
     "end_time": "2020-11-26T06:15:19.335391",
     "exception": false,
     "start_time": "2020-11-26T06:15:15.884245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for c in test.columns:\n",
    "#     if c != \"sig_id\":\n",
    "#         test[c] = np.maximum(PMIN, np.minimum(PMAX, test[c]))\n",
    "\n",
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id'] +\n",
    "                                                             target_cols],\n",
    "                                                        on='sig_id',\n",
    "                                                        how='left').fillna(0)\n",
    "# sub.to_csv('submission.csv', index=False)\n",
    "sub.to_csv('submission_2stageNN_with_ns_oldcv_0.01822.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T06:15:21.447491Z",
     "iopub.status.busy": "2020-11-26T06:15:21.444929Z",
     "iopub.status.idle": "2020-11-26T06:15:21.510280Z",
     "shell.execute_reply": "2020-11-26T06:15:21.511669Z"
    },
    "papermill": {
     "duration": 1.20979,
     "end_time": "2020-11-26T06:15:21.511971",
     "exception": false,
     "start_time": "2020-11-26T06:15:20.302181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.011808</td>\n",
       "      <td>0.019730</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.006231</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.001710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>0.012393</td>\n",
       "      <td>0.005252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.006524</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.002399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.014157</td>\n",
       "      <td>0.020908</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.003220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.014973</td>\n",
       "      <td>0.020677</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.001158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.305395</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.001611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.010189</td>\n",
       "      <td>0.020856</td>\n",
       "      <td>0.006774</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.004423</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.002178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.012438</td>\n",
       "      <td>0.020764</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.001380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.018013</td>\n",
       "      <td>0.023979</td>\n",
       "      <td>0.006361</td>\n",
       "      <td>0.007311</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.003748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.010053</td>\n",
       "      <td>0.019443</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.005514</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.001494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                     0.001149                0.001465   \n",
       "1     id_001897cda                     0.000514                0.002112   \n",
       "2     id_002429b5b                     0.000000                0.000000   \n",
       "3     id_00276f245                     0.001224                0.001149   \n",
       "4     id_0027f1083                     0.001674                0.001859   \n",
       "...            ...                          ...                     ...   \n",
       "3977  id_ff7004b87                     0.001128                0.001365   \n",
       "3978  id_ff925dd0d                     0.007152                0.002935   \n",
       "3979  id_ffb710450                     0.001556                0.001746   \n",
       "3980  id_ffbb869f2                     0.002759                0.001698   \n",
       "3981  id_ffd5800b6                     0.001038                0.001633   \n",
       "\n",
       "      acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0           0.001759                        0.011808   \n",
       "1           0.001632                        0.004301   \n",
       "2           0.000000                        0.000000   \n",
       "3           0.001648                        0.014157   \n",
       "4           0.002772                        0.014973   \n",
       "...              ...                             ...   \n",
       "3977        0.001902                        0.003931   \n",
       "3978        0.001411                        0.010189   \n",
       "3979        0.001836                        0.012438   \n",
       "3980        0.001443                        0.018013   \n",
       "3981        0.001757                        0.010053   \n",
       "\n",
       "      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                              0.019730                        0.004797   \n",
       "1                              0.002107                        0.002263   \n",
       "2                              0.000000                        0.000000   \n",
       "3                              0.020908                        0.003767   \n",
       "4                              0.020677                        0.004415   \n",
       "...                                 ...                             ...   \n",
       "3977                           0.006649                        0.002779   \n",
       "3978                           0.020856                        0.006774   \n",
       "3979                           0.020764                        0.006126   \n",
       "3980                           0.023979                        0.006361   \n",
       "3981                           0.019443                        0.004977   \n",
       "\n",
       "      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                       0.002614                       0.006231   \n",
       "1                       0.006319                       0.012393   \n",
       "2                       0.000000                       0.000000   \n",
       "3                       0.003095                       0.003870   \n",
       "4                       0.003962                       0.003042   \n",
       "...                          ...                            ...   \n",
       "3977                    0.001911                       0.003058   \n",
       "3978                    0.004249                       0.004423   \n",
       "3979                    0.003009                       0.004530   \n",
       "3980                    0.007311                       0.003258   \n",
       "3981                    0.002374                       0.004715   \n",
       "\n",
       "      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                       0.000631  ...                               0.000904   \n",
       "1                       0.005252  ...                               0.001019   \n",
       "2                       0.000000  ...                               0.000000   \n",
       "3                       0.000582  ...                               0.000742   \n",
       "4                       0.000745  ...                               0.001228   \n",
       "...                          ...  ...                                    ...   \n",
       "3977                    0.000721  ...                               0.000871   \n",
       "3978                    0.000803  ...                               0.000974   \n",
       "3979                    0.000657  ...                               0.000902   \n",
       "3980                    0.000800  ...                               0.000742   \n",
       "3981                    0.000612  ...                               0.000869   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.001267         0.002736           0.001985   \n",
       "1         0.000657         0.006524           0.000494   \n",
       "2         0.000000         0.000000           0.000000   \n",
       "3         0.001054         0.004266           0.003588   \n",
       "4         0.000941         0.004282           0.003141   \n",
       "...            ...              ...                ...   \n",
       "3977      0.005010         0.002657           0.305395   \n",
       "3978      0.000985         0.003498           0.002821   \n",
       "3979      0.001329         0.002759           0.004060   \n",
       "3980      0.000832         0.003661           0.002239   \n",
       "3981      0.001896         0.002600           0.005514   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.001602                               0.000928   \n",
       "1                      0.009789                               0.000507   \n",
       "2                      0.000000                               0.000000   \n",
       "3                      0.007000                               0.000887   \n",
       "4                      0.002014                               0.000936   \n",
       "...                         ...                                    ...   \n",
       "3977                   0.006896                               0.001572   \n",
       "3978                   0.002662                               0.001072   \n",
       "3979                   0.002292                               0.000868   \n",
       "3980                   0.001574                               0.000817   \n",
       "3981                   0.002489                               0.001245   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.002326   0.001742                    0.002772       0.001710  \n",
       "1            0.003183   0.000933                    0.001540       0.002399  \n",
       "2            0.000000   0.000000                    0.000000       0.000000  \n",
       "3            0.002099   0.002357                    0.000819       0.003220  \n",
       "4            0.001957   0.001982                    0.000786       0.001158  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977         0.003425   0.001523                    0.000795       0.001611  \n",
       "3978         0.005414   0.002896                    0.000891       0.002178  \n",
       "3979         0.002032   0.002114                    0.000941       0.001380  \n",
       "3980         0.001875   0.002406                    0.001128       0.003748  \n",
       "3981         0.001930   0.002192                    0.001106       0.001494  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.992223,
     "end_time": "2020-11-26T06:15:23.785992",
     "exception": false,
     "start_time": "2020-11-26T06:15:22.793769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.955568,
     "end_time": "2020-11-26T06:15:25.770268",
     "exception": false,
     "start_time": "2020-11-26T06:15:24.814700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.949747,
     "end_time": "2020-11-26T06:15:27.681528",
     "exception": false,
     "start_time": "2020-11-26T06:15:26.731781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.952765,
     "end_time": "2020-11-26T06:15:29.594300",
     "exception": false,
     "start_time": "2020-11-26T06:15:28.641535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 3351.245322,
   "end_time": "2020-11-26T06:15:31.060496",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-26T05:19:39.815174",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
