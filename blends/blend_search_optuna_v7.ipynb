{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T16:07:47.821830Z",
     "iopub.status.busy": "2020-11-22T16:07:47.821023Z",
     "iopub.status.idle": "2020-11-22T16:07:49.329586Z",
     "shell.execute_reply": "2020-11-22T16:07:49.328896Z"
    },
    "papermill": {
     "duration": 1.531146,
     "end_time": "2020-11-22T16:07:49.329729",
     "exception": false,
     "start_time": "2020-11-22T16:07:47.798583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[V7]\n",
    "Blend 5 Models:\n",
    "* kibuna-nn-hs-1024-last-train (aka. 2stage-NN, LB: 0.01822)\n",
    "* deepinsight-efficientnet-v7-b3-infer (LB: 0.01850)\n",
    "* deepinsight_resnest_lightning_v2_infer (LB: 0.01854)\n",
    "* deepinsight_resnest_lightning_v1_infer (LB: 0.01853)\n",
    "* improving-mark-s-2-heads-model-infer.py (LB: 0.1844)\n",
    "\n",
    "Removed for now due to low weights:\n",
    "* simpleNN-oldcv (LB: 0.01836)\n",
    "* 503-203-tabnet-with-nonscored-features (LB: 0.01836)\n",
    "* fork-of-2heads-looper-super-puper-markpeng-infer (LB: 0.1836)\n",
    "* supervised-tabnet-lightning-v2-infer.py (LB: 0.1857)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "kernel_mode = False\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import datetime\n",
    "import pickle\n",
    "from pickle import dump, load\n",
    "import glob\n",
    "\n",
    "from numba import njit\n",
    "from scipy.optimize import minimize, fsolve\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "rand_seed = 1120\n",
    "\n",
    "search_mode = True\n",
    "run_submit_script = False\n",
    "\n",
    "# method = \"CV\"\n",
    "# method = \"scipy_per_target\"\n",
    "method = \"scipy\"\n",
    "# method = \"optuna\"\n",
    "# study_name = \"blend_search_optuna_v7_10folds\"\n",
    "# study_name = \"blend_search_optuna_v7\"\n",
    "# study_name = \"blend_search_optuna_v6_per_target\"\n",
    "# n_trials = 500\n",
    "n_trials = 3000\n",
    "# n_trials = 5000\n",
    "# n_trials = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T16:07:49.374396Z",
     "iopub.status.busy": "2020-11-22T16:07:49.372601Z",
     "iopub.status.idle": "2020-11-22T16:07:57.173665Z",
     "shell.execute_reply": "2020-11-22T16:07:57.167043Z"
    },
    "papermill": {
     "duration": 7.831926,
     "end_time": "2020-11-22T16:07:57.173865",
     "exception": false,
     "start_time": "2020-11-22T16:07:49.341939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir -p /root/.cache/torch/hub/checkpoints/\n",
    "# !cp ../input/gen-efficientnet-pretrained/tf_efficientnet_*.pth /root/.cache/torch/hub/checkpoints/\n",
    "# !cp ../input/deepinsight-resnest-v1-resnest50/*.pth /root/.cache/torch/hub/checkpoints/\n",
    "# !cp ../input/deepinsight-resnest-v2-resnest50-output/*.pth /root/.cache/torch/hub/checkpoints/\n",
    "# !ls -la /root/.cache/torch/hub/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T16:07:57.302713Z",
     "iopub.status.busy": "2020-11-22T16:07:57.301888Z",
     "iopub.status.idle": "2020-11-22T16:07:59.432020Z",
     "shell.execute_reply": "2020-11-22T16:07:59.427068Z"
    },
    "papermill": {
     "duration": 2.211524,
     "end_time": "2020-11-22T16:07:59.432178",
     "exception": false,
     "start_time": "2020-11-22T16:07:57.220654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cp ../input/kaggle-moa-team/scripts/* .\n",
    "# !cp ../input/kaggle-moa-team/blends/*.pkl .\n",
    "# !ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T16:07:59.482699Z",
     "iopub.status.busy": "2020-11-22T16:07:59.481671Z",
     "iopub.status.idle": "2020-11-22T16:07:59.486348Z",
     "shell.execute_reply": "2020-11-22T16:07:59.487900Z"
    },
    "papermill": {
     "duration": 0.034902,
     "end_time": "2020-11-22T16:07:59.488095",
     "exception": false,
     "start_time": "2020-11-22T16:07:59.453193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_folder = \"../input/lish-moa\" if kernel_mode else \"/workspace/Kaggle/MoA/\"\n",
    "\n",
    "# Add your model inference script here\n",
    "# Tuple Format: (script, oof_filename, output_filename, weight)\n",
    "model_list = [\n",
    "    # 10 folds\n",
    "    (\"2stageNN_with_ns_oldcv_10folds.py\" if kernel_mode else \"../../Github/kaggle_moa_team/scripts/2stageNN_with_ns_oldcv_10folds.py\",\n",
    "     \"../../Github/kaggle_moa_team/oof/oof_2stageNN_ns_oldcv_10folds.npy\",\n",
    "     \"submission_2stageNN_with_ns_oldcv_10folds.csv\",\n",
    "     0.36704255),\n",
    "    \n",
    "    #     (\"script_simpleNN_oldcv_10folds.py\" if kernel_mode else \"../../Github/kaggle_moa_team/scripts/script_simpleNN_oldcv_10folds.py\",\n",
    "    #      \"../../Github/kaggle_moa_team/oof/oof_NN_oldcv_10fold.npy\",\n",
    "    #      \"submission_script_simpleNN_oldcv_10folds.csv\",\n",
    "    #      0.00019665601658366993),\n",
    "    \n",
    "    #     (\"2stageNN_with_ns_oldcv.py\" if kernel_mode else \"../../Github/kaggle_moa_team/scripts/2stageNN_with_ns_oldcv.py\",\n",
    "    #      \"../../Github/kaggle_moa_team/oof/oof_2stageNN_ns_oldcv.npy\",\n",
    "    #      \"submission_2stageNN_with_ns_oldcv_0.01822.csv\",\n",
    "    #      0.323528084383917),\n",
    "\n",
    "    #     (\"script_simpleNN_oldcv.py\" if kernel_mode else \"../../Github/kaggle_moa_team/scripts/script_simpleNN_oldcv.py\",\n",
    "    #      \"../../Github/kaggle_moa_team/oof/oof_script_simpleNN_oldcv.npy\",\n",
    "    #      \"submission_script_simpleNN_oldcv_0.01836.csv\",\n",
    "    #      0.08786476491118465),\n",
    "    \n",
    "    #     (\"fork-of-2heads-looper-super-puper-markpeng-infer.py\" if kernel_mode else \"../../Github/kaggle_moa_team/scripts/fork-of-2heads-looper-super-puper-markpeng-infer.py\",\n",
    "    #      \"../../Github/kaggle_moa_team/oof/oof_fork-of-2heads-looper-super-puper-markpeng.npy\",\n",
    "    #      \"submission_2heads-looper-super-puper_0.01836.csv\",\n",
    "    #      0.018966959973949222),\n",
    "    \n",
    "    (\"improving-mark-s-2-heads-model-infer.py\" if kernel_mode else \"../../Github/kaggle_moa_team/scripts/improving-mark-s-2-heads-model-infer.py\",\n",
    "     \"../../Github/kaggle_moa_team/oof/oof_improving-mark-s-2-heads-model_0.015660083675738144.npy\",\n",
    "     \"submission_improving-mark-s-2-heads-model.csv\",\n",
    "     0.0808577),\n",
    "    \n",
    "    (\"deepinsight_efficientnet_lightning_v7_b3_infer.py\" if kernel_mode else \"../../Github/kaggle_moa_team/scripts/deepinsight_efficientnet_lightning_v7_b3_infer.py\",\n",
    "     \"../../Github/kaggle_moa_team/oof/oof_deepinsight_efficientnet_lightning_v7_b3_0.01850.npy\",\n",
    "     \"submission_effnet_v7_b3_0.01850.csv\",\n",
    "     0.17120266),\n",
    "    \n",
    "    (\"deepinsight_resnest_lightning_v1_infer.py\" if kernel_mode else \"../../Github/kaggle_moa_team/scripts/deepinsight_resnest_lightning_v1_infer.py\",\n",
    "     \"../../Github/kaggle_moa_team/oof/oof_deepinsight_ResNeSt_v1_resnest50_0.014619621213185928.npy\",\n",
    "     \"submission_resnest_v1_0.01853.csv\",\n",
    "     0.10876667),\n",
    "    \n",
    "    (\"deepinsight_resnest_lightning_v2_infer.py\" if kernel_mode else \"../../Github/kaggle_moa_team/scripts/deepinsight_resnest_lightning_v2_infer.py\",\n",
    "     \"../../Github/kaggle_moa_team/oof/oof_deepinsight_ResNeSt_v2_resnest50_0.01854.npy\",\n",
    "     \"submission_resnest_v2_0.01854.csv\",\n",
    "     0.27213043),\n",
    "    \n",
    "    #     (\"supervised_tabnet_v2_seeds_infer.py\" if kernel_mode else \"../../Github/kaggle_moa_team/scripts/supervised_tabnet_v2_seeds_infer.py\",\n",
    "    #      \"../../Github/kaggle_moa_team/oof/oof_supervised_tabnet_v2_seeds_0.014939561499719265.npy\",\n",
    "    #      \"submission_supervised_tabnet_v2_seeds_0.01857.csv\",\n",
    "    #      0),\n",
    "    \n",
    "    #     (\"script_tabnet_ns_oldcv.py\" if kernel_mode else \"../../Github/kaggle_moa_team/scripts/script_tabnet_ns_oldcv.py\",\n",
    "    #      \"../../Github/kaggle_moa_team/oof/oof_tabnet_ns_oldcv.npy\",\n",
    "    #      \"submission_tabnet_ns_oldcv_0.01836.csv\",\n",
    "    #      0.0013224625996093413),\n",
    "]\n",
    "\n",
    "model_path = \".\" if kernel_mode else dataset_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T16:07:59.535457Z",
     "iopub.status.busy": "2020-11-22T16:07:59.534643Z",
     "iopub.status.idle": "2020-11-22T16:08:00.303180Z",
     "shell.execute_reply": "2020-11-22T16:08:00.303752Z"
    },
    "papermill": {
     "duration": 0.797221,
     "end_time": "2020-11-22T16:08:00.303937",
     "exception": false,
     "start_time": "2020-11-22T16:07:59.506716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(f\"{dataset_folder}/train_features.csv\",\n",
    "                             engine='c')\n",
    "train_labels = pd.read_csv(f'{dataset_folder}/train_targets_scored.csv',\n",
    "                           engine='c')\n",
    "train_classes = [c for c in train_labels.columns if c != \"sig_id\"]\n",
    "\n",
    "non_control_group_rows = train_features[\"cp_type\"] == \"trt_cp\"\n",
    "non_control_group_train_labels = train_labels.loc[\n",
    "    non_control_group_rows, :].copy().reset_index(drop=True)\n",
    "\n",
    "submission = pd.read_csv(f'{dataset_folder}/sample_submission.csv')\n",
    "submission.iloc[:, 1:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T16:08:00.340378Z",
     "iopub.status.busy": "2020-11-22T16:08:00.338486Z",
     "iopub.status.idle": "2020-11-22T16:08:00.341900Z",
     "shell.execute_reply": "2020-11-22T16:08:00.342449Z"
    },
    "papermill": {
     "duration": 0.02445,
     "end_time": "2020-11-22T16:08:00.342614",
     "exception": false,
     "start_time": "2020-11-22T16:08:00.318164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_logloss(y_pred, y_true):\n",
    "    logloss = (1 - y_true) * np.log(1 - y_pred +\n",
    "                                    1e-15) + y_true * np.log(y_pred + 1e-15)\n",
    "    return np.nanmean(-logloss)\n",
    "\n",
    "\n",
    "def save_pickle(obj, folder, name):\n",
    "    dump(obj, open(f\"{folder}/{name}.pkl\", 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_pickle(path):\n",
    "    return load(open(path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.kaggle.com/gogo827jz/optimise-blending-weights-with-bonus-0/notebook\n",
    "# CPMP's logloss from https://www.kaggle.com/c/lish-moa/discussion/183010\n",
    "def log_loss_numpy(y_pred, y_true):\n",
    "    y_true_ravel = np.asarray(y_true).ravel()\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    loss = np.where(y_true_ravel == 1, -np.log(y_pred),\n",
    "                    -np.log(1 - y_pred))\n",
    "    return loss.mean()\n",
    "\n",
    "def func_numpy_metric(weights):\n",
    "    oof_blend = np.tensordot(weights, all_oof, axes=((0), (0)))\n",
    "    return log_loss_numpy(oof_blend, y_true)\n",
    "\n",
    "@njit\n",
    "def grad_func_jit(weights):\n",
    "    oof_clip = np.minimum(1 - 1e-15, np.maximum(all_oof, 1e-15))\n",
    "    gradients = np.zeros(all_oof.shape[0])\n",
    "    for i in range(all_oof.shape[0]):\n",
    "        a, b, c = y_true, oof_clip[i], np.zeros(\n",
    "            (all_oof.shape[1], all_oof.shape[2]))\n",
    "        for j in range(oof.shape[0]):\n",
    "            if j != i:\n",
    "                c += weights[j] * oof_clip[j]\n",
    "        gradients[i] = -np.mean(\n",
    "            (-a * b + (b**2) * weights[i] + b * c) /\n",
    "            ((b**2) *\n",
    "             (weights[i]**2) + 2 * b * c * weights[i] - b * weights[i] +\n",
    "             (c**2) - c))\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPE (Tree-structured Parzen Estimator) and Sequential Least Squares Programming (SLSQP)\n",
    "https://optuna.readthedocs.io/en/stable/reference/generated/optuna.samplers.TPESampler.html#optuna.samplers.TPESampler\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/optimize.minimize-slsqp.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_scripts(submission, weights=None, target_weights=None):\n",
    "    for i, (script, oof_filename, output_filename, weight) in enumerate(model_list):\n",
    "        print(f\"Generating submission file from {script} ......\")\n",
    "        infer_start = time.time()\n",
    "        !python {model_path}/{script}\n",
    "        infer_elapsed = time.time() - infer_start\n",
    "        print(f\"Time spent on inference: {infer_elapsed/60:.2f} minutes.\")\n",
    "\n",
    "        model_submit = pd.read_csv(output_filename, engine='c')\n",
    "        print(model_submit.head(5))\n",
    "        print(model_submit.shape)\n",
    "\n",
    "        if target_weights is not None:\n",
    "            for j, target in enumerate(train_classes):\n",
    "                print(f\"Blending {script} for {target} with weight: {optimized_target_weights[j][i]} ......\")\n",
    "                submission.iloc[:, j+1] += model_submit.iloc[:, j+1] * optimized_target_weights[j][i]\n",
    "        elif weights is None:\n",
    "            print(f\"Blending {script} with weight: {weight} ......\")\n",
    "            submission.iloc[:, 1:] += weight * model_submit.iloc[:, 1:]\n",
    "        else:\n",
    "            print(f\"Blending {script} with weight: {weights[i]} ......\")\n",
    "            submission.iloc[:, 1:] += weights[i] * model_submit.iloc[:, 1:]\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T16:08:00.401604Z",
     "iopub.status.busy": "2020-11-22T16:08:00.384877Z",
     "iopub.status.idle": "2020-11-22T16:30:58.239825Z",
     "shell.execute_reply": "2020-11-22T16:30:58.238616Z"
    },
    "papermill": {
     "duration": 1377.882267,
     "end_time": "2020-11-22T16:30:58.240001",
     "exception": false,
     "start_time": "2020-11-22T16:08:00.357734",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Scipy SLSQP]\n",
      "(5, 21948, 206)\n",
      "Loading OOF from ../../Github/kaggle_moa_team/oof/oof_2stageNN_ns_oldcv_10folds.npy ......\n",
      "OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/2stageNN_with_ns_oldcv_10folds.py: 0.015461\n",
      "\n",
      "Loading OOF from ../../Github/kaggle_moa_team/oof/oof_improving-mark-s-2-heads-model_0.015660083675738144.npy ......\n",
      "OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/improving-mark-s-2-heads-model-infer.py: 0.015660\n",
      "\n",
      "Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_efficientnet_lightning_v7_b3_0.01850.npy ......\n",
      "OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_efficientnet_lightning_v7_b3_infer.py: 0.016016\n",
      "\n",
      "Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_ResNeSt_v1_resnest50_0.014619621213185928.npy ......\n",
      "OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_resnest_lightning_v1_infer.py: 0.015819\n",
      "\n",
      "Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_ResNeSt_v2_resnest50_0.01854.npy ......\n",
      "OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_resnest_lightning_v2_infer.py: 0.015756\n",
      "\n",
      "Inital Blend OOF: 0.015130728735582452\n",
      "\n",
      "[Scipy SLSQP]\n",
      "[00:32] Optimised Blend OOF: 0.015107004167705938\n",
      "Optimised Weights: [0.36704255 0.0808577  0.17120266 0.10876667 0.27213043]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_start = time.time()\n",
    "\n",
    "if not search_mode and run_submit_script:\n",
    "    if method == \"scipy_per_target\":\n",
    "        weights_path = glob.glob(f'{model_path}/{study_name}_*.pkl')[0]\n",
    "        print(f\"Loading target-wise optimized weights from {weights_path} ......\")\n",
    "        optimized_target_weights = load_pickle(weights_path)\n",
    "\n",
    "        # For 206 target weights\n",
    "        submission = run_inference_scripts(\n",
    "            submission, target_weights=optimized_target_weights)\n",
    "    else:\n",
    "        submission = run_inference_scripts(submission)\n",
    "\n",
    "elif search_mode and method == \"CV\":\n",
    "    y_true = non_control_group_train_labels[train_classes].values\n",
    "\n",
    "    all_oof = np.zeros(\n",
    "        (len(model_list), non_control_group_train_labels.shape[0], 206))\n",
    "    blend_oof = np.zeros((non_control_group_train_labels.shape[0], 206))\n",
    "    print(all_oof.shape)\n",
    "    for i, (script, oof_filename, output_filename,\n",
    "            weight) in enumerate(model_list):\n",
    "        print(f\"Loading OOF from {oof_filename} ......\")\n",
    "        oof = np.load(f\"{dataset_folder}/{oof_filename}\")\n",
    "\n",
    "        if oof.shape[0] == 23814:\n",
    "            oof = oof[non_control_group_rows, :]\n",
    "\n",
    "        all_oof[i, :, :] = oof\n",
    "        blend_oof += oof * weight\n",
    "\n",
    "        oof_loss = mean_logloss(oof, y_true)\n",
    "        print(f\"OOF Validation Loss of {script}: {oof_loss:.6f}\\n\")\n",
    "\n",
    "    blend_oof_loss = mean_logloss(blend_oof, y_true)\n",
    "    print(f\"Blend OOF Validation Loss: {blend_oof_loss:.6f}\\n\")\n",
    "\n",
    "elif search_mode and method == \"optuna\":\n",
    "    print(\"[Optuna]\")\n",
    "    ## Search Best Blend Weights by Optuna ##\n",
    "    model_oofs = []\n",
    "\n",
    "    for i, (script, oof_filename, output_filename,\n",
    "            weight) in enumerate(model_list):\n",
    "        print(f\"Loading OOF from {oof_filename} ......\")\n",
    "        oof = np.load(f\"{dataset_folder}/{oof_filename}\")\n",
    "\n",
    "        if oof.shape[0] == 23814:\n",
    "            oof = oof[non_control_group_rows, :]\n",
    "\n",
    "        oof_loss = mean_logloss(\n",
    "            oof, non_control_group_train_labels[train_classes].values)\n",
    "        print(f\"OOF Validation Loss of {script}: {oof_loss:.6f}\\n\")\n",
    "        model_oofs.append(oof)\n",
    "\n",
    "    def objective(trial):\n",
    "        weights = []\n",
    "        for i in range(len(model_list)):\n",
    "            weights.append(trial.suggest_float(f\"w{i}\", 0, 1.0))\n",
    "\n",
    "        blend = np.zeros(model_oofs[0].shape)\n",
    "        for i in range(len(model_list)):\n",
    "            blend += weights[i] * model_oofs[i]\n",
    "        blend = np.clip(blend, 0, 1.0)\n",
    "\n",
    "        loss = mean_logloss(\n",
    "            blend, non_control_group_train_labels[train_classes].values)\n",
    "        return loss\n",
    "\n",
    "    pruner = optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=5,\n",
    "        n_warmup_steps=0,\n",
    "        interval_steps=1,\n",
    "    )\n",
    "    sampler = optuna.samplers.TPESampler(seed=rand_seed)\n",
    "    study = optuna.create_study(direction=\"minimize\",\n",
    "                                pruner=pruner,\n",
    "                                sampler=sampler,\n",
    "                                study_name=study_name,\n",
    "                                storage=f'sqlite:///{study_name}.db',\n",
    "                                load_if_exists=True)\n",
    "\n",
    "    study.optimize(objective,\n",
    "                   n_trials=n_trials,\n",
    "                   timeout=None,\n",
    "                   gc_after_trial=True,\n",
    "                   n_jobs=-1)\n",
    "\n",
    "    trial = study.best_trial\n",
    "\n",
    "    if run_submit_script:\n",
    "        optimal_weights = []\n",
    "        for i, (script, oof_filename, output_filename,\n",
    "                _) in enumerate(model_list):\n",
    "            optimal_weights.append(trial.params[f\"w{i}\"])\n",
    "        submission = run_inference_scripts(submission, weights=optimal_weights)\n",
    "\n",
    "    print(\"\\n[Optuna]\")\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "    print(\"Best trial:\")\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "elif search_mode and method == \"scipy\":\n",
    "    print(\"[Scipy SLSQP]\")\n",
    "    # Optimise Blending Weights with Bonus\n",
    "    # https://www.kaggle.com/gogo827jz/optimise-blending-weights-with-bonus-0/notebook\n",
    "    model_oofs = []\n",
    "    y_true = non_control_group_train_labels[train_classes].values\n",
    "\n",
    "    all_oof = np.zeros(\n",
    "        (len(model_list), non_control_group_train_labels.shape[0], 206))\n",
    "    print(all_oof.shape)\n",
    "    for i, (script, oof_filename, output_filename,\n",
    "            weight) in enumerate(model_list):\n",
    "        print(f\"Loading OOF from {oof_filename} ......\")\n",
    "        oof = np.load(f\"{dataset_folder}/{oof_filename}\")\n",
    "\n",
    "        if oof.shape[0] == 23814:\n",
    "            oof = oof[non_control_group_rows, :]\n",
    "\n",
    "        all_oof[i, :, :] = oof\n",
    "\n",
    "        oof_loss = mean_logloss(oof, y_true)\n",
    "        print(f\"OOF Validation Loss of {script}: {oof_loss:.6f}\\n\")\n",
    "        model_oofs.append(oof)\n",
    "\n",
    "    tol = 1e-10\n",
    "    init_guess = [1 / all_oof.shape[0]] * all_oof.shape[0]\n",
    "    bnds = [(0, 1) for _ in range(all_oof.shape[0])]\n",
    "    cons = {\n",
    "        'type': 'eq',\n",
    "        'fun': lambda x: np.sum(x) - 1,\n",
    "        'jac': lambda x: [1] * len(x)\n",
    "    }\n",
    "\n",
    "    print('Inital Blend OOF:', func_numpy_metric(init_guess))\n",
    "\n",
    "    start_time = time.time()\n",
    "    res_scipy = minimize(\n",
    "        fun=func_numpy_metric,\n",
    "        x0=init_guess,\n",
    "        method='SLSQP',\n",
    "        # jac=grad_func_jit,  # grad_func\n",
    "        bounds=bnds,\n",
    "        constraints=cons,\n",
    "        tol=tol)\n",
    "    print(\"\\n[Scipy SLSQP]\")\n",
    "    print(\n",
    "        f'[{str(datetime.timedelta(seconds = time.time() - start_time))[2:7]}] Optimised Blend OOF:',\n",
    "        res_scipy.fun)\n",
    "    print(f'Optimised Weights: {res_scipy.x}\\n')\n",
    "\n",
    "    if run_submit_script:\n",
    "        submission = run_inference_scripts(submission, weights=res_scipy.x)\n",
    "\n",
    "# Target-wise Weight Optimization #\n",
    "\n",
    "elif search_mode and method == \"scipy_per_target\":\n",
    "    print(\"[Scipy SLSQP]\")\n",
    "    # Optimise Blending Weights with Bonus\n",
    "    # https://www.kaggle.com/gogo827jz/optimise-blending-weights-with-bonus-0/notebook\n",
    "    model_oofs = []\n",
    "    y_true = non_control_group_train_labels[train_classes].values\n",
    "\n",
    "    all_oof = np.zeros(\n",
    "        (len(model_list), non_control_group_train_labels.shape[0], 206))\n",
    "    print(all_oof.shape)\n",
    "    for i, (script, oof_filename, output_filename,\n",
    "            weight) in enumerate(model_list):\n",
    "        print(f\"Loading OOF from {oof_filename} ......\")\n",
    "        oof = np.load(f\"{dataset_folder}/{oof_filename}\")\n",
    "\n",
    "        if oof.shape[0] == 23814:\n",
    "            oof = oof[non_control_group_rows, :]\n",
    "\n",
    "        all_oof[i, :, :] = oof\n",
    "\n",
    "        oof_loss = mean_logloss(oof, y_true)\n",
    "        print(f\"OOF Validation Loss of {script}: {oof_loss:.6f}\\n\")\n",
    "        model_oofs.append(oof)\n",
    "\n",
    "    print(\"\\n[Scipy SLSQP Per Target]\")\n",
    "    optimized_target_weights = []\n",
    "    for i, target in enumerate(train_classes):\n",
    "        tol = 1e-10\n",
    "        init_guess = [1 / all_oof.shape[0]] * all_oof.shape[0]\n",
    "        bnds = [(0, 1) for _ in range(all_oof.shape[0])]\n",
    "        cons = {\n",
    "            'type': 'eq',\n",
    "            'fun': lambda x: np.sum(x) - 1,\n",
    "            'jac': lambda x: [1] * len(x)\n",
    "        }\n",
    "\n",
    "        def func_numpy_metric_targes(weights):\n",
    "            oof_blend = np.tensordot(weights,\n",
    "                                     all_oof[:, :, i],\n",
    "                                     axes=((0), (0)))\n",
    "            return log_loss_numpy(oof_blend, y_true[:, i])\n",
    "\n",
    "        start_time = time.time()\n",
    "        res_scipy = minimize(\n",
    "            fun=func_numpy_metric_targes,\n",
    "            x0=init_guess,\n",
    "            method='SLSQP',\n",
    "            # jac=grad_func_jit,  # grad_func\n",
    "            bounds=bnds,\n",
    "            constraints=cons,\n",
    "            tol=tol)\n",
    "\n",
    "        print(\n",
    "            f'[{str(datetime.timedelta(seconds = time.time() - start_time))[2:7]}] ' + \\\n",
    "            f'Optimised Blend OOF for {target}:', res_scipy.fun)\n",
    "        print(f'Optimised Weights for {target}: {res_scipy.x}\\n')\n",
    "        optimized_target_weights.append(res_scipy.x)\n",
    "\n",
    "    blend_targets_oof = np.zeros(\n",
    "        (non_control_group_train_labels.shape[0], 206))\n",
    "    for i, (script, oof_filename, output_filename,\n",
    "            weight) in enumerate(model_list):\n",
    "        print(f\"Loading OOF from {oof_filename} ......\")\n",
    "        oof = np.load(f\"{dataset_folder}/{oof_filename}\")\n",
    "\n",
    "        if oof.shape[0] == 23814:\n",
    "            oof = oof[non_control_group_rows, :]\n",
    "\n",
    "        for j in range(206):\n",
    "            blend_targets_oof[:,\n",
    "                              j] += oof[:, j] * optimized_target_weights[j][i]\n",
    "\n",
    "        oof_loss = mean_logloss(oof, y_true)\n",
    "        print(f\"OOF Validation Loss of {script}: {oof_loss:.6f}\\n\")\n",
    "\n",
    "    blend_targets_oof_loss = mean_logloss(blend_targets_oof, y_true)\n",
    "    print(\n",
    "        f\"Blend Target-Wise OOF Validation Loss: {blend_targets_oof_loss:.6f}\\n\"\n",
    "    )\n",
    "\n",
    "    # Save optimized weights per target\n",
    "    save_pickle(optimized_target_weights, model_path,\n",
    "                f\"{study_name}_{blend_targets_oof_loss}\")\n",
    "\n",
    "    if run_submit_script:\n",
    "        # For 206 target weights\n",
    "        submission = run_inference_scripts(\n",
    "            submission, target_weights=optimized_target_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T16:30:58.766078Z",
     "iopub.status.busy": "2020-11-22T16:30:58.764325Z",
     "iopub.status.idle": "2020-11-22T16:30:58.782502Z",
     "shell.execute_reply": "2020-11-22T16:30:58.781733Z"
    },
    "papermill": {
     "duration": 0.268265,
     "end_time": "2020-11-22T16:30:58.782670",
     "exception": false,
     "start_time": "2020-11-22T16:30:58.514405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent: 0.56 minutes.\n"
     ]
    }
   ],
   "source": [
    "total_elapsed = time.time() - total_start\n",
    "print(f\"Total time spent: {total_elapsed/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [V7 - Improved 2heads, Removed SimpleNN]\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_2stageNN_ns_oldcv_10folds.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/2stageNN_with_ns_oldcv_10folds.py: 0.015461\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_improving-mark-s-2-heads-model_0.015660083675738144.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/improving-mark-s-2-heads-model-infer.py: 0.015660\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_efficientnet_lightning_v7_b3_0.01850.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_efficientnet_lightning_v7_b3_infer.py: 0.016016\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_ResNeSt_v1_resnest50_0.014619621213185928.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_resnest_lightning_v1_infer.py: 0.015819\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_ResNeSt_v2_resnest50_0.01854.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_resnest_lightning_v2_infer.py: 0.015756\n",
    "\n",
    "# [Scipy SLSQP]\n",
    "# [00:32] Optimised Blend OOF: 0.015107004167705938\n",
    "# Optimised Weights: [0.36704255 0.0808577  0.17120266 0.10876667 0.27213043]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [V7 - Improved 2heads, Mark's TabNet V2 Seeds]\n",
    "# [Optuna]\n",
    "# Number of finished trials: 3000\n",
    "# Best trial:\n",
    "#   Value: 0.015109516210552868\n",
    "#   Params: \n",
    "#     w0: 0.345350187040706\n",
    "#     w1: 0.018804585817609087\n",
    "#     w2: 0.09890095339659595\n",
    "#     w3: 0.15486138107425962\n",
    "#     w4: 0.1302653777195202\n",
    "#     w5: 0.24674004919729609\n",
    "#     w6: 0.00020099415280697705\n",
    "\n",
    "# [Scipy SLSQP]\n",
    "# [00:32] Optimised Blend OOF: 0.015107023232510362\n",
    "# Optimised Weights: [0.36394211 0.         0.08646557 0.17174434 0.1059386  0.27190938\n",
    "#  0.        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [V7 - without TabNet, Mark's 2heads, 10-folds 2StageNN and SimpleNN, ResNeSt V1]\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_2stageNN_ns_oldcv_10folds.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/2stageNN_with_ns_oldcv_10folds.py: 0.015461\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_NN_oldcv_10fold.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/script_simpleNN_oldcv_10folds.py: 0.015741\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_improving-mark-s-2-heads-model_0.015660083675738144.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/improving-mark-s-2-heads-model-infer.py: 0.015660\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_efficientnet_lightning_v7_b3_0.01850.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_efficientnet_lightning_v7_b3_infer.py: 0.016016\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_ResNeSt_v2_resnest50_0.01854.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_resnest_lightning_v2_infer.py: 0.015756\n",
    "\n",
    "# [Optuna]\n",
    "# Number of finished trials: 5000\n",
    "# Best trial:\n",
    "#   Value: 0.015118051559985067\n",
    "#   Params: \n",
    "#     w0: 0.3693123925185777\n",
    "#     w1: 0.0004358344602283515\n",
    "#     w2: 0.11986363820431883\n",
    "#     w3: 0.18219399304034917\n",
    "#     w4: 0.32927717286142916\n",
    "\n",
    "# [Scipy SLSQP]\n",
    "# [00:24] Optimised Blend OOF: 0.015117984713726062\n",
    "# Optimised Weights: [3.79183409e-01 8.13151629e-19 1.08023618e-01 1.86335277e-01\n",
    "#  3.26457696e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [V7 - without TabNet, Mark's 2heads, 10-folds 2StageNN and SimpleNN]\n",
    "# [Optuna]\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_2stageNN_ns_oldcv_10folds.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/2stageNN_with_ns_oldcv_10folds.py: 0.015461\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_NN_oldcv_10fold.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/script_simpleNN_oldcv.py: 0.015741\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_improving-mark-s-2-heads-model_0.015660083675738144.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/improving-mark-s-2-heads-model-infer.py: 0.015660\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_efficientnet_lightning_v7_b3_0.01850.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_efficientnet_lightning_v7_b3_infer.py: 0.016016\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_ResNeSt_v1_resnest50_0.014619621213185928.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_resnest_lightning_v1_infer.py: 0.015819\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_ResNeSt_v2_resnest50_0.01854.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_resnest_lightning_v2_infer.py: 0.015756\n",
    "\n",
    "# [Optuna]\n",
    "# Number of finished trials: 10000\n",
    "# Best trial:\n",
    "#   Value: 0.015107277135046551\n",
    "#   Params: \n",
    "#     w0: 0.36295047115403034\n",
    "#     w1: 0.00019665601658366993\n",
    "#     w2: 0.10383226438101152\n",
    "#     w3: 0.16907012564901389\n",
    "#     w4: 0.10211240990528128\n",
    "#     w5: 0.26308884808653726\n",
    "\n",
    "# [Scipy SLSQP]\n",
    "# [00:48] Optimised Blend OOF: 0.015107004381942337\n",
    "# Optimised Weights: [0.36727479 0.         0.08130163 0.17091322 0.10863643 0.27187394]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [V7 - without TabNet, Mark's 2heads]\n",
    "# [Optuna]\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_2stageNN_ns_oldcv.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/2stageNN_with_ns_oldcv.py: 0.015606\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_script_simpleNN_oldcv.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/script_simpleNN_oldcv.py: 0.015846\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_improving-mark-s-2-heads-model_0.015660083675738144.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/improving-mark-s-2-heads-model-infer.py: 0.015660\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_efficientnet_lightning_v7_b3_0.01850.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_efficientnet_lightning_v7_b3_infer.py: 0.016016\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_ResNeSt_v1_resnest50_0.014619621213185928.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_resnest_lightning_v1_infer.py: 0.015819\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_ResNeSt_v2_resnest50_0.01854.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_resnest_lightning_v2_infer.py: 0.015756\n",
    "\n",
    "# [Optuna]\n",
    "# Number of finished trials: 10000\n",
    "# Best trial:\n",
    "#   Value: 0.015146055466812214\n",
    "#   Params: \n",
    "#     w0: 0.2590485239176548\n",
    "#     w1: 0.033637086725830254\n",
    "#     w2: 0.12194872432858535\n",
    "#     w3: 0.19075874431151257\n",
    "#     w4: 0.11084230101870868\n",
    "#     w5: 0.28295491196215444\n",
    "\n",
    "# [Scipy SLSQP]\n",
    "# [00:30] Optimised Blend OOF: 0.01514578929579469\n",
    "# Optimised Weights: [0.25256016 0.03296526 0.13166163 0.18166774 0.11849445 0.28265076]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [V7 - without TabNet]\n",
    "# [Optuna]\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_2stageNN_ns_oldcv.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/2stageNN_with_ns_oldcv.py: 0.015606\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_script_simpleNN_oldcv.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/script_simpleNN_oldcv.py: 0.015846\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_fork-of-2heads-looper-super-puper-markpeng.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/fork-of-2heads-looper-super-puper-markpeng-infer.py: 0.015887\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_improving-mark-s-2-heads-model_0.015660083675738144.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/improving-mark-s-2-heads-model-infer.py: 0.015660\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_efficientnet_lightning_v7_b3_0.01850.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_efficientnet_lightning_v7_b3_infer.py: 0.016016\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_ResNeSt_v1_resnest50_0.014619621213185928.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_resnest_lightning_v1_infer.py: 0.015819\n",
    "\n",
    "# Loading OOF from ../../Github/kaggle_moa_team/oof/oof_deepinsight_ResNeSt_v2_resnest50_0.01854.npy ......\n",
    "# OOF Validation Loss of ../../Github/kaggle_moa_team/scripts/deepinsight_resnest_lightning_v2_infer.py: 0.015756\n",
    "\n",
    "# Number of finished trials: 10000\n",
    "# Best trial:\n",
    "#   Value: 0.015146827058312776\n",
    "#   Params: \n",
    "#     w0: 0.2507759947969869\n",
    "#     w1: 0.03339376719044784\n",
    "#     w2: 8.528382280836113e-05\n",
    "#     w3: 0.11625864567289637\n",
    "#     w4: 0.18770116032490702\n",
    "#     w5: 0.09530145379465743\n",
    "#     w6: 0.3164264877487286\n",
    "\n",
    "# [Scipy SLSQP]\n",
    "# [00:45] Optimised Blend OOF: 0.015145788791365362\n",
    "# Optimised Weights: [2.52672054e-01 3.32734786e-02 1.05430191e-17 1.30957268e-01\n",
    "#  1.82060938e-01 1.18387855e-01 2.82648406e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [V6 - without TabNet, 2heads]\n",
    "# Total time spent: 0.68 minutes.\n",
    "# Blend Target-Wise OOF Validation Loss: 0.015044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [V6 - without TabNet, 2heads]\n",
    "# [Optuna]\n",
    "# Number of finished trials: 3000\n",
    "# Best trial:\n",
    "#   Value: 0.015171999561900233\n",
    "#   Params: \n",
    "#     w0: 0.323528084383917\n",
    "#     w1: 0.08786476491118465\n",
    "#     w2: 0.21849845883367852\n",
    "#     w3: 0.3704230222796271\n",
    "\n",
    "# [Scipy SLSQP]\n",
    "# [00:22] Optimised Blend OOF: 0.015172004593585666\n",
    "# Optimised Weights: [0.32020133 0.09043987 0.22122948 0.36812932]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [V6 - without TabNet]\n",
    "# [Optuna]\n",
    "# Number of finished trials: 3000\n",
    "# Best trial:\n",
    "#   Value: 0.015172424601530761\n",
    "#   Params: \n",
    "#     w0: 0.3138176484100186\n",
    "#     w1: 0.07850519440561339\n",
    "#     w2: 0.0007183363099561991\n",
    "#     w3: 0.23849563017967007\n",
    "#     w4: 0.3694870328388392\n",
    "\n",
    "# [Scipy SLSQP]\n",
    "# [00:21] Optimised Blend OOF: 0.015172004898867827\n",
    "# Optimised Weights: [0.32045559 0.09026525 0.         0.22069638 0.36858278]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [V6]\n",
    "# [Optuna]\n",
    "# Number of finished trials: 5000\n",
    "# Best trial:\n",
    "#   Value: 0.015173437622007157\n",
    "#   Params: \n",
    "#     w0: 0.30923325055652684\n",
    "#     w1: 0.09831493504786226\n",
    "#     w2: 0.018966959973949222\n",
    "#     w3: 0.19863369862866234\n",
    "#     w4: 0.0013224625996093413\n",
    "#     w5: 0.3728865483320761\n",
    "\n",
    "# [Scipy SLSQP]\n",
    "# [00:36] Optimised Blend OOF: 0.015172005464591968\n",
    "# Optimised Weights: [3.20472642e-01 9.01191588e-02 1.78893358e-18 2.20448482e-01\n",
    "#  3.27971157e-18 3.68959717e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [V5]\n",
    "# Number of finished trials: 3000\n",
    "# Best trial:\n",
    "#   Value: 0.015344701181290615\n",
    "#   Params: \n",
    "#     w0: 0.5141433844379889\n",
    "#     w1: 0.11747776562133813\n",
    "#     w2: 0.3668324643717302\n",
    "\n",
    "# [00:14] Optimised Blend OOF: 0.015344695215068541\n",
    "# Optimised Weights: [0.51922623 0.11292509 0.36784869]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [V4]\n",
    "# [Optuna]\n",
    "# Number of finished trials: 3000\n",
    "# Best trial:\n",
    "#   Value: 0.015331901615194453\n",
    "#   Params: \n",
    "#     w0: 0.4505928450756189\n",
    "#     w1: 0.13010257032841785\n",
    "#     w2: 0.06308933354044946\n",
    "#     w3: 0.35639153615958885\n",
    "#\n",
    "# [Scipy]\n",
    "# [00:23] Optimised Blend OOF: 0.015331777381591449\n",
    "# Optimised Weights: [0.44090106 0.14508641 0.05945655 0.35455598]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [V3]\n",
    "# improving-mark-s-2-heads-model-infer\n",
    "# Number of finished trials: 3000\n",
    "# Best trial:\n",
    "#   Value: 0.01515466145873492\n",
    "#   Params: \n",
    "#     w0: 0.0002980690037490555\n",
    "#     w1: 0.29771381784976886\n",
    "#     w2: 0.1569191862042946\n",
    "#     w3: 0.18156875605872544\n",
    "#     w4: 0.36371774630338105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [V3]\n",
    "# fork-of-2heads-looper-super-puper-markpeng-infer\n",
    "# Number of finished trials: 3000\n",
    "# Best trial:\n",
    "#   Value: 0.015170138066049686\n",
    "#   Params: \n",
    "#     w0: 0.00019903389488299251\n",
    "#     w1: 0.3853752127955825\n",
    "#     w2: 0.015968332256452233\n",
    "#     w3: 0.22945916769823432\n",
    "#     w4: 0.3711290150522236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if search_mode and method == \"scipy_per_target\":\n",
    "    # OOF scores per target\n",
    "    target_oof_losses = []\n",
    "    for i, target in enumerate(train_classes):\n",
    "        print(target)\n",
    "        # print(y_true[:, i])\n",
    "\n",
    "        oof_loss = mean_logloss(blend_targets_oof[:, i], y_true[:, i])\n",
    "        target_oof_losses.append(oof_loss)\n",
    "        print(f\"Blend OOF Validation Loss of {target}: {oof_loss:.6f}\\n\")\n",
    "\n",
    "    target_loss_df = pd.DataFrame(\n",
    "        data={\n",
    "            \"target\": train_classes,\n",
    "            \"oof_logloss\": target_oof_losses\n",
    "        },\n",
    "        columns=[\"target\", \"oof_logloss\"\n",
    "                 ]).sort_values(by=\"oof_logloss\",\n",
    "                                ascending=False).reset_index(drop=True)\n",
    "    print(target_loss_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T16:31:00.729455Z",
     "iopub.status.busy": "2020-11-22T16:31:00.728462Z",
     "iopub.status.idle": "2020-11-22T16:31:00.766500Z",
     "shell.execute_reply": "2020-11-22T16:31:00.767046Z"
    },
    "papermill": {
     "duration": 0.294364,
     "end_time": "2020-11-22T16:31:00.767175",
     "exception": false,
     "start_time": "2020-11-22T16:31:00.472811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if run_submit_script:\n",
    "    print(submission.shape)\n",
    "    print(submission)\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.239792,
     "end_time": "2020-11-22T16:31:03.876454",
     "exception": false,
     "start_time": "2020-11-22T16:31:03.636662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T16:31:04.372710Z",
     "iopub.status.busy": "2020-11-22T16:31:04.371600Z",
     "iopub.status.idle": "2020-11-22T16:31:05.717376Z",
     "shell.execute_reply": "2020-11-22T16:31:05.716504Z"
    },
    "papermill": {
     "duration": 1.595866,
     "end_time": "2020-11-22T16:31:05.717490",
     "exception": false,
     "start_time": "2020-11-22T16:31:04.121624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if kernel_mode:\n",
    "    !rm ./*.py\n",
    "    !ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.243405,
     "end_time": "2020-11-22T16:31:06.199770",
     "exception": false,
     "start_time": "2020-11-22T16:31:05.956365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 1402.82753,
   "end_time": "2020-11-22T16:31:06.568888",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-22T16:07:43.741358",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
